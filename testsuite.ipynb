{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gzip\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as sci\n",
    "import scipy.stats as scs\n",
    "import scipy.optimize as sco\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.colors import LogNorm\n",
    "from astropy.time import Time as astrotime\n",
    "\n",
    "from tdepps.utils import (make_rate_records, rebin_rate_rec,\n",
    "                          get_pixel_in_sigma_region,interval_overlap,\n",
    "                          make_spl_edges, fit_spl_to_hist, arr2str,\n",
    "                          power_law_flux, dict_map, fill_dict_defaults,\n",
    "                          make_src_records, make_src_records)\n",
    "from tdepps.grb import GRBLLH, GRBModel, MultiGRBLLH\n",
    "from tdepps.grb import (SignalFluenceInjector, UniformTimeSampler,\n",
    "                        HealpySignalFluenceInjector,\n",
    "                        TimeDecDependentBGDataInjector)\n",
    "from tdepps.grb import MultiBGDataInjector, MultiSignalFluenceInjector\n",
    "import tdepps.grb.analysis as GRBAna\n",
    "from tdepps.grb import SinusFixedConstRateFunction\n",
    "import tdepps.utils.phys as phys\n",
    "import tdepps.utils.stats as stats\n",
    "\n",
    "from mypyscripts.stats import sigma2prob, prob2sigma\n",
    "\n",
    "from _loader import loader as LOADER\n",
    "from _paths import PATHS_ORIG as PATHS  # Use the original 22 HESE sources\n",
    "import _plots as plots\n",
    "\n",
    "# Make some globals\n",
    "SECINDAY = 24. * 60. * 60.\n",
    "RNDGEN = np.random.RandomState(42439462)\n",
    "loader = LOADER(PATHS, verb=False)\n",
    "\n",
    "print(\"Started: \", astrotime.now())\n",
    "print(\"Paths are:\\n\", PATHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Pre-loading stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make a local source list version with adapted paths, only when an updated version from cobalt is fetched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from _loader import _change_local_src_map_paths\n",
    "_change_local_src_map_paths(PATHS.local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Reload stuff mini example:\n",
    "\n",
    "```Python\n",
    "# GRBLLHAnalysis was loaded with: from tdepps.grb import GRBLLHAnalysis\n",
    "import tdepps.grb.analysis as ANA\n",
    "reload(ANA)\n",
    "GRBLLHAnalysis = ANA.GRBLLHAnalysis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Single sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**TODO**\n",
    "Put all plots for single samples in the multi sample part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Load sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check loaders for available names\n",
    "tw_id = 10\n",
    "sample_name = \"IC86_2012-2014\"  # IC79, IC86_2011, IC86_2012-2014, IC86_2015\n",
    "\n",
    "dt0, dt1 = loader.time_window_loader(tw_id)\n",
    "srcs = loader.source_list_loader(sample_name)\n",
    "runlist_dict = loader.runlist_loader(sample_name)\n",
    "\n",
    "# Data\n",
    "exp_off_dict = loader.off_data_loader(sample_name)\n",
    "exp_on_dict = loader.on_data_loader(sample_name)\n",
    "mc_dict = loader.mc_loader(sample_name)\n",
    "\n",
    "# Process to other formats\n",
    "exp_off = exp_off_dict[sample_name]\n",
    "exp_on = exp_on_dict[sample_name]\n",
    "mc = mc_dict[sample_name]\n",
    "srcs_rec = make_src_records(srcs[sample_name], dt0=dt0, dt1=dt1)\n",
    "runlist = runlist_dict[sample_name]\n",
    "rate_recs = make_rate_records(exp_off[\"Run\"], run_list=runlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Setup models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Binning\n",
    "# Finer resolution around the horizon region, where we usually switch the event\n",
    "# selections from northern to southern samples\n",
    "hor = np.sin(np.deg2rad(30))\n",
    "sindec_bins = np.unique(np.concatenate([\n",
    "                        np.linspace(-1., -hor, 3 + 1),    # south\n",
    "                        np.linspace(-hor, +hor, 14 + 1),  # horizon\n",
    "                        np.linspace(+hor, 1., 3 + 1),     # north\n",
    "                        ]))\n",
    "nbins = 12 if not sample_name == \"IC86_2012-2014\" else 3 * 12\n",
    "rate_rebins = np.linspace(np.amin(exp_off[\"time\"]),\n",
    "                          np.amax(exp_off[\"time\"]), nbins)\n",
    "\n",
    "logE_bins = np.linspace(np.floor(np.amin(mc[\"logE\"])),\n",
    "                        np.ceil(np.amax(mc[\"logE\"])), 30)\n",
    "\n",
    "def flux_model(trueE):\n",
    "    return power_law_flux(trueE, gamma=2.19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build and fit bg injector\n",
    "# Choose spl_s so that the spline sticks a little more to the data\n",
    "bg_inj_opts = {\"sindec_bins\": sindec_bins, \"rate_rebins\": rate_rebins,\n",
    "               \"spl_s\": len(sindec_bins) // 2, \"n_scan_bins\": 25}\n",
    "bg_inj = TimeDecDependentBGDataInjector(inj_opts=bg_inj_opts,\n",
    "                                        random_state=RNDGEN)\n",
    "bg_inj.fit(X=exp_off, srcs=srcs_rec, run_list=runlist)\n",
    "bg_inj_opts = bg_inj.inj_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Build and fit sig injector\n",
    "sig_inj_opts = {\"mode\": \"band\", \"sindec_inj_width\": 0.035,\n",
    "                \"dec_range\": np.array([-np.pi / 2., np.pi / 2.])}\n",
    "time_sam = UniformTimeSampler(random_state=None)\n",
    "sig_inj = SignalFluenceInjector(flux_model=flux_model, time_sampler=time_sam,\n",
    "                                inj_opts=sig_inj_opts)\n",
    "sig_inj.fit(srcs_rec, MC=mc)\n",
    "sig_inj_opts = sig_inj.inj_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build and fit llh model\n",
    "mod_spatial_opts = dict(bg_inj_opts.items(), select_ev_sigma=5., kent=True)\n",
    "\n",
    "# Test signal weightes, if gammas are same, then ratio is 1 everywhere\n",
    "# mc_bg_w = MC_[\"ow\"] * power_law_flux(MC_[\"trueE\"], gamma=2.19)\n",
    "mc_bg_w = None\n",
    "\n",
    "mod_energy_opts = {\"bins\": [sindec_bins, logE_bins],\n",
    "                   \"flux_model\": flux_model, \"mc_bg_w\": mc_bg_w,\n",
    "                   \"force_logE_asc\": True, \"edge_fillval\": \"minmax_col\",\n",
    "                   \"interp_col_log\": False}\n",
    "grb_mod = GRBModel(X=exp_off, MC=mc, srcs=srcs_rec, run_list=runlist,\n",
    "                   spatial_opts=mod_spatial_opts,\n",
    "                   energy_opts=mod_energy_opts)\n",
    "llh = GRBLLH(llh_model=grb_mod, llh_opts=None)\n",
    "llh_opts = llh.llh_opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ana = GRBAna.GRBLLHAnalysis(llh, bg_inj, sig_inj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_plot(folder, fname, **savefig_args):\n",
    "    \"\"\" Checks existence of save folder and saves current figure.\"\"\"\n",
    "    dpi = savefig_args.pop(\"dpi\", 200)\n",
    "    bbox_inches = savefig_args.pop(\"bbox_inches\", \"tight\")\n",
    "    outp = os.path.join(PATHS.plots, folder)\n",
    "    if not os.path.isdir(outp):\n",
    "        os.makedirs(outp)\n",
    "    plt.tight_layout()\n",
    "    fname = os.path.join(outp, fname)\n",
    "    plt.savefig(fname, dpi=dpi, bbox_inches=bbox_inches, **savefig_args)\n",
    "    print(\"Saved plot to:\\n  {}\".format(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Split on/off data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_name = \"IC79\"\n",
    "# Load all data for comparison\n",
    "name2skylab = {\n",
    "    \"IC79\" : \"IC79b_exp.npy\",\n",
    "    \"IC86_2011\" : \"IC86_exp.npy\",\n",
    "    \"IC86_2012-2014\" : [\"IC86-2012_exp_v2.npy\",\n",
    "                        \"IC86-2013_exp_v2.npy\",\n",
    "                        \"IC86-2014_exp_v2.npy\"],\n",
    "    \"IC86_2015\" : \"SplineMPEmax.MuEx.IC86-2015.npy\",\n",
    "}\n",
    "if isinstance(name2skylab[sample_name], list):\n",
    "    _files = [os.path.join(PATHS.skylab_data, n) for n\n",
    "              in name2skylab[sample_name]]\n",
    "    _exp = np.concatenate([np.load(n) for n in _files])\n",
    "else:\n",
    "    _exp = np.load(os.path.join(PATHS.skylab_data, name2skylab[sample_name]))\n",
    "    \n",
    "_ev_t_all = _exp[::10][\"time\"]\n",
    "_ev_t_off = exp_off[::10][\"time\"]\n",
    "_ev_t_on = exp_on[::10][\"time\"]\n",
    "# Load largest window to show borders\n",
    "dt0_max, dt1_max = loader.time_window_loader(-1)\n",
    "\n",
    "for i, t in enumerate(srcs_rec[\"time\"]):\n",
    "    plt.vlines(_ev_t_all, 0, 1, colors=\"C7\", label=\"all\")\n",
    "    plt.vlines(_ev_t_off, 1, 2, colors=\"C1\", label=\"off time\")\n",
    "    plt.vlines(_ev_t_on, 1.2, 1.8, colors=\"C0\", label=\"on time\")\n",
    "\n",
    "    plt.axhline(1, 0, 1, ls=\"-\", c=\"k\")\n",
    "    plt.axvline(t, 0, 1, ls=\"-\", c=\"k\", label=\"src time\")\n",
    "    plt.axvline(t + dt0_max / SECINDAY, 0, 1, ls=\"--\", c=\"k\")\n",
    "    plt.axvline(t + dt1_max / SECINDAY, 0, 1, ls=\"--\", c=\"k\")\n",
    "    \n",
    "    plt.xlim(t + 2 * dt0 / SECINDAY, t + 2 * dt1 / SECINDAY)\n",
    "    \n",
    "    plt.xlabel(\"MJD\")\n",
    "    plt.ylabel(\"MJD\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Show all off data again, hard to see but global\n",
    "plt.vlines(exp_off[\"time\"][::100], 0, 1)\n",
    "\n",
    "plt.vlines(srcs_rec[\"time\"] + dt0_max / SECINDAY, 0, 1, linestyles=\"--\",\n",
    "           colors=\"C0\")\n",
    "plt.vlines(srcs_rec[\"time\"] + dt0_max / SECINDAY, 0, 1, linestyles=\"--\",\n",
    "           colors=\"C0\")\n",
    "\n",
    "plt.xlabel(\"MJD\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Filtered HESE events in MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Manually load all data and recreate LLH model with new MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_hese_from_mc(mc, heseids):\n",
    "    \"\"\"\n",
    "    Mask all values in ``mc`` that have the same run and event ID combination\n",
    "    as in ``heseids``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mc : record-array\n",
    "        Needs names ``'Run', 'Event'``.\n",
    "    heseids : dict or record-array\n",
    "        Needs names / keys ``'run_id', 'event_id``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    is_hese_mask : array-like, shape (len(mc),)\n",
    "        Mask: ``True`` if for each event in ``mc`` that is HESE like.\n",
    "    \"\"\"\n",
    "    # Make combined IDs to easily match against HESE IDs with `np.isin`\n",
    "    factor_mc = 10**np.ceil(np.log10(np.amax(mc[\"Event\"])))\n",
    "    _evids = np.atleast_1d(heseids[\"event_id\"])\n",
    "    factor_hese = 10**np.ceil(np.log10(np.amax(_evids)))\n",
    "    factor = max(factor_mc, factor_hese)\n",
    "\n",
    "    combined_mcids = (factor * mc[\"Run\"] + mc[\"Event\"]).astype(int)\n",
    "    assert np.all(combined_mcids > factor)  # Is int overflow a thing here?\n",
    "\n",
    "    _runids = np.atleast_1d(heseids[\"run_id\"])\n",
    "    combined_heseids = (factor * _runids + _evids).astype(int)\n",
    "    assert np.all(combined_heseids > factor)\n",
    "\n",
    "    # Check which MC event is tagged as HESE like\n",
    "    is_hese_mask = np.isin(combined_mcids, combined_heseids)\n",
    "    print(\"  Found {} / {} HESE like events in MC\".format(np.sum(is_hese_mask),\n",
    "                                                          len(mc)))\n",
    "    return is_hese_mask\n",
    "\n",
    "\n",
    "name2skylab = {\n",
    "    \"IC79\" : \"IC79b_corrected_MC.npy\",\n",
    "    \"IC86_2011\" : \"IC86_corrected_MC.npy\",\n",
    "    \"IC86_2012-2014\" : \"IC86-2012_corrected_MC_v2.npy\",\n",
    "    \"IC86_2015\" : \"SplineMPEmax.MuEx.MC.npy\",\n",
    "}\n",
    "name2idx = {\n",
    "    \"IC79\" : \"IC79.json.gz\",\n",
    "    \"IC86_2011\" : \"IC86_2011.json.gz\",\n",
    "    \"IC86_2012-2014\" : \"IC86-2012-2015.json.gz\",\n",
    "    \"IC86_2015\" : \"IC86-2012-2015.json.gz\",    \n",
    "}\n",
    "\n",
    "# Load full skylab data\n",
    "_mc = np.load(os.path.join(PATHS.skylab_data, name2skylab[sample_name]))\n",
    "\n",
    "# Filter HESE events\n",
    "_path = os.path.join(PATHS.local, \"check_hese_mc_ids\", name2idx[sample_name])\n",
    "heseids = json.load(gzip.open(_path))\n",
    "is_hese_mask = remove_hese_from_mc(_mc, heseids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot filtered out HESE events\n",
    "_mc_hese = _mc[is_hese_mask]\n",
    "_mc_no_hese = _mc[~is_hese_mask]\n",
    "\n",
    "w_hese = _mc_hese[\"ow\"] * power_law_flux(_mc_hese[\"ow\"], gamma=2.19)\n",
    "w_no_hese = _mc_no_hese[\"ow\"] * power_law_flux(_mc_no_hese[\"ow\"], gamma=2.19)\n",
    "\n",
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "h, bx, by, img = axl.hist2d(np.sin(_mc_no_hese[\"dec\"]),\n",
    "                            np.log10(_mc_no_hese[\"trueE\"]),\n",
    "                            bins=50, norm=LogNorm(), cmap=\"inferno\",\n",
    "                            weights=w_no_hese)\n",
    "fig.colorbar(img, ax=axl)\n",
    "_, _, _, img = axr.hist2d(np.sin(_mc_hese[\"dec\"]), np.log10(_mc_hese[\"trueE\"]),\n",
    "                          bins=[bx, by], norm=LogNorm(), cmap=\"inferno\",\n",
    "                          weights=w_hese, vmax=np.amax(h))\n",
    "fig.colorbar(img, ax=axr)\n",
    "axl.set_title(\"No HESE\")\n",
    "axr.set_title(\"Only HESE like\")\n",
    "plt.show()\n",
    "\n",
    "_, b, _ = plt.hist(np.log10(_mc[\"trueE\"]), bins=50, alpha=0.5,\n",
    "                   density=False, label=\"All\",\n",
    "                   weights=_mc[\"ow\"] * power_law_flux(_mc[\"ow\"], gamma=2.19))\n",
    "_ = plt.hist(np.log10(_mc_hese[\"trueE\"]), bins=b, alpha=0.5,\n",
    "             density=False, label=\"Only HESE like\",\n",
    "             weights=_mc_hese[\"ow\"] * power_law_flux(_mc_hese[\"ow\"],\n",
    "                                                     gamma=2.19))\n",
    "plt.yscale(\"log\", nonposy=\"clip\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Rate allsky model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Redo the allsky rate fit for testing\n",
    "recs = make_rate_records(T=exp_[\"time\"], run_dict=run_dict_)\n",
    "rates, new_bins, stddev, _ = rebin_rate_rec(rate_rec=recs, bins=rate_rebins,\n",
    "                                     ignore_zero_runs=True)\n",
    "mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "\n",
    "rate_func = SinusFixedConstRateFunction(p_fix=365.)\n",
    "allsky_res = rate_func.fit(rate=rates, srcs=srcs_, t=mids, w=1. / stddev)\n",
    "\n",
    "t0_fix = allsky_res.x[1]\n",
    "print(\"Best fit t0 before first event: \",\n",
    "      t0_fix - exp_[\"time\"].min(), \"days\")\n",
    "\n",
    "rate_func = SinusFixedConstRateFunction(p_fix=365., t0_fix=t0_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### BG splines and sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show build spline models for timedependent injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100)\n",
    "bins = bg_inj_opts[\"sindec_bins\"]\n",
    "mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "allsky_pars = bg_inj._spl_info[\"allsky_best_params\"]\n",
    "print(\"Allsky best params: \" + arr2str(allsky_pars))\n",
    "\n",
    "TEST = False\n",
    "\n",
    "for n in [\"amp\", \"base\"]:\n",
    "    spl = bg_inj._spl_info[\"param_splines\"][n]\n",
    "    vals = np.copy(bg_inj._spl_info[\"best_pars_norm\"][n])\n",
    "    err = np.copy(bg_inj._spl_info[\"best_stddevs_norm\"][n])\n",
    "         \n",
    "    # Quickly switch smoothing for testing\n",
    "    if TEST:\n",
    "        w = 1. / err\n",
    "        vals_, pts_, w = make_spl_edges(vals=vals, bins=sindec_bins, w=w)\n",
    "        stop = False\n",
    "        s_ = bg_inj_opts[\"spl_s\"]\n",
    "        spl_ = sci.UnivariateSpline(pts_, vals_, w=w, s=s_)\n",
    "        _last_max_der2 = np.amax(np.abs(spl_.derivative(n=2)(x)))\n",
    "        _last_down = False\n",
    "        print(\"Start with: \", s_, _last_down, _last_max_der2)\n",
    "        i = 0\n",
    "        while not stop and i < 50:\n",
    "            spl_ = sci.UnivariateSpline(pts_, vals_, w=w, s=s_)\n",
    "            norm_ = (allsky_pars[0] if n == \"amp\" else allsky_pars[-1])\n",
    "\n",
    "            spl2_ = spl_.derivative(n=2)\n",
    "            _der2 = np.abs(spl2_(x))\n",
    "            stop = np.all(_der2 < 1.)\n",
    "            if not stop:\n",
    "                print(\"  Current: \", _last_down, _last_max_der2)\n",
    "                _max_der2_cur = np.amax(_der2)\n",
    "                if (_last_max_der2 <= _max_der2_cur) and not _last_down:\n",
    "                    s_ *=  0.8\n",
    "                    _last_down = True\n",
    "                    print(\"Going down. 2nd derivative was \",\n",
    "                          _max_der2_cur, \" New : \", s_, _last_down)\n",
    "                elif (_last_max_der2 <= _max_der2_cur) and _last_down:\n",
    "                    s_ *=  1.2\n",
    "                    _last_down = False\n",
    "                    print(\"Going up. 2nd derivative was \",\n",
    "                          _max_der2_cur, \" New : \", s_, _last_down)\n",
    "                elif _last_down:\n",
    "                    s_ *=  0.8\n",
    "                    print(\"Going down. 2nd derivative was \",\n",
    "                          _max_der2_cur)\n",
    "                else:\n",
    "                    s_ *=  1.2\n",
    "                    print(\"Going up. 2nd derivative was \",\n",
    "                          _max_der2_cur)\n",
    "                _last_max_der2 = _max_der2_cur\n",
    "            i += 1\n",
    "#                 plt.plot(x, spl_(x), color=\"C0\", ls=\"--\")\n",
    "#                 plt.show()\n",
    "        print(\"Finish: \", s_)\n",
    "        if i == 50:\n",
    "            print(\"Reached maxiter\")\n",
    "\n",
    "        # Renorm to allsky for comparison\n",
    "        scale_ = norm_ / spl_.integral(-1, 1)\n",
    "   \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(x, spl(x), color=\"k\")\n",
    "    ax.plot(mids, vals, color=\"C7\", ls=\"--\")\n",
    "    ax.errorbar(mids, vals, yerr=err, fmt=\"o\", color=\"C1\")\n",
    "    \n",
    "    if n == \"amp\":\n",
    "        ax.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "    else:\n",
    "        ax.set_ylim(0, None)\n",
    "\n",
    "    ax.set_xlabel(\"sindec\")\n",
    "    ax.set_ylabel(n)\n",
    "    ax.set_title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "    # Show sindec bin borders\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.vlines(sindec_bins, ylim[0], ylim[1],\n",
    "               linestyles=\":\", colors=\"C7\")\n",
    "    ylim = ax.set_ylim(ylim)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Compare hist to allsky model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 200)\n",
    "bins = 100\n",
    "plt.vlines(sindec_bins, 0, 1, linestyles=\"--\", colors=\"C7\", zorder=-1)\n",
    "plt.hist(np.sin(exp_off[\"dec\"]), bins=bins, density=True)\n",
    "plt.plot(x, bg_inj._spl_info[\"data_sin_dec_pdf_spline\"](x))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make multiple trials and concat to compare to spline with large stats.\n",
    "Use internal debug var to get samples per source to compare to splines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrcs = len(bg_inj.srcs)\n",
    "sam = [list() for _ in range(nsrcs)]\n",
    "nsamples = 1000\n",
    "for _ in range(nsamples):\n",
    "    sami = bg_inj.sample(debug=True)\n",
    "    src_idx = bg_inj._sample_idx[\"src_idx\"]\n",
    "    for j in range(nsrcs):\n",
    "        sam[j].append(sami[src_idx == j])\n",
    "        \n",
    "sam = [np.concatenate(sami) for sami in sam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# These should match closely\n",
    "print(map(lambda spl: spl.integral(-1, 1),\n",
    "          bg_inj._spl_info[\"sin_dec_splines\"]))\n",
    "print(bg_inj._nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 200)\n",
    "bins = bg_inj_opts[\"sindec_bins\"]\n",
    "bins = np.linspace(-1, 1, 40)\n",
    "for j, sami in enumerate(sam):\n",
    "    plt.vlines(sindec_bins, 0, 1, linestyles=\"--\", colors=\"C7\", zorder=-1)\n",
    "    # Plot allyear sample for comparison\n",
    "    plt.hist(np.sin(exp_off[\"dec\"]), bins=bins, density=True, color=\"0.75\")\n",
    "    plt.plot(x, bg_inj._spl_info[\"data_sin_dec_pdf_spline\"](x),\n",
    "             color=\"C0\", ls=\":\", lw=3)\n",
    "    # Drawn sample per source. Red hist should approx. follow black spline\n",
    "    # It doesnt here because we need to make the allsky bg spline follow the\n",
    "    # data as close as possbile, but we chose sindec spliens so that didn't work\n",
    "#     plt.hist(np.sin(sami[\"dec\"]), bins=bins, density=True,\n",
    "#              histtype=\"step\", lw=2.5, color=\"C3\")\n",
    "    plt.plot(x, bg_inj._spl_info[\"sin_dec_pdf_splines\"][j](x), color=\"k\")\n",
    "    plt.xlabel(\"sin dec\")\n",
    "    plt.ylabel(\"PDF\")\n",
    "    plt.title(\"{}. Source {:02d}\".format(sample_name, j))\n",
    "    \n",
    "#     save_plot(os.path.join(\"bg_injector\", \"sindec_splines\"),\n",
    "#               \"{}_src_{:02d}.png\".format(sample_name, j))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show sampling weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pts = np.sin(exp_off[\"dec\"])\n",
    "idx = np.argsort(pts)\n",
    "pts = pts[idx]\n",
    "\n",
    "for j, w in enumerate(bg_inj._spl_info[\"sample_weights\"]):\n",
    "    plt.plot(pts, w[idx])\n",
    "\n",
    "plt.axhline(1, 0, 1, c=\"k\")\n",
    "plt.xlabel(\"sin dec\")\n",
    "plt.ylabel(\"Sample weights\")\n",
    "plt.title(\"{}\".format(sample_name))\n",
    "\n",
    "save_plot(os.path.join(\"bg_injector\", \"sindec_splines\"),\n",
    "          \"{}_sample_weights.png\".format(sample_name))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### MC Injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Testing signal injector\n",
    "sam = sig_inj.sample(n_samples=10000)\n",
    "idx = sig_inj._sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sampled MC hist\n",
    "for name in [\"ra\", \"dec\", \"logE\", \"time\", \"sigma\"]:\n",
    "    # Show sampled data-like attributes\n",
    "    if name != \"time\":\n",
    "        # Compare to full MC pool distribution\n",
    "        w = sig_inj._MC[\"ow\"] * sig_inj.flux_model(sig_inj._MC[\"trueE\"])\n",
    "        _ = plt.hist(sig_inj._MC[name], weights=w, density=True, bins=100,\n",
    "                     alpha=.5)\n",
    "        _ = plt.hist(sam[name], density=True, bins=100, histtype=\"step\", lw=3)\n",
    "    if name in [\"ra\", \"dec\"]:\n",
    "        plt.vlines(sig_inj.srcs[name], 0, 1)\n",
    "        plt.yscale(\"log\", nonposy=\"clip\")\n",
    "    if name == \"time\":\n",
    "        ts = sig_inj.srcs[\"time\"]\n",
    "        dt0s, dt1s = sig_inj.srcs[\"dt0\"], sig_inj.srcs[\"dt1\"]\n",
    "        for j in range(len(ts)):\n",
    "            plt.title(\"{}. {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "                name, ts[j], dt0s[j], dt1s[j]))\n",
    "            mask = (idx[\"src_idx\"] == j)\n",
    "            trel = (ts[j] - sam[name][mask]) * SECINDAY\n",
    "            _ = plt.hist(trel, density=False, bins=100,\n",
    "                         histtype=\"step\", lw=3)\n",
    "            plt.axvline(0, 0, 1)\n",
    "            plt.axvline(dt0s[j], 0, 1, ls=\"--\")\n",
    "            plt.axvline(dt1s[j], 0, 1, ls=\"--\")\n",
    "            plt.show()\n",
    "    else:\n",
    "        plt.title(name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show sindec distribution used for sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(np.sin(mc[\"trueDec\"]), bins=np.linspace(-1, 1, 100),\n",
    "                weights=mc[\"ow\"] * flux_model(mc[\"trueE\"]))\n",
    "\n",
    "for srci in srcs_rec:\n",
    "    plt.axvline(np.sin(srci[\"dec\"]), 0, 1, ls=\"--\", c=\"k\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show injected event positions and full weighted MC distribtuion together with spline used to get src weights.\n",
    "Relativ number of injected events should scatter around the spline which models the expected injection.\n",
    "If injection bands are too broad they may start to differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sample a bit more for better stats\n",
    "nsamples = 10000\n",
    "_Xsig = sig_inj.sample(n_samples=nsamples)\n",
    "_src_idx = sig_inj._sample_idx[\"src_idx\"]\n",
    "\n",
    "bins = grb_mod._spatial_opts[\"sindec_bins\"]\n",
    "mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "lo, hi = bins[0], bins[-1]\n",
    "\n",
    "# Make signal distribution from which is sampled\n",
    "w_sig = mc[\"ow\"] * flux_model(mc[\"trueE\"])\n",
    "sindec = np.sin(mc[\"trueDec\"])\n",
    "hist, _ = np.histogram(sindec, bins=sindec_bins, weights=w_sig)\n",
    "var, _ = np.histogram(sindec, bins=sindec_bins, weights=w_sig**2)\n",
    "dA = np.diff(bins)\n",
    "hist = hist / dA\n",
    "stddev = np.sqrt(var) / dA\n",
    "\n",
    "# Normalize hist as injection weights: sum w = 1. Get weights from src weights\n",
    "src_w = grb_mod.get_args()[\"src_w_dec\"]\n",
    "norm = np.sum(src_w)\n",
    "spl = grb_mod._spl_info[\"mc_sin_dec_pdf_spline\"]\n",
    "hist = hist / norm\n",
    "stddev = stddev / norm\n",
    "\n",
    "# Plot the spline and the histogram\n",
    "x = np.linspace(lo, hi, 250)\n",
    "plt.plot(bins, np.r_[hist[0], hist], drawstyle=\"steps-pre\", color=\"C7\")\n",
    "plt.errorbar(mids, hist, yerr=stddev, fmt=\",\", color=\"C7\")\n",
    "plt.plot(x, spl(x) / norm)\n",
    "\n",
    "for j, srci in enumerate(sig_inj.srcs):\n",
    "    # Plot source positions in dec\n",
    "    plt.axvline(np.sin(srci[\"dec\"]), 0, 1, ls=\"--\", c=\"C7\")\n",
    "    # Plot relativ number of sampled events per src\n",
    "    m = (_src_idx == j)\n",
    "    nsam = np.sum(m) / len(m)\n",
    "    nsam_err = np.sqrt(np.sum(m)) / len(m)\n",
    "    plt.errorbar(np.sin(srci[\"dec\"]), nsam, yerr=nsam_err,\n",
    "                 fmt=\"o\", c=\"C{}\".format(j), zorder=5, alpha=1.)\n",
    "    # Plot 1D scatter of sampled events per source\n",
    "    plt.vlines(np.sin(_Xsig[m][\"dec\"]), -0.15 * np.amax(hist), 0.,\n",
    "               linestyles=\"-\", colors=\"C{}\".format(j), alpha=0.1)\n",
    "    # Plot expected relativ event numbers (spline values)\n",
    "    plt.plot(np.sin(srci[\"dec\"]), src_w[j] / norm, c=\"C{}\".format(j),\n",
    "             marker=\"d\", ls=\"\", mec=\"k\", zorder=6)\n",
    "\n",
    "    plt.axhline(0, 0, 1, c=\"k\", ls=\"-\")\n",
    "    \n",
    "plt.ylim(-0.15 * np.amax(hist), None)\n",
    "plt.title(sample_name)\n",
    "\n",
    "# plt.savefig(\"/Users/tmenne/Downloads/mc_inject_expect_\" +\n",
    "#             \"{}_nsam={}.png\".format(sample_name, nsamples), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### LLH model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sample some data and get soverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Xbg = bg_inj.sample()\n",
    "Xsig = sig_inj.sample(n_samples=20)\n",
    "X = np.concatenate((Xbg, Xsig))\n",
    "\n",
    "bg_idx = bg_inj._sample_idx[\"src_idx\"]\n",
    "sig_idx = sig_inj._sample_idx[\"src_idx\"]\n",
    "src_idx = np.concatenate((bg_idx, sig_idx))\n",
    "\n",
    "dec_mask = grb_mod._select_X(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show the band selection effect (only dec band selection for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsig = grb_mod._spatial_opts[\"select_ev_sigma\"]\n",
    "\n",
    "# Scatter all, highlight selected events per src\n",
    "plt.scatter(X[\"ra\"], X[\"dec\"], s=100*np.rad2deg(X[\"sigma\"]), color=\"C7\",\n",
    "            alpha=.5)\n",
    "for j, m in enumerate(dec_mask):\n",
    "    plt.scatter(X[m][\"ra\"], X[m][\"dec\"], s=10*np.rad2deg(X[m][\"sigma\"]),\n",
    "                color=\"C{}\".format(j))\n",
    "    plt.scatter(srcs_rec[j][\"ra\"], srcs_rec[j][\"dec\"], color=\"C{}\".format(j),\n",
    "                marker=\"*\", edgecolor=\"k\", linewidth=1, s=100)\n",
    "plt.xlim(0, 2 * np.pi)\n",
    "plt.ylim(-np.pi / 2, np.pi / 2)\n",
    "plt.xlabel(\"ra\")\n",
    "plt.ylabel(\"dec\")\n",
    "plt.show()\n",
    "\n",
    "# Plot all that made the selection\n",
    "if tw_id < 16:\n",
    "    for j, srci in enumerate(grb_mod.srcs):\n",
    "        # Combining the masks show not all selected, because an injected event\n",
    "        # can of course show up for a different src, especially in BG\n",
    "        # m = (src_idx == j) & dec_mask[j]\n",
    "        # This simply show, if the global dec band selection is working\n",
    "        m = dec_mask[j]\n",
    "        los = X[\"dec\"][m] - nsig * X[m][\"sigma\"]\n",
    "        his = X[\"dec\"][m] + nsig * X[m][\"sigma\"]\n",
    "        for i, (lo, hi) in enumerate(zip(los, his)):\n",
    "            plt.fill_between([lo, hi], [i, i], [i+1, i+1], alpha=.25,\n",
    "                             color=\"C{}\".format(j))\n",
    "            plt.vlines(X[\"dec\"][m][i], i, i+1, color=\"C{}\".format(j),\n",
    "                       linestyles=\"-\")\n",
    "        plt.axvline(srci[\"dec\"], 0, 1, color=\"C{}\".format(j), ls=\"--\",\n",
    "                    label=\"src {}\".format(j))\n",
    "    plt.xlabel(\"dec\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Events that made the selection\")\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping midlle plot with too many events...\")\n",
    "    \n",
    "# And all that didn't (only if there aren't so many events, takes too long)\n",
    "if tw_id < 16:\n",
    "    mask = np.any(dec_mask, axis=0)\n",
    "    los = X[\"dec\"][~mask] - nsig * X[~mask][\"sigma\"]\n",
    "    his = X[\"dec\"][~mask] + nsig * X[~mask][\"sigma\"]\n",
    "    for j, (lo, hi) in enumerate(zip(los, his)):\n",
    "        plt.fill_between([lo, hi], [j, j], [j+1, j+1], alpha=.25, color=\"C3\")\n",
    "        plt.vlines(X[\"dec\"][~mask][j], j, j+1, color=\"C3\")\n",
    "    for j, srci in enumerate(grb_mod.srcs):\n",
    "        plt.axvline(srci[\"dec\"], 0, 1, color=\"C{}\".format(j),\n",
    "                    ls=\"--\", label=\"src {}\".format(j))\n",
    "    plt.xlabel(\"dec\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Events that didn't make the selection\")\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping last plot with too many events...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Here we combine both masks to show selected events, that also belong to a\n",
    "# specific source by the time selection. That's why there might be no events\n",
    "# here, even if they were shown in the plot above.\n",
    "for j in range(len(grb_mod.srcs)):\n",
    "    _bg = Xbg[\"time\"][bg_idx == j]\n",
    "    _sig = Xsig[\"time\"][sig_idx == j] \n",
    "    _src = grb_mod.srcs[j][\"time\"]\n",
    "\n",
    "    trel_bg = (_bg - _src) * SECINDAY\n",
    "    trel_sig = (_sig - _src) * SECINDAY\n",
    "\n",
    "    plt.vlines(trel_bg, 0, 1, color=\"C{}\".format(j), linestyles=\":\")\n",
    "    plt.vlines(trel_sig, 0, 1, color=\"k\", linestyles=\"-\")\n",
    "\n",
    "    plt.axvline(0, 0, 1, ls=\"-\", c=\"C7\")\n",
    "    plt.axvline(srci[\"dt0\"], 0, 1, ls=\"-\", c=\"C7\")\n",
    "    plt.axvline(srci[\"dt1\"], 0, 1, ls=\"-\", c=\"C7\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get sob and scatter non zero sobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sob = grb_mod.get_soverb(X)\n",
    "\n",
    "# Prepare X same as done in get_soverb\n",
    "X_ = X[np.any(dec_mask, axis=0)]\n",
    "\n",
    "for j, sobi in enumerate(sob):\n",
    "    m = (src_idx == j) & dec_mask[j]\n",
    "    plt.scatter(X[m][\"ra\"], X[m][\"dec\"], color=\"C{}\".format(j), alpha=.25)\n",
    "    \n",
    "    m = (sobi > .1)\n",
    "    plt.scatter(X_[m][\"ra\"], X_[m][\"dec\"], color=\"C{}\".format(j), marker=\"d\",\n",
    "                edgecolor=\"k\")\n",
    "    plt.scatter(srcs_rec[j][\"ra\"], srcs_rec[j][\"dec\"], marker=\"*\", color=\"k\")\n",
    "    \n",
    "plt.xlabel(\"ra\")\n",
    "plt.ylabel(\"dec\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For all events, show energy and spatial contribution separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sob = grb_mod.get_soverb(X)\n",
    "\n",
    "# Prepare X same as done in get_soverb\n",
    "X_ = X[np.any(dec_mask, axis=0)]\n",
    "\n",
    "for j, sobi in enumerate(sob):\n",
    "    m = (src_idx == j) & dec_mask[j]\n",
    "    plt.hist(X[m][\"logE\"], bins=20, density=True, color=\"C{}\".format(j))\n",
    "    \n",
    "    m = (sobi > .1)\n",
    "    for logEi in X_[m][\"logE\"]:\n",
    "        plt.axvline(logEi, 0, 1, ls=\"--\", color=\"k\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sob = grb_mod.get_soverb(X)\n",
    "\n",
    "# Prepare X same as done in get_soverb\n",
    "X_ = X[np.any(dec_mask, axis=0)]\n",
    "\n",
    "soverb_spatial = grb_mod._soverb_spatial(X_[\"ra\"], np.sin(X_[\"dec\"]),\n",
    "                                         X_[\"sigma\"]).sum(axis=0)\n",
    "soverb_energy = grb_mod._soverb_energy(np.sin(X_[\"dec\"]), X_[\"logE\"])\n",
    "   \n",
    "for srci in srcs_rec:\n",
    "    plt.axvline(srci[\"dec\"], 0, 1, ls=\"--\", c=\"k\")\n",
    "\n",
    "    sort_idx = np.argsort(X_[\"dec\"])\n",
    "plt.plot(np.sin(X_[\"dec\"])[sort_idx], soverb_spatial[sort_idx])\n",
    "plt.plot(np.sin(X_[\"dec\"])[sort_idx], soverb_energy[sort_idx])\n",
    "\n",
    "plt.yscale(\"log\", nonposy=\"clip\")\n",
    "plt.ylim(1e-3, None)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show energy PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xbins = grb_mod.energy_opts[\"bins\"][0]\n",
    "ybins = grb_mod.energy_opts[\"bins\"][1]\n",
    "\n",
    "xlo, xhi = np.amin(xbins), np.amax(xbins)\n",
    "ylo, yhi = np.amin(ybins), np.amax(ybins)\n",
    "\n",
    "x = np.linspace(xlo, xhi, 250)\n",
    "y = np.linspace(ylo, yhi, 250)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "xmids, ymids = map(lambda b: 0.5 * (b[:-1] + b[1:]), [x, y])\n",
    "XX, YY = map(np.ravel, np.meshgrid(xmids, ymids))\n",
    "pts = np.vstack((XX, YY)).T\n",
    "\n",
    "# zz = grb_mod._energy_interpol(pts)\n",
    "zz = grb_mod._soverb_energy(XX, YY)\n",
    "zz = zz.reshape(len(xmids), len(ymids))\n",
    "\n",
    "plt.pcolormesh(xx, yy, np.log10(zz), cmap=\"coolwarm\", vmin=-3, vmax=3)\n",
    "cbar = plt.colorbar()\n",
    "\n",
    "cbar.set_label(\"log10(S/B)\")\n",
    "plt.xlabel(\"sin(dec)\")\n",
    "plt.ylabel(\"log10(MuEx / GeV)\")\n",
    "plt.title(sample_name)\n",
    "\n",
    "# plt.savefig(\"/Users/tmenne/Downloads/IC86I_energy.png\", dpi=150)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show spatial BG splines and allyear data histogram for each source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins = grb_mod._spatial_opts[\"sindec_bins\"]\n",
    "lo, hi = np.amin(bins), np.amax(bins)\n",
    "x = np.linspace(lo, hi, 250)\n",
    "\n",
    "# Normalize allyear data to PDF on a sphere\n",
    "h, b = np.histogram(np.sin(exp_off[\"dec\"]), bins=100, range=[lo, hi],\n",
    "                    density=False)\n",
    "mids = 0.5 * (b[:-1] + b[1:])\n",
    "norm = np.sum(h) * np.diff(b) * 2. * np.pi\n",
    "hn = h / norm\n",
    "errn = np.sqrt(h) / norm\n",
    "\n",
    "# Show data hist\n",
    "plt.plot(b, np.r_[hn[0], hn], color=\"C0\", drawstyle=\"steps-pre\")\n",
    "plt.errorbar(mids, hn, fmt=\",\", color=\"C0\")\n",
    "\n",
    "# Show allyear data spline (normalized to ra, sindec PDF)\n",
    "# Need to steal from the inj, with the same settings, illustration only\n",
    "plt.plot(x, bg_inj._spl_info[\"data_sin_dec_pdf_spline\"](x) / 2. / np.pi,\n",
    "         color=\"k\", ls=\"--\")\n",
    "\n",
    "for j, srci in enumerate(grb_mod.srcs):\n",
    "    spl = grb_mod._spatial_bg_spls[j]\n",
    "    plt.plot(x, spl(x), c=\"C{}\".format((j + 1) % 9),\n",
    "             label=\"src {}\".format(j + 1))\n",
    "    int_ = spl.integral(-1, 1) * 2. * np.pi\n",
    "    plt.title(\"Integral over ra, sindec: {:.2f}\".format(int_))\n",
    "    \n",
    "plt.axvline(lo, 0, 1, ls=\"-\", color=\"C7\")\n",
    "plt.axvline(hi, 0, 1, ls=\"-\", color=\"C7\")\n",
    "plt.ylim(0, None)\n",
    "plt.legend(loc=\"best\", ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Set new time window.\n",
    "Redo the spline plot and check the LLH args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_bg_spline_plot(grb_mod, exp_off, title):\n",
    "    bins = grb_mod._spatial_opts[\"sindec_bins\"]\n",
    "    lo, hi = np.amin(bins), np.amax(bins)\n",
    "    x = np.linspace(lo, hi, 250)\n",
    "\n",
    "    # Normalize allyear data to PDF on a sphere\n",
    "    h, b = np.histogram(np.sin(exp_off[\"dec\"]), bins=100, range=[lo, hi],\n",
    "                        density=False)\n",
    "    mids = 0.5 * (b[:-1] + b[1:])\n",
    "    norm = np.sum(h) * np.diff(b) * 2. * np.pi\n",
    "    hn = h / norm\n",
    "    errn = np.sqrt(h) / norm\n",
    "\n",
    "    # Show data hist\n",
    "    plt.plot(b, np.r_[hn[0], hn], color=\"C7\", drawstyle=\"steps-pre\", alpha=.5)\n",
    "    plt.errorbar(mids, hn, fmt=\",\", color=\"C7\", alpha=.5)\n",
    "\n",
    "    for j, srci in enumerate(grb_mod.srcs):\n",
    "        spl = grb_mod._spatial_bg_spls[j]\n",
    "        plt.plot(x, spl(x), c=\"C{}\".format(j + 1), label=\"src {}\".format(j + 1))\n",
    "        int_ = spl.integral(-1, 1) * 2. * np.pi\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.axvline(lo, 0, 1, ls=\"-\", color=\"C7\")\n",
    "    plt.axvline(hi, 0, 1, ls=\"-\", color=\"C7\")\n",
    "    plt.ylim(0, None)\n",
    "    plt.legend(loc=\"best\", ncol=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Show old settings\n",
    "print(\"Original settings:\")\n",
    "print(dt0, dt1)\n",
    "print(arr2str(grb_mod.get_args()[\"nb\"], fmt=\"{:.2f}\"))\n",
    "make_bg_spline_plot(grb_mod, exp_off, \"Original: tw = {}\".format(tw_id))\n",
    "\n",
    "# Make new\n",
    "new_tw = 5  # tw5 is approx. tw20 / 1e4 -> Rate should be equally lower\n",
    "new_dt0, new_dt1 = loader.time_window_loader(new_tw)\n",
    "scale = ((new_dt1 - new_dt0) / (dt1 - dt0))[0]\n",
    "grb_mod.set_new_srcs_dt(new_dt0[0], new_dt1[0])\n",
    "print(\"New settings:\")\n",
    "print(\"Rate scale factor: {:.2g}\".format(scale))\n",
    "print(grb_mod.srcs[\"dt0\"])\n",
    "print(grb_mod.srcs[\"dt1\"])\n",
    "print(grb_mod.get_args()[\"nb\"])\n",
    "print(\"Scaled up rates: {}\".format(\n",
    "    arr2str(grb_mod.get_args()[\"nb\"] / scale, fmt=\"{:.2f}\")))\n",
    "make_bg_spline_plot(grb_mod, exp_off, \"New: tw = {}\".format(new_tw))\n",
    "\n",
    "# Make really large windows to see the effect on the splines\n",
    "new_dt0, new_dt1 = 100 * dt0, 100 * dt1\n",
    "scale = ((new_dt1 - new_dt0) / (dt1 - dt0))[0]\n",
    "grb_mod.set_new_srcs_dt(new_dt0[0], new_dt1[0])\n",
    "print(\"New settings:\")\n",
    "print(\"Rate scale factor: {:.2g}\".format(scale))\n",
    "print(grb_mod.srcs[\"dt0\"])\n",
    "print(grb_mod.srcs[\"dt1\"])\n",
    "print(grb_mod.get_args()[\"nb\"])\n",
    "make_bg_spline_plot(grb_mod, exp_off, \"New: dt = {}s\".format(2 * new_dt1[0]))\n",
    "\n",
    "# Reset\n",
    "_dt0, _dt1 = loader.time_window_loader(tw_id)\n",
    "grb_mod.set_new_srcs_dt(_dt0[0], dt1[0])\n",
    "make_bg_spline_plot(grb_mod, exp_off, \"Reset: tw = {}\".format(tw_id))\n",
    "print(\"Reset settings:\")\n",
    "print(grb_mod.srcs[\"dt0\"])\n",
    "print(grb_mod.srcs[\"dt1\"])\n",
    "print(arr2str(grb_mod.get_args()[\"nb\"], fmt=\"{:.2f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### LLH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Xbg = bg_inj.sample()\n",
    "nsig = 1\n",
    "Xsig = sig_inj.sample(n_samples=nsig)\n",
    "X = np.concatenate((Xbg, Xsig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sample some data and get the LLH values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "llh_args = llh.model.get_args()\n",
    "for key, val in llh_args.items():\n",
    "    print(\"{:11s}: {}\".format(key, arr2str(val, fmt=\"{:5.2f}\")))\n",
    "    \n",
    "print(\"Weights are normed: \", np.isclose(\n",
    "    np.sum(llh._src_w_over_nb * llh_args[\"nb\"][:, None]), 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make a quick LLH scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ts, grad = [], []\n",
    "ns = np.linspace(0, max(5, 5 * nsig), 500)\n",
    "for nsi in ns:\n",
    "    tsi, gradi = llh.lnllh_ratio(ns=nsi, X=X)\n",
    "    ts.append(tsi)\n",
    "    grad.append(gradi)\n",
    "    \n",
    "plt.plot(ns, ts, label=\"TS\", color=\"C0\")\n",
    "plt.plot(ns, grad, label=\"grad\", color=\"C3\")\n",
    "plt.plot(0.5 * (ns[:-1] + ns[1:]), np.diff(ts) / np.diff(ns), ls=\":\",\n",
    "         color=\"k\", label=\"numgrad\")\n",
    "\n",
    "plt.axhline(0, 0, 1, ls=\"-\", c=\"C7\")\n",
    "plt.axvline(0, 0, 1, ls=\"-\", c=\"C7\")\n",
    "plt.axvline(nsig, 0, 1, ls=\"-.\", c=\"C2\", label=\"n signal\")\n",
    "\n",
    "plt.xlabel(\"ns\")\n",
    "plt.ylabel(\"ts\")\n",
    "plt.legend()\n",
    "\n",
    "plt.ylim(min(-4, -2. * np.amax(ts)), max(1., 2. * np.amax(ts)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test if band selection in model effectively doesn't change the LLH values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_nsig = 5\n",
    "ntrials = 100\n",
    "\n",
    "# Set additional sob cuts in the LLH\n",
    "_rel, _abs = 0., 0.\n",
    "llh._llh_opts[\"sob_abs_eps\"] = _abs\n",
    "llh._llh_opts[\"sob_rel_eps\"] = _rel\n",
    "\n",
    "ts_all = np.empty(ntrials, dtype=float)\n",
    "ts_sel = np.empty(ntrials, dtype=float)\n",
    "ts_all_fit = np.empty(ntrials, dtype=float)\n",
    "ts_sel_fit = np.empty(ntrials, dtype=float)\n",
    "ns_all_fit = np.empty(ntrials, dtype=float)\n",
    "ns_sel_fit = np.empty(ntrials, dtype=float)\n",
    "\n",
    "for i in range(ntrials):\n",
    "    # Make a new set of data\n",
    "    _Xbg = bg_inj.sample()\n",
    "    _Xsig = sig_inj.sample(n_samples=_nsig)\n",
    "    _X = np.concatenate((_Xbg, _Xsig))\n",
    "    \n",
    "    # First using all events\n",
    "    ts_all[i], _ = llh.lnllh_ratio(ns=_nsig, X=_X, band_select=False)\n",
    "    ns_all_fit[i], ts_all_fit[i] = llh.fit_lnllh_ratio(ns0=_nsig, X=_X,\n",
    "                                                       band_select=False)\n",
    "    \n",
    "    # Now same data with band selection\n",
    "    ts_sel[i], _ = llh.lnllh_ratio(ns=_nsig, X=_X, band_select=True)\n",
    "    ns_sel_fit[i], ts_sel_fit[i] = llh.fit_lnllh_ratio(ns0=_nsig, X=_X,\n",
    "                                                       band_select=False)\n",
    "    \n",
    "\n",
    "_, (axl, axr) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "# Show difference in fixed ns evaluation\n",
    "diff_fixed = ts_all - ts_sel\n",
    "axl.plot(diff_fixed)\n",
    "axl.set_title(\"sob cuts: abs = {:.3g}, rel = {:.3g}.\".format(_abs, _rel))\n",
    "axl.set_yscale(\"log\", nonposy=\"clip\")\n",
    "axl.set_ylabel(\"diff\")\n",
    "\n",
    "# Show difference but with fitted ns each time\n",
    "diff_fitted = ts_all_fit - ts_sel_fit\n",
    "axr.plot(diff_fitted)\n",
    "axr.set_title(\"All fitted diffs zero: {}\".format(np.allclose(\n",
    "    diff_fitted, 0.)))\n",
    "axr.set_ylabel(\"diff\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show fitted values, where fixed eval had differences\n",
    "m = (diff_fitted > 0.)\n",
    "print(arr2str(ns_all_fit[m], fmt=\"{:6.5f}\"))\n",
    "print(arr2str(ts_all_fit[m], fmt=\"{:6.5f}\"))\n",
    "print(arr2str(ns_sel_fit[m], fmt=\"{:6.5f}\"))\n",
    "print(arr2str(ts_sel_fit[m], fmt=\"{:6.5f}\"))\n",
    "\n",
    "# Reset model\n",
    "for name in [\"sob_abs_eps\", \"sob_rel_eps\"]:\n",
    "    llh._llh_opts[name] = llh_opts[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Do the same, but when a diff occurs, scan the LLH\n",
    "def scan_llh(llh, X, nsig):\n",
    "    ns = np.linspace(0, max(5, 5 * nsig), 500)\n",
    "    ts_all, ts_sel = np.empty(500), np.empty(500)\n",
    "    for i, nsi in enumerate(ns):\n",
    "        ts_all[i], _ = llh.lnllh_ratio(ns=nsi, X=X, band_select=False)\n",
    "        ts_sel[i], _ = llh.lnllh_ratio(ns=nsi, X=X, band_select=True)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[4, 1])\n",
    "    axb = fig.add_subplot(gs[1])\n",
    "    axt = fig.add_subplot(gs[0])\n",
    "    _ = axt.set_xticklabels(axt.get_xticklabels(), visible=False)\n",
    "        \n",
    "    axt.plot(ns, ts_all, label=\"All\", color=\"C3\")\n",
    "    axt.plot(ns, ts_sel, label=\"Sel\", color=\"k\", ls=\":\")\n",
    "    axb.plot(ns, ts_all - ts_sel, label=\"Diff\", color=\"C7\", ls=\"-\")\n",
    "\n",
    "    axt.axhline(0, 0, 1, ls=\"-\", c=\"C7\")\n",
    "    axt.axvline(0, 0, 1, ls=\"-\", c=\"C7\")\n",
    "    axt.axvline(nsig, 0, 1, ls=\"-.\", c=\"C2\", label=\"n signal\")\n",
    "\n",
    "    axb.set_xlabel(\"ns\")\n",
    "    axb.set_ylabel(\"diff\")\n",
    "    axt.set_ylabel(\"ts\")\n",
    "    axt.legend(loc=\"best\")\n",
    "    axt.set_title(\"sob cuts: abs = {:.3g}, rel = {:.3g}.\".format(_abs, _rel))\n",
    "    axt.set_ylim(min(-4, -2. * np.amax(ts_all)),\n",
    "                 max(1., 2. * np.amax(ts_all)))\n",
    "    plt.show()\n",
    "\n",
    "_nsig = 5\n",
    "ntrials_max = 1000\n",
    "\n",
    "# Set additional sob cuts in the LLH\n",
    "_rel, _abs = 0., 0.\n",
    "llh._llh_opts[\"sob_abs_eps\"] = _abs\n",
    "llh._llh_opts[\"sob_rel_eps\"] = _rel\n",
    "\n",
    "# Change selection sigma, for small values the difference is large, as expected\n",
    "llh.model._spatial_opts[\"select_ev_sigma\"] = 5\n",
    "\n",
    "# Do trials but show at most 3 scan plots\n",
    "i = 0\n",
    "nscans, nscans_max = 0, 5\n",
    "while nscans < nscans_max and i < ntrials_max:\n",
    "    # Make a new set of data\n",
    "    _Xbg = bg_inj.sample()\n",
    "    _Xsig = sig_inj.sample(n_samples=_nsig)\n",
    "    _X = np.concatenate((_Xbg, _Xsig))\n",
    "    \n",
    "    # First using all events\n",
    "    ts_all, grad_all = llh.lnllh_ratio(ns=_nsig, X=_X, band_select=False)\n",
    "    \n",
    "    # Now same data with band selection\n",
    "    ts_sel, grad_sel = llh.lnllh_ratio(ns=_nsig, X=_X, band_select=True)\n",
    "\n",
    "    if ts_all - ts_sel != 0.:\n",
    "        print(\"Scanning LLH for trial {:d}\".format(i))\n",
    "        # Plot scan for current X once with band select, once without\n",
    "        scan_llh(llh, _X, _nsig)\n",
    "        nscans += 1\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "print(\"Done after {} trials\".format(i))\n",
    "\n",
    "# Reset model and LLH\n",
    "for name in [\"sob_abs_eps\", \"sob_rel_eps\"]:\n",
    "    llh._llh_opts[name] = llh_opts[name]\n",
    "    \n",
    "llh.model._spatial_opts[\"select_ev_sigma\"] = mod_spatial_opts[\"select_ev_sigma\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Timing tests**\n",
    "\n",
    "- tw00: 1e5 trials in ~ 8.2s -> ~12150 trials / sec\n",
    "- tw10: 1e4 trials in ~ 5.3s -> ~ 1850 trials / sec\n",
    "- tw20: 1e4 trials in ~83.0s -> ~  120 trials / sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "n_trials = int(1e3)\n",
    "n_signal = 0.\n",
    "trials, nzeros, nsig = ana.do_trials(n_trials=n_trials, n_signal=n_signal,\n",
    "                                     ns0=1., poisson=True, full_out=True)\n",
    "\n",
    "ns, ts = trials[\"ns\"], trials[\"ts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = \"ts\"\n",
    "var = trials[name]\n",
    "bins = np.arange(0, max(1, np.amax(var)) + 0.25, 0.25)\n",
    "\n",
    "h = plt.hist(var, bins=bins, density=True, color=\"C0\", alpha=0.5)[0]\n",
    "if name == \"ns\":\n",
    "    plt.axvline(n_signal, 0, 1, ls=\"--\", color=\"k\")\n",
    "\n",
    "plt.yscale(\"log\", nonposy=\"clip\")\n",
    "plt.xlabel(name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### TEST: Fixate x,y ratio hist edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Similar to make_spl_edges, but just repeat the outermost values.\n",
    "We have the full bin range covered with the interpolator, without introducing artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "rndgen = np.random.RandomState(3242342)\n",
    "x = rndgen.uniform(0, 1, size=1000)\n",
    "y = rndgen.uniform(0, 1, size=1000)\n",
    "\n",
    "bx = np.linspace(0, 1, 6)\n",
    "by = np.linspace(0, 1, 11)\n",
    "bxm, bym = map(lambda b: 0.5 * (b[:-1] + b[1:]), [bx, by])\n",
    "\n",
    "print(h.shape)\n",
    "print(len(bx))\n",
    "print(len(by))\n",
    "\n",
    "h = plt.hist2d(x, y, bins=[bx, by], normed=True)[0]\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Repeat outermost values, first in all cols, then the rows\n",
    "h_ext = np.zeros((len(bxm) + 2, len(bym) + 2), dtype=h.dtype) - 1.\n",
    "for j, col in enumerate(h):\n",
    "    h_ext[j+1] = np.concatenate([col[[0]], col, col[[-1]]])\n",
    "h_ext[0] = h_ext[1]\n",
    "h_ext[-1] = h_ext[-2]\n",
    "pts_x = np.concatenate((bx[[0]], bxm, bx[[-1]]))\n",
    "pts_y = np.concatenate((by[[0]], bym, by[[-1]]))\n",
    "\n",
    "print(h_ext.shape)\n",
    "print(len(pts_x))\n",
    "print(len(pts_y))\n",
    "\n",
    "# Orignal bins\n",
    "xx, yy = np.meshgrid(bx, by)\n",
    "# Original bin mids\n",
    "xxm, yym = np.meshgrid(bxm, bym)\n",
    "# New grid points from bin mids\n",
    "xxg, yyg = np.meshgrid(pts_x, pts_y)\n",
    "\n",
    "# Plot original hist again\n",
    "plt.pcolormesh(xx, yy, h.T)\n",
    "plt.colorbar()\n",
    "# Plot original bin edges, bin mids and new pts for the interpolator\n",
    "plt.scatter(xx, yy, marker=\"o\", color=\"C3\", s=50)\n",
    "plt.scatter(xxm, yym, marker=\"o\", color=\"w\", s=50)\n",
    "plt.scatter(xxg, yyg, marker=\".\", color=\"k\")\n",
    "plt.show()\n",
    "\n",
    "# Plot rows and cols of the new hist\n",
    "# Note: The first/last row and col are repeated and are drawn on top of the next\n",
    "# row/col in the plot\n",
    "for i, col in enumerate(h_ext):\n",
    "    plt.plot(pts_y, col, label=\"{:d}\".format(i))\n",
    "for p in pts_y:\n",
    "    plt.axvline(p, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.title(\"Cols\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=\"upper center\", ncol=4)\n",
    "plt.savefig(\"/Users/tmenne/Downloads/col_rep\")\n",
    "plt.show()\n",
    "\n",
    "for i, row in enumerate(h_ext.T):\n",
    "    plt.plot(pts_x, row, label=\"{:d}\".format(i))\n",
    "for p in pts_x:\n",
    "    plt.axvline(p, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.title(\"Rows\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=\"upper center\", ncol=6)\n",
    "plt.savefig(\"/Users/tmenne/Downloads/row_rep\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Linearly extrapolate outermost values, first in all cols, then the rows\n",
    "h_ext = np.zeros((len(bxm) + 2, len(bym) + 2), dtype=h.dtype) - 1.\n",
    "for j, col in enumerate(h):\n",
    "    vals, pts_y, _ = make_spl_edges(vals=col, bins=by)\n",
    "    h_ext[j+1] = vals\n",
    "for i, row in enumerate(h_ext.T):\n",
    "    vals, pts_x, _ = make_spl_edges(vals=row[1:-1], bins=bx)\n",
    "    h_ext[:, i] = vals\n",
    "\n",
    "print(h_ext.shape)\n",
    "print(len(pts_x))\n",
    "print(len(pts_y))\n",
    "\n",
    "# Orignal bins\n",
    "xx, yy = np.meshgrid(bx, by)\n",
    "# Original bin mids\n",
    "xxm, yym = np.meshgrid(bxm, bym)\n",
    "# New grid points from bin mids\n",
    "xxg, yyg = np.meshgrid(pts_x, pts_y)\n",
    "\n",
    "# Plot original hist again\n",
    "plt.pcolormesh(xx, yy, h.T)\n",
    "plt.colorbar()\n",
    "# Plot original bin edges, bin mids and new pts for the interpolator\n",
    "plt.scatter(xx, yy, marker=\"o\", color=\"C3\", s=50)\n",
    "plt.scatter(xxm, yym, marker=\"o\", color=\"w\", s=50)\n",
    "plt.scatter(xxg, yyg, marker=\".\", color=\"k\")\n",
    "plt.show()\n",
    "\n",
    "# Plot rows and cols of the new hist\n",
    "for i, col in enumerate(h_ext):\n",
    "    plt.plot(pts_y, col, label=\"{:d}\".format(i))\n",
    "for p in pts_y:\n",
    "    plt.axvline(p, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.title(\"Cols\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=\"upper center\", ncol=4)\n",
    "plt.savefig(\"/Users/tmenne/Downloads/col_lin\")\n",
    "plt.show()\n",
    "\n",
    "for i, row in enumerate(h_ext.T):\n",
    "    plt.plot(pts_x, row, label=\"{:d}\".format(i))\n",
    "for p in pts_x:\n",
    "    plt.axvline(p, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.title(\"Rows\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=\"upper center\", ncol=6)\n",
    "plt.savefig(\"/Users/tmenne/Downloads/row_lin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### TEST: LLH scan instead of hess_inv from fitres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     35
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_llh_scan(bfs, stds, llh, grid):\n",
    "    \"\"\"\n",
    "    Plot the llh scan with errors and contours\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bfs : array-like, shape (2)\n",
    "        Best fit result parameters, around which the LLH was scanned.\n",
    "    stds : array-like, shape (2)\n",
    "        Approximate standard deviations (symmetric) for each fit parameter,\n",
    "        obtained using Wilks' theorem on the scanned space.\n",
    "    llh : array-like, shape (nbins, nbins)\n",
    "        Scanned LLH values.\n",
    "    grid : list\n",
    "        X, Y grid, same shape as ``llh``.\n",
    "    \"\"\"\n",
    "    bf_x, bf_y = bfs\n",
    "    std_x, std_y = stds\n",
    "    x, y = grid\n",
    "    \n",
    "    # Plot scan\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    img = ax.pcolormesh(x, y, llh)\n",
    "    fig.colorbar(img, ax=ax)\n",
    "\n",
    "    # Plot 1, 2, 3 sigma contours\n",
    "    vals = np.amin(llh) - scs.chi2.logsf(df=2, x=[1**2, 2**2, 3**2])\n",
    "    ax.contour(x, y, llh, vals, linestyles=[\"--\", \"-.\", \"--\"], colors=\"w\")\n",
    "    \n",
    "    # Plot best fit with symmetric errors\n",
    "    ax.errorbar(bf_x, bf_y, xerr=std_x, yerr=std_y, fmt=\"o\", c=\"w\", capsize=5)   \n",
    "    \n",
    "    ax.xlabel = (\"amplitude\")\n",
    "    ax.ylabel = (\"baseline\")\n",
    "\n",
    "def get_stddev_from_scan(func, args, bfs, rngs, nbins=50):\n",
    "    \"\"\"\n",
    "    Scan the rate_func chi2 fit LLH to get stddevs for the best fit params a, d.\n",
    "    Using matplotlib contours and averaging to approximately get the variances.\n",
    "    Note: This is not a true LLH profile scan in both variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        Loss function to be scanned, used to obtain the best fit. Function\n",
    "        is called as done with a scipy fitter, ``func(x, *args)``.\n",
    "    args : tuple\n",
    "        Args passed to the loss function ``func``. For a rate function, this is\n",
    "        ``(mids, rates, weights)``.\n",
    "    bfs : array-like, shape (2)\n",
    "        Best fit result parameters.\n",
    "    rngs : list\n",
    "        Parameter ranges to scan: ``[bf[i] - rng[i], bf[i] + rng[i]]``.\n",
    "    nbins : int, optional\n",
    "        Number of bins in each dimension to scan. (Default: 100)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    stds : array-like, shape (2)\n",
    "        Approximate standard deviations (symmetric) for each fit parameter,\n",
    "        obtained using Wilks' theorem on the scanned space.\n",
    "    llh : array-like, shape (nbins, nbins)\n",
    "        Scanned LLH values.\n",
    "    grid : list\n",
    "        X, Y grid, same shape as ``llh``.\n",
    "    \"\"\"\n",
    "    def _scan_llh(bf_x, rng_x, bf_y, rng_y):\n",
    "        \"\"\" Scan LLH and return contour vertices \"\"\"\n",
    "        x_bins = np.linspace(bf_x - rng_x, bf_x + rng_x, nbins)\n",
    "        y_bins = np.linspace(bf_y - rng_y, bf_y + rng_y, nbins)   \n",
    "        x, y = np.meshgrid(x_bins, y_bins)\n",
    "        AA, DD = map(np.ravel, [x, y])\n",
    "        llh = np.empty_like(AA)\n",
    "        for i, (ai, di) in enumerate(zip(AA, DD)):\n",
    "            llh[i] = func((ai, di), *args)\n",
    "        llh = llh.reshape(x.shape)\n",
    "        # Get the contour points and average over min, max per parameter\n",
    "        one_sigma_level = np.amin(llh) - scs.chi2.logsf(df=2, x=[1**2])\n",
    "\n",
    "        # https://stackoverflow.com/questions/5666056\n",
    "        cntr = plt.contour(x, y, llh, one_sigma_level)\n",
    "        plt.close(\"all\")\n",
    "        paths = [lcol.vertices for lcol in cntr.collections[0].get_paths()]\n",
    "        # Call undocumented base of plt.contour, to avoid creating a figure.\n",
    "        # Not working for mpl 2.2.2 any more, because _cntr was deleted.\n",
    "        # cntr = contour.Cntr(x, y, llh)\n",
    "        # paths = cntr.trace(level0=one_sigma_level)\n",
    "        # paths = paths[:len(paths) // 2]  # First half of list has the vertices\n",
    "        return paths, llh, [x, y]\n",
    "\n",
    "    def _is_path_closed(paths, rng_x, rng_y):\n",
    "        \"\"\"\n",
    "        We want the contour to be fully contained. Means there is only one path\n",
    "        and the first and last point are close together.\n",
    "        Returns ``True`` if contour is closed.\n",
    "        \"\"\"\n",
    "        closed = False\n",
    "        if len(paths) == 1:\n",
    "            vertices = paths[0]\n",
    "            # If no contour is made, only 1 vertex is returned -> invalid\n",
    "            if len(vertices) > 1:\n",
    "                max_bin_dist = np.amax([rng_x / float(nbins),\n",
    "                                        rng_y / float(nbins)])\n",
    "                closed = np.allclose(vertices[0], vertices[-1],\n",
    "                                     atol=max_bin_dist, rtol=0.)\n",
    "        return closed\n",
    "    \n",
    "    def _get_stds_from_path(path):\n",
    "        \"\"\" Create symmetric stddevs from the path vertices \"\"\"\n",
    "        x, y = path[:, 0], path[:, 1]\n",
    "        # Average asymmetricities in both direction\n",
    "        x_min, x_max = np.amin(x), np.amax(x)\n",
    "        y_min, y_max = np.amin(y), np.amax(y)\n",
    "        return 0.5 * (x_max - x_min), 0.5 * (y_max - y_min)\n",
    "           \n",
    "    # Scan the LLH, adapt scan range if contour is not closed\n",
    "    bf_x, bf_y = bfs\n",
    "    rng_x, rng_y = rngs\n",
    "    closed = False\n",
    "    while not closed:\n",
    "        # Default is scaling up, when range is too small\n",
    "        scalex, scaley = 10., 10.\n",
    "        # Get contour from scanned LLH space\n",
    "        paths, llh, grid = _scan_llh(bf_x, rng_x, bf_y, rng_y)\n",
    "        closed = _is_path_closed(paths, rng_x, rng_y)       \n",
    "        if closed:\n",
    "            vertices = paths[0]\n",
    "            # Estimate scale factors to get contour in optimum resolution\n",
    "            diffx = np.abs(np.amax(vertices[:, 0]) - np.amin(vertices[:, 0]))\n",
    "            diffy = np.abs(np.amax(vertices[:, 1]) - np.amin(vertices[:, 1]))\n",
    "            scalex = diffx / rng_x\n",
    "            scaley = diffy / rng_y\n",
    "            # Contour can be closed, but extremely zoomed out in only one param\n",
    "            if not np.allclose([scalex, scaley], 1., atol=0.5, rtol=0.):\n",
    "                print(\"Contour is very distorted in one direction\")\n",
    "                closed = False\n",
    "            else:\n",
    "                # Rescan valid contour to use optimal scan resolution\n",
    "                for i in range(2):\n",
    "                    std_x, std_y = _get_stds_from_path(vertices)\n",
    "                    rng_x = std_x * 1.05  # Allow a little padding\n",
    "                    rng_y = std_y * 1.05\n",
    "                    paths, llh, grid = _scan_llh(bf_x, rng_x, bf_y, rng_y)\n",
    "                    # Recheck if path is still valid\n",
    "                    closed = _is_path_closed(paths, rng_x, rng_y)\n",
    "        # Must be seperated if, because path can get invalid in rescaling step\n",
    "        if not closed:\n",
    "            print(\"Open or no contour, rescale\")\n",
    "            rng_x *= scalex\n",
    "            rng_y *= scaley\n",
    "\n",
    "    vertices = paths[0]\n",
    "    stds = np.array(_get_stds_from_path(vertices))\n",
    "    return stds, llh, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sindec = exp_[\"sinDec\"]\n",
    "t_ = np.linspace(exp_[\"timeMJD\"].min(), exp_[\"timeMJD\"].max(), 200)\n",
    "\n",
    "allres = []\n",
    "errs = []\n",
    "for j, (lo, hi) in enumerate(zip(sindec_bins[:-1], sindec_bins[1:])[:]):\n",
    "    mask = (sindec >= lo) & (sindec <= hi)\n",
    "\n",
    "    recs = make_rate_records(T=exp_[\"timeMJD\"][mask], run_dict=run_dict_)\n",
    "    rates, new_bins, stddev, _ = rebin_rate_rec(rate_rec=recs, bins=rate_rebins,\n",
    "                                                ignore_zero_runs=True)\n",
    "    new_mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "    weights = 1. / stddev\n",
    "    res = rate_func.fit(rate=rates, srcs=srcs_, t=new_mids, w=weights)\n",
    "    bfs = np.array([res.x[0], res.x[1]])\n",
    "    allres.append(res)\n",
    "    \n",
    "    plt.errorbar(recs[\"start_mjd\"], recs[\"rate\"], yerr=recs[\"rate_std\"],\n",
    "                 fmt=\",\", alpha=0.2, color=\"C0\")\n",
    "    plt.plot(recs[\"start_mjd\"], recs[\"rate\"], marker=\".\", ls=\"\", color=\"C0\")\n",
    "    plt.plot(new_bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "    plt.plot(t_, rate_func.fun(t=t_, pars=bfs), color=\"C3\")\n",
    "    plt.ylim(0, 3. * bfs[1])\n",
    "    plt.show()\n",
    "    \n",
    "    # Empirical seed estimates for amplitude and baseline scan range\n",
    "    args = (new_mids, rates, weights)\n",
    "    rngs = np.array([bfs[0], bfs[1] / 10.])\n",
    "    stds, llh, grid = get_stddev_from_scan(\n",
    "        func=rate_func._lstsq, args=args, bfs=bfs, rngs=rngs, nbins=20)\n",
    "    \n",
    "    plot_llh_scan(bfs, stds, llh, grid)\n",
    "    plt.show()\n",
    "    \n",
    "    errs.append(stds)\n",
    "\n",
    "errs = np.array(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 0 = amp, 1 = base\n",
    "# Note: The spline is not renormalized here, so there might be differences in\n",
    "#       scale to the one from the module\n",
    "for idx in [0, 1]:\n",
    "    x = np.linspace(-1, 1, 100)\n",
    "    mids = 0.5 * (sindec_bins[:-1] + sindec_bins[1:])\n",
    "    norm = np.diff(sindec_bins)\n",
    "\n",
    "    vals = np.array([res.x[idx] for res in allres]) / norm\n",
    "    err_ = errs.T[idx] / norm\n",
    "\n",
    "    # Prepare for spl fit\n",
    "    w = 1. / err_\n",
    "    spl, vals, pts, w = fit_spl_to_hist(h=vals, bins=sindec_bins, w=w, s=10)\n",
    "    \n",
    "    plt.plot(pts, vals, color=\"C7\", ls=\"--\")\n",
    "    plt.errorbar(pts, vals, yerr=1. / w, fmt=\"o\", color=\"C1\")\n",
    "    plt.plot(x, spl(x), color=\"k\")\n",
    "    plt.title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "\n",
    "    if idx == 0:\n",
    "        plt.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "        plt.ylabel(\"amp\")\n",
    "    else:\n",
    "        plt.ylim(0, None)\n",
    "        plt.ylabel(\"base\")\n",
    "    plt.xlabel(\"sindec\")\n",
    " \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### TEST: Event preselection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    exp_.keys()\n",
    "    name = \"86II_III\"\n",
    "except:\n",
    "    name = sample_name\n",
    "\n",
    "ev_dec = exp[name][\"dec\"]\n",
    "ev_ra = exp[name][\"ra\"]\n",
    "ev_sigma = exp[name][\"sigma\"]\n",
    "\n",
    "src_dec = srcs[name][\"dec\"][:, None]\n",
    "src_ra = srcs[name][\"ra\"][:, None]\n",
    "\n",
    "nsigma = 1.\n",
    "\n",
    "# Only mask events in a square with length nsigma * sigma to one of the sources\n",
    "dec_mask = ((ev_dec > src_dec - ev_sigma * nsigma) &\n",
    "            (ev_dec < src_dec + ev_sigma * nsigma))\n",
    "mask = dec_mask\n",
    "# RA mask needs more thought due to soild angle differences\n",
    "# ra_mask = ((ev_ra > (src_ra - ev_sigma * nsigma / np.cos(src_dec))) &\n",
    "#            (ev_ra < (src_ra + ev_sigma * nsigma / np.cos(src_dec))))\n",
    "# mask = ra_mask & dec_mask\n",
    "\n",
    "print(np.sum(mask, axis=1))\n",
    "\n",
    "# Plot events per source\n",
    "m = (ev_sigma < np.deg2rad(1.))  # Only show well reconstructed events\n",
    "plt.plot(ev_ra[m], ev_dec[m], color=\"C7\", alpha=.1, marker=\".\", ls=\"\", ms=1)\n",
    "for j, m in enumerate(mask[:]):\n",
    "    m = m & (ev_sigma < np.deg2rad(1.))  # Only show well reconstructed events\n",
    "    plt.scatter(ev_ra[m], ev_dec[m], s=100 * ev_sigma[m], alpha=.5)\n",
    "    plt.plot(src_ra[j], src_dec[j], marker=\"*\", ms=5)\n",
    "    \n",
    "# Show events contributing to all sources (if any)\n",
    "m = np.where(np.all(mask, axis=0))\n",
    "plt.scatter(ev_ra[m], ev_dec[m], s=10 * ev_sigma[m], alpha=1, color=\"k\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### TEST: Renormalize spline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Apparently we can renormalize a spline by evluating it at the original data grid, renormalizing the points and refit an interpolating spline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 15)  # Try for less and more points, always works...\n",
    "y = np.random.uniform(1, 2, size=len(x))\n",
    "\n",
    "spl = sci.UnivariateSpline(x, y, s=1)\n",
    "\n",
    "# Make a new spline by interpolating the original grid\n",
    "new_spl = sci.UnivariateSpline(x, spl(x), s=0)\n",
    "\n",
    "# Now rescale before fitting a new one\n",
    "old_norm = spl.integral(x[0], x[-1])\n",
    "new_norm = 2.\n",
    "new_spl_res = sci.UnivariateSpline(x, spl(x) / old_norm * new_norm, s=0)\n",
    "\n",
    "# Plot it\n",
    "x_ = np.linspace(x[0], x[-1], 200)\n",
    "\n",
    "# Unscaled\n",
    "plt.plot(x_, spl(x_), c=\"C7\", label=\"orig\")\n",
    "plt.plot(x_, new_spl(x_), ls=\"--\", c=\"C3\")\n",
    "\n",
    "# Rescaled\n",
    "plt.plot(x_, spl(x_) / old_norm * new_norm, c=\"k\", label=\"rescaled\")\n",
    "plt.plot(x_, new_spl_res(x_), ls=\"--\", c=\"r\")\n",
    "\n",
    "plt.plot(x, y, ls=\"\", marker=\"o\")\n",
    "knots = spl.get_knots()\n",
    "plt.plot(knots, spl(knots), ls=\"\", marker=\"d\")\n",
    "\n",
    "plt.title(\"Old norm: {:.2f}, new norm: {:.2f}\".format(\n",
    "    spl.integral(x[0], x[-1]), new_spl_res.integral(x[0], x[-1])))\n",
    "plt.ylim(0, None)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### TEST: Energy PDF dependent of gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mc_dict = loader.mc_loader(\"all\")\n",
    "off_dict = loader.off_data_loader(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "key = \"IC86_2012-2014\"\n",
    "exp = off_dict[key]\n",
    "mc = mc_dict[key]\n",
    "\n",
    "\n",
    "log_proxy_E = exp[\"logE\"]\n",
    "lo, hi = np.percentile(log_proxy_E, [5, 95])\n",
    "\n",
    "h, b, _ = plt.hist(log_proxy_E, bins=50, color=\"C7\")\n",
    "\n",
    "plt.hist(log_proxy_E[exp[\"dec\"] > 0], bins=b, histtype=\"step\",\n",
    "         color=\"k\", lw=2, ls=\"--\", label=\"north\")\n",
    "plt.hist(log_proxy_E[exp[\"dec\"] <= 0], bins=b, histtype=\"step\",\n",
    "         color=\"k\", lw=2, ls=\":\", label=\"south\")\n",
    "\n",
    "plt.axvline(lo, ls=\"-\", c=\"C3\")\n",
    "plt.axvline(hi, ls=\"-\", c=\"C1\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(r\"$\\log_{10}(E_\\mathrm{proxy} / \\mathrm{GeV})$\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "log_true_E = np.log10(mc[\"trueE\"])\n",
    "log_proxy_E = mc[\"logE\"]\n",
    "w = mc[\"ow\"] * power_law_flux(trueE=mc[\"trueE\"], E0=1e5, phi0=0.9e-18,\n",
    "                               gamma=2.13)\n",
    "\n",
    "plt.hist2d(log_true_E, log_proxy_E, weights=w, bins=50, norm=LogNorm())\n",
    "plt.axhline(lo, ls=\"-\", c=\"k\")\n",
    "plt.axhline(hi, ls=\"-\", c=\"k\")\n",
    "\n",
    "plt.xlabel(r\"$\\log_{10}(E_\\nu) / \\mathrm{GeV})$\")\n",
    "plt.ylabel(r\"$\\log_{10}(E_\\mathrm{proxy} / \\mathrm{GeV})$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "key = \"IC86_2012-2014\"\n",
    "exp = off_dict[key]\n",
    "mc = mc_dict[key]\n",
    "\n",
    "data_proxy_E = exp[\"logE\"]\n",
    "data_sin_dec = np.sin(exp[\"dec\"])\n",
    "\n",
    "mc_log_proxy_E = mc[\"logE\"]\n",
    "mc_sin_dec = np.sin(mc[\"dec\"])\n",
    "\n",
    "sindec_bins = np.arange(-1, 1 +  0.05, 0.05)\n",
    "log_E_bins = np.linspace(np.amin(mc_log_proxy_E),\n",
    "                         np.amax(mc_log_proxy_E), 30 + 1)\n",
    "bins = [sindec_bins, log_E_bins]\n",
    "\n",
    "dgamma = 0.1\n",
    "gammas = np.arange(1, 4 + dgamma, dgamma)\n",
    "\n",
    "ratio_hists = []\n",
    "for gamma in gammas:\n",
    "    w = mc[\"ow\"] * power_law_flux(trueE=mc[\"trueE\"], E0=1, phi0=1, gamma=gamma)\n",
    "    d_h = np.histogram2d(data_sin_dec, data_proxy_E, bins=bins, normed=True)[0]\n",
    "    mc_h = np.histogram2d(mc_sin_dec, mc_proxy_E, bins=bins, weights=w,\n",
    "                          normed=True)[0]\n",
    "\n",
    "    m = (d_h > 0)\n",
    "    d_h[~m] = np.amin(d_h[m])\n",
    "    m = (mc_h > 0)\n",
    "    mc_h[~m] = np.amin(mc_h[m])\n",
    "    \n",
    "    ratio_hists.append(mc_h / d_h)\n",
    "    \n",
    "ratio_hists = np.array(ratio_hists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_log_E = 0.5 * (log_E_bins[:-1] + log_E_bins[1:])\n",
    "\n",
    "XX, YY = np.meshgrid(gammas, m_log_E)\n",
    "\n",
    "for i in range(len(sindec_bins) - 1):\n",
    "    plt.pcolormesh(XX, YY, ratio_hists[:, i, :].T, cmap=\"coolwarm\",\n",
    "                   norm=LogNorm(), vmin=1e-3, vmax=1e3)\n",
    "    plt.colorbar()\n",
    "    plt.title(sindec_bins[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_sin_dec = 0.5 * (sindec_bins[:-1] + sindec_bins[1:])\n",
    "\n",
    "XX, YY = np.meshgrid(gammas, m_sin_dec)\n",
    "\n",
    "for i in range(len(log_E_bins) - 1):\n",
    "    plt.pcolormesh(XX, YY, ratio_hists[:, :, i].T, cmap=\"coolwarm\",\n",
    "                   norm=LogNorm(), vmin=1e-3, vmax=1e3)\n",
    "    plt.colorbar()\n",
    "    plt.title(log_E_bins[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, rh in enumerate(ratio_hists):\n",
    "    plt.pcolormesh(rh.T, norm=LogNorm(), cmap=\"coolwarm\", vmin=1e-3, vmax=1e3)\n",
    "    plt.title(\"{:.1f}\".format(gammas[i]))\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"sindec\")\n",
    "    plt.ylabel(\"logE\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi containers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Load data and setup models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This defines the tested sources time windows\n",
    "tw_id = -1\n",
    "dt0, dt1 = loader.time_window_loader(tw_id)\n",
    "print(\"Time window: [{:.0f}, {:.0f}]\".format(dt0, dt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "bg_injs = {}\n",
    "sig_injs = {}\n",
    "llhs = {}\n",
    "\n",
    "# :: Debug ::\n",
    "bg_inj_opts = {}\n",
    "sig_inj_opts = {}\n",
    "mod_spatial_opts = {}\n",
    "mod_energy_opts = {}\n",
    "llh_opts = {}\n",
    "srcs_dict = {}\n",
    "runlists_dict = {}\n",
    "exp_off_dict = {}\n",
    "mc_dict = {}\n",
    "srcs_recs_dict = {}\n",
    "rate_recs_dict = {}\n",
    "# :: Debug :: END\n",
    "\n",
    "time_sam = UniformTimeSampler(random_state=RNDGEN)\n",
    "HEALPY_SIG = True\n",
    "\n",
    "# Load files and build the models one after another to save memory\n",
    "sample_names = loader.source_list_loader()\n",
    "for key in sample_names:\n",
    "    print(\"\\n\" + 80 * \"#\")\n",
    "    print(\"# :: Setup for sample {} ::\".format(key))\n",
    "    opts = loader.settings_loader(key)[key].copy()\n",
    "    exp_off = loader.off_data_loader(key)[key]\n",
    "    mc = loader.mc_loader(key)[key]\n",
    "    srcs_i = loader.source_list_loader(key)[key]\n",
    "    runlist_i = loader.runlist_loader(key)[key]\n",
    "    # Process to tdepps format\n",
    "    srcs_rec_i = make_src_records(srcs_i, dt0=dt0, dt1=dt1)\n",
    "    \n",
    "    # Setup BG injector\n",
    "    bg_inj_i = TimeDecDependentBGDataInjector(inj_opts=opts[\"bg_inj_opts\"],\n",
    "                                              random_state=RNDGEN)\n",
    "    bg_inj_i.fit(X=exp_off, srcs=srcs_rec_i, run_list=runlist_i)\n",
    "    bg_injs[key] = bg_inj_i\n",
    "    \n",
    "    # Setup Signal injector\n",
    "    fmod = opts[\"sig_inj_opts\"].pop(\"flux_model\")\n",
    "    flux_model = phys.flux_model_factory(fmod[\"model\"], **fmod[\"args\"])\n",
    "    if HEALPY_SIG:\n",
    "        opts[\"sig_inj_opts\"][\"inj_sigma\"] = 3.\n",
    "        src_maps = loader.source_map_loader(src_list=srcs_i)\n",
    "        sig_inj_i = HealpySignalFluenceInjector(\n",
    "            flux_model, time_sampler=time_sam, inj_opts=opts[\"sig_inj_opts\"],\n",
    "            random_state=RNDGEN)\n",
    "        sig_inj_i.fit(srcs_rec_i, src_maps=src_maps, MC=mc)\n",
    "    else:\n",
    "        sig_inj_i = SignalFluenceInjector(\n",
    "            flux_model, time_sampler=time_sam, inj_opts=opts[\"sig_inj_opts\"],\n",
    "            random_state=RNDGEN)\n",
    "        sig_inj_i.fit(srcs_rec_i, MC=mc)\n",
    "    sig_injs[key] = sig_inj_i\n",
    "    \n",
    "    # Setup LLH model and LLH\n",
    "    fmod = opts[\"model_energy_opts\"].pop(\"flux_model\")\n",
    "    flux_model = phys.flux_model_factory(fmod[\"model\"], **fmod[\"args\"])\n",
    "    opts[\"model_energy_opts\"][\"flux_model\"] = flux_model\n",
    "    llhmod = GRBModel(X=exp_off, MC=mc, srcs=srcs_rec_i, run_list=runlist_i,\n",
    "                      spatial_opts=opts[\"model_spatial_opts\"],\n",
    "                      energy_opts=opts[\"model_energy_opts\"])\n",
    "    llhs[key] = GRBLLH(llh_model=llhmod, llh_opts=opts[\"llh_opts\"])\n",
    "    \n",
    "    # Add debug info for tests\n",
    "    bg_inj_opts[key] = bg_inj_i.inj_opts\n",
    "    sig_inj_opts[key] = sig_inj_i.inj_opts\n",
    "    mod_spatial_opts[key] = llhmod.spatial_opts\n",
    "    mod_energy_opts[key] = llhmod.energy_opts\n",
    "    llh_opts[key] = llhs[key].llh_opts\n",
    "    srcs_dict[key] = srcs_i\n",
    "    runlists_dict[key] = runlist_i\n",
    "    exp_off_dict[key] = exp_off\n",
    "    mc_dict[key] = mc\n",
    "    srcs_recs_dict[key] = srcs_rec_i\n",
    "    rate_recs_dict[key] = make_rate_records(ev_runids=exp_off[\"Run\"],\n",
    "                                            run_list=runlist_i)\n",
    "\n",
    "exp_on_dict = loader.on_data_loader(\"all\")\n",
    "print(\":: Done ::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "multi_bg_inj = MultiBGDataInjector()\n",
    "multi_bg_inj.fit(bg_injs)\n",
    "\n",
    "multi_sig_inj = MultiSignalFluenceInjector(random_state=RNDGEN)\n",
    "multi_sig_inj.fit(sig_injs)\n",
    "\n",
    "multi_llh_opts = loader.settings_loader(\"multi_llh\")[\"multi_llh\"]\n",
    "multi_llh = MultiGRBLLH(llh_opts=multi_llh_opts)\n",
    "multi_llh.fit(llhs=llhs)\n",
    "\n",
    "ana = GRBAna.GRBLLHAnalysis(multi_llh, multi_bg_inj, sig_inj=multi_sig_inj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(folder, fname, **savefig_args):\n",
    "    \"\"\" Checks existence of save folder and saves current figure.\"\"\"\n",
    "    dpi = savefig_args.pop(\"dpi\", 200)\n",
    "    bbox_inches = savefig_args.pop(\"bbox_inches\", \"tight\")\n",
    "    outp = os.path.join(PATHS.plots, folder)\n",
    "    if not os.path.isdir(outp):\n",
    "        os.makedirs(outp)\n",
    "    plt.tight_layout()\n",
    "    fname = os.path.join(outp, fname)\n",
    "    plt.savefig(fname, dpi=dpi, bbox_inches=bbox_inches, **savefig_args)\n",
    "    print(\"Saved plot to:\\n  {}\".format(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Method TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Local coord BG PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://icecube.wisc.edu/~tkintscher/internal/gfu_doc/likelihood.html#background-space-pdf\n",
    "# 'azimuth', 'zenith' only in GFU so far\n",
    "exp = np.load(\"/Users/tmenne/Downloads/hese_transient_stacking_data/\" +\n",
    "              \"skylab_data/SplineMPEmax.MuEx.IC86-2015.npy\")\n",
    "\n",
    "bx = np.linspace(0, 2. * np.pi, 72 + 1)\n",
    "by = np.linspace(-1, 1, 40 + 1)\n",
    "h, bx, by = np.histogram2d(exp[\"azimuth\"], np.cos(exp[\"zenith\"]), bins=[bx, by],\n",
    "                           normed=True)\n",
    "xx, yy = np.meshgrid(bx, by)\n",
    "mx, my = 0.5 * (bx[:-1] + bx[1:]), 0.5 * (by[:-1] + by[1:])\n",
    "coszen, _ =  np.histogram(np.cos(exp[\"zenith\"]), bins=by, normed=True)\n",
    "flat = np.repeat([coszen], repeats=len(bx)-1, axis=0) / (2. * np.pi)\n",
    "\n",
    "ratio = h / flat\n",
    "ratio_interpol = sci.RegularGridInterpolator(points=[mx, my], values=ratio,\n",
    "                                             bounds_error=False, fill_value=0.)\n",
    "\n",
    "plt.pcolormesh(xx, yy, h.T, cmap=\"Blues\", vmin=0, vmax=0.2)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.pcolormesh(xx, yy, flat.T, cmap=\"Blues\", vmin=0, vmax=0.2)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "x = np.linspace(bx[0], bx[-1], 500)\n",
    "y = np.linspace(by[0], by[-1], 500)\n",
    "XX, YY = np.meshgrid(x, y)\n",
    "pts = np.vstack((map(np.ravel, [XX, YY]))).T\n",
    "plt.pcolormesh(XX, YY, ratio_interpol(pts).reshape(XX.shape),\n",
    "                                      cmap=\"coolwarm\", vmin=0., vmax=2.)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Interval overlap test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test interval overlap\n",
    "# Fixed interval\n",
    "a0, a1 = [1, 2]\n",
    "# Test intervals, all cases. Overlap: [0, 0, 0.6, 1, 0.2, 0.2]\n",
    "b0 = np.array([0.5  , 2.2, 1.2, 0.8, 0.8, 1.8])\n",
    "b1 = np.array([0.8, 2.5, 1.8, 2.2, 1.2, 2.2])\n",
    "idx = np.argsort(b0)\n",
    "b0, b1 = b0[idx], b1[idx]\n",
    "\n",
    "nintervals = len(b0)\n",
    "overlap = interval_overlap(a0, a1, b0, b1)\n",
    "\n",
    "c = plt.cm.viridis(np.linspace(0, 1, nintervals))\n",
    "for i in range(nintervals):\n",
    "    plt.fill_between([b0[i], b1[i]], 1 + i / 5., 2 + i / 5.,\n",
    "                     color=c[i], alpha=0.5)\n",
    "    plt.vlines(b0[i], 1 + i / 5., 2 + i / 5., color=\"k\")\n",
    "    plt.vlines(b1[i], 1 + i / 5., 2 + i / 5., color=\"k\")\n",
    "    plt.axhline(1, 0, 1, c=\"k\", ls=\"--\")\n",
    "    plt.text(s=\"{:.1f}\".format(overlap[i]),\n",
    "             horizontalalignment=\"center\",\n",
    "             verticalalignment=\"bottom\",\n",
    "             x=0.5 * (b0[i] + b1[i]), y=2 + i / 5.)\n",
    "\n",
    "plt.fill_between([a0, a1], 0, 1, color=\"C7\")\n",
    "plt.vlines(a0, 0, 1, colors=\"k\")\n",
    "plt.vlines(a1, 0, 1, colors=\"k\")\n",
    "plt.ylim(0, None)    \n",
    "    \n",
    "save_plot(\"misc\", \"interval_overlap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Sample only in ontime runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sample_uniform(runtimes, size=1, random_state=None):\n",
    "    \"\"\"\n",
    "    Draws ``size`` event times uniformly distributed over all ontime regions,\n",
    "    which borders are defined by ``runtimes[i] = [tstart_i, tstop_i]``.\n",
    "    \n",
    "    The method draws a random number from the effective livetime w/o offtime\n",
    "    runs and rescales them linearly to the correct absolute time in the ontime\n",
    "    runs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    runtimes : array-like, shape (nruns, 2)\n",
    "        Start and end times of each run. Each pair\n",
    "        ``runtimes[i] = [tstart_i, tstop_i]`` defines the livetime of run ``i``.\n",
    "    size : int, optional\n",
    "        How many events to sample over all runs in ``runtimes``.\n",
    "    random_state : int, None or np.random.RandomState instance\n",
    "        Passes to ``sklearn.utils.check_random_state``. (default: ``None``)\n",
    "    \"\"\"\n",
    "    rndgen = check_random_state(random_state)\n",
    "    # Make empiric cum. dist. for the effective ontime runs\n",
    "    comb_ontime = np.hstack((0, np.cumsum(np.diff(runtimes, axis=0))))\n",
    "    cdf = comb_ontime / comb_ontime[-1]\n",
    "    # Draw uniformly and scale to total livetime\n",
    "    u = rndgen.uniform(0, 1, size=size)\n",
    "    total_mjd = u * comb_ontime[-1]\n",
    "    # Get the ontime run id, subtract the combined ontime from all runs before\n",
    "    # and add the run's start time to get the absolute event time information\n",
    "    run_idx = np.searchsorted(cdf, u, side=\"right\") - 1\n",
    "    print(run_idx)\n",
    "    sample = total_mjd - comb_ontime[run_idx] + runtimes[0][run_idx]\n",
    "    return sample\n",
    "    \n",
    "def sample_expectation(runtimes, expectations, random_state=None):\n",
    "    \"\"\"\n",
    "    Same as ``sample_uniform`` but the number of events per ontime bin is drawn\n",
    "    from a poisson distribution with given expectation per bin. The events times\n",
    "    per bin are still drawn uniformly.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    runtimes : array-like, shape (nruns, 2)\n",
    "        Start and end times of each run. Each pair\n",
    "        ``runtimes[i] = [tstart_i, tstop_i]`` defines the livetime of run ``i``.\n",
    "    expectations : array-like, shape (nruns, )\n",
    "        Poisson expectation values per run.\n",
    "    random_state : int, None or np.random.RandomState instance\n",
    "        Passes to ``sklearn.utils.check_random_state``. (default: ``None``)\n",
    "    \"\"\"\n",
    "    if len(expectations) != runtimes.shape[1]:\n",
    "        raise ValueError(\"`runtimes` and `expectations` must match.\")\n",
    "    rndgen = check_random_state(random_state)\n",
    "    # Poisson sampling the new total event number for all runs\n",
    "    total_expectation = np.sum(expectations)\n",
    "    weights = expectations / total_expectation\n",
    "    # Distribute events to single runs weighting with relative expectations\n",
    "    nevts_total = rndgen.poisson(total_expectation, size=None)\n",
    "    nevts_per_run = rndgen.multinomial(nevts_total, weights, size=None)\n",
    "    # Sample the number of events per bin uniformly in each bin by transforming\n",
    "    # the uniform numbers with the start time and length of the correct runs\n",
    "    u = np.random.uniform(0, 1, size=nevts_total)\n",
    "    nruns = len(expectations)\n",
    "    run_idx = np.repeat(np.arange(nruns), repeats=nevts_per_run)\n",
    "    livetimes = np.ravel(np.diff(runtimes, axis=0))\n",
    "    sample = u * livetimes[run_idx] + runtimes[0][run_idx]\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _iso2mjd(iso):\n",
    "    return astrotime(iso, format=\"iso\").mjd\n",
    "\n",
    "rl = loader.runlist_loader(\"IC79\")[\"IC79\"]\n",
    "tstart = np.array([_iso2mjd(d[\"good_tstart\"]) for d in rl])\n",
    "tstop = np.array([_iso2mjd(d[\"good_tstop\"]) for d in rl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_rndgen = np.random.RandomState(123123)\n",
    "runtimes = np.array([[1, 2, 3, 4], [1.5, 2.5, 3.5, 5.5]])\n",
    "size=100\n",
    "\n",
    "sample = sample_uniform(runtimes, size, _rndgen)\n",
    "for ti in sample:\n",
    "    plt.axvline(ti, color=\"C7\", alpha=0.5)\n",
    "    \n",
    "plt.vlines(runtimes[0], 0, 1, colors=\"C2\")\n",
    "plt.vlines(runtimes[1], 0, 1, colors=\"C3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_rndgen = np.random.RandomState(123123)\n",
    "runtimes = np.array([[1, 2, 3, 4], [1.5, 2.5, 3.5, 5.5]])\n",
    "expectations = (np.arange(0, len(runtimes.T)) + 1) * 10\n",
    "\n",
    "sample = sample_expectation(runtimes, expectations, _rndgen)\n",
    "for ti in sample:\n",
    "    plt.axvline(ti, color=\"C7\", alpha=0.5)\n",
    "    \n",
    "plt.vlines(runtimes[0], 0, 1, colors=\"C2\")\n",
    "plt.vlines(runtimes[1], 0, 1, colors=\"C3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Sample empirically from spline PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sample_spline(spl, a, b, nbins, size=None, random_state=None):\n",
    "    rndgen = check_random_state(random_state)\n",
    "    # Scan the PDF to create the empirical CDF\n",
    "    x = np.linspace(a, b, nbins + 1)\n",
    "    cdf = np.array([spl.integral(a, xi) for xi in x])\n",
    "    cdf = cdf / cdf[-1]\n",
    "    # Draw from the empirical CDF\n",
    "    u = rndgen.uniform(0, 1, size=size)\n",
    "    idx = np.searchsorted(cdf, u, side=\"right\") - 1\n",
    "    return x[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a, b = -1, 10\n",
    "x = np.linspace(a, b, 20)\n",
    "y = np.sin(x) + 1\n",
    "\n",
    "spl = sci.InterpolatedUnivariateSpline(x, y, k=3)\n",
    "norm = spl.integral(a, b)\n",
    "\n",
    "t = np.linspace(a, b, 100)\n",
    "plt.plot(t, spl(t) / norm)\n",
    "\n",
    "nbins = 100\n",
    "sample = sample_spline(spl, a, b, nbins=nbins, size=10000)\n",
    "plt.hist(sample, bins=np.linspace(a, b, 50 + 1), density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Split on/off data and effective runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mypyscripts.general.misc import idx2rowcol\n",
    "\n",
    "exp_on_dict = loader.on_data_loader(\"all\")\n",
    "exp_off_dict = loader.off_data_loader(\"all\")\n",
    "src_dict = loader.source_list_loader(\"all\")\n",
    "run_dict = loader.runlist_loader(\"all\")\n",
    "dt0_max, dt1_max = loader.time_window_loader(-1)\n",
    "\n",
    "livetimes = {}\n",
    "for key in sorted(exp_on_dict.keys()):\n",
    "    exp_on = exp_on_dict[key]\n",
    "    exp_off = exp_off_dict[key]\n",
    "    srcs = src_dict[key]\n",
    "    all_ids = np.concatenate([exp_on[\"Run\"], exp_off[\"Run\"]])\n",
    "    run_rec = phys.make_rate_records(ev_runids=all_ids, run_list=run_dict[key])\n",
    "    \n",
    "    ncols = int(np.ceil(np.sqrt(len(srcs))))\n",
    "    nrows = ncols\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharey=True, sharex=True,\n",
    "                           figsize=(ncols * 4, nrows * 3))\n",
    "    \n",
    "    livetimes[key] = []\n",
    "    for i, src in enumerate(srcs):\n",
    "        src_t = src[\"mjd\"]\n",
    "        \n",
    "        def mjd2sec(mjd):\n",
    "            return  (mjd - src_t) * SECINDAY\n",
    "        \n",
    "        src_tstart = src_t + dt0_max / SECINDAY\n",
    "        src_tstop = src_t + dt1_max / SECINDAY\n",
    "      \n",
    "        r, c = idx2rowcol(idx=i, ncols=ncols)\n",
    "        dt_plot = 0.2\n",
    "        \n",
    "        m_on = ((exp_on[\"time\"] > src_tstart - dt_plot) &\n",
    "                (exp_on[\"time\"] < src_tstop + dt_plot))\n",
    "        ax[r, c].vlines(mjd2sec(exp_on[\"time\"][m_on]),\n",
    "                        0.1, 0.9, colors=\"C7\", label=\"On data\")\n",
    "        m_off = ((exp_off[\"time\"] > src_tstart - dt_plot) &\n",
    "                 (exp_off[\"time\"] < src_tstop + dt_plot))\n",
    "        ax[r, c].vlines(mjd2sec(exp_off[\"time\"][m_off]),\n",
    "                        0, 1, colors=\"#BBBBBB\", label=\"Off data\")\n",
    "\n",
    "        ax[r, c].axvline(mjd2sec(src_tstart), 0, 1, ls=\"-\", c=\"k\")\n",
    "        ax[r, c].axvline(mjd2sec(src_tstop), 0, 1, ls=\"-\", c=\"k\")\n",
    "\n",
    "        for rt0, rt1 in zip(run_rec[\"start_mjd\"], run_rec[\"stop_mjd\"]):\n",
    "            if rt1 > src_tstart and rt0 < src_tstop:\n",
    "                ax[r, c].axvline(mjd2sec(rt0), 0, 1, ls=\":\", c=\"k\")\n",
    "                ax[r, c].axvline(mjd2sec(rt1), 0, 1, ls=\":\", c=\"k\")\n",
    "                \n",
    "        lt = np.sum(interval_overlap(\n",
    "            src_tstart, src_tstop, run_rec[\"start_mjd\"], run_rec[\"stop_mjd\"]))\n",
    "        livetimes[key].append(lt)\n",
    "        \n",
    "        ax[r, c].set_xlabel(\"Time in sec rel. to src\")\n",
    "        ax[r, c].set_title(\"Src {}. Livetime {:.2f} / {} d ({:.1%})\".format(\n",
    "            i, lt, src_tstop - src_tstart, lt / (src_tstop - src_tstart)))\n",
    "        ax[r, c].set_xlim(mjd2sec(src_tstart - dt_plot),\n",
    "                          mjd2sec(src_tstop + dt_plot))\n",
    "        if i == len(srcs) - 1:\n",
    "            ax[r, c].legend(loc=\"upper center\")\n",
    "        \n",
    "    for j in range(i + 1, ax.size):\n",
    "        fig.delaxes(ax[idx2rowcol(idx=j, ncols=ncols)])\n",
    "\n",
    "    suptitle = fig.suptitle(\"On-/offdata for sources in sample \" +\n",
    "                            \"'{}'\".format(key))  # Gets displaced by bbox...\n",
    "    fig.suptitle(key)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    save_plot(\"on_off_data_split\", \"{}.png\".format(key),\n",
    "              rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_dict(d):\n",
    "    shift = max(map(len, d.keys())) + 1\n",
    "    for key, val in d.items():\n",
    "        print(\"{1:{0:d}s}: {2:.1%}\".format(shift, key, val))\n",
    "        \n",
    "mean_lt = dict_map(lambda k, v: np.mean(v) / 5., livetimes)\n",
    "mean_lt_tot = np.mean(mean_lt.values())\n",
    "\n",
    "print_dict(mean_lt)\n",
    "print(\"Total mean livetime in all time windows: {:.1%}\".format(mean_lt_tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Sources and rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot rates and sources for each sample\n",
    "_Hz2mHz = 1e3\n",
    "max_y = _Hz2mHz * 0.015\n",
    "for i, key in enumerate(sorted(exp_off_dict.keys())):\n",
    "    mids = 0.5 * (rate_recs_dict[key][\"start_mjd\"] +\n",
    "                  rate_recs_dict[key][\"stop_mjd\"])\n",
    "\n",
    "    min_x = np.amin(rate_recs_dict[key][\"start_mjd\"])\n",
    "    max_x = np.amax(rate_recs_dict[key][\"stop_mjd\"])\n",
    "#     plt.fill_between([min_x, max_x], [0, 0], [2, 2],\n",
    "#                      color=\"C{}\".format(i), alpha=0.05)\n",
    "    \n",
    "    plt.text(0.5 * (min_x + max_x), max_y - 1,\n",
    "             r\"{}\".format(key.replace(\"_\", \"\\n\")),\n",
    "             ha=\"center\", va=\"center\", color=\"C{}\".format(i))\n",
    "    \n",
    "    plt.errorbar(mids, _Hz2mHz * rate_recs_dict[key][\"rate\"],\n",
    "                 yerr=_Hz2mHz * rate_recs_dict[key][\"rate_std\"],\n",
    "                 fmt=\",\", color=\"C7\", alpha=0.1)\n",
    "        \n",
    "    plt.vlines(srcs_recs_dict[key][\"time\"], 0, 2, colors=\"C{}\".format(i),\n",
    "               linestyles=\"-\", label=key)\n",
    "    plt.axvline(np.amin(rate_recs_dict[key][\"start_mjd\"]), c=\"k\", ls=\"-.\")\n",
    "    \n",
    "plt.xlim(np.amin(rate_recs_dict[\"IC79\"][\"start_mjd\"]),\n",
    "         np.amax(rate_recs_dict[\"IC86_2015\"][\"stop_mjd\"]))\n",
    "plt.ylim(0, max_y)\n",
    "plt.xlabel(\"time in MJD days\")\n",
    "plt.ylabel(\"Rate in mHz\")\n",
    "plt.title(\"Rates and sources\")\n",
    "\n",
    "save_plot(\"sources_and_rates\", \"rate_all_samples.png\", dpi=200,\n",
    "          bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Source maps and source coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot a mollview with all prior maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import mypyscripts.plots as myplt\n",
    "\n",
    "all_srcs = loader.source_list_loader(\"all\")\n",
    "all_maps = []\n",
    "for src_list in all_srcs.values():\n",
    "    all_maps.append(loader.source_map_loader(src_list))\n",
    "    \n",
    "summed_maps = np.sum(np.concatenate(all_maps), axis=0)\n",
    "myplt.mollview(summed_maps, coords=\"equatorial\")\n",
    "\n",
    "save_plot(\"source_maps\", \"summed_maps.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Load source s and source maps and check if the source coordinates match the maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "for key in [\"IC79\", \"IC86_2011\", \"IC86_2012-2014\", \"IC86_2015\"]:\n",
    "    # Load maps and sources\n",
    "    _srcs = loader.source_list_loader(key)[key]\n",
    "    _maps = loader.source_map_loader(_srcs)\n",
    "\n",
    "    # Get direct trafo ra, dec\n",
    "    _ras = np.array([s[\"ra\"] for s in _srcs])\n",
    "    _decs = np.array([s[\"dec\"] for s in _srcs])\n",
    "    _th = np.pi / 2. - _decs\n",
    "\n",
    "    # Compare to ra, dec to map\n",
    "    for i, m in enumerate(_maps):\n",
    "        m[m <= 0] = np.amin(m[m > 0])\n",
    "        hp.cartview(np.log10(m), cmap=\"gray_r\")\n",
    "        hp.projscatter(_th[i], _ras[i], marker=\"+\", color=\"r\")\n",
    "        hp.graticule(verbose=False)\n",
    "        plt.title(\"Sample: {}\".format(key))\n",
    "        save_plot(os.path.join(\"source_maps\", \"maps_and_src_points\"),\n",
    "                  \"sample_{}_src_{:02d}.png\".format(key, i), dpi=100)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show difference in truncated and maps with smoothing artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "# A map truncated to zero after 6 sigma contour\n",
    "_f = (\"/Users/tmenne/Downloads/hese_transient_stacking_data/\" +\n",
    "      \"123326.i3.bz2_event0000.json\")\n",
    "with open(_f) as f:\n",
    "    _src = json.load(f)\n",
    "    \n",
    "_m = np.array(_src[\"map\"])\n",
    "print(\"Chi2 6 sigma : \", scs.chi2.sf(6**2, df=2))\n",
    "print(\"Map min / max: \",np.amin(_m[_m > 0]) / np.amax(_m[_m > 0]))\n",
    "\n",
    "hp.cartview(np.log10(_m), cmap=\"gray_r\")\n",
    "hp.graticule(verbose=False)\n",
    "save_plot(os.path.join(\"source_maps\", \"artifacts\"), \"HESE_123326.png\")\n",
    "plt.show()\n",
    "\n",
    "# Now a map with smoothing artifacts\n",
    "_f = (\"/Users/tmenne/Downloads/hese_transient_stacking_data/\" +\n",
    "      \"123326.i3.bz2_event0000_art.json\")\n",
    "with open(_f) as f:\n",
    "    _src = json.load(f)\n",
    "    \n",
    "_m = np.array(_src[\"map\"])\n",
    "hp.cartview(np.log10(_m), cmap=\"gray_r\")\n",
    "hp.graticule(verbose=False)\n",
    "save_plot(os.path.join(\"source_maps\", \"artifacts\"), \"HESE_123326_artifacts.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Healpy source injection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Draw samples and show how the drawn sources scatter around the best fit position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, inj_i in multi_sig_inj.injs.items():\n",
    "    ra, dec = [], []\n",
    "    for i in range(1000):\n",
    "        sam = inj_i.sample(n_samples=1)\n",
    "        ra.append(inj_i._src_ra)\n",
    "        dec.append(inj_i._src_dec)\n",
    "\n",
    "    ra = np.array(ra)\n",
    "    dec = np.array(dec)\n",
    "\n",
    "    for i, (rai, deci) in enumerate(zip(ra.T, dec.T)):\n",
    "        plt.scatter(rai, deci, color=\"C{}\".format(i % 10), marker=\".\")\n",
    "        plt.plot(inj_i._srcs[\"ra\"][i], inj_i._srcs[\"dec\"][i],\n",
    "                 marker=\"o\", c=\"k\")\n",
    "\n",
    "    plt.xlim(0., 2. * np.pi)\n",
    "    plt.ylim(-np.pi / 2., np.pi / 2.)\n",
    "    plt.title(key)\n",
    "    save_plot(os.path.join(\"healpy_injection\", \"allsky\"),\n",
    "              \"sample_{}.png\".format(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Zoom in a cartview with the llh map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mypyscripts.plots.astro import cartzoom_radius\n",
    "\n",
    "for key, inj in multi_sig_inj.injs.items():\n",
    "   # Sample some new source positions\n",
    "    ras, decs = [], []\n",
    "    for _ in range(1000):\n",
    "        _ = inj.sample(n_samples=1)\n",
    "        ras.append(inj._src_ra)\n",
    "        decs.append(inj._src_dec)\n",
    "    ras, decs = map(np.array, (ras, decs))\n",
    "    # Plot sampled positions and fixed source for each map\n",
    "    for i, cdf in enumerate(inj._src_map_CDFs):\n",
    "        # Rebuild map from CDF\n",
    "        map_i = np.diff(np.r_[cdf[0], cdf])\n",
    "        \n",
    "        max_idx = np.argmax(map_i)\n",
    "        ra_src, dec_src = inj._pix2ra[max_idx], inj._pix2dec[max_idx]\n",
    "\n",
    "        # Get declination band\n",
    "        _decs, _, _ = get_pixel_in_sigma_region(pdf_map=map_i, sigma=3)\n",
    "        min_dec, max_dec = np.amin(_decs), np.amax(_decs)\n",
    "        radius = 0.55 * (max_dec - min_dec)\n",
    "\n",
    "        map_i[map_i <= 0] = np.amin(map_i[map_i > 0])\n",
    "        cartzoom_radius(np.log10(map_i), center=[ra_src, dec_src],\n",
    "                        r=radius, cmap=\"viridis_r\")\n",
    "        # Plot declination band\n",
    "        _x0, _x1 = plt.gca().get_xlim()\n",
    "        plt.fill_between(x=[_x0, _x1], y1=[min_dec, min_dec],\n",
    "                         y2=[max_dec, max_dec], alpha=0.1, color=\"k\",\n",
    "                         label=\"MC selection region\")\n",
    "\n",
    "        plt.scatter(ras[:, i], decs[:, i], facecolors=\"w\", marker=\".\",\n",
    "                    edgecolors=\"k\", alpha=0.25, label=\"Injected sources\")\n",
    "        plt.scatter(ra_src, dec_src, marker=\"*\", color=\"C3\", s=30,\n",
    "                    label=\"Best fit HESE\")\n",
    "        plt.legend()\n",
    "        plt.title(\"{}. Source {}\".format(key, i))\n",
    "        save_plot(os.path.join(\"healpy_injection\", \"zoomed_with_map\"),\n",
    "                  \"{}_src_{:02d}\".format(key, i), dpi=200)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nbins = 100\n",
    "nsam = len(exp_off_dict)\n",
    "name2xlabel = {\"ra\": \"RA in rad\",\n",
    "               \"dec\": \"DEC in rad\",\n",
    "               \"logE\": \"log(E / GeV) proxy\",\n",
    "               \"sigma\": \"Circular sigma in deg\"}\n",
    "for name in [\"ra\", \"dec\", \"logE\", \"sigma\"]:\n",
    "    fig, ax = plt.subplots(1, nsam, figsize=(5 * nsam, 4))\n",
    "    for i, key in enumerate(sorted(exp_off_dict.keys())):\n",
    "        if name == \"sigma\":\n",
    "            ax[i].hist(np.rad2deg(exp_off_dict[key][name]), bins=nbins)\n",
    "        else:\n",
    "            ax[i].hist(exp_off_dict[key][name], bins=nbins)\n",
    "        ax[i].set_title(key)\n",
    "        if name in [\"sigma\", \"logE\"]:\n",
    "            ax[i].set_yscale(\"log\")\n",
    "        ax[i].set_xlabel(name2xlabel[name])\n",
    "    fig.tight_layout()\n",
    "    save_plot(\"data_distribution\", name, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### BG splines and sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test if multi sampler samples correctly from each single injector.\n",
    "In the BG case this just collects all single samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "multi_bg_sam_ = [multi_bg_inj.sample() for i in range(n_samples)]\n",
    "multi_bg_sam = {}\n",
    "for key in multi_bg_inj.names:\n",
    "    multi_bg_sam[key] = np.concatenate([sam_i[key] for sam_i in multi_bg_sam_])\n",
    "nsam = map(len, multi_bg_sam.values())\n",
    "for i, key in enumerate(multi_bg_inj.names):\n",
    "    print(\"{:8s} : {}\".format(key, nsam[i]))\n",
    "    \n",
    "name2xlabel = {\"ra\": \"RA in rad\",\n",
    "               \"dec\": \"DEC in rad\",\n",
    "               \"logE\": \"log(E / GeV) proxy\",\n",
    "               \"sigma\": \"Circular sigma in deg\"}\n",
    "nbins = 100\n",
    "for name in [\"ra\", \"dec\", \"logE\", \"sigma\"]:\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(18, 4))\n",
    "    for i, key in enumerate(sorted(multi_bg_inj.names)):\n",
    "        if name == \"sigma\":\n",
    "            ax[i].hist(np.rad2deg(multi_bg_sam[key][name]), bins=nbins)\n",
    "        else:\n",
    "            ax[i].hist(multi_bg_sam[key][name], bins=nbins)\n",
    "        ax[i].set_title(\"{}. {} times sampled BG\".format(key, n_samples))\n",
    "        if name in [\"sigma\", \"logE\"]:\n",
    "            ax[i].set_yscale(\"log\")\n",
    "        ax[i].set_xlabel(name2xlabel[name])\n",
    "    save_plot(os.path.join(\"bg_injector\", \"sample_dist\"),\n",
    "              \"bg_sample_{}.png\".format(name), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show build spline models for time dependent injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100)\n",
    "for key, bg_inj in sorted(multi_bg_inj._injs.items()):\n",
    "    print(\"Plotting for sample '{}'\".format(key))\n",
    "\n",
    "    bins = bg_inj_opts[key][\"sindec_bins\"]\n",
    "    mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "    print(\"Allsky best params: \" + arr2str(\n",
    "        bg_inj._spl_info[\"allsky_best_params\"]))\n",
    "\n",
    "    for n in [\"amp\", \"base\"]:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        spl = bg_inj._spl_info[\"param_splines\"][n]\n",
    "        vals = np.copy(bg_inj._spl_info[\"best_pars_norm\"][n])\n",
    "        err = np.copy(bg_inj._spl_info[\"best_stddevs_norm\"][n])\n",
    "\n",
    "        ax.plot(x, spl(x), color=\"k\")\n",
    "        ax.plot(mids, vals, color=\"C7\", ls=\"--\")\n",
    "        ax.errorbar(mids, vals, yerr=err, fmt=\"o\", color=\"C1\")\n",
    "\n",
    "        if n == \"amp\":\n",
    "            ax.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "        else:\n",
    "            ax.set_ylim(0, None)\n",
    "\n",
    "        ax.set_xlabel(\"sindec\")\n",
    "        ax.set_ylabel(n)\n",
    "        ax.set_title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "        # Show sindec bin borders\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.vlines(bins, ylim[0], ylim[1], linestyles=\":\", colors=\"C7\")\n",
    "        ylim = ax.set_ylim(ylim)\n",
    "        save_plot(os.path.join(\"bg_injector\", \"param_splines\"),\n",
    "                  \"{}_{}.png\".format(key, n))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot rates vs rate model for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, bg_inj in sorted(multi_bg_inj._injs.items())[:]:\n",
    "    # Show also rebinned\n",
    "    rebin = rebin_rate_rec(rate_rec=rate_recs_dict[key],\n",
    "                           bins=bg_inj_opts[key][\"rate_rebins\"],\n",
    "                           ignore_zero_runs=True)\n",
    "    rates, bins, rate_std, _ = rebin\n",
    "\n",
    "    mids = 0.5 * (rate_recs_dict[key][\"start_mjd\"] +\n",
    "                  rate_recs_dict[key][\"stop_mjd\"])\n",
    "    diff = rate_recs_dict[key][\"stop_mjd\"] - rate_recs_dict[key][\"start_mjd\"]\n",
    "    t = np.linspace(bins[0], bins[-1], 200)\n",
    "    \n",
    "    # Plot it\n",
    "    plt.errorbar(mids, rate_recs_dict[key][\"rate\"],\n",
    "                 xerr=diff, yerr=rate_recs_dict[key][\"rate_std\"],\n",
    "                 fmt=\",\", color=\"C0\", alpha=0.5, zorder=-5)\n",
    "    plt.plot(bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "    plt.plot(t, bg_inj._spl_info[\"allsky_rate_func\"].bf_fun(t),\n",
    "             color=\"C3\", lw=2)\n",
    "        \n",
    "    plt.ylim(0, 0.015)\n",
    "    plt.xlabel(\"time in MJD days\")\n",
    "    plt.ylabel(\"Rate in Hz\")\n",
    "    plt.title(\"Allsky rate model for sample {}\".format(key))\n",
    "    save_plot(os.path.join(\"bg_injector\", \"rate_models_and_rates\"),\n",
    "              key + \".png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot rate model for each sindec bin per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, bg_inj in sorted(multi_bg_inj._injs.items())[:]:\n",
    "    print(\"Making plots for sample: '{}'\".format(key))\n",
    "    runids = exp_off_dict[key][\"Run\"]\n",
    "    sindec = np.sin(exp_off_dict[key][\"dec\"])\n",
    "    sd_bins = bg_inj_opts[key][\"sindec_bins\"]\n",
    "    rate_fun = bg_inj._spl_info[\"allsky_rate_func\"]\n",
    "\n",
    "    # Make a plot grid\n",
    "    nplots, nrows, ncols = 20, 4, 5\n",
    "    assert ncols * nrows == nplots\n",
    "    assert nplots == len(sd_bins) - 1\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(24, 13.5),\n",
    "                           sharex=True, sharey=True)\n",
    "    \n",
    "    for i, (lo, hi) in enumerate(zip(sd_bins[:-1], sd_bins[1:])):\n",
    "        mask = (sindec >= lo) & (sindec < hi)\n",
    "        recs = make_rate_records(run_list=runlists_dict[key],\n",
    "                                 ev_runids=runids[mask])\n",
    "        rebin = rebin_rate_rec(\n",
    "            rate_rec=recs, bins=bg_inj_opts[key][\"rate_rebins\"],\n",
    "            ignore_zero_runs=True)\n",
    "        rates, bins, rate_std, _ = rebin\n",
    "        \n",
    "        mids = 0.5 * (recs[\"start_mjd\"] + recs[\"stop_mjd\"])\n",
    "        diff = recs[\"stop_mjd\"] - recs[\"start_mjd\"]\n",
    "        t = np.linspace(bins[0], bins[-1], 200)\n",
    "        \n",
    "        amp, base = bg_inj._spl_info[\"best_pars\"][i]\n",
    "        pars = (amp, bg_inj._spl_info[\"allsky_best_params\"][1], base)\n",
    "        lab = \"{:.2f} <= sindec < {:.2f}\".format(lo, hi)\n",
    "        \n",
    "        # Plot it\n",
    "        row, col = plots.idx2rowcol(i, ncols=ncols)\n",
    "        ax_ = ax[row, col]\n",
    "        ax_.errorbar(mids, recs[\"rate\"], xerr=diff, yerr=recs[\"rate_std\"],\n",
    "                     fmt=\",\", color=\"C0\", alpha=0.5, label=lab, zorder=-5)\n",
    "        ax_.plot(bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "        ax_.plot(t, rate_fun.fun(t, pars), color=\"C3\", lw=2.5)\n",
    "\n",
    "        ax_.set_ylim(0, 0.001)\n",
    "        ax_.legend(loc=\"upper right\")\n",
    "    ax[0, 0].text(s=\"Sample: '{}'\".format(key), x=bins[0], y=0.0009,\n",
    "                  bbox={\"facecolor\": \"w\", \"alpha\": 0.5}, fontsize=12)\n",
    "    save_plot(os.path.join(\"bg_injector\", \"rate_models_per_dec_bin\"),\n",
    "              key + \".png\", dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compare hist to allsky model\n",
    "x = np.linspace(-1, 1, 200)\n",
    "for key, bg_inj in sorted(multi_bg_inj._injs.items())[:]:\n",
    "    bins = bg_inj_opts[key][\"sindec_bins\"]\n",
    "    plt.vlines(bins, 0, 1, linestyles=\"--\",\n",
    "               colors=\"C7\", zorder=-1)\n",
    "    bins = np.linspace(-1, 1, 100)\n",
    "    h, b = np.histogram(np.sin(exp_off_dict[key][\"dec\"]),\n",
    "                        bins=bins, density=False)\n",
    "    m = 0.5 * (b[:-1] + b[1:])\n",
    "    norm = np.diff(b) * np.sum(h)\n",
    "    err = np.sqrt(h)\n",
    "    h_n = h / norm\n",
    "    err_n = err / norm\n",
    "    \n",
    "    plt.plot(b, np.r_[h_n[0], h_n], drawstyle=\"steps-pre\", c=\"C0\")\n",
    "    plt.errorbar(m, h_n, yerr=err_n, fmt=\",\", color=\"C0\")\n",
    "    \n",
    "    plt.plot(x, bg_inj._spl_info[\"data_sin_dec_pdf_spline\"](x), c=\"C1\")\n",
    "    plt.title(key)\n",
    "#     save_plot(os.path.join(\"bg_injector\", \"allsky_model\"),\n",
    "#               key + \".png\", dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show that sampled distribtuion follows PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, bg_inj in multi_bg_inj.injs.items():\n",
    "    print(\"Sample \", key)\n",
    "    nsrcs = len(bg_inj.srcs)\n",
    "    sam = [list() for _ in range(nsrcs)]\n",
    "    # Sample a few times to have better stats for smaller timw windows\n",
    "    nsamples = 5000\n",
    "    for _ in range(nsamples):\n",
    "        sami = bg_inj.sample(debug=True)\n",
    "        src_idx = bg_inj._sample_idx[\"src_idx\"]\n",
    "        for j in range(nsrcs):\n",
    "            sam[j].append(sami[src_idx == j])\n",
    "\n",
    "    sam = [np.concatenate(sami) for sami in sam]\n",
    "    # These should match closely\n",
    "    print(map(lambda spl: spl.integral(-1, 1),\n",
    "              bg_inj._spl_info[\"sin_dec_splines\"]))\n",
    "    print(bg_inj._nb)\n",
    "    \n",
    "    # Plot average all data distribution and the spline for each source\n",
    "    x = np.linspace(-1, 1, 200)\n",
    "    sindec_bins = bg_inj.inj_opts[\"sindec_bins\"]\n",
    "    _bins = np.linspace(-1, 1, 50)\n",
    "\n",
    "    for j, sami in enumerate(sam):\n",
    "        plt.vlines(sindec_bins, 0, 1, linestyles=\"--\", colors=\"C7\", zorder=-1)\n",
    "        # Plot allyear sample for comparison\n",
    "        h, b, _ = plt.hist(np.sin(exp_off_dict[key][\"dec\"]), bins=sindec_bins,\n",
    "                           density=True, color=\"C7\", alpha=0.5)\n",
    "        _spl = fit_spl_to_hist(h=h, bins=b)[0]\n",
    "        plt.plot(x, _spl(x), color=\"C0\", ls=\":\", lw=3)\n",
    "        # Drawn sample per source. Red hist should approx. follow black spline\n",
    "        h, b = np.histogram(np.sin(sami[\"dec\"]), bins=_bins, density=False)\n",
    "        norm = np.sum(h) * np.diff(b)\n",
    "        err = np.sqrt(h) / norm\n",
    "        h = h / norm\n",
    "        m = 0.5 * (b[:-1] + b[1:])\n",
    "        plt.plot(b, np.r_[h[0], h], drawstyle=\"steps-pre\", lw=2.5, color=\"C3\")\n",
    "        plt.errorbar(m, h, yerr=err, fmt=\",\", color=\"C3\")\n",
    "        plt.plot(x, bg_inj._spl_info[\"sin_dec_pdf_splines\"][j](x), color=\"k\")\n",
    "        plt.xlabel(\"sin dec\")\n",
    "        plt.ylabel(\"PDF\")\n",
    "        plt.title(\"{}. Source {:02d}\".format(key, j))\n",
    "\n",
    "        save_plot(os.path.join(\"bg_injector\", \"sindec_splines\"),\n",
    "                  \"{}_src_{:02d}.png\".format(key, j))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show sampling weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, bg_inj in multi_bg_inj.injs.items():\n",
    "    pts = np.sin(exp_off_dict[key][\"dec\"])\n",
    "    idx = np.argsort(pts)\n",
    "    pts = pts[idx]\n",
    "\n",
    "    nsrcs = len(bg_inj.srcs)\n",
    "    c = plt.cm.inferno(np.linspace(0, 0.8, nsrcs))\n",
    "    for j, w in enumerate(bg_inj._spl_info[\"sample_weights\"]):\n",
    "        plt.plot(pts, w[idx], label=\"source {}\".format(j), color=c[j])\n",
    "\n",
    "    plt.axhline(1, 0, 1, c=\"k\")\n",
    "    plt.xlabel(\"sin dec\")\n",
    "    plt.ylabel(\"Sample weights\")\n",
    "    plt.title(\"{}\".format(key))\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(0.75, 1.5)   \n",
    "    plt.legend(ncol=nsrcs // 5 + 1, loc=\"best\")\n",
    "\n",
    "    save_plot(os.path.join(\"bg_injector\", \"sample_weights\"),\n",
    "              \"{}_sample_weights.png\".format(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### MC injector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test splitting of signal samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsamples = 10000\n",
    "multi_sig_sam = multi_sig_inj.sample(n_samples=nsamples)\n",
    "# Total sample weight should be normed to 1\n",
    "print(sum(map(len, (multi_sig_sam.values()))))\n",
    "print(nsamples * sum(multi_sig_inj._distribute_weights.values()))\n",
    "# Show sampled events from each injector and split weights normed to tot samples\n",
    "print(dict_map(lambda key, sam: len(sam), multi_sig_sam))\n",
    "print(dict_map(lambda key, wts: \"{:.1f}\".format(wts * nsamples),\n",
    "               multi_sig_inj._distribute_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show sample distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, sami in multi_sig_sam.items():\n",
    "    # Sampled MC hist\n",
    "    _inj = multi_sig_inj.injs[key]\n",
    "    _idx = multi_sig_inj.injs[key]._sample_idx\n",
    "    for name in [\"ra\", \"dec\", \"logE\", \"time\", \"sigma\"]:\n",
    "        # Show sampled data-like attributes\n",
    "        if name != \"time\":\n",
    "            # Compare to full MC pool distribution\n",
    "            w = _inj._MC[\"ow\"] * _inj.flux_model(_inj._MC[\"trueE\"])\n",
    "            if name == \"sigma\" and key == \"IC86_2015\":\n",
    "                bins = np.linspace(0, np.amax(sami[name]), 100)\n",
    "            else:\n",
    "                bins = 100\n",
    "\n",
    "            _ = plt.hist(_inj._MC[name], weights=w, density=True, bins=bins,\n",
    "                         alpha=.5)\n",
    "            _ = plt.hist(sami[name], density=True, bins=bins,\n",
    "                         histtype=\"step\", lw=3)\n",
    "        if name in [\"ra\", \"dec\"]:\n",
    "            plt.vlines(_inj.srcs[name], 0, 1)\n",
    "            plt.yscale(\"log\", nonposy=\"clip\")\n",
    "        if name == \"time\":\n",
    "            ts = _inj.srcs[\"time\"]\n",
    "            dt0s, dt1s = _inj.srcs[\"dt0\"], _inj.srcs[\"dt1\"]\n",
    "            for j in range(len(ts)):\n",
    "                plt.title(\"{}. {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "                    name, ts[j], dt0s[j], dt1s[j]))\n",
    "                mask = (_idx[\"src_idx\"] == j)\n",
    "                trel = (ts[j] - sami[name][mask]) * SECINDAY\n",
    "                _ = plt.hist(trel, density=False, bins=bins,\n",
    "                             histtype=\"step\", lw=3)\n",
    "                plt.axvline(0, 0, 1)\n",
    "                plt.axvline(dt0s[j], 0, 1, ls=\"--\")\n",
    "                plt.axvline(dt1s[j], 0, 1, ls=\"--\")\n",
    "                save_plot(os.path.join(\"sig_inj\", \"sample\"),\n",
    "                          \"{}_time_src_{}.png\".format(key, j), dpi=150)\n",
    "                plt.show()\n",
    "        else:\n",
    "            plt.title(\"{}: {}\".format(key, name))\n",
    "            save_plot(os.path.join(\"sig_inj\", \"sample\"),\n",
    "                      \"{}_{}.png\".format(key, name), dpi=150)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sample from each injector on its own and show that the expected number of events match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nsamples = 10000\n",
    "\n",
    "# Plot for each sample\n",
    "for key in sorted(multi_sig_inj.injs.keys()):\n",
    "    _inj = multi_sig_inj.injs[key]\n",
    "    _grb_mod = multi_llh.model[key]\n",
    "    _Xsig = _inj.sample(n_samples=nsamples)\n",
    "    _src_idx = _inj._sample_idx[\"src_idx\"]\n",
    "\n",
    "    bins = _grb_mod._spatial_opts[\"sindec_bins\"]\n",
    "    mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "    lo, hi = bins[0], bins[-1]\n",
    "\n",
    "    # Make signal distribution from which is sampled\n",
    "    w_sig = mc_dict[key][\"ow\"] * _inj._flux_model(mc_dict[key][\"trueE\"])\n",
    "    sindec = np.sin(mc_dict[key][\"trueDec\"])\n",
    "    hist, _ = np.histogram(sindec, bins=bins, weights=w_sig)\n",
    "    var, _ = np.histogram(sindec, bins=bins, weights=w_sig**2)\n",
    "    dA = np.diff(bins)\n",
    "    hist = hist / dA\n",
    "    stddev = np.sqrt(var) / dA\n",
    "\n",
    "    # Normalize hist as injection weights: sum w = 1. Weights from src weights\n",
    "    src_w = _grb_mod.get_args()[\"src_w_dec\"]\n",
    "    norm = np.sum(src_w)\n",
    "    hist = hist / norm\n",
    "    stddev = stddev / norm\n",
    "    spl = _grb_mod._spl_info[\"mc_sin_dec_pdf_spline\"]\n",
    "\n",
    "    # Plot the spline and the histogram\n",
    "    x = np.linspace(lo, hi, 250)\n",
    "    plt.plot(bins, np.r_[hist[0], hist], drawstyle=\"steps-pre\", color=\"C7\")\n",
    "    plt.errorbar(mids, hist, yerr=stddev, fmt=\",\", color=\"C7\")\n",
    "    plt.plot(x, spl(x) / norm)\n",
    "\n",
    "    for j, srci in enumerate(_inj.srcs):\n",
    "        # Plot source positions in dec\n",
    "        plt.axvline(np.sin(srci[\"dec\"]), 0, 1, ls=\"--\", c=\"C7\")\n",
    "        # Plot relativ number of sampled events per src\n",
    "        m = (_src_idx == j)\n",
    "        nsam = np.sum(m) / len(m)\n",
    "        nsam_err = np.sqrt(np.sum(m)) / len(m)\n",
    "        plt.errorbar(np.sin(srci[\"dec\"]), nsam, yerr=nsam_err,\n",
    "                     fmt=\"o\", c=\"C{}\".format(j % 9), zorder=5, alpha=1.)\n",
    "        # Plot 1D scatter of sampled events per source\n",
    "        plt.vlines(np.sin(_Xsig[m][\"dec\"]), -0.15 * np.amax(hist), 0.,\n",
    "                   linestyles=\"-\", colors=\"C{}\".format(j % 9), alpha=0.1)\n",
    "        # Plot expected relativ event numbers (spline values)\n",
    "        plt.plot(np.sin(srci[\"dec\"]), src_w[j] / norm, c=\"C{}\".format(j % 9),\n",
    "                 marker=\"d\", ls=\"\", mec=\"k\", zorder=6)\n",
    "\n",
    "        plt.axhline(0, 0, 1, c=\"k\", ls=\"-\")\n",
    "\n",
    "    plt.ylim(-0.15 * np.amax(hist), None)\n",
    "    plt.title(key)\n",
    "\n",
    "    # plt.savefig(\"/Users/tmenne/Downloads/mc_inject_expect_\" +\n",
    "    #             \"{}_nsam={}.png\".format(sample_name, nsamples), dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now sample the multiinjector and get the events per injector and per source to see that the expectation still matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sample with the multi injector and entangle to check single sample plots\n",
    "nsamples = 10000\n",
    "sam = multi_sig_inj.sample(nsamples)\n",
    "# Get samples event and source indices\n",
    "sig_idx = dict_map(lambda k, inj: inj._sample_idx, multi_sig_inj.injs)\n",
    "\n",
    "# Print stats\n",
    "print(\"Total samples: \", sum([len(sami) for sami in sam.values()]))\n",
    "for key, sami in sam.items():\n",
    "    _dw = multi_sig_inj._distribute_weights[key]\n",
    "    _space = int(np.ceil(np.log10(nsamples)))\n",
    "    print(\"  - {0:15s}: {1:{3:}d} (Expected: {2:{4:}.1f})\".format(\n",
    "        key, len(sami), nsamples * _dw, _space, _space + 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot for each sample\n",
    "for key in sorted(multi_sig_inj.injs.keys()):\n",
    "    _inj = multi_sig_inj.injs[key]\n",
    "    _grb_mod = multi_llh.model[key]\n",
    "    _Xsig = sam[key]\n",
    "    _src_idx = sig_idx[key][\"src_idx\"]\n",
    "\n",
    "    bins = _grb_mod._spatial_opts[\"sindec_bins\"]\n",
    "    lo, hi = bins[0], bins[-1]\n",
    "    bins = np.linspace(lo, hi, 100)  # Overwrite for finer binning\n",
    "    mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "    # Make signal distribution from which is sampled\n",
    "    w_sig = mc_dict[key][\"ow\"] * _inj._flux_model(mc_dict[key][\"trueE\"])\n",
    "    sindec = np.sin(mc_dict[key][\"trueDec\"])\n",
    "    hist, _ = np.histogram(sindec, bins=bins, weights=w_sig)\n",
    "    var, _ = np.histogram(sindec, bins=bins, weights=w_sig**2)\n",
    "    dA = np.diff(bins)\n",
    "    hist = hist / dA\n",
    "    stddev = np.sqrt(var) / dA\n",
    "\n",
    "    # Normalize hist as injection weights: sum w = 1. Weights from src weights\n",
    "    src_w = _grb_mod.get_args()[\"src_w_dec\"]\n",
    "    norm = np.sum(src_w)\n",
    "    hist = hist / norm\n",
    "    stddev = stddev / norm\n",
    "    spl = _grb_mod._spl_info[\"mc_sin_dec_pdf_spline\"]\n",
    "\n",
    "    # Plot the spline and the histogram\n",
    "    x = np.linspace(lo, hi, 250)\n",
    "    plt.plot(bins, np.r_[hist[0], hist], drawstyle=\"steps-pre\", color=\"C7\")\n",
    "    plt.errorbar(mids, hist, yerr=stddev, fmt=\",\", color=\"C7\")\n",
    "    plt.plot(x, spl(x) / norm)\n",
    "\n",
    "    for j, srci in enumerate(_inj.srcs):\n",
    "        # Plot source positions in dec\n",
    "        plt.axvline(np.sin(srci[\"dec\"]), 0, 1, ls=\"--\", c=\"C7\")\n",
    "        # Plot relativ number of sampled events per src\n",
    "        m = (_src_idx == j)\n",
    "        nsam = np.sum(m) / len(m)\n",
    "        nsam_err = np.sqrt(np.sum(m)) / len(m)\n",
    "        plt.errorbar(np.sin(srci[\"dec\"]), nsam, yerr=nsam_err,\n",
    "                     fmt=\"o\", c=\"C{}\".format(j % 9), zorder=5, alpha=1.)\n",
    "        # Plot 1D scatter of sampled events per source\n",
    "        plt.vlines(np.sin(_Xsig[m][\"dec\"]), -0.15 * np.amax(hist), 0.,\n",
    "                   linestyles=\"-\", colors=\"C{}\".format(j % 9), alpha=0.1)\n",
    "        # Plot expected relativ event numbers (spline values)\n",
    "        plt.plot(np.sin(srci[\"dec\"]), src_w[j] / norm, c=\"C{}\".format(j % 9),\n",
    "                 marker=\"d\", ls=\"\", mec=\"k\", zorder=6)\n",
    "\n",
    "        plt.axhline(0, 0, 1, c=\"k\", ls=\"-\")\n",
    "\n",
    "    plt.ylim(-0.15 * np.amax(hist), None)\n",
    "    plt.title(key)\n",
    "\n",
    "    save_plot(os.path.join(\"sig_inj\", \"mc_inject_expect\"),\n",
    "              \"{}_nsam={}.png\".format(key, len(_src_idx)), dpi=250)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### LLH Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Energy PDF ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, grb_mod_i in multi_llh.model.items():\n",
    "    xbins = grb_mod_i.energy_opts[\"bins\"][0]\n",
    "    ybins = grb_mod_i.energy_opts[\"bins\"][1]\n",
    "\n",
    "    xlo, xhi = np.amin(xbins), np.amax(xbins)\n",
    "    ylo, yhi = np.amin(ybins), np.amax(ybins)\n",
    "\n",
    "    x = np.linspace(xlo, xhi, 250)\n",
    "    y = np.linspace(ylo, yhi, 250)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "    xmids, ymids = map(lambda b: 0.5 * (b[:-1] + b[1:]), [x, y])\n",
    "    XX, YY = map(np.ravel, np.meshgrid(xmids, ymids))\n",
    "    pts = np.vstack((XX, YY)).T\n",
    "\n",
    "    # zz = grb_mod_i._energy_interpol(pts)\n",
    "    zz = grb_mod_i._soverb_energy(XX, YY)\n",
    "    zz = zz.reshape(len(xmids), len(ymids))\n",
    "\n",
    "    plt.pcolormesh(xx, yy, np.log10(zz), cmap=\"coolwarm\", vmin=-3, vmax=3)\n",
    "    cbar = plt.colorbar()\n",
    "\n",
    "    cbar.set_label(\"log10(S/B)\")\n",
    "    plt.xlabel(\"sin(dec)\")\n",
    "    plt.ylabel(\"log10(E proxy / GeV)\")\n",
    "    plt.title(key)\n",
    "\n",
    "    save_plot(os.path.join(\"llh_model\", \"energy_pdfs\"), key, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Expected signal stacking weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot for each sample\n",
    "for key in sorted(multi_sig_inj.injs.keys()):\n",
    "    _inj = multi_sig_inj.injs[key]\n",
    "    _grb_mod = multi_llh.model[key]\n",
    "\n",
    "    bins = np.linspace(-1, 1, 100)\n",
    "    mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "    lo, hi = bins[0], bins[-1]\n",
    "\n",
    "    # Make signal distribution from which is sampled\n",
    "    w_sig = mc_dict[key][\"ow\"] * _inj._flux_model(mc_dict[key][\"trueE\"])\n",
    "    sindec = np.sin(mc_dict[key][\"trueDec\"])\n",
    "    hist, _ = np.histogram(sindec, bins=bins, weights=w_sig)\n",
    "    var, _ = np.histogram(sindec, bins=bins, weights=w_sig**2)\n",
    "    dA = np.diff(bins)\n",
    "    hist = hist / dA\n",
    "    stddev = np.sqrt(var) / dA\n",
    "\n",
    "    # Normalize hist as injection weights: sum w = 1. Weights from src weights\n",
    "    src_w = _grb_mod.get_args()[\"src_w_dec\"]\n",
    "    norm = np.sum(src_w)\n",
    "    hist = hist / norm\n",
    "    stddev = stddev / norm\n",
    "    spl = _grb_mod._spl_info[\"mc_sin_dec_pdf_spline\"]\n",
    "\n",
    "    # Plot the spline and the histogram\n",
    "    x = np.linspace(lo, hi, 250)\n",
    "    plt.plot(bins, np.r_[hist[0], hist], drawstyle=\"steps-pre\", color=\"C7\")\n",
    "    plt.errorbar(mids, hist, yerr=stddev, fmt=\",\", color=\"C7\")\n",
    "    plt.plot(x, spl(x) / norm)\n",
    "\n",
    "    c = plt.cm.inferno(np.linspace(0., 0.8, len(_inj.srcs)))\n",
    "    for j, srci in enumerate(_inj.srcs):\n",
    "        # Plot source positions in dec\n",
    "        plt.axvline(np.sin(srci[\"dec\"]), 0, 1, ls=\"--\", c=\"C7\")\n",
    "        # Plot expected relativ event numbers (spline values)\n",
    "        plt.plot(np.sin(srci[\"dec\"]), src_w[j] / norm, c=c[j], marker=\"d\",\n",
    "                 ls=\"\", mec=\"k\", zorder=6, label=\"src {}\".format(j))\n",
    "        plt.axhline(0, 0, 1, c=\"k\", ls=\"-\")\n",
    "\n",
    "    plt.ylim(-0.15 * np.amax(hist), None)\n",
    "    plt.xlabel(\"sin(dec)\")\n",
    "    plt.title(key)\n",
    "    plt.legend(ncol=len(_inj.srcs) // 5 + 1)\n",
    "\n",
    "    save_plot(os.path.join(\"llh_model\", \"stacking_src_weights\"), key, dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### LLH evaluation, test wrong injection mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make trial data and scan the LLH.\n",
    "Then overestimate n_B and rescan to see the effect.\n",
    "Becuase of the rate function the detector downtime is interpolated over.\n",
    "Thhis leads to overestimated livetime and overestimated background expectation.\n",
    "The injectors suffer the sam eproblem, becuase they inject without regarding the downtimes (uniformly in comlete time window).\n",
    "The trials themsleves are therefore self-consitent but a fit on data would be worse than needed.\n",
    "\n",
    "This tries to estimate the scale of which this affects this analysis.\n",
    "The effective livetime loss is approx. 10% for data compared to trials.\n",
    "So 10% of the data is randomly thrown away after trial generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make a BG trial data set and inject some signal\n",
    "def _concat(X, Xsig):\n",
    "    return dict_map(lambda k, Xi: np.concatenate((Xi, Xsig[k])), X)\n",
    "\n",
    "def _choice(X, eff):\n",
    "    return dict_map(lambda k, Xi: np.random.choice(Xi, replace=False,\n",
    "                                                   size=int(eff * len(Xi))), X)\n",
    "\n",
    "def _drop(X, eff):\n",
    "    return dict_map(lambda k, Xi: Xi[:int(eff * len(Xi))], X)\n",
    "\n",
    "n_sig = 0\n",
    "efficiencies = [0.8, 0.9, 0.95, 1.0]\n",
    "ns_scan = np.linspace(0, 10, 50)\n",
    "\n",
    "X = multi_bg_inj.sample()\n",
    "if n_sig > 0:\n",
    "    Xsig = multi_sig_inj.sample(n_sig)\n",
    "    X = _concat(X, Xsig)\n",
    "map(np.random.shuffle, X.values())\n",
    "\n",
    "ts = np.empty((len(efficiencies), len(ns_scan)), dtype=float)\n",
    "for j, eff in enumerate(efficiencies):\n",
    "    X_use = _drop(X, eff)\n",
    "    for i, nsi in enumerate(ns_scan):\n",
    "        ts[j, i], _ = multi_llh.lnllh_ratio(ns=nsi, X=X_use)\n",
    "        \n",
    "\n",
    "# Plot it\n",
    "for j, eff in enumerate(efficiencies):\n",
    "    plt.plot(ns_scan, ts[j], c=\"C{}\".format(j),\n",
    "             label=r\"$\\epsilon={:.2f}$\".format(eff))\n",
    "    plt.axvline(n_sig, 0, 1, ls=\"--\", c=\"k\")\n",
    "    plt.axvline(ns_scan[np.argmax(ts[j])], 0, 1, ls=\"-\", c=\"k\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now fit a few trials and see the TS changes.\n",
    "It should shift to smaller TS values for less efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _do_comp_trials(ntrials=int(1e5))\n",
    "    def _drop(X, eff):\n",
    "        # Not completely realistic but easiest to simulate data loss\n",
    "        return dict_map(lambda k, Xi: Xi[:int(eff * len(Xi))], X)\n",
    "    \n",
    "    efficiencies = [0.8, 0.9, 0.95, 1.0]\n",
    "    ts = np.empty((len(efficiencies), ntrials), dtype=float)\n",
    "\n",
    "    for i in range(ntrials):\n",
    "        X = multi_bg_inj.sample()\n",
    "        map(np.random.shuffle, X.values())\n",
    "        for j, eff in enumerate(efficiencies):\n",
    "            X_use = _drop(X, eff)\n",
    "            _, ts[j, i] = multi_llh.fit_lnllh_ratio(ns0=0.1, X=X_use)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Trial {}\".format(i))\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_path = os.path.join(PATHS.plots, \"misc\", \"ts_test_nb_var.npy\")\n",
    "try:\n",
    "    ts = np.load(_path)\n",
    "except:\n",
    "    try:\n",
    "        np.save(arr=ts, file=_path)\n",
    "    except:\n",
    "        print(\"No trials found to save or to load, generating new ones.\")\n",
    "        ts = _do_comp_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bins = np.arange(0, np.amax(ts), 0.5)\n",
    "perc_ls = [\":\", \"--\", \"-\"]\n",
    "perc_a = [0.7, 0.8, 0.9]\n",
    "sigmas = [2, 3, 4]\n",
    "test_percs = 100 * sigma2prob(sigmas)\n",
    "percentiles = []\n",
    "\n",
    "for j, eff in enumerate(efficiencies):\n",
    "    c = \"C{}\".format(j)\n",
    "    plt.hist(ts[j], color=c, lw=1.5, bins=bins, density=True,\n",
    "             label=r\"$\\epsilon={:.2f}$\".format(eff), histtype=\"step\")\n",
    "    percentiles.append(np.percentile(ts[j], test_percs))\n",
    "    for i, perc in enumerate(percentiles[-1]):\n",
    "        if j == len(efficiencies) - 1:\n",
    "            label = r\"${:1d}\\sigma$\".format(sigmas[i])\n",
    "        else:\n",
    "            label = None\n",
    "        plt.axvline(perc,0, 1, ls=perc_ls[i], alpha=perc_a[i], c=c, label=label)\n",
    "\n",
    "plt.xlabel(\"test statistic\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.title(\"TS for largest time window for various data dropout efficiencies\")\n",
    "plt.xlim(bins[0], None)\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(ncol=2)\n",
    "plt.tight_layout()\n",
    "save_plot(\"misc\", \"data_dropout_tw_{:02d}.png\".format(tw_id))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Ratios of the 3sigma lines behave exactly as the efficiency ratios. Why?\n",
    "percentiles = np.array(percentiles)\n",
    "percentiles_normalized = percentiles / percentiles[-1]\n",
    "percentiles_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### BG trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Timing tests: For 6 year pass2 HESE, 5 years PS tracks data, 1 year GFU\n",
    "\n",
    "- tw00: 1e8 trials in 11h 19min 6s -> ~2455 trials / sec\n",
    "- tw10: 1e5 trials in ~193s -> ~ 518 trials / sec\n",
    "- tw20: 1e4 trials in ~430s -> ~  23 trials / sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Time window ID is: {}\".format(tw_id))\n",
    "n_trials = int(1e8)\n",
    "n_signal = 0\n",
    "trials, nzeros, nsig = ana.do_trials(n_trials=n_trials, ns0=0.1, full_out=False)\n",
    "\n",
    "ns, ts = trials[\"ns\"], trials[\"ts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out = {\n",
    "    \"ns\": trials[\"ns\"].tolist(),\n",
    "    \"ts\": trials[\"ts\"].tolist(),\n",
    "    \"time_window\": [dt0, dt1],\n",
    "    \"time_window_id\": tw_id,\n",
    "    \"nzeros\": nzeros,\n",
    "    \"rnd_seed\": [42439462],\n",
    "    \"ntrials\": n_trials,\n",
    "    \"ntrials_per_batch\": [n_trials],\n",
    "    }\n",
    "outpath = \"/Users/tmenne/Downloads/\"\n",
    "fpath = os.path.join(outpath, \"tw_{:02d}.json.gz\".format(tw_id))\n",
    "with gzip.open(fpath, \"w\") as outf:\n",
    "    json.dump(out, fp=outf, indent=2)\n",
    "    print(\"- Saved to:\\n    {}\".format(fpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Try stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Create empirical PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "_tw = 20\n",
    "fpath = os.path.join(PATHS.data, \"bg_trials_combined\",\n",
    "                     \"tw_{:02d}.json.gz\".format(_tw))\n",
    "with gzip.open(fpath) as inf:\n",
    "    trials = json.load(inf)\n",
    "    print(\"- Loaded:\\n    {}\".format(fpath))\n",
    "    \n",
    "nzeros = trials[\"nzeros\"]\n",
    "ntrials = trials[\"ntrials\"]\n",
    "trials[\"ts\"] = np.array(trials[\"ts\"])\n",
    "trials[\"ns\"] = np.array(trials[\"ns\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Scan thresholds to select a good one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Scan it\n",
    "emp_dist = stats.emp_with_exp_tail_dist(trials[\"ts\"], trials[\"nzeros\"],\n",
    "                                        thresh=np.amax(trials[\"ts\"]))\n",
    "pval_thresh = 0.5\n",
    "lo, hi = emp_dist.ppf(q=100. * stats.sigma2prob([3., 5.5]))\n",
    "thresh_vals = np.arange(lo, hi, 0.1)\n",
    "best_thresh, best_idx, pvals, scales = stats.scan_best_thresh(\n",
    "    emp_dist, thresh_vals, pval_thresh=pval_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save it in float16\n",
    "fname = \"/Users/tmenne/Downloads/bg_pdf_tw_{:02d}.json.gz\".format(_tw)\n",
    "with gzip.open(fname, \"w\") as f:\n",
    "    emp_dist.to_json(fp=f, dtype=np.float16, indent=1, separators=(\",\",\":\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot ts and ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_bg_pdf_scan_plots(fname, emp_dist, thresh_vals, pvals, scales,\n",
    "                           pval_thresh):\n",
    "    def _plot_sigma_lines(ax, sigmas):\n",
    "        sigmas = np.sort(sigmas)\n",
    "        q = 100. * np.atleast_1d(stats.sigma2prob(sigmas))\n",
    "        _p = stats.percentile_nzeros(emp_dist.data, emp_dist.nzeros,\n",
    "                                     q=q, sorted=True)\n",
    "        for i, pi in enumerate(_p):\n",
    "            ax.axvline(pi, 0, 1, ls=\"--\", c=\"C7\",\n",
    "                       alpha=sigmas[i] / np.amax(sigmas),\n",
    "                       label=r\"{:.1f}$\\sigma$\".format(sigmas[i]))\n",
    "\n",
    "    fig, (axl, axc, axr) = plt.subplots(1, 3, figsize=(17.5, 5))\n",
    "\n",
    "    # ## Left: Plot the selected combined PDF ##\n",
    "    # Plot empirical PDF part\n",
    "    h, b, err, _ = emp_dist.data_hist(dx=.25, density=True, which=\"emp\")\n",
    "    axl.plot(b, np.r_[h[0], h], drawstyle=\"steps-pre\", color=\"k\")\n",
    "    mids = 0.5 * (b[:-1] + b[1:])\n",
    "    axl.errorbar(mids, h, yerr=err, fmt=\",\", color=\"k\")\n",
    "    # Plot exponential data part\n",
    "    h, b, err, _ = emp_dist.data_hist(dx=.25, density=True, which=\"exp\")\n",
    "    axl.plot(b, np.r_[h[0], h], drawstyle=\"steps-pre\", color=\"C7\")\n",
    "    mids = 0.5 * (b[:-1] + b[1:])\n",
    "    axl.errorbar(mids, h, yerr=err, fmt=\",\", color=\"C7\")\n",
    "    # Plot the exponetial PDF part\n",
    "    x = np.linspace(emp_dist.thresh, np.amax(emp_dist.data), 100)\n",
    "    axl.plot(x, emp_dist.pdf(x), color=\"C3\",\n",
    "             label=(\"exp tail\\n\" +\n",
    "                    r\"$\\lambda$={:.2f}\".format(1. / emp_dist.scale)))\n",
    "    axl.axvline(emp_dist.thresh, 0, 1, ls=\":\", color=\"C3\")\n",
    "    _plot_sigma_lines(axl, [3., 4., 5., 5.5])\n",
    "    axl.set_yscale(\"log\", nonposy=\"clip\")\n",
    "    axl.set_xlabel(\"ts\")\n",
    "    axl.set_title(\"Test Statitics\")\n",
    "    axl.legend()\n",
    "\n",
    "    # ## Center: Plot the selected combined p-values ##\n",
    "    x = np.linspace(0, np.amax(emp_dist.data), 500)\n",
    "    cdf_emp = 1. - stats.cdf_nzeros(emp_dist.data, emp_dist.nzeros, vals=x,\n",
    "                                    sorted=True)\n",
    "    cdf_dist = emp_dist.sf(x)\n",
    "    axc.plot(x, cdf_emp, color=\"k\")\n",
    "    axc.plot(x, cdf_dist, color=\"C3\")\n",
    "    axc.axvline(emp_dist.thresh, 0, 1, ls=\":\", color=\"C3\", label=\"threshold\")\n",
    "    _plot_sigma_lines(axc, [3., 4., 5., 5.5])\n",
    "    axc.set_yscale(\"log\", nonposy=\"clip\")\n",
    "    axc.set_xlabel(\"ts\")\n",
    "    axc.set_title(\"p-values\")\n",
    "    axc.legend()\n",
    "\n",
    "    # ## Right: Threshold scan\n",
    "    _plot_sigma_lines(axr, [3., 4., 5., 5.5])\n",
    "    axr.axhline(1, 0, 1, ls=\"--\", c=\"C7\")\n",
    "    axr.axhline(pval_thresh, 0, 1, ls=\"-\", c=\"C7\")      # Rejection line\n",
    "    axr.axvline(emp_dist.thresh, 0, 1, ls=\"-\", c=\"k\")   # Best thresh\n",
    "    axr.plot(thresh_vals, pvals, c=\"C1\", label=\"KS pval\")\n",
    "    axr.plot(thresh_vals, 1. / scales, c=\"C2\", label=\"lambdas\")\n",
    "    axr.set_xlabel(\"ts\")\n",
    "    axr.set_title(\"Best thresh: {:.2f}\".format(emp_dist.thresh))\n",
    "    axr.legend()\n",
    "    \n",
    "    for axi in [axl, axc, axr]:\n",
    "        axi.set_xlim(0, 40)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(fname, dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "make_bg_pdf_scan_plots(\"/Users/tmenne/Downloads/tw_{}.png\".format(_tw),\n",
    "                       emp_dist, thresh_vals, pvals, scales, pval_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot the ns distribution\n",
    "ns = trials[\"ns\"]\n",
    "dx = 0.5\n",
    "bins = np.arange(0, max(1, np.amax(ns)) + dx, dx)\n",
    "mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "h, _ = np.histogram(ns, bins=bins, density=False)\n",
    "h[0] += trials[\"nzeros\"]\n",
    "norm = np.diff(bins) * np.sum(h)\n",
    "err = np.sqrt(h) / norm\n",
    "h = h / norm\n",
    "\n",
    "plt.plot(bins, np.r_[h[0], h], drawstyle=\"steps-pre\", color=\"k\")\n",
    "plt.errorbar(mids, h, yerr=err, fmt=\",\", color=\"k\")\n",
    "    \n",
    "plt.yscale(\"log\", nonposy=\"clip\")\n",
    "plt.xlabel(\"ns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make some CDF, SF and PPF verification plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emp_dist = stats.emp_with_exp_tail_dist(trials[\"ts\"], trials[\"nzeros\"],\n",
    "                                        thresh=best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 30, 500)\n",
    "y = emp_dist.pdf(x, dx=0.25)\n",
    "\n",
    "h, b, _, _ = emp_dist.data_hist(dx=0.25, density=True, which=\"exp\")\n",
    "plt.plot(b, np.r_[h[0], h], drawstyle=\"steps-pre\", c=\"C7\", alpha=.75)\n",
    "\n",
    "plt.plot(x, y, c=\"k\")\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 30, 500)\n",
    "y = emp_dist.cdf(x)\n",
    "plt.plot(x, y, c=\"k\", label=\"fitted CDF\")\n",
    "\n",
    "plt.xlabel(\"test statistic\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.ylim(1. - len(emp_dist.data) / emp_dist.nzeros, 1)\n",
    "plt.ylim(0.9998, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 30, 500)\n",
    "y = emp_dist.sf(x)\n",
    "plt.plot(x, y, c=\"k\", label=\"fitted SF\")\n",
    "\n",
    "y2 = 1. - stats.cdf_nzeros(emp_dist.data, emp_dist.nzeros, vals=x, sorted=True)\n",
    "plt.plot(x, y2, c=\"C3\", ls=\"--\", label=\"empiric SF\")\n",
    "\n",
    "plt.xlabel(\"test statistic\")\n",
    "plt.ylabel(\"p-value\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "q = np.linspace(sigma2prob(4), sigma2prob(6), 500)\n",
    "y = emp_dist.ppf(q * 100.)\n",
    "plt.plot(q, y, c=\"k\", label=\"fitted CDF\")\n",
    "\n",
    "plt.xlabel(\"percentile\")\n",
    "plt.ylabel(\"PPF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Integrate PDF and compare in tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def exp_pdf_integral(exp_pars, bins):\n",
    "    loc, scale = exp_pars\n",
    "    lam = 1. / scale\n",
    "    lo, hi = np.vstack([bins[:-1], bins[1:]])\n",
    "    return np.exp(lam * loc) * (np.exp(-lam * lo) - np.exp(-lam * hi))\n",
    "\n",
    "# Plot data hist\n",
    "dx = 0.25\n",
    "h, b, err, exp_norm = emp_dist.data_hist(dx, density=True, which=\"exp\")\n",
    "plt.plot(bins, np.r_[h_n[0], h_n], drawstyle=\"steps-pre\", color=\"C7\")\n",
    "mids = 0.5 * (b[:-1] + b[1:])\n",
    "plt.errorbar(mids, h, yerr=err, fmt=\",\", color=\"C7\")\n",
    "\n",
    "# Plot binned exponential tail\n",
    "pdf_binned = exp_norm * exp_pdf_integral(\n",
    "    (emp_dist.thresh, emp_dist.scale), b) / np.diff(b)\n",
    "plt.plot(b, np.r_[pdf_binned[0], pdf_binned],\n",
    "         drawstyle=\"steps-pre\", color=\"C3\")\n",
    "\n",
    "plt.xlabel(\"ts\")\n",
    "plt.xlim(emp_dist.thresh, None)\n",
    "plt.ylim(10**np.floor(np.log10(np.amin(pdf_binned))),\n",
    "         10**np.ceil(np.log10(np.amax(pdf_binned))))\n",
    "plt.yscale(\"log\", nonposy=\"clip\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Compare PDFs to independent trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We made a second set of independent trials for all time windows.\n",
    "We can compare the built PDFs with the new trials and see if the model was chosen OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _load_lido_bg_pdfs(tw_id):\n",
    "    path = os.path.join(PATHS.local, \"bg_pdfs_lido\",\n",
    "                        \"bg_pdf_tw_{:02d}.json.gz\".format(tw_id))\n",
    "    with gzip.open(path) as json_file:\n",
    "        emp_dist = stats.emp_with_exp_tail_dist.from_json(json_file)\n",
    "        \n",
    "    return emp_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_ids = loader.time_window_loader()\n",
    "pvals = []\n",
    "\n",
    "dists = []\n",
    "dists_lido = []\n",
    "\n",
    "for _tw in all_ids:\n",
    "    print(\"Testing tw {}\".format(_tw))\n",
    "    emp_dist = loader.bg_pdf_loader(_tw)[_tw]\n",
    "    emp_dist_lido = _load_lido_bg_pdfs(_tw)\n",
    "    \n",
    "    # Get best fit loc, scale from original trials\n",
    "    loc, scale = emp_dist.thresh, emp_dist.scale\n",
    "    # Get the lido trial data for the KS test in that region\n",
    "    emp_dist_lido.fit_thresh(loc)\n",
    "    lido_over_thresh_data, _ = emp_dist_lido.get_split_data(emp=False)\n",
    "    \n",
    "    pvals.append(scs.kstest(lido_over_thresh_data, \"expon\",\n",
    "                            args=(loc, scale)).pvalue)\n",
    "    dists.append(emp_dist)\n",
    "    dists_lido.append(emp_dist_lido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(all_ids, pvals)\n",
    "plt.yscale(\"log\")\n",
    "for sigi in sigma2prob([1, 2, 3, 4, 5]):\n",
    "    plt.axhline(1. - sigi, 0, 1, ls=\"--\", c=\"C7\")\n",
    "plt.xticks(all_ids[::2])\n",
    "plt.xlabel(\"tw ID\")\n",
    "plt.ylabel(\"p-value\")\n",
    "plt.xlim(all_ids[0], all_ids[-1])\n",
    "plt.ylim(None, 1)\n",
    "\n",
    "save_plot(os.path.join(\"bg_trials\", \"ks_test_lido_trials\"), \"pvalues.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, ed in enumerate(dists):\n",
    "    x = np.linspace(0, ed.data.max(), 500)\n",
    "    y = ed.pdf(x, dx=0.1)\n",
    "    h, b, err, norm = dists_lido[i].data_hist(dx=0.25, which=\"exp\",\n",
    "                                              density=True)\n",
    "    m = 0.5 * (b[:-1] + b[1:])\n",
    "\n",
    "    plt.plot(b, np.r_[h[0], h], c=\"C7\", drawstyle=\"steps-pre\",\n",
    "             label=\"lido trials\")\n",
    "    plt.errorbar(m, h, yerr=err, c=\"C7\", fmt=\",\")\n",
    "    plt.plot(x, y, label=\"orig trial PDF\")\n",
    "\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(i)\n",
    "    plt.legend()\n",
    "    save_plot(os.path.join(\"bg_trials\", \"ks_test_lido_trials\", \"dist_compare\"),\n",
    "              \"tw_{:02d}.png\".format(i), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Post Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fname = os.path.join(PATHS.local, \"post_trials_combined\", \"post_trials.json.gz\")\n",
    "with gzip.open(fname) as infile:\n",
    "    post_trials = json.load(infile)\n",
    "    post_trials[\"ts\"] = np.array(post_trials[\"ts\"])\n",
    "    post_trials[\"ns\"] = np.array(post_trials[\"ns\"])\n",
    "    print(\"Loaded post trials from:\\n  {}\".format(fname))\n",
    "        \n",
    "ts = post_trials[\"ts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show TS values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TS values per time window\n",
    "for i, tsi in enumerate(ts.T):\n",
    "    plt.plot(tsi + 2 * i, zorder=-i)\n",
    "plt.show()\n",
    "\n",
    "# Show histogram of each time window, should be similar to other BG trials\n",
    "bins = np.arange(0, np.amax(ts), 0.25)\n",
    "for i in range(len(ts.T)):\n",
    "    plt.hist(ts.T[i], bins=bins, density=True, alpha=0.1)\n",
    "    plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now load the BG only test statistic PDFs and pick the highest p-value per trial to build the post trial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bg_pdfs = loader.bg_pdf_loader(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculate all p-values from the BG only test statistics\n",
    "pvals = np.ones_like(ts)\n",
    "for i, bg_pdf in bg_pdfs.items():\n",
    "    pvals[:, i] = bg_pdf.sf(ts[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create an empirical PDF object for the post trial PDF\n",
    "post_pvals = np.amin(pvals, axis=1)\n",
    "neglogpvals = -np.log10(post_pvals)\n",
    "post_neglog10_pdf = stats.emp_dist(neglogpvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot the -log10(p-val) test statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_LOG = True\n",
    "# Distribution of best p-val per trial (p=1. excluded)\n",
    "bins = np.arange(0, int(np.amax(neglogpvals)) + 1, 0.1)\n",
    "mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "sigmas = [1, 2, 3, 4]\n",
    "ls = [\":\", \"--\", \"-.\", \"-\"]\n",
    "\n",
    "# Make hist and sqrt(N) errs\n",
    "h, _ = np.histogram(neglogpvals, bins=bins, density=False)\n",
    "err = np.sqrt(h)\n",
    "norm = np.sum(h) * np.diff(bins)\n",
    "h_n = h / norm\n",
    "err_n = err / norm\n",
    "\n",
    "# \"Broken\" axis for the zero entries\n",
    "height_ratios = [1, 3]\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=height_ratios)\n",
    "axt = plt.subplot(gs[0])\n",
    "ax = plt.subplot(gs[1])\n",
    "\n",
    "axt.hist(neglogpvals, bins=bins, density=True, color=\"C7\", alpha=0.5)\n",
    "axt.hist(neglogpvals, bins=bins, density=True, color=\"k\", histtype=\"step\")\n",
    "\n",
    "ax.plot(bins, np.r_[h_n[0], h_n], c=\"k\", drawstyle=\"steps-pre\", lw=1)\n",
    "ax.errorbar(mids, h_n, yerr=err_n, c=\"k\", fmt=\",\", elinewidth=1, ms=0)\n",
    "ax.hist(neglogpvals, bins=bins, density=True, color=\"C7\", alpha=0.5)\n",
    "\n",
    "# Adapt y-lims so the markers show the same distances (only for lin-lin axes)\n",
    "ax_ymax = np.sort(h_n)[-2] + 0.05\n",
    "axt_ymax = np.amax(h_n) + 0.05\n",
    "axt_ymin = axt_ymax - ax_ymax * height_ratios[0] / height_ratios[1]\n",
    "axt.set_ylim(axt_ymin, axt_ymax)\n",
    "\n",
    "if _LOG:\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylim(10**np.floor(np.log10(np.amin(h_n[h_n>0]))), ax_ymax)\n",
    "else:\n",
    "    ax.set_ylim(0, ax_ymax)\n",
    "\n",
    "ax.set_xlim(0, np.amax(neglogpvals) + 0.2)\n",
    "axt.set_xlim(ax.get_xlim())\n",
    "\n",
    "# Broken axis: matplotlib.org/2.0.2/examples/pylab_examples/broken_axis.html\n",
    "def breakmarks(ax, hr, d=0.01, where=\"top\"):\n",
    "    # hr: height ratios to make both diag lines have same slope\n",
    "    kwargs = dict(transform=ax.transAxes, clip_on=False, c=\"k\", lw=1)\n",
    "    if where == \"top\":\n",
    "        ax.plot((-d, +d), (-d * hr[1], +d * hr[1]), **kwargs)\n",
    "        ax.plot((1 - d, 1 + d), (-d * hr[1], +d * hr[1]), **kwargs)\n",
    "    elif where == \"bottom\":\n",
    "        ax.plot((-d, +d), (1 - d * hr[0], 1 + d * hr[0]), **kwargs)\n",
    "        ax.plot((1 - d, 1 + d), (1 - d * hr[0], 1 + d * hr[0]), **kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"'where' can be 'top' or 'bottom'.\")\n",
    "\n",
    "# Plot sigma lines\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    perc = 100 * sigma2prob(sigma)\n",
    "    ax.axvline(post_neglog10_pdf.ppf(perc), 0, 1.47, c=\"k\", ls=ls[i],\n",
    "                label=r\"${}\\sigma$\".format(sigma), clip_on=False)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.xaxis.tick_bottom()\n",
    "axt.spines['bottom'].set_visible(False)\n",
    "axt.xaxis.tick_top()\n",
    "axt.tick_params(labeltop='off')  # don't put tick labels at the top\n",
    "breakmarks(axt, hr=height_ratios, where=\"top\")\n",
    "breakmarks(ax, hr=height_ratios, where=\"bottom\")\n",
    "\n",
    "ax.set_xlabel(r\"Pre-trial $-\\log_{10}(p)$\")\n",
    "axt.set_title(\"Pre trial p-value distribution\")\n",
    "ax.legend()\n",
    "\n",
    "save_plot(\"post_trials\", \"post_trials{}.png\".format(\"_log\" if _LOG else \"\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show post-trial(pre-trial) dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "thresh = np.amin(neglogpvals[neglogpvals > 0])\n",
    "\n",
    "neglog10_pre_trial = np.linspace(thresh, -np.log10(1. - sigma2prob(4)))\n",
    "_post_trial_vals = post_neglog10_pdf.sf(neglog10_pre_trial)\n",
    "neglog10_post_trial = -np.log10(_post_trial_vals)\n",
    "\n",
    "# Ratio between log10 post and pre trial, must be < 1\n",
    "plt.plot(neglog10_pre_trial, neglog10_post_trial / neglog10_pre_trial,\n",
    "         color=\"k\", lw=2.5)\n",
    "plt.axhline(1, 0, 1, c=\"C7\", ls=\"--\")\n",
    "plt.xlabel(r\"Pre-trial $-\\log_{10}(p)$\")\n",
    "plt.ylabel(\"post / pre trial p-value\")\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, 2)\n",
    "save_plot(\"post_trials\", \"pre_vs_post_ratio.png\")\n",
    "plt.show()\n",
    "\n",
    "# Same but in sigma significance\n",
    "plt.plot(prob2sigma(1. - 10**-neglog10_pre_trial),\n",
    "         prob2sigma(1. - 10**-neglog10_post_trial), color=\"k\", lw=2.5)\n",
    "plt.plot([0, 5], [0, 5], c=\"C7\", ls=\"--\")\n",
    "plt.xlabel(r\"Pre-trial significance in $\\sigma$\")\n",
    "plt.ylabel(r\"Post-trial significance in $\\sigma$\")\n",
    "plt.xlim(0, 5)\n",
    "plt.ylim(0, 5)\n",
    "plt.grid()\n",
    "save_plot(\"post_trials\", \"pre_vs_post_sigmas.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show all p-values per time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i, pvali in enumerate(pvals.T):\n",
    "    plt.plot(pvali + 0 * i, zorder=-i)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show histogram of all pre-trial p-values per time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# p-vals should be approx. uniform in all windows, because we inject uniformly\n",
    "# and the background expectation is also almost uniformly. Although we see that\n",
    "# it doesn't quite hold for small time windows.\n",
    "dx = 0.01\n",
    "bins = np.arange(0., np.amax(pvals[pvals<1]) + dx, dx)  # (p=1. excluded)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(pvals.T)))\n",
    "for i, pvali in enumerate(pvals.T):\n",
    "    plt.hist(pvali, bins=bins, density=False, zorder=-i, color=colors[i],\n",
    "             alpha=.2)\n",
    "    plt.hist(pvali, bins=bins, density=False, zorder=-i,\n",
    "             color=\"k\", histtype=\"step\", alpha=i / len(pvals.T))\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"p value\")\n",
    "plt.show()\n",
    "\n",
    "# Same in -log10(p-val)\n",
    "dx = 0.1\n",
    "bins = np.arange(0.1, 6. + dx, dx)  # (p=1. excluded)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(pvals.T)))\n",
    "for i, pvali in enumerate(pvals.T):\n",
    "    _neglogp = -np.log10(pvali)\n",
    "    plt.hist(_neglogp, bins=bins, density=False, zorder=-i, color=colors[i],\n",
    "             alpha=0.2)\n",
    "    plt.hist(_neglogp, bins=bins, density=False, zorder=-i,\n",
    "             color=\"k\", histtype=\"step\", alpha=i / len(pvals.T))\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"-log10(p)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The percentage of zero trials should approx. be the same as for the single BG trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for j in range(len(ts.T)):\n",
    "    print(\"TW ID: \", j)\n",
    "    print(\" Post Trials, % zeros: \", np.sum(ts[:, j] == 0) / len(ts[:, j]) * 100)\n",
    "    print(\" BG trials, % nzeros : \", bg_pdfs[j].nzeros / 1e8 * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "beta = 0.9\n",
    "ts_val = 0.\n",
    "ns0 = 1.\n",
    "mu_sig = np.r_[0.1, 0.5, np.arange(1, 20, 1)]\n",
    "n_batch_trials = 2500\n",
    "\n",
    "perf = ana.performance(ts_val=ts_val, beta=beta, mus=mu_sig, ns0=ns0,\n",
    "                       n_batch_trials=n_batch_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get n sigma ts values from BG PDF and show performance for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Change typ 'healpy' |'ps' and make all plots in cells below\n",
    "typ = \"ps\"\n",
    "sigmas = [1, 2, 3, 4, 5]\n",
    "betas = [0.9, 0.9, 0.9, 0.9, 0.9]\n",
    "tw_ids = loader.time_window_loader()\n",
    "\n",
    "# Store mus per sigma, beta and tw combination\n",
    "mu_bfs = []\n",
    "ts_vals = []\n",
    "\n",
    "for _tw in tw_ids:\n",
    "    emp_dist = loader.bg_pdf_loader(_tw)[_tw]\n",
    "    perf = loader.perf_trials_loader(typ=typ, idx=_tw)[_tw]\n",
    "\n",
    "    ts_vals_tw = emp_dist.ppf(q=100. * sigma2prob(sigmas))\n",
    "    ts_vals.append(ts_vals_tw)\n",
    "\n",
    "    x = np.linspace(0, perf[\"mus\"][-1], 100)\n",
    "    ls = [\"-\", \"-.\", \"--\", \":\", \":\"][::-1]\n",
    "    assert len(ls) == len(ts_vals_tw)\n",
    "\n",
    "    # Plot performances\n",
    "    mu_bfs.append([])\n",
    "    for beta in betas:\n",
    "        plt.axhline(beta, 0, 1, ls=\":\", color=\"k\")\n",
    "    for i, ts_vali in enumerate(ts_vals_tw):\n",
    "        p0 = [1., 1., 1.]\n",
    "        mu_bf, cdfs, pars = stats.fit_chi2_cdf(ts_val=ts_vali, beta=betas[i],\n",
    "                                               ts=perf[\"ts\"], mus=perf[\"mus\"],\n",
    "                                               p0=p0)\n",
    "        print(pars)\n",
    "        mu_bfs[-1].append(mu_bf)\n",
    "\n",
    "        plt.axvline(mu_bf, 0, 1, ls=ls[i], color=\"k\", alpha=.5)\n",
    "        plt.errorbar(perf[\"mus\"], 1. - cdfs, fmt=\".\", color=\"k\")\n",
    "        if ts_vali == 0:\n",
    "            _label = r\"{:.0%} > 0\".format(betas[i])\n",
    "        else:\n",
    "            _label = r\"{:.0%} > {:.0f}$\\sigma$\".format(betas[i], sigmas[i])\n",
    "        if ts_vali == 0. and i > 0:\n",
    "            pass\n",
    "        else:\n",
    "            plt.plot(x, scs.chi2.cdf(x, *pars), color=\"C7\", ls=ls[i],\n",
    "                     label=_label)\n",
    "\n",
    "    plt.xlim(0, None)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(\"Mean injected\")\n",
    "    plt.ylabel(\"Fraction of TS\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"Time window {:02d}\".format(_tw))\n",
    "    plt.tight_layout()\n",
    "    save_plot(os.path.join(\"performance\", typ, \"chi2_fits\"),\n",
    "              \"tw_{:02d}.png\".format(_tw), dpi=250)\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Done!\")\n",
    "\n",
    "mu_bfs = np.array(mu_bfs)\n",
    "ts_vals = np.array(ts_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot BG PDF n sigma per time windows overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_dt0, _dt1 = loader.time_window_loader(\"all\")\n",
    "_dt = _dt1 - _dt0\n",
    "\n",
    "ls = [\"-\", \"--\", \"-.\", \":\", \"-\"][::-1]\n",
    "alpha = [1, 1, 1, 1, 0.5][::-1]\n",
    "\n",
    "for i, ts_vals_i in enumerate(ts_vals.T[:5]):\n",
    "    plt.plot(_dt, ts_vals_i, ls=ls[i], color=\"#353132\",\n",
    "             alpha=alpha[i], label=r\"{}$\\sigma$\".format(sigmas[i]))\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Time window length in seconds\")\n",
    "plt.ylabel(\"TS value\")\n",
    "plt.legend(ncol=2, framealpha=0)\n",
    "save_plot(\"performance\", \"ts_vals.png\", dpi=200)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot performance in n inj and flux per for each trial type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_perf_vs_dt(mu_bfs, sigmas, betas, ls, alphas, typ, mu2flux=None):\n",
    "    from scipy.optimize import brentq\n",
    "    def get_poisson_ul(a, b, k=0, beta=0.9):\n",
    "        return brentq(lambda mu: scs.poisson.sf(k=k, mu=mu) - beta, a, b)\n",
    "\n",
    "    _dt0, _dt1 = loader.time_window_loader(\"all\")\n",
    "    _dt = _dt1 - _dt0\n",
    "\n",
    "    try:\n",
    "        poisson_k0_90ul = mu2flux(get_poisson_ul(2, 3, k=0, beta=0.9))\n",
    "    except:\n",
    "        poisson_k0_90ul = get_poisson_ul(2, 3, k=0, beta=0.9)\n",
    "    plt.axhline(poisson_k0_90ul, 0, 1, ls=\":\", alpha=1, color=\"C7\",\n",
    "                label=\"Poisson zero BG 90% UL\")\n",
    "\n",
    "    for i, mu_bfs_i in enumerate(mu_bfs.T):\n",
    "        if mu2flux is None:\n",
    "            vals = mu_bfs_i\n",
    "            ylabel = \"Mean injected no. of events\"\n",
    "            info = \"ninj\"\n",
    "        else:\n",
    "            vals = mu2flux(mu_bfs_i)\n",
    "            ylabel = (r\"Mean injected flux \" +\n",
    "                      r\"$\\left(\\frac{E}{\\mathrm{GeV}}\\right)^2\\phi$ \" +\n",
    "                      r\"in GeV$^{-1}$ cm$^{-2}$\")\n",
    "            info = \"flux\"\n",
    "        plt.plot(_dt, vals, ls=ls[i], alpha=alphas[i], color=\"#353132\",\n",
    "                 label=r\"{:.0%} > {:.0f}$\\sigma$\".format(betas[i], sigmas[i]))\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Time window length in seconds\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(framealpha=0)\n",
    "    plt.xlim(_dt[0], _dt[-1])\n",
    "    plt.ylim(0, None)\n",
    "    plt.title(r\"Performance for $E^{-2}$ signal flux\")\n",
    "    save_plot(os.path.join(\"performance\", typ),\n",
    "              \"perf_{}.png\".format(info), dpi=200)\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ls = [\"-\", \"--\", \"-.\", \":\", \"-\"][::-1]\n",
    "alphas = [1, 1, 1, 1, 0.5][::-1]\n",
    "plot_perf_vs_dt(mu_bfs, sigmas, betas, ls, alphas, typ=typ, mu2flux=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_mu2flux(typ=\"ps\"):\n",
    "    \"\"\"\n",
    "    Make mu2flux method from saved mu2fux(1) from healpy or ps injector.\n",
    "    \"\"\"\n",
    "    if typ == \"ps\":\n",
    "        fname = os.path.join(\"/Users\", \"tmenne\", \"Downloads\",\n",
    "                             \"hese_transient_stacking_data\", \"mu2flux_ps.json\")\n",
    "    elif typ == \"healpy\":\n",
    "        fname = os.path.join(\"/Users\", \"tmenne\", \"Downloads\",\n",
    "                             \"hese_transient_stacking_data\",\n",
    "                             \"mu2flux_healpy.json\")\n",
    "    else:\n",
    "        raise ValueError(\"`typ` can be 'ps' or 'healpy'.\")\n",
    "    with open(fname) as f:\n",
    "        mu2fluxinfo = json.load(f)\n",
    "\n",
    "    def mu2flux(mu):\n",
    "        return mu * mu2fluxinfo[\"all\"]\n",
    "\n",
    "    return mu2flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ls = [\"-\", \"--\", \"-.\", \":\", \"-\"][::-1]\n",
    "alphas = [1, 1, 1, 1, 0.5][::-1]\n",
    "plot_perf_vs_dt(mu_bfs, sigmas, betas, ls, alphas, typ=typ,\n",
    "                mu2flux=make_mu2flux(typ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def flux_model_factory(model, **model_args):\n",
    "    def flux_model(trueE):\n",
    "        flux_mod = getattr(phys, model)\n",
    "        return flux_mod(trueE, **model_args)\n",
    "\n",
    "    return flux_model\n",
    "\n",
    "mc_dict = loader.mc_loader(\"all\")\n",
    "log_E_nu_lo = 2.0\n",
    "log_E_nu_hi = 2.5\n",
    "tw_id = 10\n",
    "dt0, dt1 = loader.time_window_loader(tw_id)\n",
    "\n",
    "time_sam = UniformTimeSampler(random_state=RNDGEN)\n",
    "\n",
    "sig_injs = {}\n",
    "for key, mc in mc_dict.items():\n",
    "    print(\"\\n\" + 80 * \"#\")\n",
    "    print(\"# :: Setup for sample {} ::\".format(key))\n",
    "    opts = loader.settings_loader(key)[key].copy()\n",
    "    srcs = loader.source_list_loader(key)[key]\n",
    "    # Process to tdepps format\n",
    "    srcs_rec = make_src_records(srcs, dt0=dt0, dt1=dt1)\n",
    "\n",
    "    # Setup Signal injector\n",
    "    fmod = opts[\"sig_inj_opts\"].pop(\"flux_model\")\n",
    "    flux_model = flux_model_factory(fmod[\"model\"], **fmod[\"args\"])\n",
    "\n",
    "    # Cut energy range for differential limit\n",
    "    _log_E_nu = np.log10(mc[\"trueE\"])\n",
    "    mask = (_log_E_nu >= log_E_nu_lo) & (_log_E_nu < log_E_nu_hi)\n",
    "    print(\"- Selected {} / {} MC events in energy range [{}, {}).\".format(\n",
    "        np.sum(mask), len(mc), log_E_nu_lo, log_E_nu_hi))\n",
    "\n",
    "    sig_inj_i = SignalFluenceInjector(\n",
    "        flux_model, time_sampler=time_sam, inj_opts=opts[\"sig_inj_opts\"],\n",
    "        random_state=RNDGEN)\n",
    "    sig_inj_i.fit(srcs_rec, MC=mc[mask])\n",
    "    sig_injs[key] = sig_inj_i\n",
    "\n",
    "# Build the multi models\n",
    "multi_sig_inj = MultiSignalFluenceInjector(random_state=RNDGEN)\n",
    "multi_sig_inj.fit(sig_injs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, sig_inj in sig_injs.items():\n",
    "    print(key)\n",
    "    print(\"  \", sig_inj._raw_flux)\n",
    "    print(\"  \", sig_inj._raw_flux_per_src)\n",
    "    print(\"  \", sig_inj.mu2flux(1., per_source=True))\n",
    "    print(\"  \", sig_inj.flux2mu(1., per_source=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### Differential Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sig_inj_type = \"healpy\"\n",
    "perf_trials = loader.perf_trials_loader(sig_inj_type, diff=True, idx=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bg_pdfs = loader.bg_pdf_loader(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Prepare signal injector to convert mu to flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "perf_sig_injs = {}\n",
    "_time_sam = UniformTimeSampler(random_state=RNDGEN)\n",
    "\n",
    "# Load files and build the models one after another to save memory\n",
    "sample_names = loader.source_list_loader()\n",
    "for key in sample_names:\n",
    "    _opts = loader.settings_loader(key)[key].copy()\n",
    "    _mc = loader.mc_loader(key)[key]\n",
    "    _srcs_i = loader.source_list_loader(key)[key]\n",
    "    # Process to tdepps format\n",
    "    _srcs_rec_i = make_src_records(_srcs_i, dt0=np.nan, dt1=np.nan)\n",
    "    \n",
    "    # Setup Signal injector\n",
    "    _fmod = _opts[\"sig_inj_opts\"].pop(\"flux_model\")\n",
    "    _flux_model = phys.flux_model_factory(_fmod[\"model\"], **_fmod[\"args\"])\n",
    "    if sig_inj_type == \"healpy\":\n",
    "        _opts[\"sig_inj_opts\"][\"inj_sigma\"] = 3.\n",
    "        src_maps = loader.source_map_loader(src_list=_srcs_i)\n",
    "        sig_inj_i = HealpySignalFluenceInjector(\n",
    "            _flux_model, time_sampler=_time_sam, inj_opts=_opts[\"sig_inj_opts\"],\n",
    "            random_state=RNDGEN)\n",
    "        sig_inj_i.fit(_srcs_rec_i, src_maps=src_maps, MC=_mc)\n",
    "    elif sig_inj_type == \"ps\":\n",
    "        sig_inj_i = SignalFluenceInjector(\n",
    "            _flux_model, time_sampler=_time_sam, inj_opts=_opts[\"sig_inj_opts\"],\n",
    "            random_state=RNDGEN)\n",
    "        sig_inj_i.fit(_srcs_rec_i, MC=_mc)\n",
    "    else: \n",
    "        raise ValueError(\"`sig_inj_type` can be 'healpy' or 'ps'.\")\n",
    "    perf_sig_injs[key] = sig_inj_i\n",
    "    \n",
    "perf_multi_sig_inj = MultiSignalFluenceInjector(random_state=RNDGEN)\n",
    "perf_multi_sig_inj.fit(perf_sig_injs)\n",
    "\n",
    "print(\":: Done, setup {} signal injector ::\".format(sig_inj_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot sensitivity vs energy for a single time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def _cdf_func(x, df, loc, scale):\n",
    "    return scs.chi2.cdf(x, df, loc, scale)\n",
    "\n",
    "FLUX = True  # If True, use mu2flux as y units\n",
    "sigmas = [3., 5., 5.]\n",
    "betas = [0.9, 0.5, 0.9]\n",
    "ls = [\"-.\", \":\", \"-\"]\n",
    "label = [\"Sensitivity\", \"Disc. Pot. 50%\", \"Disc. Pot. 90%\"]\n",
    "sigmas = [3., 5.]\n",
    "betas = [0.9, 0.9]\n",
    "label = [\"Sensitivity\", \"Disc. Pot. 90%\"]\n",
    "ls = [\"-.\", \"-\"]\n",
    "tw_ids = loader.time_window_loader()\n",
    "\n",
    "_x = np.linspace(0, 100)\n",
    "hotfix_id = [100 * 18 + 0]  # Combined ID where to apply a hotfix chi2 solution\n",
    "\n",
    "for tw_id in tw_ids:\n",
    "    perf_bf_pars = []\n",
    "    logE_bins = perf_trials[tw_id][\"log_E_bins\"]\n",
    "    # For each logE bin get the mean injected events\n",
    "    for i in range(len(logE_bins) - 1):\n",
    "        bg_pdf = bg_pdfs[tw_id]\n",
    "        perf = perf_trials[tw_id]\n",
    "        # Get the BG TS values for the desired betas\n",
    "        bg_ts_vals = bg_pdf.ppf(q=100. * sigma2prob(sigmas))\n",
    "\n",
    "        # Get the best mus from the chi2 fits\n",
    "        bf_pars_i = []\n",
    "        ts_i = np.array(perf[\"ts\"][i])\n",
    "        \n",
    "        for j, bg_ts_val in enumerate(bg_ts_vals):\n",
    "            p0 = [1., 1., 1.]\n",
    "            mu_bf, cdfs, chi2_fit_pars = stats.fit_chi2_cdf(\n",
    "                ts_val=bg_ts_val, beta=betas[j],\n",
    "                ts=perf[\"ts\"][i], mus=perf[\"mus\"], p0=p0)\n",
    "            \n",
    "            if tw_id * 100 + i in hotfix_id:\n",
    "                # Hotfix for missing stats in high ninj regions: Add a CDF = 1\n",
    "                # point for very high signal to make the fit converge\n",
    "                chi2_fit_pars, _ = sco.curve_fit(\n",
    "                    _cdf_func, xdata=np.r_[perf[\"mus\"], 200],\n",
    "                    ydata=1. - np.r_[cdfs, 0], p0=p0)\n",
    "                mu_bf = scs.chi2.ppf(betas[j], *chi2_fit_pars)\n",
    "                # plt.plot(_x, scs.chi2.cdf(x, *chi2_fit_pars), c=\"C7\")\n",
    "                # plt.plot(np.r_[perf[\"mus\"], 200], 1. - np.r_[cdfs, 0],\n",
    "                #          ls=\"\", marker=\"o\", c=\"k\")\n",
    "                # plt.xlim(0, np.amax(perf[\"mus\"]) + 2)\n",
    "                # plt.show()\n",
    "    \n",
    "            bf_pars_i.append(mu_bf)\n",
    "        perf_bf_pars.append(bf_pars_i)\n",
    "    \n",
    "    # Plot performance curves per time window\n",
    "    perf_bf_pars = np.array(perf_bf_pars)\n",
    "    if FLUX:\n",
    "        perf_bf_pars = perf_multi_sig_inj.mu2flux(perf_bf_pars)\n",
    "        ylabel = (r\"Mean injected flux \" +\n",
    "                  r\"$\\left(\\frac{E}{\\mathrm{GeV}}\\right)^2\\phi$ \" +\n",
    "                  r\"in GeV$^{-1}$ cm$^{-2}$\")\n",
    "        info = \"flux\"\n",
    "    else:\n",
    "        ylabel = \"Mean injected no. of events\"\n",
    "        info = \"ninj\"\n",
    "    for j, _pars in enumerate(perf_bf_pars.T):\n",
    "        plt.plot(logE_bins, np.r_[_pars[0], _pars], ls=ls[j], c=\"C7\",\n",
    "                 label=label[j], drawstyle=\"steps-pre\")\n",
    "\n",
    "    plt.ylim(0, None)\n",
    "    plt.xlabel(r\"$\\log_{10}(E_\\nu / \\mathrm{GeV})$\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(\"Time window {}\".format(tw_id))\n",
    "    plt.legend()\n",
    "\n",
    "    save_plot(os.path.join(\"differential_perf\", sig_inj_type),\n",
    "              \"tw_{:02d}_{}.png\".format(tw_id, info))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialisation Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2 (OSX)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

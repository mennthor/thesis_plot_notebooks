{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as sci\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from astropy.time import Time as astrotime\n",
    "\n",
    "import tdepps.model_injection as Inj\n",
    "from tdepps.model_toolkit import (create_run_dict, SignalFluenceInjector,\n",
    "                                  make_rate_records, rebin_rate_rec,\n",
    "                                  UniformTimeSampler, SinusFixedConstRateFunction)\n",
    "from tdepps.utils import fit_spl_to_hist, arr2str\n",
    "\n",
    "secinday = 24. * 60. * 60.\n",
    "rndgen = np.random.RandomState(42439462)\n",
    "print(\"Started: \", astrotime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def setup_data(sample_name):\n",
    "    names = [\"79\", \"86I\", \"86II\", \"86III\"]\n",
    "\n",
    "    print(\"# Loading experimental data arrays:\")\n",
    "    exp = {}\n",
    "    p = \"/Users/tmenne/git/phd/hese_tdepps/data/proc/offdata\"\n",
    "    for n in names:\n",
    "        if n == sample_name or sample_name ==\"ALL\":\n",
    "            p_ = os.path.join(p, \"{}.npy\".format(n))\n",
    "            exp[n] = np.load(p_)\n",
    "            print(\" - {}: '{}'\".format(n, p_))\n",
    "\n",
    "    # Seperate names for signal injector input\n",
    "    exp_names = {key: exp_i.dtype.names for key, exp_i in exp.items()}\n",
    "\n",
    "\n",
    "    print(\"# Loading Monte Carlo data arrays:\")\n",
    "    mc = {}\n",
    "    files_ = [\"IC79/IC79_corrected_MC.npy\",\n",
    "              \"IC86_2011/IC86_corrected_MC.npy\",\n",
    "              \"IC86_2012/IC86-2012_corrected_MC.npy\",\n",
    "              \"IC86_2012/IC86-2012_corrected_MC.npy\"]\n",
    "    p = \"/Users/tmenne/git/phd/hese_tdepps/data/raw\"\n",
    "    for n, f_ in zip(names, files_):\n",
    "        if n == sample_name or sample_name ==\"ALL\":\n",
    "            p_ = os.path.join(p, f_)\n",
    "            mc[n] = np.load(p_)\n",
    "            print(\" - {}: '{}'\".format(n, p_))\n",
    "\n",
    "    # We need \"timeMJD\" as a name, so change the dtype names\n",
    "    for mci in mc.values():\n",
    "        if \"timeMJD\" not in mci.dtype.names:\n",
    "            idx = mci.dtype.names.index(\"time\")\n",
    "            mci.dtype.names = (mci.dtype.names[:idx] + (\"timeMJD\",) +\n",
    "                               mci.dtype.names[idx + 1:])\n",
    "\n",
    "\n",
    "    print(\"# Loading runlists:\")\n",
    "    rundict = {}\n",
    "    files_ = [\"IC79v24.json\", \"IC86_2011.json\",\n",
    "              \"IC86_2012.json\", \"IC86_2013.json\"]\n",
    "    p = \"/Users/tmenne/git/phd/hese_tdepps/data/proc/goodruns\"\n",
    "    for n, f_ in zip(names, files_):\n",
    "        if n == sample_name or sample_name ==\"ALL\":\n",
    "            p_ = os.path.join(p, f_)\n",
    "            rundict[n] = json.load(open(p_))\n",
    "            print(\" - {}: '{}'\".format(n, p_))\n",
    "\n",
    "\n",
    "    print(\"# Load HESE tracks locations and prepare srcs:\")\n",
    "    p = os.path.join(\"/Users/tmenne/git/phd/hese_tdepps/data/raw/\",\n",
    "                     \"public_data_release/All_HESE_Events_4_years_tracks.txt\")\n",
    "    src_t, src_dec, src_ra = np.loadtxt(p, usecols=[1, 2, 3], unpack=True)\n",
    "    src_ra = np.deg2rad(src_ra)\n",
    "    src_dec = np.deg2rad(src_dec)\n",
    "\n",
    "    src_arr_names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "    types = len(src_arr_names) * [np.float]\n",
    "    dtype = [(name, typ) for name, typ in zip(src_arr_names, types)]\n",
    "\n",
    "    srcs = {}\n",
    "    for key, rl in rundict.items():\n",
    "        runs = rl[\"runs\"]\n",
    "        tmin = np.amin([astrotime(r[\"good_tstart\"]).mjd for r in runs])\n",
    "        tmax = np.amax([astrotime(r[\"good_tstop\"]).mjd for r in runs])\n",
    "        t_mask = (src_t >= tmin) & (src_t <= tmax)\n",
    "\n",
    "        src_ti = src_t[t_mask]\n",
    "        nsrcs_i = len(src_ti)\n",
    "\n",
    "        srcs_i = np.empty((nsrcs_i, ), dtype=dtype)\n",
    "\n",
    "        srcs_i[\"t\"] = src_ti\n",
    "        # Leave empty for now, time window is set explicitely below\n",
    "        srcs_i[\"dt0\"] = np.zeros(nsrcs_i, dtype=np.float)\n",
    "        srcs_i[\"dt1\"] = np.zeros(nsrcs_i, dtype=np.float)\n",
    "        srcs_i[\"ra\"] = src_ra[t_mask]\n",
    "        srcs_i[\"dec\"] = src_dec[t_mask]\n",
    "        srcs_i[\"w_theo\"] = np.ones(nsrcs_i, dtype=np.float)\n",
    "        srcs[key] = srcs_i\n",
    "\n",
    "    p = (\"/Users/tmenne/git/phd/hese_tdepps/data/proc/\" +\n",
    "         \"time_windows/time_windows.txt\")\n",
    "    time_window = np.loadtxt(fname=p)[tw_id]\n",
    "    print(\"   + Loaded time window list: '{}'\".format(p))\n",
    "    print(\"   + Using time window {:2d}: {:.2f}s\".format(tw_id,\n",
    "                                                       np.diff(time_window)[0]))\n",
    "    for key, srcs_i in sorted(srcs.items()):\n",
    "        print(\" - {}:\".format(key))\n",
    "        srcs_i[\"dt0\"] = np.repeat(time_window[0], repeats=len(srcs_i))\n",
    "        srcs_i[\"dt1\"] = np.repeat(time_window[1], repeats=len(srcs_i))\n",
    "        for n in srcs_i.dtype.names:\n",
    "            print(\"   + {}: [{}]\".format(n, arr2str(srcs_i[n], fmt=\"{:.2f}\")))\n",
    "            \n",
    "    return exp, exp_names, mc, srcs, rundict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Loading data setup\n",
    "tw_id = 20\n",
    "sample_name = \"86I\"  # One of: 79, 86I, 86II, 86III or ALL\n",
    "if sample_name not in [\"79\", \"86I\", \"86II\", \"86III\", \"ALL\"]:\n",
    "    raise ValueError(\"Wrong name for `n` chosen.\")\n",
    "\n",
    "exp, exp_names, mc, srcs, rundict = setup_data(sample_name)\n",
    "\n",
    "# Single year aliases for testing\n",
    "if sample_name is not \"ALL\":\n",
    "    exp_ = exp[sample_name]\n",
    "    MC_ = mc[sample_name]\n",
    "    srcs_ = srcs[sample_name]\n",
    "    run_dict_ = create_run_dict(rundict[sample_name][\"runs\"])\n",
    "\n",
    "print(\"\\nDone, loaded sample(s) for '{}'.\".format(sample_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Finer resolution around the horizon region, where we usually switch the event\n",
    "# selections from northern to southern samples\n",
    "hor = np.sin(np.deg2rad(30))\n",
    "sindec_bins = np.unique(np.concatenate([\n",
    "                        np.linspace(-1., -hor, 3 + 1),    # south\n",
    "                        np.linspace(-hor, +hor, 14 + 1),  # horizon\n",
    "                        np.linspace(+hor, 1., 3 + 1),     # north\n",
    "                        ]))\n",
    "rate_rebins = np.linspace(exp_[\"timeMJD\"].min(), exp_[\"timeMJD\"].max(), 12)\n",
    "\n",
    "# Choose spl_s so that the spline sticks a little more to the data\n",
    "bg_inj_args = {\"sindec_bins\": sindec_bins, \"rate_rebins\": rate_rebins,\n",
    "               \"spl_s\": len(sindec_bins) // 2}\n",
    "grb_inj = Inj.GRBModelInjector(bg_inj_args=bg_inj_args, rndgen=rndgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = make_rate_records(T=exp_[\"timeMJD\"], run_dict=run_dict_)\n",
    "rates, new_bins, stddev, _ = rebin_rate_rec(rate_rec=recs, bins=rate_rebins,\n",
    "                                     ignore_zero_runs=True)\n",
    "mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "\n",
    "rate_func = SinusFixedConstRateFunction(p_fix=365.)\n",
    "allsky_res = rate_func.fit(rate=rates, srcs=srcs_, t=mids, w=1. / stddev)\n",
    "\n",
    "t0_fix = allsky_res.x[1]\n",
    "print(\"Best fit t0 before first event: \",\n",
    "      t0_fix - exp_[\"timeMJD\"].min(), \"days\")\n",
    "\n",
    "rate_func = SinusFixedConstRateFunction(p_fix=365., t0_fix=t0_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_flux_model(trueE, E0=1., gamma=2.):\n",
    "    return (trueE / E0)**(-gamma)\n",
    "\n",
    "ts = UniformTimeSampler(random_state=None)\n",
    "\n",
    "sig_inj = SignalFluenceInjector(signal_flux_model, time_sampler=ts)\n",
    "sig_inj.fit(srcs_, MC=MC_, exp_names=[\"timeMJD\", \"dec\", \"ra\", \"sigma\", \"logE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grb_inj.fit(X=exp_, srcs=srcs_, run_dict=run_dict_, sig_inj=sig_inj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### BG splines and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100)\n",
    "bins = grb_inj._sin_dec_bins\n",
    "mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "print(\"Allsky best params: \" + arr2str(grb_inj._allsky_pars))\n",
    "\n",
    "for n in [\"amp\", \"base\"]:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    spl = grb_inj._param_splines[n]\n",
    "    vals = grb_inj._best_pars[n]\n",
    "    err = np.copy(grb_inj._best_stddevs[n])\n",
    "   \n",
    "    ax.plot(mids, grb_inj._best_pars[n], color=\"C7\", ls=\"--\")\n",
    "    ax.errorbar(mids, vals, yerr=err, fmt=\"o\", color=\"C1\")\n",
    "    ax.plot(x, spl(x), color=\"k\")\n",
    "\n",
    "    if n == \"amp\":\n",
    "        ax.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "    else:\n",
    "        ax.set_ylim(0, None)\n",
    "\n",
    "    ax.set_xlabel(\"sindec\")\n",
    "    ax.set_ylabel(n)\n",
    "    ax.set_title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "    # Show sindec bin borders\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.vlines(sindec_bins, ylim[0], ylim[1],\n",
    "               linestyles=\":\", colors=\"C7\")\n",
    "    ylim = ax.set_ylim(ylim)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 200)\n",
    "bins = 100\n",
    "plt.vlines(sindec_bins, 0, 1, linestyles=\"--\", colors=\"C7\", zorder=-1)\n",
    "plt.hist(np.sin(exp_[\"dec\"]), bins=bins, density=True)\n",
    "plt.plot(x, grb_inj._data_spl(x))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make multiple trials and concat to compare to spline with large stats\n",
    "# Use internal debug var to get samples per source to compare to splines\n",
    "sam = [list() for _ in range(len(grb_inj.srcs))]\n",
    "for _ in range(200):\n",
    "    _ = grb_inj.get_sample()\n",
    "    for i, sami in enumerate(grb_inj._bg_cur_sam):\n",
    "        sam[i].append(sami)\n",
    "        \n",
    "sam = [np.concatenate(sami) for sami in sam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 200)\n",
    "bins = 40\n",
    "# bins = np.linspace(-1, 1, 17 + 1)\n",
    "for j, sami in enumerate(sam):\n",
    "    plt.vlines(sindec_bins, 0, 1, linestyles=\"--\", colors=\"C7\", zorder=-1)\n",
    "    # Plot allyear sample for comparison\n",
    "    plt.hist(np.sin(exp_[\"dec\"]), bins=bins, density=True, color=\"0.75\")\n",
    "    plt.plot(x, grb_inj._data_spl(x), color=\"C0\", ls=\":\", lw=3)\n",
    "    # Drawn sample per source. Red hist should approx. follow black spline\n",
    "    plt.hist(np.sin(sami[\"dec\"]), bins=bins, density=True,\n",
    "             histtype=\"step\", lw=2.5, color=\"C3\")\n",
    "    plt.plot(x, grb_inj._sin_dec_splines[j](x), color=\"k\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MC Injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing signal injector\n",
    "grb_inj.get_sample(n_signal=10000)\n",
    "sig_sam = grb_inj._sig_cur_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampled MC hist\n",
    "n = \"timeMJD\"\n",
    "_ = plt.hist(sig_sam[n], density=True, bins=100)\n",
    "if n != \"timeMJD\":\n",
    "    plt.vlines(grb_inj.srcs[n], 0, 1)\n",
    "    plt.yscale(\"log\", nonposy=\"clip\")\n",
    "    plt.show()\n",
    "else:\n",
    "    for src_idx\n",
    "    plt.vlines(grb_inj.srcs[\"t\"], 0, 1)\n",
    "    plt.vlines(grb_inj.srcs[\"t\"] + grb_inj.srcs[\"dt0\"] / 86400.,\n",
    "               0, 1, linestyles=\"--\")\n",
    "    plt.vlines(grb_inj.srcs[\"t\"] + grb_inj.srcs[\"dt1\"] / 86400.,\n",
    "               0, 1, linestyles=\"--\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to full MC pool distribution\n",
    "smc = sig_inj._MC\n",
    "_ = plt.hist(smc[\"dec\"], bins=100, density=True,\n",
    "             weights=smc[\"trueE\"]**-2*smc[\"ow\"])\n",
    "if n in [\"ra\", \"dec\"]:\n",
    "    plt.vlines(grb_inj.srcs[n], 0, 2)\n",
    "plt.yscale(\"log\", nonposy=\"clip\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test LLH scan instead of hess_inv from fitres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     2,
     37
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_llh_scan(bfs, stds, llh, grid):\n",
    "    \"\"\"\n",
    "    Plot the llh scan with errors and contours\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bfs : array-like, shape (2)\n",
    "        Best fit result parameters, around which the LLH was scanned.\n",
    "    stds : array-like, shape (2)\n",
    "        Approximate standard deviations (symmetric) for each fit parameter,\n",
    "        obtained using Wilks' theorem on the scanned space.\n",
    "    llh : array-like, shape (nbins, nbins)\n",
    "        Scanned LLH values.\n",
    "    grid : list\n",
    "        X, Y grid, same shape as ``llh``.\n",
    "    \"\"\"\n",
    "    bf_x, bf_y = bfs\n",
    "    std_x, std_y = stds\n",
    "    x, y = grid\n",
    "    \n",
    "    # Plot scan\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    img = ax.pcolormesh(x, y, llh)\n",
    "    fig.colorbar(img, ax=ax)\n",
    "\n",
    "    # Plot 1, 2, 3 sigma contours\n",
    "    vals = np.amin(llh) - scs.chi2.logsf(df=2, x=[1**2, 2**2, 3**2])\n",
    "    ax.contour(x, y, llh, vals, linestyles=[\"--\", \"-.\", \"--\"], colors=\"w\")\n",
    "    \n",
    "    # Plot best fit with symmetric errors\n",
    "    ax.errorbar(bf_x, bf_y, xerr=std_x, yerr=std_y, fmt=\"o\", c=\"w\", capsize=5)   \n",
    "    \n",
    "    ax.xlabel = (\"amplitude\")\n",
    "    ax.ylabel = (\"baseline\")\n",
    "\n",
    "def get_stddev_from_scan(func, args, bfs, rngs, nbins=50):\n",
    "    \"\"\"\n",
    "    Scan the rate_func chi2 fit LLH to get stddevs for the best fit params a, d.\n",
    "    Using matplotlib contours and averaging to approximately get the variances.\n",
    "    Note: This is not a true LLH profile scan in both variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        Loss function to be scanned, used to obtain the best fit. Function\n",
    "        is called as done with a scipy fitter, ``func(x, *args)``.\n",
    "    args : tuple\n",
    "        Args passed to the loss function ``func``. For a rate function, this is\n",
    "        ``(mids, rates, weights)``.\n",
    "    bfs : array-like, shape (2)\n",
    "        Best fit result parameters.\n",
    "    rngs : list\n",
    "        Parameter ranges to scan: ``[bf[i] - rng[i], bf[i] + rng[i]]``.\n",
    "    nbins : int, optional\n",
    "        Number of bins in each dimension to scan. (Default: 100)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    stds : array-like, shape (2)\n",
    "        Approximate standard deviations (symmetric) for each fit parameter,\n",
    "        obtained using Wilks' theorem on the scanned space.\n",
    "    llh : array-like, shape (nbins, nbins)\n",
    "        Scanned LLH values.\n",
    "    grid : list\n",
    "        X, Y grid, same shape as ``llh``.\n",
    "    \"\"\"\n",
    "    def _scan_llh(bf_x, rng_x, bf_y, rng_y):\n",
    "        \"\"\" Scan LLH and return contour vertices \"\"\"\n",
    "        x_bins = np.linspace(bf_x - rng_x, bf_x + rng_x, nbins)\n",
    "        y_bins = np.linspace(bf_y - rng_y, bf_y + rng_y, nbins)   \n",
    "        x, y = np.meshgrid(x_bins, y_bins)\n",
    "        AA, DD = map(np.ravel, [x, y])\n",
    "        llh = np.empty_like(AA)\n",
    "        for i, (ai, di) in enumerate(zip(AA, DD)):\n",
    "            llh[i] = func((ai, di), *args)\n",
    "        llh = llh.reshape(x.shape)\n",
    "        # Get the contour points and average over min, max per parameter\n",
    "        one_sigma_level = np.amin(llh) - scs.chi2.logsf(df=2, x=[1**2])\n",
    "\n",
    "        # https://stackoverflow.com/questions/5666056\n",
    "        cntr = plt.contour(x, y, llh, one_sigma_level)\n",
    "        plt.close(\"all\")\n",
    "        paths = [lcol.vertices for lcol in cntr.collections[0].get_paths()]\n",
    "        # Call undocumented base of plt.contour, to avoid creating a figure.\n",
    "        # Not working for mpl 2.2.2 any more, because _cntr was deleted.\n",
    "        # cntr = contour.Cntr(x, y, llh)\n",
    "        # paths = cntr.trace(level0=one_sigma_level)\n",
    "        # paths = paths[:len(paths) // 2]  # First half of list has the vertices\n",
    "        return paths, llh, [x, y]\n",
    "\n",
    "    def _is_path_closed(paths, rng_x, rng_y):\n",
    "        \"\"\"\n",
    "        We want the contour to be fully contained. Means there is only one path\n",
    "        and the first and last point are close together.\n",
    "        Returns ``True`` if contour is closed.\n",
    "        \"\"\"\n",
    "        closed = False\n",
    "        if len(paths) == 1:\n",
    "            vertices = paths[0]\n",
    "            # If no contour is made, only 1 vertex is returned -> invalid\n",
    "            if len(vertices) > 1:\n",
    "                max_bin_dist = np.amax([rng_x / float(nbins),\n",
    "                                        rng_y / float(nbins)])\n",
    "                closed = np.allclose(vertices[0], vertices[-1],\n",
    "                                     atol=max_bin_dist, rtol=0.)\n",
    "        return closed\n",
    "    \n",
    "    def _get_stds_from_path(path):\n",
    "        \"\"\" Create symmetric stddevs from the path vertices \"\"\"\n",
    "        x, y = path[:, 0], path[:, 1]\n",
    "        # Average asymmetricities in both direction\n",
    "        x_min, x_max = np.amin(x), np.amax(x)\n",
    "        y_min, y_max = np.amin(y), np.amax(y)\n",
    "        return 0.5 * (x_max - x_min), 0.5 * (y_max - y_min)\n",
    "           \n",
    "    # Scan the LLH, adapt scan range if contour is not closed\n",
    "    bf_x, bf_y = bfs\n",
    "    rng_x, rng_y = rngs\n",
    "    closed = False\n",
    "    while not closed:\n",
    "        # Default is scaling up, when range is too small\n",
    "        scalex, scaley = 10., 10.\n",
    "        # Get contour from scanned LLH space\n",
    "        paths, llh, grid = _scan_llh(bf_x, rng_x, bf_y, rng_y)\n",
    "        closed = _is_path_closed(paths, rng_x, rng_y)       \n",
    "        if closed:\n",
    "            vertices = paths[0]\n",
    "            # Estimate scale factors to get contour in optimum resolution\n",
    "            diffx = np.abs(np.amax(vertices[:, 0]) - np.amin(vertices[:, 0]))\n",
    "            diffy = np.abs(np.amax(vertices[:, 1]) - np.amin(vertices[:, 1]))\n",
    "            scalex = diffx / rng_x\n",
    "            scaley = diffy / rng_y\n",
    "            # Contour can be closed, but extremely zoomed out in only one param\n",
    "            if not np.allclose([scalex, scaley], 1., atol=0.5, rtol=0.):\n",
    "                print(\"Contour is very distorted in one direction\")\n",
    "                closed = False\n",
    "            else:\n",
    "                # Rescan valid contour to use optimal scan resolution\n",
    "                for i in range(2):\n",
    "                    std_x, std_y = _get_stds_from_path(vertices)\n",
    "                    rng_x = std_x * 1.05  # Allow a little padding\n",
    "                    rng_y = std_y * 1.05\n",
    "                    paths, llh, grid = _scan_llh(bf_x, rng_x, bf_y, rng_y)\n",
    "                    # Recheck if path is still valid\n",
    "                    closed = _is_path_closed(paths, rng_x, rng_y)\n",
    "        # Must be seperated if, because path can get invalid in rescaling step\n",
    "        if not closed:\n",
    "            print(\"Open or no contour, rescale\")\n",
    "            rng_x *= scalex\n",
    "            rng_y *= scaley\n",
    "\n",
    "    vertices = paths[0]\n",
    "    stds = np.array(_get_stds_from_path(vertices))\n",
    "    return stds, llh, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sindec = exp_[\"sinDec\"]\n",
    "t_ = np.linspace(exp_[\"timeMJD\"].min(), exp_[\"timeMJD\"].max(), 200)\n",
    "\n",
    "allres = []\n",
    "errs = []\n",
    "for j, (lo, hi) in enumerate(zip(sindec_bins[:-1], sindec_bins[1:])[:]):\n",
    "    mask = (sindec >= lo) & (sindec <= hi)\n",
    "\n",
    "    recs = make_rate_records(T=exp_[\"timeMJD\"][mask], run_dict=run_dict_)\n",
    "    rates, new_bins, stddev, _ = rebin_rate_rec(rate_rec=recs, bins=rate_rebins,\n",
    "                                                ignore_zero_runs=True)\n",
    "    new_mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "    weights = 1. / stddev\n",
    "    res = rate_func.fit(rate=rates, srcs=srcs_, t=new_mids, w=weights)\n",
    "    bfs = np.array([res.x[0], res.x[1]])\n",
    "    allres.append(res)\n",
    "    \n",
    "    plt.errorbar(recs[\"start_mjd\"], recs[\"rate\"], yerr=recs[\"rate_std\"],\n",
    "                 fmt=\",\", alpha=0.2, color=\"C0\")\n",
    "    plt.plot(recs[\"start_mjd\"], recs[\"rate\"], marker=\".\", ls=\"\", color=\"C0\")\n",
    "    plt.plot(new_bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "    plt.plot(t_, rate_func.fun(t=t_, pars=bfs), color=\"C3\")\n",
    "    plt.ylim(0, 3. * bfs[1])\n",
    "    plt.show()\n",
    "    \n",
    "    # Empirical seed estimates for amplitude and baseline scan range\n",
    "    args = (new_mids, rates, weights)\n",
    "    rngs = np.array([bfs[0], bfs[1] / 10.])\n",
    "    stds, llh, grid = get_stddev_from_scan(\n",
    "        func=rate_func._lstsq, args=args, bfs=bfs, rngs=rngs, nbins=20)\n",
    "    \n",
    "    plot_llh_scan(bfs, stds, llh, grid)\n",
    "    plt.show()\n",
    "    \n",
    "    errs.append(stds)\n",
    "\n",
    "errs = np.array(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 0 = amp, 1 = base\n",
    "# Note: The spline is not renormalized here, so there might be differences in\n",
    "#       scale to the one from the module\n",
    "for idx in [0, 1]:\n",
    "    x = np.linspace(-1, 1, 100)\n",
    "    mids = 0.5 * (sindec_bins[:-1] + sindec_bins[1:])\n",
    "    norm = np.diff(sindec_bins)\n",
    "\n",
    "    vals = np.array([res.x[idx] for res in allres]) / norm\n",
    "    err_ = errs.T[idx] / norm\n",
    "\n",
    "    # Prepare for spl fit\n",
    "    w = 1. / err_\n",
    "    spl, vals, pts, w = fit_spl_to_hist(h=vals, bins=sindec_bins, w=w, s=10)\n",
    "    \n",
    "    plt.plot(pts, vals, color=\"C7\", ls=\"--\")\n",
    "    plt.errorbar(pts, vals, yerr=1. / w, fmt=\"o\", color=\"C1\")\n",
    "    plt.plot(x, spl(x), color=\"k\")\n",
    "    plt.title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "\n",
    "    if idx == 0:\n",
    "        plt.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "        plt.ylabel(\"amp\")\n",
    "    else:\n",
    "        plt.ylim(0, None)\n",
    "        plt.ylabel(\"base\")\n",
    "    plt.xlabel(\"sindec\")\n",
    " \n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialisation Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2 (OSX)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as sci\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from astropy.time import Time as astrotime\n",
    "from anapymods3.general import idx2rowcol\n",
    "\n",
    "from tdepps.utils import (create_run_dict, make_rate_records, rebin_rate_rec,\n",
    "                          make_spl_edges, fit_spl_to_hist, arr2str,\n",
    "                          power_law_flux, dict_map)\n",
    "from tdepps.grb import GRBLLH, GRBModel, MultiGRBLLH\n",
    "from tdepps.grb import (SignalFluenceInjector, UniformTimeSampler,\n",
    "                        TimeDecDependentBGDataInjector)\n",
    "from tdepps.grb import MultiBGDataInjector, MultiSignalFluenceInjector\n",
    "from tdepps.grb import GRBLLHAnalysis\n",
    "from tdepps.grb import SinusFixedConstRateFunction\n",
    "\n",
    "secinday = 24. * 60. * 60.\n",
    "rndgen = np.random.RandomState(42439462)\n",
    "print(\"Started: \", astrotime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def setup_data(sample_name):\n",
    "    names = [\"79\", \"86I\", \"86II\", \"86III\"]\n",
    "\n",
    "    print(\"# Loading experimental data arrays:\")\n",
    "    exp = {}\n",
    "    p = \"/Users/tmenne/git/phd/hese_tdepps/data/proc/offdata\"\n",
    "    for n in names:\n",
    "        if n == sample_name or sample_name ==\"ALL\":\n",
    "            p_ = os.path.join(p, \"{}.npy\".format(n))\n",
    "            exp[n] = np.load(p_)\n",
    "            print(\" - {}: '{}'\".format(n, p_))\n",
    "\n",
    "\n",
    "    print(\"# Loading Monte Carlo data arrays:\")\n",
    "    mc = {}\n",
    "    files_ = [\"IC79/IC79_corrected_MC.npy\",\n",
    "              \"IC86_2011/IC86_corrected_MC.npy\",\n",
    "              \"IC86_2012/IC86-2012_corrected_MC.npy\",\n",
    "              \"IC86_2012/IC86-2012_corrected_MC.npy\"]\n",
    "    p = \"/Users/tmenne/git/phd/hese_tdepps/data/raw\"\n",
    "    for n, f_ in zip(names, files_):\n",
    "        if n == sample_name or sample_name ==\"ALL\":\n",
    "            p_ = os.path.join(p, f_)\n",
    "            mc[n] = np.load(p_)\n",
    "            print(\" - {}: '{}'\".format(n, p_))\n",
    "\n",
    "    # We need \"timeMJD\" as a name, so change the dtype names\n",
    "    for mci in mc.values():\n",
    "        if \"timeMJD\" not in mci.dtype.names:\n",
    "            idx = mci.dtype.names.index(\"time\")\n",
    "            mci.dtype.names = (mci.dtype.names[:idx] + (\"timeMJD\",) +\n",
    "                               mci.dtype.names[idx + 1:])\n",
    "\n",
    "\n",
    "    print(\"# Loading runlists:\")\n",
    "    rundict = {}\n",
    "    files_ = [\"IC79v24.json\", \"IC86_2011.json\",\n",
    "              \"IC86_2012.json\", \"IC86_2013.json\"]\n",
    "    p = \"/Users/tmenne/git/phd/hese_tdepps/data/proc/goodruns\"\n",
    "    for n, f_ in zip(names, files_):\n",
    "        if n == sample_name or sample_name ==\"ALL\":\n",
    "            p_ = os.path.join(p, f_)\n",
    "            rundict[n] = json.load(open(p_))\n",
    "            print(\" - {}: '{}'\".format(n, p_))\n",
    "\n",
    "\n",
    "    print(\"# Load HESE tracks locations and prepare srcs:\")\n",
    "    p = os.path.join(\"/Users/tmenne/git/phd/hese_tdepps/data/raw/\",\n",
    "                     \"public_data_release/All_HESE_Events_4_years_tracks.txt\")\n",
    "    src_t, src_dec, src_ra = np.loadtxt(p, usecols=[1, 2, 3], unpack=True)\n",
    "    src_ra = np.deg2rad(src_ra)\n",
    "    src_dec = np.deg2rad(src_dec)\n",
    "\n",
    "    src_arr_names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "    types = len(src_arr_names) * [np.float]\n",
    "    dtype = [(name, typ) for name, typ in zip(src_arr_names, types)]\n",
    "\n",
    "    srcs = {}\n",
    "    for key, rl in rundict.items():\n",
    "        runs = rl[\"runs\"]\n",
    "        tmin = np.amin([astrotime(r[\"good_tstart\"]).mjd for r in runs])\n",
    "        tmax = np.amax([astrotime(r[\"good_tstop\"]).mjd for r in runs])\n",
    "        t_mask = (src_t >= tmin) & (src_t <= tmax)\n",
    "\n",
    "        src_ti = src_t[t_mask]\n",
    "        nsrcs_i = len(src_ti)\n",
    "\n",
    "        srcs_i = np.empty((nsrcs_i, ), dtype=dtype)\n",
    "\n",
    "        srcs_i[\"t\"] = src_ti\n",
    "        # Leave empty for now, time window is set explicitely below\n",
    "        srcs_i[\"dt0\"] = np.zeros(nsrcs_i, dtype=np.float)\n",
    "        srcs_i[\"dt1\"] = np.zeros(nsrcs_i, dtype=np.float)\n",
    "        srcs_i[\"ra\"] = src_ra[t_mask]\n",
    "        srcs_i[\"dec\"] = src_dec[t_mask]\n",
    "        srcs_i[\"w_theo\"] = np.ones(nsrcs_i, dtype=np.float)\n",
    "        srcs[key] = srcs_i\n",
    "\n",
    "    p = (\"/Users/tmenne/git/phd/hese_tdepps/data/proc/\" +\n",
    "         \"time_windows/time_windows.txt\")\n",
    "    time_window = np.loadtxt(fname=p)[tw_id]\n",
    "    print(\"   + Loaded time window list: '{}'\".format(p))\n",
    "    print(\"   + Using time window {:2d}: {:.2f}s\".format(tw_id,\n",
    "                                                       np.diff(time_window)[0]))\n",
    "    for key, srcs_i in sorted(srcs.items()):\n",
    "        print(\" - {}:\".format(key))\n",
    "        srcs_i[\"dt0\"] = np.repeat(time_window[0], repeats=len(srcs_i))\n",
    "        srcs_i[\"dt1\"] = np.repeat(time_window[1], repeats=len(srcs_i))\n",
    "        for n in srcs_i.dtype.names:\n",
    "            print(\"   + {}: [{}]\".format(n, arr2str(srcs_i[n], fmt=\"{:.2f}\")))\n",
    "            \n",
    "    # If all selected, concat IC86II & III, because they have the same MC    \n",
    "    if sample_name == \"ALL\":\n",
    "        exp[\"86II_III\"] = np.concatenate((exp[\"86II\"], exp[\"86III\"]))\n",
    "        _ = exp.pop(\"86II\")\n",
    "        _ = exp.pop(\"86III\")\n",
    "        \n",
    "        mc[\"86II_III\"] = mc[\"86II\"]\n",
    "        _ = mc.pop(\"86II\")\n",
    "        _ = mc.pop(\"86III\")\n",
    "        \n",
    "        srcs[\"86II_III\"] = np.concatenate((srcs[\"86II\"], srcs[\"86III\"]))\n",
    "        _ = srcs.pop(\"86II\")\n",
    "        _ = srcs.pop(\"86III\")\n",
    "        \n",
    "        rundict[\"86II_III\"] = {\n",
    "            \"runs\": rundict[\"86II\"][\"runs\"] + rundict[\"86III\"][\"runs\"]}\n",
    "        _ = rundict.pop(\"86II\")\n",
    "        _ = rundict.pop(\"86III\")\n",
    "        print(\"All samples selected, combined 86II and 86III tp 86II_III.\")\n",
    "                \n",
    "    return exp, mc, srcs, rundict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Loading data setup\n",
    "tw_id = 15\n",
    "sample_name = \"ALL\"  # One of: 79, 86I, 86II, 86III or ALL\n",
    "if sample_name not in [\"79\", \"86I\", \"86II\", \"86III\", \"ALL\"]:\n",
    "    raise ValueError(\"Wrong name for `n` chosen.\")\n",
    "\n",
    "exp, mc, srcs, rundict = setup_data(sample_name)\n",
    "\n",
    "# Single year aliases for testing\n",
    "if sample_name is not \"ALL\":\n",
    "    exp_ = exp[sample_name]\n",
    "    MC_ = mc[sample_name]\n",
    "    srcs_ = srcs[sample_name]\n",
    "    run_dict_ = create_run_dict(rundict[sample_name][\"runs\"])\n",
    "else:\n",
    "    exp_ = exp\n",
    "    MC_ = mc\n",
    "    srcs_ = srcs\n",
    "    run_dict_ = {key: create_run_dict(rd[\"runs\"]) for key, rd\n",
    "                 in rundict.items()}\n",
    "\n",
    "print(\"\\nDone, loaded sample(s) for '{}'.\".format(sample_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build and fit bg injector\n",
    "# Finer resolution around the horizon region, where we usually switch the event\n",
    "# selections from northern to southern samples\n",
    "hor = np.sin(np.deg2rad(30))\n",
    "sindec_bins = np.unique(np.concatenate([\n",
    "                        np.linspace(-1., -hor, 3 + 1),    # south\n",
    "                        np.linspace(-hor, +hor, 14 + 1),  # horizon\n",
    "                        np.linspace(+hor, 1., 3 + 1),     # north\n",
    "                        ]))\n",
    "rate_rebins = np.linspace(exp_[\"timeMJD\"].min(), exp_[\"timeMJD\"].max(), 12)\n",
    "# Choose spl_s so that the spline sticks a little more to the data\n",
    "bg_inj_opts = {\"sindec_bins\": sindec_bins, \"rate_rebins\": rate_rebins,\n",
    "               \"spl_s\": len(sindec_bins) // 2, \"n_scan_bins\": 25}\n",
    "bg_inj = TimeDecDependentBGDataInjector(inj_opts=bg_inj_opts, rndgen=rndgen)\n",
    "bg_inj.fit(X=exp_, srcs=srcs_, run_dict=run_dict_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and fit sig injector\n",
    "ts = UniformTimeSampler(random_state=None)\n",
    "sig_inj = SignalFluenceInjector(power_law_flux, time_sampler=ts)\n",
    "sig_inj.fit(srcs_, MC=MC_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and fit llh\n",
    "mod_opts = None\n",
    "grb_mod = GRBModel(exp_, MC_, srcs_, model_opts=mod_opts)\n",
    "llh_opts = None\n",
    "llh = GRBLLH(llh_model=grb_mod, llh_opts=llh_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana = GRBLLHAnalysis(llh, bg_inj, sig_inj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Rate allsky model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Redo the allsky rate fit for testing\n",
    "recs = make_rate_records(T=exp_[\"timeMJD\"], run_dict=run_dict_)\n",
    "rates, new_bins, stddev, _ = rebin_rate_rec(rate_rec=recs, bins=rate_rebins,\n",
    "                                     ignore_zero_runs=True)\n",
    "mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "\n",
    "rate_func = SinusFixedConstRateFunction(p_fix=365.)\n",
    "allsky_res = rate_func.fit(rate=rates, srcs=srcs_, t=mids, w=1. / stddev)\n",
    "\n",
    "t0_fix = allsky_res.x[1]\n",
    "print(\"Best fit t0 before first event: \",\n",
    "      t0_fix - exp_[\"timeMJD\"].min(), \"days\")\n",
    "\n",
    "rate_func = SinusFixedConstRateFunction(p_fix=365., t0_fix=t0_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### BG splines and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Show build spline models for timedependent injector\n",
    "x = np.linspace(-1, 1, 100)\n",
    "bins = bg_inj_opts[\"sindec_bins\"]\n",
    "mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "allsky_pars = bg_inj._spl_info[\"allsky_best_params\"]\n",
    "print(\"Allsky best params: \" + arr2str(allsky_pars))\n",
    "\n",
    "TEST = True\n",
    "\n",
    "for n in [\"amp\", \"base\"]:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    spl = bg_inj._spl_info[\"param_splines\"][n]\n",
    "    vals = np.copy(bg_inj._spl_info[\"best_pars_norm\"][n])\n",
    "    err = np.copy(bg_inj._spl_info[\"best_stddevs_norm\"][n])\n",
    "   \n",
    "    ax.plot(x, spl(x), color=\"k\")\n",
    "    ax.plot(mids, vals, color=\"C7\", ls=\"--\")\n",
    "    ax.errorbar(mids, vals, yerr=err, fmt=\"o\", color=\"C1\")\n",
    "        \n",
    "    # Quickly switch smoothing for testing\n",
    "    if TEST:\n",
    "        w = 1. / err\n",
    "        vals_, pts_, w = make_spl_edges(vals=vals, bins=sindec_bins, w=w)\n",
    "        stop = False\n",
    "        s_ = bg_inj_opts[\"spl_s\"]\n",
    "        while not stop:\n",
    "            spl_ = sci.UnivariateSpline(pts_, vals_, w=w, s=s_)\n",
    "            norm_ = (allsky_pars[0] if n == \"amp\" else allsky_pars[-1])\n",
    "\n",
    "            spl2_ = spl_.derivative(n=2)\n",
    "            stop = np.all(np.abs(spl2_(x)) < 1.)\n",
    "            if not stop:\n",
    "                s_ = s_ * 0.9\n",
    "                print(\"Degraded s_. 2nd derivative was \",\n",
    "                      np.abs(spl2_(x)).max())\n",
    "        # Renorm to allsky for comparison\n",
    "        scale_ = norm_ / spl_.integral(-1, 1)\n",
    "        ax.plot(x, spl_(x) * scale_, color=\"C0\", ls=\"--\")\n",
    "    \n",
    "    if n == \"amp\":\n",
    "        ax.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "    else:\n",
    "        ax.set_ylim(0, None)\n",
    "\n",
    "    ax.set_xlabel(\"sindec\")\n",
    "    ax.set_ylabel(n)\n",
    "    ax.set_title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "    # Show sindec bin borders\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.vlines(sindec_bins, ylim[0], ylim[1],\n",
    "               linestyles=\":\", colors=\"C7\")\n",
    "    ylim = ax.set_ylim(ylim)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compare hist to allsky model\n",
    "x = np.linspace(-1, 1, 200)\n",
    "bins = 100\n",
    "plt.vlines(sindec_bins, 0, 1, linestyles=\"--\", colors=\"C7\", zorder=-1)\n",
    "plt.hist(np.sin(exp_[\"dec\"]), bins=bins, density=True)\n",
    "plt.plot(x, bg_inj._spl_info[\"data_spl\"](x))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make multiple trials and concat to compare to spline with large stats\n",
    "# Use internal debug var to get samples per source to compare to splines\n",
    "nsrcs = len(bg_inj.srcs)\n",
    "sam = [list() for _ in range(nsrcs)]\n",
    "nsamples = 1000\n",
    "for _ in range(nsamples):\n",
    "    sami = bg_inj.sample()\n",
    "    src_idx = bg_inj._sample_idx[\"src_idx\"]\n",
    "    for j in range(nsrcs):\n",
    "        sam[j].append(sami[src_idx == j])\n",
    "        \n",
    "sam = [np.concatenate(sami) for sami in sam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 200)\n",
    "bins = 40\n",
    "# bins = np.linspace(-1, 1, 17 + 1)\n",
    "for j, sami in enumerate(sam):\n",
    "    plt.vlines(sindec_bins, 0, 1, linestyles=\"--\", colors=\"C7\", zorder=-1)\n",
    "    # Plot allyear sample for comparison\n",
    "    plt.hist(np.sin(exp_[\"dec\"]), bins=bins, density=True, color=\"0.75\")\n",
    "    plt.plot(x, bg_inj._spl_info[\"data_spl\"](x), color=\"C0\", ls=\":\", lw=3)\n",
    "    # Drawn sample per source. Red hist should approx. follow black spline\n",
    "    plt.hist(np.sin(sami[\"dec\"]), bins=bins, density=True,\n",
    "             histtype=\"step\", lw=2.5, color=\"C3\")\n",
    "    plt.plot(x, bg_inj._spl_info[\"sin_dec_splines\"][j](x), color=\"k\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### MC Injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Testing signal injector\n",
    "sam = sig_inj.sample(n_samples=10000)\n",
    "idx = sig_inj._sample_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sampled MC hist\n",
    "for name in [\"ra\", \"dec\", \"logE\", \"timeMJD\", \"sigma\"]:\n",
    "    # Show sampled data-like attributes\n",
    "    if name != \"timeMJD\":\n",
    "        # Compare to full MC pool distribution\n",
    "        w = sig_inj._MC[\"ow\"] * sig_inj.flux_model(sig_inj._MC[\"trueE\"])\n",
    "        _ = plt.hist(sig_inj._MC[name], weights=w, density=True, bins=100,\n",
    "                     alpha=.5)\n",
    "        _ = plt.hist(sam[name], density=True, bins=100, histtype=\"step\", lw=3)\n",
    "    if name in [\"ra\", \"dec\"]:\n",
    "        plt.vlines(sig_inj.srcs[name], 0, 1)\n",
    "        plt.yscale(\"log\", nonposy=\"clip\")\n",
    "    if name == \"timeMJD\":\n",
    "        ts = sig_inj.srcs[\"t\"]\n",
    "        dt0s, dt1s = sig_inj.srcs[\"dt0\"], sig_inj.srcs[\"dt1\"]\n",
    "        for j in range(len(ts)):\n",
    "            plt.title(\"{}. {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "                name, ts[j], dt0s[j], dt1s[j]))\n",
    "            mask = (idx[\"src_idx\"] == j)\n",
    "            trel = (ts[j] - sam[name][mask]) * secinday\n",
    "            _ = plt.hist(trel, density=False, bins=100,\n",
    "                         histtype=\"step\", lw=3)\n",
    "            plt.axvline(0, 0, 1)\n",
    "            plt.axvline(dt0s[j], 0, 1, ls=\"--\")\n",
    "            plt.axvline(dt1s[j], 0, 1, ls=\"--\")\n",
    "            plt.show()\n",
    "    else:\n",
    "        plt.title(name)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### TEST: Fixate x,y ratio hist edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Similar to make_spl_edges, but just repeat the outermost values.\n",
    "We have the full bin range covered with the interpolator, without introducing artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "rndgen = np.random.RandomState(3242342)\n",
    "x = rndgen.uniform(0, 1, size=1000)\n",
    "y = rndgen.uniform(0, 1, size=1000)\n",
    "\n",
    "bx = np.linspace(0, 1, 6)\n",
    "by = np.linspace(0, 1, 11)\n",
    "bxm, bym = map(lambda b: 0.5 * (b[:-1] + b[1:]), [bx, by])\n",
    "\n",
    "print(h.shape)\n",
    "print(len(bx))\n",
    "print(len(by))\n",
    "\n",
    "h = plt.hist2d(x, y, bins=[bx, by], normed=True)[0]\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Repeat outermost values, first in all cols, then the rows\n",
    "h_ext = np.zeros((len(bxm) + 2, len(bym) + 2), dtype=h.dtype) - 1.\n",
    "for j, col in enumerate(h):\n",
    "    h_ext[j+1] = np.concatenate([col[[0]], col, col[[-1]]])\n",
    "h_ext[0] = h_ext[1]\n",
    "h_ext[-1] = h_ext[-2]\n",
    "pts_x = np.concatenate((bx[[0]], bxm, bx[[-1]]))\n",
    "pts_y = np.concatenate((by[[0]], bym, by[[-1]]))\n",
    "\n",
    "print(h_ext.shape)\n",
    "print(len(pts_x))\n",
    "print(len(pts_y))\n",
    "\n",
    "# Orignal bins\n",
    "xx, yy = np.meshgrid(bx, by)\n",
    "# Original bin mids\n",
    "xxm, yym = np.meshgrid(bxm, bym)\n",
    "# New grid points from bin mids\n",
    "xxg, yyg = np.meshgrid(pts_x, pts_y)\n",
    "\n",
    "# Plot original hist again\n",
    "plt.pcolormesh(xx, yy, h.T)\n",
    "plt.colorbar()\n",
    "# Plot original bin edges, bin mids and new pts for the interpolator\n",
    "plt.scatter(xx, yy, marker=\"o\", color=\"C3\", s=50)\n",
    "plt.scatter(xxm, yym, marker=\"o\", color=\"w\", s=50)\n",
    "plt.scatter(xxg, yyg, marker=\".\", color=\"k\")\n",
    "plt.show()\n",
    "\n",
    "# Plot rows and cols of the new hist\n",
    "# Note: The first/last row and col are repeated and are drawn on top of the next\n",
    "# row/col in the plot\n",
    "for i, col in enumerate(h_ext):\n",
    "    plt.plot(pts_y, col, label=\"{:d}\".format(i))\n",
    "for p in pts_y:\n",
    "    plt.axvline(p, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.title(\"Cols\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=\"upper center\", ncol=4)\n",
    "plt.savefig(\"/Users/tmenne/Downloads/col_rep\")\n",
    "plt.show()\n",
    "\n",
    "for i, row in enumerate(h_ext.T):\n",
    "    plt.plot(pts_x, row, label=\"{:d}\".format(i))\n",
    "for p in pts_x:\n",
    "    plt.axvline(p, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.title(\"Rows\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=\"upper center\", ncol=6)\n",
    "plt.savefig(\"/Users/tmenne/Downloads/row_rep\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Linearly extrapolate outermost values, first in all cols, then the rows\n",
    "h_ext = np.zeros((len(bxm) + 2, len(bym) + 2), dtype=h.dtype) - 1.\n",
    "for j, col in enumerate(h):\n",
    "    vals, pts_y, _ = make_spl_edges(vals=col, bins=by)\n",
    "    h_ext[j+1] = vals\n",
    "for i, row in enumerate(h_ext.T):\n",
    "    vals, pts_x, _ = make_spl_edges(vals=row[1:-1], bins=bx)\n",
    "    h_ext[:, i] = vals\n",
    "\n",
    "print(h_ext.shape)\n",
    "print(len(pts_x))\n",
    "print(len(pts_y))\n",
    "\n",
    "# Orignal bins\n",
    "xx, yy = np.meshgrid(bx, by)\n",
    "# Original bin mids\n",
    "xxm, yym = np.meshgrid(bxm, bym)\n",
    "# New grid points from bin mids\n",
    "xxg, yyg = np.meshgrid(pts_x, pts_y)\n",
    "\n",
    "# Plot original hist again\n",
    "plt.pcolormesh(xx, yy, h.T)\n",
    "plt.colorbar()\n",
    "# Plot original bin edges, bin mids and new pts for the interpolator\n",
    "plt.scatter(xx, yy, marker=\"o\", color=\"C3\", s=50)\n",
    "plt.scatter(xxm, yym, marker=\"o\", color=\"w\", s=50)\n",
    "plt.scatter(xxg, yyg, marker=\".\", color=\"k\")\n",
    "plt.show()\n",
    "\n",
    "# Plot rows and cols of the new hist\n",
    "for i, col in enumerate(h_ext):\n",
    "    plt.plot(pts_y, col, label=\"{:d}\".format(i))\n",
    "for p in pts_y:\n",
    "    plt.axvline(p, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.title(\"Cols\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=\"upper center\", ncol=4)\n",
    "plt.savefig(\"/Users/tmenne/Downloads/col_lin\")\n",
    "plt.show()\n",
    "\n",
    "for i, row in enumerate(h_ext.T):\n",
    "    plt.plot(pts_x, row, label=\"{:d}\".format(i))\n",
    "for p in pts_x:\n",
    "    plt.axvline(p, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.title(\"Rows\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=\"upper center\", ncol=6)\n",
    "plt.savefig(\"/Users/tmenne/Downloads/row_lin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST: LLH scan instead of hess_inv from fitres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     35
    ]
   },
   "outputs": [],
   "source": [
    "def plot_llh_scan(bfs, stds, llh, grid):\n",
    "    \"\"\"\n",
    "    Plot the llh scan with errors and contours\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bfs : array-like, shape (2)\n",
    "        Best fit result parameters, around which the LLH was scanned.\n",
    "    stds : array-like, shape (2)\n",
    "        Approximate standard deviations (symmetric) for each fit parameter,\n",
    "        obtained using Wilks' theorem on the scanned space.\n",
    "    llh : array-like, shape (nbins, nbins)\n",
    "        Scanned LLH values.\n",
    "    grid : list\n",
    "        X, Y grid, same shape as ``llh``.\n",
    "    \"\"\"\n",
    "    bf_x, bf_y = bfs\n",
    "    std_x, std_y = stds\n",
    "    x, y = grid\n",
    "    \n",
    "    # Plot scan\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    img = ax.pcolormesh(x, y, llh)\n",
    "    fig.colorbar(img, ax=ax)\n",
    "\n",
    "    # Plot 1, 2, 3 sigma contours\n",
    "    vals = np.amin(llh) - scs.chi2.logsf(df=2, x=[1**2, 2**2, 3**2])\n",
    "    ax.contour(x, y, llh, vals, linestyles=[\"--\", \"-.\", \"--\"], colors=\"w\")\n",
    "    \n",
    "    # Plot best fit with symmetric errors\n",
    "    ax.errorbar(bf_x, bf_y, xerr=std_x, yerr=std_y, fmt=\"o\", c=\"w\", capsize=5)   \n",
    "    \n",
    "    ax.xlabel = (\"amplitude\")\n",
    "    ax.ylabel = (\"baseline\")\n",
    "\n",
    "def get_stddev_from_scan(func, args, bfs, rngs, nbins=50):\n",
    "    \"\"\"\n",
    "    Scan the rate_func chi2 fit LLH to get stddevs for the best fit params a, d.\n",
    "    Using matplotlib contours and averaging to approximately get the variances.\n",
    "    Note: This is not a true LLH profile scan in both variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        Loss function to be scanned, used to obtain the best fit. Function\n",
    "        is called as done with a scipy fitter, ``func(x, *args)``.\n",
    "    args : tuple\n",
    "        Args passed to the loss function ``func``. For a rate function, this is\n",
    "        ``(mids, rates, weights)``.\n",
    "    bfs : array-like, shape (2)\n",
    "        Best fit result parameters.\n",
    "    rngs : list\n",
    "        Parameter ranges to scan: ``[bf[i] - rng[i], bf[i] + rng[i]]``.\n",
    "    nbins : int, optional\n",
    "        Number of bins in each dimension to scan. (Default: 100)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    stds : array-like, shape (2)\n",
    "        Approximate standard deviations (symmetric) for each fit parameter,\n",
    "        obtained using Wilks' theorem on the scanned space.\n",
    "    llh : array-like, shape (nbins, nbins)\n",
    "        Scanned LLH values.\n",
    "    grid : list\n",
    "        X, Y grid, same shape as ``llh``.\n",
    "    \"\"\"\n",
    "    def _scan_llh(bf_x, rng_x, bf_y, rng_y):\n",
    "        \"\"\" Scan LLH and return contour vertices \"\"\"\n",
    "        x_bins = np.linspace(bf_x - rng_x, bf_x + rng_x, nbins)\n",
    "        y_bins = np.linspace(bf_y - rng_y, bf_y + rng_y, nbins)   \n",
    "        x, y = np.meshgrid(x_bins, y_bins)\n",
    "        AA, DD = map(np.ravel, [x, y])\n",
    "        llh = np.empty_like(AA)\n",
    "        for i, (ai, di) in enumerate(zip(AA, DD)):\n",
    "            llh[i] = func((ai, di), *args)\n",
    "        llh = llh.reshape(x.shape)\n",
    "        # Get the contour points and average over min, max per parameter\n",
    "        one_sigma_level = np.amin(llh) - scs.chi2.logsf(df=2, x=[1**2])\n",
    "\n",
    "        # https://stackoverflow.com/questions/5666056\n",
    "        cntr = plt.contour(x, y, llh, one_sigma_level)\n",
    "        plt.close(\"all\")\n",
    "        paths = [lcol.vertices for lcol in cntr.collections[0].get_paths()]\n",
    "        # Call undocumented base of plt.contour, to avoid creating a figure.\n",
    "        # Not working for mpl 2.2.2 any more, because _cntr was deleted.\n",
    "        # cntr = contour.Cntr(x, y, llh)\n",
    "        # paths = cntr.trace(level0=one_sigma_level)\n",
    "        # paths = paths[:len(paths) // 2]  # First half of list has the vertices\n",
    "        return paths, llh, [x, y]\n",
    "\n",
    "    def _is_path_closed(paths, rng_x, rng_y):\n",
    "        \"\"\"\n",
    "        We want the contour to be fully contained. Means there is only one path\n",
    "        and the first and last point are close together.\n",
    "        Returns ``True`` if contour is closed.\n",
    "        \"\"\"\n",
    "        closed = False\n",
    "        if len(paths) == 1:\n",
    "            vertices = paths[0]\n",
    "            # If no contour is made, only 1 vertex is returned -> invalid\n",
    "            if len(vertices) > 1:\n",
    "                max_bin_dist = np.amax([rng_x / float(nbins),\n",
    "                                        rng_y / float(nbins)])\n",
    "                closed = np.allclose(vertices[0], vertices[-1],\n",
    "                                     atol=max_bin_dist, rtol=0.)\n",
    "        return closed\n",
    "    \n",
    "    def _get_stds_from_path(path):\n",
    "        \"\"\" Create symmetric stddevs from the path vertices \"\"\"\n",
    "        x, y = path[:, 0], path[:, 1]\n",
    "        # Average asymmetricities in both direction\n",
    "        x_min, x_max = np.amin(x), np.amax(x)\n",
    "        y_min, y_max = np.amin(y), np.amax(y)\n",
    "        return 0.5 * (x_max - x_min), 0.5 * (y_max - y_min)\n",
    "           \n",
    "    # Scan the LLH, adapt scan range if contour is not closed\n",
    "    bf_x, bf_y = bfs\n",
    "    rng_x, rng_y = rngs\n",
    "    closed = False\n",
    "    while not closed:\n",
    "        # Default is scaling up, when range is too small\n",
    "        scalex, scaley = 10., 10.\n",
    "        # Get contour from scanned LLH space\n",
    "        paths, llh, grid = _scan_llh(bf_x, rng_x, bf_y, rng_y)\n",
    "        closed = _is_path_closed(paths, rng_x, rng_y)       \n",
    "        if closed:\n",
    "            vertices = paths[0]\n",
    "            # Estimate scale factors to get contour in optimum resolution\n",
    "            diffx = np.abs(np.amax(vertices[:, 0]) - np.amin(vertices[:, 0]))\n",
    "            diffy = np.abs(np.amax(vertices[:, 1]) - np.amin(vertices[:, 1]))\n",
    "            scalex = diffx / rng_x\n",
    "            scaley = diffy / rng_y\n",
    "            # Contour can be closed, but extremely zoomed out in only one param\n",
    "            if not np.allclose([scalex, scaley], 1., atol=0.5, rtol=0.):\n",
    "                print(\"Contour is very distorted in one direction\")\n",
    "                closed = False\n",
    "            else:\n",
    "                # Rescan valid contour to use optimal scan resolution\n",
    "                for i in range(2):\n",
    "                    std_x, std_y = _get_stds_from_path(vertices)\n",
    "                    rng_x = std_x * 1.05  # Allow a little padding\n",
    "                    rng_y = std_y * 1.05\n",
    "                    paths, llh, grid = _scan_llh(bf_x, rng_x, bf_y, rng_y)\n",
    "                    # Recheck if path is still valid\n",
    "                    closed = _is_path_closed(paths, rng_x, rng_y)\n",
    "        # Must be seperated if, because path can get invalid in rescaling step\n",
    "        if not closed:\n",
    "            print(\"Open or no contour, rescale\")\n",
    "            rng_x *= scalex\n",
    "            rng_y *= scaley\n",
    "\n",
    "    vertices = paths[0]\n",
    "    stds = np.array(_get_stds_from_path(vertices))\n",
    "    return stds, llh, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sindec = exp_[\"sinDec\"]\n",
    "t_ = np.linspace(exp_[\"timeMJD\"].min(), exp_[\"timeMJD\"].max(), 200)\n",
    "\n",
    "allres = []\n",
    "errs = []\n",
    "for j, (lo, hi) in enumerate(zip(sindec_bins[:-1], sindec_bins[1:])[:]):\n",
    "    mask = (sindec >= lo) & (sindec <= hi)\n",
    "\n",
    "    recs = make_rate_records(T=exp_[\"timeMJD\"][mask], run_dict=run_dict_)\n",
    "    rates, new_bins, stddev, _ = rebin_rate_rec(rate_rec=recs, bins=rate_rebins,\n",
    "                                                ignore_zero_runs=True)\n",
    "    new_mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "    weights = 1. / stddev\n",
    "    res = rate_func.fit(rate=rates, srcs=srcs_, t=new_mids, w=weights)\n",
    "    bfs = np.array([res.x[0], res.x[1]])\n",
    "    allres.append(res)\n",
    "    \n",
    "    plt.errorbar(recs[\"start_mjd\"], recs[\"rate\"], yerr=recs[\"rate_std\"],\n",
    "                 fmt=\",\", alpha=0.2, color=\"C0\")\n",
    "    plt.plot(recs[\"start_mjd\"], recs[\"rate\"], marker=\".\", ls=\"\", color=\"C0\")\n",
    "    plt.plot(new_bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "    plt.plot(t_, rate_func.fun(t=t_, pars=bfs), color=\"C3\")\n",
    "    plt.ylim(0, 3. * bfs[1])\n",
    "    plt.show()\n",
    "    \n",
    "    # Empirical seed estimates for amplitude and baseline scan range\n",
    "    args = (new_mids, rates, weights)\n",
    "    rngs = np.array([bfs[0], bfs[1] / 10.])\n",
    "    stds, llh, grid = get_stddev_from_scan(\n",
    "        func=rate_func._lstsq, args=args, bfs=bfs, rngs=rngs, nbins=20)\n",
    "    \n",
    "    plot_llh_scan(bfs, stds, llh, grid)\n",
    "    plt.show()\n",
    "    \n",
    "    errs.append(stds)\n",
    "\n",
    "errs = np.array(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = amp, 1 = base\n",
    "# Note: The spline is not renormalized here, so there might be differences in\n",
    "#       scale to the one from the module\n",
    "for idx in [0, 1]:\n",
    "    x = np.linspace(-1, 1, 100)\n",
    "    mids = 0.5 * (sindec_bins[:-1] + sindec_bins[1:])\n",
    "    norm = np.diff(sindec_bins)\n",
    "\n",
    "    vals = np.array([res.x[idx] for res in allres]) / norm\n",
    "    err_ = errs.T[idx] / norm\n",
    "\n",
    "    # Prepare for spl fit\n",
    "    w = 1. / err_\n",
    "    spl, vals, pts, w = fit_spl_to_hist(h=vals, bins=sindec_bins, w=w, s=10)\n",
    "    \n",
    "    plt.plot(pts, vals, color=\"C7\", ls=\"--\")\n",
    "    plt.errorbar(pts, vals, yerr=1. / w, fmt=\"o\", color=\"C1\")\n",
    "    plt.plot(x, spl(x), color=\"k\")\n",
    "    plt.title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "\n",
    "    if idx == 0:\n",
    "        plt.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "        plt.ylabel(\"amp\")\n",
    "    else:\n",
    "        plt.ylim(0, None)\n",
    "        plt.ylabel(\"base\")\n",
    "    plt.xlabel(\"sindec\")\n",
    " \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TEST: Event preselection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"86II_III\"\n",
    "\n",
    "ev_dec = exp[name][\"dec\"]\n",
    "ev_ra = exp[name][\"ra\"]\n",
    "ev_sigma = exp[name][\"sigma\"]\n",
    "\n",
    "src_dec = srcs[name][\"dec\"][:, None]\n",
    "src_ra = srcs[name][\"ra\"][:, None]\n",
    "\n",
    "nsigma = 1.\n",
    "\n",
    "# Only mask events in a square with length nsigma * sigma to one of the sources\n",
    "dec_mask = ((ev_dec > src_dec - ev_sigma * nsigma) &\n",
    "            (ev_dec < src_dec + ev_sigma * nsigma))\n",
    "mask = dec_mask\n",
    "# RA mask needs more thought due to soild angle differences\n",
    "# ra_mask = ((ev_ra > (src_ra - ev_sigma * nsigma / np.cos(src_dec))) &\n",
    "#            (ev_ra < (src_ra + ev_sigma * nsigma / np.cos(src_dec))))\n",
    "# mask = ra_mask & dec_mask\n",
    "\n",
    "print(np.sum(mask, axis=1))\n",
    "\n",
    "# Plot events per source\n",
    "m = (ev_sigma < np.deg2rad(1.))  # Only show well reconstructed events\n",
    "plt.plot(ev_ra[m], ev_dec[m], color=\"C7\", alpha=.1, marker=\".\", ls=\"\", ms=1)\n",
    "for j, m in enumerate(mask[:]):\n",
    "    m = m & (ev_sigma < np.deg2rad(1.))  # Only show well reconstructed events\n",
    "    plt.scatter(ev_ra[m], ev_dec[m], s=100 * ev_sigma[m], alpha=.5)\n",
    "    plt.plot(src_ra[j], src_dec[j], marker=\"*\", ms=5)\n",
    "    \n",
    "# Show events contributing to all sources (if any)\n",
    "m = np.where(np.all(mask, axis=0))\n",
    "plt.scatter(ev_ra[m], ev_dec[m], s=10 * ev_sigma[m], alpha=1, color=\"k\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare and fit multi BG injector\n",
    "hor = np.sin(np.deg2rad(30))\n",
    "sindec_bins = np.unique(np.concatenate([\n",
    "                        np.linspace(-1., -hor, 3 + 1),    # south\n",
    "                        np.linspace(-hor, +hor, 14 + 1),  # horizon\n",
    "                        np.linspace(+hor, 1., 3 + 1),     # north\n",
    "                        ]))\n",
    "\n",
    "bg_injs = {}\n",
    "bg_inj_opts = {}\n",
    "for key in exp_.keys():\n",
    "    print(\"Fitting BGInj {}\".format(key))\n",
    "    if key == \"86II_III\":\n",
    "        n_rate_bins = 24\n",
    "    else:\n",
    "        n_rate_bins = 12\n",
    "    rate_rebins = np.linspace(exp_[key][\"timeMJD\"].min(),\n",
    "                              exp_[key][\"timeMJD\"].max(), n_rate_bins)\n",
    "    bg_inj_opts[key] = {\"sindec_bins\": sindec_bins, \"rate_rebins\": rate_rebins,\n",
    "                        \"spl_s\": len(sindec_bins) // 2, \"n_scan_bins\": 25}\n",
    "\n",
    "    bg_inj_i = TimeDecDependentBGDataInjector(inj_opts=bg_inj_opts[key],\n",
    "                                              rndgen=rndgen)\n",
    "    bg_inj_i.fit(X=exp_[key], srcs=srcs_[key], run_dict=run_dict_[key])\n",
    "    bg_injs[key] = bg_inj_i\n",
    "multi_bg_inj = MultiBGDataInjector()\n",
    "multi_bg_inj.fit(bg_injs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and fit multi Signal injector\n",
    "sig_injs = {}\n",
    "ts = UniformTimeSampler(random_state=None)\n",
    "for key in exp_.keys():\n",
    "    print(\"Fitting SigInj {}\".format(key))\n",
    "    sig_inj_i = SignalFluenceInjector(power_law_flux, time_sampler=ts)\n",
    "    sig_inj_i.fit(srcs_[key], MC=MC_[key])\n",
    "    sig_injs[key] = sig_inj_i\n",
    "\n",
    "multi_sig_inj = MultiSignalFluenceInjector()\n",
    "multi_sig_inj.fit(sig_injs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare and fit multi LLH\n",
    "llhs = {}\n",
    "for key in exp_names.keys():\n",
    "    print(\"Preparing LLH {}\".format(key))\n",
    "    pdf_i = GRBPDF(exp_[key], MC_[key], srcs_[key])\n",
    "    llh_args = None\n",
    "    llh_i = GRBLLH(model_pdf=pdf_i, llh_args=llh_args)\n",
    "    llhs[key] = llh_i\n",
    "multi_llh = MultiGRBLLH()\n",
    "multi_llh.fit(llhs=llhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_ana = GRBLLHAnalysis(multi_llh, multi_bg_inj, multi_sig_inj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### BG splines and sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test if multi sampler samples correctly from each single injector.\n",
    "In the BG case this just collects all single samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "multi_bg_sam_ = [multi_bg_inj.sample() for i in range(n_samples)]\n",
    "multi_bg_sam = {}\n",
    "for key in multi_bg_inj.names:\n",
    "    multi_bg_sam[key] = np.concatenate([sam_i[key] for sam_i in multi_bg_sam_])\n",
    "nsam = map(len, multi_bg_sam.values())\n",
    "for i, key in enumerate(multi_bg_inj.names):\n",
    "    print(\"{:8s} : {}\".format(key, nsam[i]))\n",
    "    \n",
    "nbins = 100\n",
    "for name in [\"ra\", \"dec\", \"logE\", \"sigma\"]:\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    for i, key in enumerate(sorted(multi_bg_inj.names)):\n",
    "        ax[i].hist(multi_bg_sam[key][name], bins=nbins)\n",
    "        ax[i].set_title(key)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show build spline models for timedependent injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TEST = False\n",
    "x = np.linspace(-1, 1, 100)\n",
    "for key, bg_inj in multi_bg_inj._injs.items():\n",
    "    print(\"Plotting for sample '{}'\".format(key))\n",
    "\n",
    "    bins = bg_inj_opts[key][\"sindec_bins\"]\n",
    "    mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "    print(\"Allsky best params: \" + arr2str(\n",
    "        bg_inj._spl_info[\"allsky_best_params\"]))\n",
    "\n",
    "    for n in [\"amp\", \"base\"]:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        spl = bg_inj._spl_info[\"param_splines\"][n]\n",
    "        vals = np.copy(bg_inj._spl_info[\"best_pars_norm\"][n])\n",
    "        err = np.copy(bg_inj._spl_info[\"best_stddevs_norm\"][n])\n",
    "\n",
    "        ax.plot(x, spl(x), color=\"k\")\n",
    "        ax.plot(mids, vals, color=\"C7\", ls=\"--\")\n",
    "        ax.errorbar(mids, vals, yerr=err, fmt=\"o\", color=\"C1\")\n",
    "\n",
    "        # Quickly switch smoothing for testing\n",
    "        if TEST:\n",
    "            w = 1. / err\n",
    "            vals_, pts_, w = make_spl_edges(vals=vals, bins=sindec_bins, w=w)\n",
    "            stop = False\n",
    "            s_ = bg_inj_opts[key][\"spl_s\"]\n",
    "            while not stop:\n",
    "                spl_ = sci.UnivariateSpline(pts_, vals_, w=w, s=s_)\n",
    "                norm_ = (bg_inj._spl_info[\"allsky_best_params\"][0] if n == \"amp\"\n",
    "                         else bg_inj._spl_info[\"allsky_best_params\"][-1])\n",
    "\n",
    "                spl2_ = spl_.derivative(n=2)\n",
    "                stop = np.all(np.abs(spl2_(x)) < 1.)\n",
    "                if not stop:\n",
    "                    s_ = s_ * 0.9\n",
    "                    print(\"Degraded s_. 2nd derivative was \",\n",
    "                          np.abs(spl2_(x)).max())\n",
    "            # Renorm to allsky for comparison\n",
    "            scale_ = norm_ / spl_.integral(-1, 1)\n",
    "            ax.plot(x, spl_(x) * scale_, color=\"C0\", ls=\"--\")\n",
    "\n",
    "        if n == \"amp\":\n",
    "            ax.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "        else:\n",
    "            ax.set_ylim(0, None)\n",
    "\n",
    "        ax.set_xlabel(\"sindec\")\n",
    "        ax.set_ylabel(n)\n",
    "        ax.set_title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "        # Show sindec bin borders\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.vlines(sindec_bins, ylim[0], ylim[1],\n",
    "                   linestyles=\":\", colors=\"C7\")\n",
    "        ylim = ax.set_ylim(ylim)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot rates vs rate model for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, bg_inj in sorted(multi_bg_inj._injs.items())[:]:\n",
    "    recs = make_rate_records(run_dict=run_dict_[key], T=exp_[key][\"timeMJD\"])   \n",
    "    rebin = rebin_rate_rec(rate_rec=recs, bins=bg_inj_opts[key][\"rate_rebins\"],\n",
    "                           ignore_zero_runs=True)\n",
    "    rates, bins, rate_std, _ = rebin\n",
    "\n",
    "    mids = 0.5 * (recs[\"start_mjd\"] + recs[\"stop_mjd\"])\n",
    "    diff = recs[\"stop_mjd\"] - recs[\"start_mjd\"]\n",
    "    t = np.linspace(bins[0], bins[-1], 200)\n",
    "    \n",
    "    # Plot it\n",
    "    plt.errorbar(mids, recs[\"rate\"], xerr=diff, yerr=recs[\"rate_std\"], fmt=\",\",\n",
    "                 color=\"C0\", alpha=0.5)\n",
    "    plt.plot(bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "    plt.plot(t, bg_inj._spl_info[\"allsky_rate_func\"].bf_fun(t),\n",
    "             color=\"C3\", lw=2.5)\n",
    "        \n",
    "    plt.ylim(0, 0.01)\n",
    "    plt.xlabel(\"time in MJD days\")\n",
    "    plt.ylabel(\"Rate in mHz\")\n",
    "    plt.title(\"Allsky rate model for sample {}\".format(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot rate model for each sindec bin per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, bg_inj in sorted(multi_bg_inj._injs.items())[:]:\n",
    "    T = exp_[key][\"timeMJD\"]\n",
    "    sindec = np.sin(exp_[key][\"dec\"])\n",
    "    sd_bins = bg_inj_opts[key][\"sindec_bins\"]\n",
    "    rate_fun = bg_inj._spl_info[\"allsky_rate_func\"]\n",
    "\n",
    "    nplots, nrows, ncols = 20, 4, 5\n",
    "    assert ncols * nrows == nplots\n",
    "    assert nplots == len(sindec_bins) - 1\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(24, 13.5),\n",
    "                           sharex=True, sharey=True)\n",
    "    \n",
    "    for i, (lo, hi) in enumerate(zip(sd_bins[:-1], sd_bins[1:])):\n",
    "        mask = (sindec >= lo) & (sindec < hi)              \n",
    "        recs = make_rate_records(run_dict=run_dict_[key], T=T[mask])\n",
    "        rebin = rebin_rate_rec(\n",
    "            rate_rec=recs, bins=bg_inj_opts[key][\"rate_rebins\"],\n",
    "            ignore_zero_runs=True)\n",
    "        rates, bins, rate_std, _ = rebin\n",
    "        \n",
    "        mids = 0.5 * (recs[\"start_mjd\"] + recs[\"stop_mjd\"])\n",
    "        diff = recs[\"stop_mjd\"] - recs[\"start_mjd\"]\n",
    "        t = np.linspace(bins[0], bins[-1], 200)\n",
    "        \n",
    "        amp, base = bg_inj._spl_info[\"best_pars\"][i]\n",
    "        pars = (amp, bg_inj._spl_info[\"allsky_best_params\"][1], base)\n",
    "        lab = \"{:.2f} <= sindec < {:.2f}\".format(lo, hi)\n",
    "        \n",
    "        # Plot it\n",
    "        row, col = idx2rowcol(i, ncols=ncols)\n",
    "        ax_ = ax[row, col]\n",
    "        ax_.errorbar(mids, recs[\"rate\"], xerr=diff, yerr=recs[\"rate_std\"],\n",
    "                     fmt=\",\", color=\"C0\", alpha=0.5, label=lab)\n",
    "        ax_.plot(bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "        ax_.plot(t, rate_fun.fun(t, pars), color=\"C3\", lw=2.5)\n",
    "\n",
    "        ax_.set_ylim(0, 0.001)\n",
    "        ax_.legend(loc=\"upper right\")\n",
    "    ax[0, 0].text(s=\"Sample: '{}'\".format(key), x=bins[0], y=0.0009,\n",
    "                  bbox={\"facecolor\": \"w\", \"alpha\": 0.5}, fontsize=12)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compare hist to allsky model\n",
    "x = np.linspace(-1, 1, 200)\n",
    "bins = 100\n",
    "for key, bg_inj in sorted(multi_bg_inj._injs.items())[:]:\n",
    "    plt.vlines(bg_inj_opts[key][\"sindec_bins\"], 0, 1, linestyles=\"--\",\n",
    "               colors=\"C7\", zorder=-1)\n",
    "    plt.hist(np.sin(exp_[key][\"dec\"]), bins=bins, density=True)\n",
    "    plt.plot(x, bg_inj._spl_info[\"data_spl\"](x))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### MC injector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test splitting of signal samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsamples = 10000\n",
    "multi_sig_sam = multi_sig_inj.sample(n_samples=nsamples)\n",
    "print(sum(map(len, (multi_sig_sam.values()))))\n",
    "print(dict_map(lambda key, sam: len(sam), multi_sig_sam))\n",
    "print(dict_map(lambda key, wts: wts * nsamples,\n",
    "               multi_sig_inj._distribute_weights))\n",
    "\n",
    "dict_map(lambda key, val: np.sum(val) / multi_sig_inj.flux2mu(1.),\n",
    "         multi_sig_inj.flux2mu(1., per_source=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, sami in multi_sig_sam.items():\n",
    "    # Sampled MC hist\n",
    "    _inj = multi_sig_inj.injs[key]\n",
    "    _idx = multi_sig_inj.injs[key]._sample_idx\n",
    "    for name in [\"ra\", \"dec\", \"logE\", \"timeMJD\", \"sigma\"]:\n",
    "        # Show sampled data-like attributes\n",
    "        if name != \"timeMJD\":\n",
    "            # Compare to full MC pool distribution\n",
    "            w = _inj._MC[\"ow\"] * _inj.flux_model(_inj._MC[\"trueE\"])\n",
    "            _ = plt.hist(_inj._MC[name], weights=w, density=True, bins=100,\n",
    "                         alpha=.5)\n",
    "            _ = plt.hist(sami[name], density=True, bins=100,\n",
    "                         histtype=\"step\", lw=3)\n",
    "        if name in [\"ra\", \"dec\"]:\n",
    "            plt.vlines(_inj.srcs[name], 0, 1)\n",
    "            plt.yscale(\"log\", nonposy=\"clip\")\n",
    "        if name == \"timeMJD\":\n",
    "            ts = _inj.srcs[\"t\"]\n",
    "            dt0s, dt1s = _inj.srcs[\"dt0\"], _inj.srcs[\"dt1\"]\n",
    "            for j in range(len(ts)):\n",
    "                plt.title(\"{}. {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "                    name, ts[j], dt0s[j], dt1s[j]))\n",
    "                mask = (_idx[\"src_idx\"] == j)\n",
    "                trel = (ts[j] - sami[name][mask]) * secinday\n",
    "                _ = plt.hist(trel, density=False, bins=100,\n",
    "                             histtype=\"step\", lw=3)\n",
    "                plt.axvline(0, 0, 1)\n",
    "                plt.axvline(dt0s[j], 0, 1, ls=\"--\")\n",
    "                plt.axvline(dt1s[j], 0, 1, ls=\"--\")\n",
    "                plt.show()\n",
    "        else:\n",
    "            plt.title(\"{}: {}\".format(key, name))\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialisation Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2 (OSX)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.interpolate as sci\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from astropy.time import Time as astrotime\n",
    "\n",
    "import tdepps.model_injection as Inj\n",
    "from tdepps.model_toolkit import (create_run_dict, SignalFluenceInjector,\n",
    "                                  make_rate_records, rebin_rate_rec,\n",
    "                                  UniformTimeSampler, SinusFixedConstRateFunction)\n",
    "from tdepps.utils import make_spl_edges\n",
    "\n",
    "secinday = 24. * 60. * 60.\n",
    "rndgen = np.random.RandomState(42439462)\n",
    "print(\"Loaded: \", astrotime.now())\n",
    "\n",
    "tw_id = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# ###### Load data for each sample\n",
    "p = \"/Users/tmenne/git/phd/hese_tdepps/data/proc\"\n",
    "exp = {}\n",
    "names = [\"79\", \"86I\", \"86II\", \"86III\"]\n",
    "for key in names[:1]:\n",
    "    exp[key] = np.load(os.path.join(p, \"offdata/{}.npy\".format(key)))\n",
    "    print(\"Loaded exp {}.\".format(os.path.join(p,\n",
    "                                               \"offdata/{}.npy\".format(key))))\n",
    "\n",
    "exp_names = {key: exp_i.dtype.names for key, exp_i in exp.items()}\n",
    "\n",
    "p = \"/Users/tmenne/git/phd/hese_tdepps/data/raw\"\n",
    "mc = {}\n",
    "mc[\"79\"] = np.load(os.path.join(p, \"IC79/IC79_corrected_MC.npy\"))\n",
    "print(\"Loaded mc from: {}\".format(\n",
    "    os.path.join(p, \"IC79/IC79_corrected_MC.npy\")))\n",
    "# mc[\"86I\"] = np.load(os.path.join(p, \"IC86_2011/IC86_corrected_MC.npy\"))\n",
    "# print(\"Loaded mc from: {}\".format(\n",
    "#     os.path.join(p, \"IC79/IC79_corrected_MC.npy\")))\n",
    "# mc[\"86II\"] = np.load(os.path.join(p, \"IC86_2012/IC86-2012_corrected_MC.npy\"))\n",
    "# mc[\"86III\"] = mc[\"86II\"]  # MC is the same here\n",
    "# print(\"Loaded mc from: {} for 86II & 86III\".format(\n",
    "#     os.path.join(p, \"IC86_2012/IC86-2012_corrected_MC.npy\")))\n",
    "\n",
    "# We need \"timeMJD\" as a key, so change the dtype names\n",
    "for mci in mc.values():\n",
    "    if \"timeMJD\" not in mci.dtype.names:\n",
    "        idx = mci.dtype.names.index(\"time\")\n",
    "        mci.dtype.names = (mci.dtype.names[:idx] + (\"timeMJD\",) +\n",
    "                           mci.dtype.names[idx + 1:])\n",
    "\n",
    "\n",
    "# ###### Get prepared run time lists\n",
    "p = \"/Users/tmenne/git/phd/hese_tdepps/data/proc\"\n",
    "rundict = {}\n",
    "\n",
    "rundict[\"79\"] = json.load(open(os.path.join(p, \"goodruns/IC79v24.json\")))\n",
    "# rundict[\"86I\"] = json.load(open(os.path.join(p, \"goodruns/IC86_2011.json\")))\n",
    "# rundict[\"86II\"] = json.load(open(os.path.join(p, \"goodruns/IC86_2012.json\")))\n",
    "# rundict[\"86III\"] = json.load(open(os.path.join(p, \"goodruns/IC86_2013.json\")))\n",
    "\n",
    "print(\"Loaded goodrun dicts from: \" + p + \"/goddruns\")\n",
    "\n",
    "\n",
    "# ###### Load HESE tracks locations\n",
    "p = \"/Users/tmenne/git/phd/hese_tdepps/data/raw\"\n",
    "path = os.path.join(p, \"public_data_release/All_HESE_Events_4_years_tracks.txt\")\n",
    "src_t, src_dec, src_ra = np.loadtxt(path, usecols=[1, 2, 3], unpack=True)\n",
    "src_ra = np.deg2rad(src_ra)\n",
    "src_dec = np.deg2rad(src_dec)\n",
    "\n",
    "names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "types = len(names) * [np.float]\n",
    "dtype = [(name, typ) for name, typ in zip(names, types)]\n",
    "\n",
    "srcs = {}\n",
    "for key, rl in rundict.items():\n",
    "    runs = rl[\"runs\"]\n",
    "    tmin = np.amin([astrotime(r[\"good_tstart\"]).mjd for r in runs])\n",
    "    tmax = np.amax([astrotime(r[\"good_tstop\"]).mjd for r in runs])\n",
    "    t_mask = (src_t >= tmin) & (src_t <= tmax)\n",
    "\n",
    "    src_ti = src_t[t_mask]\n",
    "    nsrcs_i = len(src_ti)\n",
    "\n",
    "    srcs_i = np.empty((nsrcs_i, ), dtype=dtype)\n",
    "\n",
    "    srcs_i[\"t\"] = src_ti\n",
    "    # Leave empty for now, time window is set explicitely below\n",
    "    srcs_i[\"dt0\"] = np.zeros(nsrcs_i, dtype=np.float)\n",
    "    srcs_i[\"dt1\"] = np.zeros(nsrcs_i, dtype=np.float)\n",
    "    srcs_i[\"ra\"] = src_ra[t_mask]\n",
    "    srcs_i[\"dec\"] = src_dec[t_mask]\n",
    "    srcs_i[\"w_theo\"] = np.ones(nsrcs_i, dtype=np.float)\n",
    "    srcs[key] = srcs_i\n",
    "\n",
    "print(\"Made HESE srcs from: \" + path)\n",
    "\n",
    "\n",
    "# ###### Setup time window for all srcs\n",
    "fname = \"/Users/tmenne/git/phd/hese_tdepps/data/proc/time_windows/time_windows.txt\"\n",
    "time_window = np.loadtxt(fname=fname)[tw_id]\n",
    "print(\"Using time window {:2d}: {:.2f}s\".format(tw_id, np.diff(time_window)[0]))\n",
    "for key, srcs_i in srcs.items():\n",
    "    srcs_i[\"dt0\"] = np.repeat(time_window[0], repeats=len(srcs_i))\n",
    "    srcs_i[\"dt1\"] = np.repeat(time_window[1], repeats=len(srcs_i))\n",
    "    print(srcs_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp_ = exp[\"79\"]\n",
    "MC_ = mc[\"79\"]\n",
    "srcs_ = srcs[\"79\"]\n",
    "rate_func = create_run_dict(rundict[\"79\"][\"runs\"])\n",
    "\n",
    "hor = 0.25\n",
    "sindec_bins = np.unique(np.concatenate([\n",
    "                        np.linspace(-1., -hor, 5 + 1),    # south\n",
    "                        np.linspace(-hor, +hor, 10 + 1),  # horizon\n",
    "                        np.linspace(+hor, 1., 5 + 1),     # north\n",
    "                        ]))\n",
    "rate_rebins = np.linspace(exp_[\"timeMJD\"].min(), exp_[\"timeMJD\"].max(), 12)\n",
    "\n",
    "bg_inj_args = {\"sindec_bins\": sindec_bins, \"rate_rebins\": rate_rebins}\n",
    "grb_inj = Inj.GRBModelInjector(bg_inj_args=bg_inj_args, rndgen=rndgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recs = make_rate_records(T=exp_[\"timeMJD\"], run_dict=rate_func)\n",
    "rates, new_bins, stddev, _ = rebin_rate_rec(rate_rec=recs, bins=rate_rebins,\n",
    "                                     ignore_zero_runs=True)\n",
    "mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "\n",
    "rf = SinusFixedConstRateFunction(p_fix=365.)\n",
    "allsky_res = rf.fit(rate=rates, srcs=srcs_, t=mids, w=1. / stddev)\n",
    "\n",
    "t0_fix = allsky_res.x[1]\n",
    "print(\"Best fit t0 before first event: \",\n",
    "      t0_fix - exp_[\"timeMJD\"].min(), \"days\")\n",
    "\n",
    "rf = SinusFixedConstRateFunction(p_fix=365., t0_fix=t0_fix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_flux_model(trueE, E0=1., gamma=2.):\n",
    "    return (trueE / E0)**(-gamma)\n",
    "\n",
    "ts = UniformTimeSampler(random_state=None)\n",
    "\n",
    "sig_inj = SignalFluenceInjector(signal_flux_model, time_sampler=ts)\n",
    "sig_inj.fit(srcs_, MC=MC_, exp_names=[\"timeMJD\", \"dec\", \"ra\", \"sigma\", \"logE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grb_inj.fit(X=exp_, srcs=srcs_, run_dict=rate_func, sig_inj=sig_inj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = \"amp\"\n",
    "x = np.linspace(-1, 1, 100)\n",
    "\n",
    "bins = grb_inj._sin_dec_bins\n",
    "mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "vals = grb_inj._best_pars[n]\n",
    "err = np.copy(grb_inj._best_stddevs[n])\n",
    "\n",
    "plt.plot(mids, grb_inj._best_pars[n], color=\"C7\", ls=\"--\")\n",
    "plt.errorbar(mids, vals, yerr=err, fmt=\"o\", color=\"C1\")\n",
    "plt.plot(x, grb_inj._param_splines[n](x), color=\"k\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 200)\n",
    "bins = 40\n",
    "plt.hist(np.sin(exp_[\"dec\"]), bins=bins, density=True)\n",
    "plt.plot(x, grb_inj._data_spl(x))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam = np.concatenate([grb_inj.get_sample() for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 200)\n",
    "bins = 40\n",
    "# bins = np.linspace(-1, 1, 17 + 1)\n",
    "for j, ev in enumerate(grb_inj._bg_inj):\n",
    "    plt.hist(np.sin(exp_[\"dec\"]), bins=bins, density=True)\n",
    "    plt.plot(x, grb_inj._data_spl(x))\n",
    "\n",
    "    plt.hist(np.sin(ev[\"dec\"]), bins=bins, density=True, histtype=\"step\", lw=2.5)\n",
    "    plt.plot(x, grb_inj._sin_dec_splines[j](x))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Test LLH scan instead of hess_inv from fitres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_llh_scan(bfs, stds, llh, grid):\n",
    "    \"\"\"\n",
    "    Plot the llh scan with errors and contours\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bfs : array-like, shape (2)\n",
    "        Best fit result parameters, around which the LLH was scanned.\n",
    "    stds : array-like, shape (2)\n",
    "        Approximate standard deviations (symmetric) for each fit parameter,\n",
    "        obtained using Wilks' theorem on the scanned space.\n",
    "    llh : array-like, shape (nbins, nbins)\n",
    "        Scanned LLH values.\n",
    "    grid : list\n",
    "        X, Y grid, same shape as ``llh``.\n",
    "    \"\"\"\n",
    "    bf_a, bf_d = bfs\n",
    "    std_a, std_d = stds\n",
    "    a, d = grid\n",
    "    \n",
    "    # Plot scan\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    img = ax.pcolormesh(a, d, llh)\n",
    "    fig.colorbar(img, ax=ax)\n",
    "\n",
    "    # Plot 1, 2, 3 sigma contours\n",
    "    vals = np.amin(llh) - scs.chi2.logsf(df=2, x=[1**2, 2**2, 3**2])\n",
    "    ax.contour(a, d, llh, vals, linestyles=[\"--\", \"-.\", \"--\"], colors=\"w\")\n",
    "    \n",
    "    # Plot best fit with symmetric errors\n",
    "    ax.errorbar(bf_a, bf_d, xerr=std_a, yerr=std_d, fmt=\"o\", c=\"w\", capsize=5)   \n",
    "    \n",
    "    ax.xlabel = (\"amplitude\")\n",
    "    ax.ylabel = (\"baseline\")\n",
    "    plt.show()\n",
    "\n",
    "def get_stddev_from_scan(mids, rates, weights, bfs, rngs, rate_func, nbins=100):\n",
    "    \"\"\"\n",
    "    Scan the rate_func chi2 fit LLH to get stddevs for the best fit params a, d.\n",
    "    Using matplotlib contours and averaging to approximately get the variances.\n",
    "    Note: This is not a true LLH profile scan in both variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mids : array-like\n",
    "        Time points (x) used in the original fit.\n",
    "    rates : array-like, shape (len(mids))\n",
    "        Rate values (y) used in the original fit.\n",
    "    weights : array-like, shape (len(mids))\n",
    "        Weights used in the original chi2 fit.\n",
    "    bfs : array-like, shape (2)\n",
    "        Best fit result parameters.\n",
    "    rngs : list\n",
    "        Parameter ranges ``[rng_x, rng_y]`` to scan.\n",
    "    rate_func : RateFunction instance\n",
    "        Rate function used to do the original fit.\n",
    "    nbins : int, optional\n",
    "        Number of bin in each dimension to sca. (Default: 100)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    stds : array-like, shape (2)\n",
    "        Approximate standard deviations (symmetric) for each fit parameter,\n",
    "        obtained using Wilks' theorem on the scanned space.\n",
    "    llh : array-like, shape (nbins, nbins)\n",
    "        Scanned LLH values.\n",
    "    grid : list\n",
    "        X, Y grid, same shape as ``llh``.\n",
    "    \"\"\"\n",
    "    def _scan_llh(bf_a, rng_a, bf_d, rng_d):\n",
    "        \"\"\" Scan LLH and return contour vertices \"\"\"\n",
    "        a_bins = np.linspace(bf_a - rng_a, bf_a + rng_a, nbins)\n",
    "        d_bins = np.linspace(bf_d - rng_d, bf_d + rng_d, nbins)   \n",
    "        a, d = np.meshgrid(a_bins, d_bins)\n",
    "        AA, DD = map(np.ravel, [a, d])\n",
    "        llh = np.empty_like(AA)\n",
    "        for i, (ai, di) in enumerate(zip(AA, DD)):\n",
    "            llh[i] = rf._lstsq((ai, di), mids, rates, weights)\n",
    "        llh = llh.reshape(a.shape)\n",
    "        # Get the contour points and average over min, max per parameter\n",
    "        one_sigma = np.amin(llh) - scs.chi2.logsf(df=2, x=[1**2])\n",
    "        cont = contour.Cntr(a, d, llh, one_sigma)\n",
    "#         plt.clf()\n",
    "        # https://stackoverflow.com/questions/5666056\n",
    "        # Collection list contains one LineCollection per contour value\n",
    "        return cont.collections[0].get_paths(), llh, [a, d]\n",
    "    \n",
    "    def _get_stds_from_path(path):\n",
    "        \"\"\" Create symmetric stddevs from the path vertices \"\"\"\n",
    "        x = path.vertices[:, 0]\n",
    "        y = path.vertices[:, 1]\n",
    "        # Average asymmetricities in both direction\n",
    "        a_min, a_max = np.amin(x), np.amax(x)\n",
    "        d_min, d_max = np.amin(y), np.amax(y)\n",
    "        return 0.5 * (a_max - a_min), 0.5 * (d_max - d_min)\n",
    "        \n",
    "    bf_a, bf_d = bfs\n",
    "    rng_a, rng_d = rngs\n",
    "    \n",
    "    # Scan the LLH, adapt scan range if contour is not closed\n",
    "    closed = False\n",
    "    while not closed:\n",
    "        # Get contour from scanned LLH space\n",
    "        paths, llh, grid = _scan_llh(bf_a, rng_a, bf_d, rng_d)\n",
    "        \n",
    "        # We want the contour to be fully contained. Means there is only one\n",
    "        # path and the first and last point are close.\n",
    "        if len(paths) == 1:\n",
    "            path = paths[0]\n",
    "            # If no contour is made, path has only a single vertex\n",
    "            if len(path.vertices) > 1:\n",
    "                max_bin_dist = np.amax([rng_a / float(nbins),\n",
    "                                        rng_d / float(nbins)])\n",
    "                closed = np.allclose(path.vertices[0], path.vertices[-1],\n",
    "                                     atol=max_bin_dist)\n",
    "        if not closed:\n",
    "            # Otherwise make the scan range twice as large and retry\n",
    "            # TODO: Is there a mechanism to decide if only y OR y needs scaling?\n",
    "            rng_a *= 2\n",
    "            rng_d *= 2\n",
    "            \n",
    "    for i in range(2):\n",
    "        std_a, std_d = _get_stds_from_path(path)\n",
    "        rng_a = std_a * 1.1\n",
    "        rng_d = std_d * 1.1\n",
    "        paths, llh, grid = _scan_llh(bf_a, rng_a, bf_d, rng_d)\n",
    "        path = paths[0]\n",
    "\n",
    "    stds = np.array(_get_stds_from_path(path))\n",
    "    return stds, llh, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import matplotlib._cntr as contour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sindec = IC79[\"sinDec\"]\n",
    "t_ = np.linspace(IC79[\"timeMJD\"].min(), IC79[\"timeMJD\"].max(), 200)\n",
    "\n",
    "allres = []\n",
    "errs = []\n",
    "for j, (lo, hi) in enumerate(zip(sindec_bins[:-1], sindec_bins[1:])[:]):\n",
    "    mask = (sindec >= lo) & (sindec <= hi)\n",
    "\n",
    "    recs = make_rate_records(T=IC79[\"timeMJD\"][mask], run_dict=IC79rd)\n",
    "    rates, new_bins, stddev, _ = rebin_rate_rec(rate_rec=recs, bins=rate_rebins,\n",
    "                                                ignore_zero_runs=True)\n",
    "    new_mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "    weights = 1. / stddev\n",
    "    res = rf.fit(rate=rates, srcs=IC79srcs, t=new_mids, w=weights)\n",
    "    allres.append(res)\n",
    "    \n",
    "    plt.errorbar(recs[\"start_mjd\"], recs[\"rate\"], yerr=recs[\"rate_std\"],\n",
    "                 fmt=\",\", alpha=0.2, color=\"C0\")\n",
    "    plt.plot(recs[\"start_mjd\"], recs[\"rate\"], marker=\".\", ls=\"\", color=\"C0\")\n",
    "    plt.plot(new_bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "    plt.plot(t_, rf.fun(t=t_, pars=res.x), color=\"C3\")\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    bfs = np.array([res.x[0], res.x[1]])\n",
    "    # Empirical estimates for amplitude and baseline scan range\n",
    "    rngs = np.array([bfs[0], bfs[1] / 10.])\n",
    "    stds, llh, grid = get_stddev_from_scan(\n",
    "        new_mids, rates, weights, bfs=bfs, rngs=rngs, rate_func=rf)\n",
    "    \n",
    "    plot_llh_scan(bfs, stds, llh, grid)\n",
    "    \n",
    "    errs.append(stds)\n",
    "\n",
    "errs = np.array(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "x = np.linspace(-1, 1, 100)\n",
    "mids = 0.5 * (sindec_bins[:-1] + sindec_bins[1:])\n",
    "norm = np.diff(sindec_bins)\n",
    "\n",
    "vals = np.array([res.x[idx] for res in allres]) / norm\n",
    "err_ = errs.T[idx] / norm\n",
    "\n",
    "vals, pts, err_ = make_spl_edges(vals, sindec_bins, err_)\n",
    "err_[[0, -1]] = np.amax(err_)\n",
    "w = 1. / err_\n",
    "spl = sci.UnivariateSpline(pts, vals, w=w, s=len(vals) - 2)\n",
    "\n",
    "plt.errorbar(pts, vals, yerr=err_, fmt=\".\", color=\"C7\")\n",
    "plt.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.plot(x, spl(x))\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2 (OSX)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

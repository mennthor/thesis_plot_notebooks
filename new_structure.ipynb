{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as sci\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from astropy.time import Time as astrotime\n",
    "\n",
    "from tdepps.utils import (create_run_dict, make_rate_records, rebin_rate_rec,\n",
    "                          make_spl_edges, fit_spl_to_hist, arr2str,\n",
    "                          power_law_flux)\n",
    "from tdepps.toolkit import (SignalFluenceInjector, UniformTimeSampler,\n",
    "                            TimeDecDependentBGDataInjector,\n",
    "                            SinusFixedConstRateFunction)\n",
    "from tdepps.toolkit import MultiSignalFluenceInjector, MultiBGDataInjector\n",
    "from tdepps.model_pdf import GRBPDF\n",
    "from tdepps.llh import GRBLLH, MultiGRBLLH\n",
    "from tdepps.analysis import GRBLLHAnalysis\n",
    "\n",
    "secinday = 24. * 60. * 60.\n",
    "rndgen = np.random.RandomState(42439462)\n",
    "print(\"Started: \", astrotime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Setup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def setup_data(sample_name):\n",
    "    names = [\"79\", \"86I\", \"86II\", \"86III\"]\n",
    "\n",
    "    print(\"# Loading experimental data arrays:\")\n",
    "    exp = {}\n",
    "    p = \"/Users/tmenne/git/phd/hese_tdepps/data/proc/offdata\"\n",
    "    for n in names:\n",
    "        if n == sample_name or sample_name ==\"ALL\":\n",
    "            p_ = os.path.join(p, \"{}.npy\".format(n))\n",
    "            exp[n] = np.load(p_)\n",
    "            print(\" - {}: '{}'\".format(n, p_))\n",
    "\n",
    "\n",
    "    print(\"# Loading Monte Carlo data arrays:\")\n",
    "    mc = {}\n",
    "    files_ = [\"IC79/IC79_corrected_MC.npy\",\n",
    "              \"IC86_2011/IC86_corrected_MC.npy\",\n",
    "              \"IC86_2012/IC86-2012_corrected_MC.npy\",\n",
    "              \"IC86_2012/IC86-2012_corrected_MC.npy\"]\n",
    "    p = \"/Users/tmenne/git/phd/hese_tdepps/data/raw\"\n",
    "    for n, f_ in zip(names, files_):\n",
    "        if n == sample_name or sample_name ==\"ALL\":\n",
    "            p_ = os.path.join(p, f_)\n",
    "            mc[n] = np.load(p_)\n",
    "            print(\" - {}: '{}'\".format(n, p_))\n",
    "\n",
    "    # We need \"timeMJD\" as a name, so change the dtype names\n",
    "    for mci in mc.values():\n",
    "        if \"timeMJD\" not in mci.dtype.names:\n",
    "            idx = mci.dtype.names.index(\"time\")\n",
    "            mci.dtype.names = (mci.dtype.names[:idx] + (\"timeMJD\",) +\n",
    "                               mci.dtype.names[idx + 1:])\n",
    "\n",
    "\n",
    "    print(\"# Loading runlists:\")\n",
    "    rundict = {}\n",
    "    files_ = [\"IC79v24.json\", \"IC86_2011.json\",\n",
    "              \"IC86_2012.json\", \"IC86_2013.json\"]\n",
    "    p = \"/Users/tmenne/git/phd/hese_tdepps/data/proc/goodruns\"\n",
    "    for n, f_ in zip(names, files_):\n",
    "        if n == sample_name or sample_name ==\"ALL\":\n",
    "            p_ = os.path.join(p, f_)\n",
    "            rundict[n] = json.load(open(p_))\n",
    "            print(\" - {}: '{}'\".format(n, p_))\n",
    "\n",
    "\n",
    "    print(\"# Load HESE tracks locations and prepare srcs:\")\n",
    "    p = os.path.join(\"/Users/tmenne/git/phd/hese_tdepps/data/raw/\",\n",
    "                     \"public_data_release/All_HESE_Events_4_years_tracks.txt\")\n",
    "    src_t, src_dec, src_ra = np.loadtxt(p, usecols=[1, 2, 3], unpack=True)\n",
    "    src_ra = np.deg2rad(src_ra)\n",
    "    src_dec = np.deg2rad(src_dec)\n",
    "\n",
    "    src_arr_names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "    types = len(src_arr_names) * [np.float]\n",
    "    dtype = [(name, typ) for name, typ in zip(src_arr_names, types)]\n",
    "\n",
    "    srcs = {}\n",
    "    for key, rl in rundict.items():\n",
    "        runs = rl[\"runs\"]\n",
    "        tmin = np.amin([astrotime(r[\"good_tstart\"]).mjd for r in runs])\n",
    "        tmax = np.amax([astrotime(r[\"good_tstop\"]).mjd for r in runs])\n",
    "        t_mask = (src_t >= tmin) & (src_t <= tmax)\n",
    "\n",
    "        src_ti = src_t[t_mask]\n",
    "        nsrcs_i = len(src_ti)\n",
    "\n",
    "        srcs_i = np.empty((nsrcs_i, ), dtype=dtype)\n",
    "\n",
    "        srcs_i[\"t\"] = src_ti\n",
    "        # Leave empty for now, time window is set explicitely below\n",
    "        srcs_i[\"dt0\"] = np.zeros(nsrcs_i, dtype=np.float)\n",
    "        srcs_i[\"dt1\"] = np.zeros(nsrcs_i, dtype=np.float)\n",
    "        srcs_i[\"ra\"] = src_ra[t_mask]\n",
    "        srcs_i[\"dec\"] = src_dec[t_mask]\n",
    "        srcs_i[\"w_theo\"] = np.ones(nsrcs_i, dtype=np.float)\n",
    "        srcs[key] = srcs_i\n",
    "\n",
    "    p = (\"/Users/tmenne/git/phd/hese_tdepps/data/proc/\" +\n",
    "         \"time_windows/time_windows.txt\")\n",
    "    time_window = np.loadtxt(fname=p)[tw_id]\n",
    "    print(\"   + Loaded time window list: '{}'\".format(p))\n",
    "    print(\"   + Using time window {:2d}: {:.2f}s\".format(tw_id,\n",
    "                                                       np.diff(time_window)[0]))\n",
    "    for key, srcs_i in sorted(srcs.items()):\n",
    "        print(\" - {}:\".format(key))\n",
    "        srcs_i[\"dt0\"] = np.repeat(time_window[0], repeats=len(srcs_i))\n",
    "        srcs_i[\"dt1\"] = np.repeat(time_window[1], repeats=len(srcs_i))\n",
    "        for n in srcs_i.dtype.names:\n",
    "            print(\"   + {}: [{}]\".format(n, arr2str(srcs_i[n], fmt=\"{:.2f}\")))\n",
    "            \n",
    "    # If all selected, concat IC86II & III, because they have the same MC    \n",
    "    if sample_name == \"ALL\":\n",
    "        exp[\"86II_III\"] = np.concatenate((exp[\"86II\"], exp[\"86III\"]))\n",
    "        _ = exp.pop(\"86II\")\n",
    "        _ = exp.pop(\"86III\")\n",
    "        \n",
    "        mc[\"86II_III\"] = mc[\"86II\"]\n",
    "        _ = mc.pop(\"86II\")\n",
    "        _ = mc.pop(\"86III\")\n",
    "        \n",
    "        srcs[\"86II_III\"] = np.concatenate((srcs[\"86II\"], srcs[\"86III\"]))\n",
    "        _ = srcs.pop(\"86II\")\n",
    "        _ = srcs.pop(\"86III\")\n",
    "        \n",
    "        rundict[\"86II_III\"] = {\n",
    "            \"runs\": rundict[\"86II\"][\"runs\"] + rundict[\"86III\"][\"runs\"]}\n",
    "        _ = rundict.pop(\"86II\")\n",
    "        _ = rundict.pop(\"86III\")\n",
    "        print(\"All samples selected, combined 86II and 86III tp 86II_III.\")\n",
    "                \n",
    "    return exp, mc, srcs, rundict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "# Loading data setup\n",
    "tw_id = 15\n",
    "sample_name = \"ALL\"  # One of: 79, 86I, 86II, 86III or ALL\n",
    "if sample_name not in [\"79\", \"86I\", \"86II\", \"86III\", \"ALL\"]:\n",
    "    raise ValueError(\"Wrong name for `n` chosen.\")\n",
    "\n",
    "exp, mc, srcs, rundict = setup_data(sample_name)\n",
    "\n",
    "# Single year aliases for testing\n",
    "if sample_name is not \"ALL\":\n",
    "    exp_ = exp[sample_name]\n",
    "    MC_ = mc[sample_name]\n",
    "    srcs_ = srcs[sample_name]\n",
    "    run_dict_ = create_run_dict(rundict[sample_name][\"runs\"])\n",
    "else:\n",
    "    exp_ = exp\n",
    "    MC_ = mc\n",
    "    srcs_ = srcs\n",
    "    run_dict_ = {key: create_run_dict(rd[\"runs\"]) for key, rd\n",
    "                 in rundict.items()}\n",
    "\n",
    "print(\"\\nDone, loaded sample(s) for '{}'.\".format(sample_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build and fit bg injector\n",
    "# Finer resolution around the horizon region, where we usually switch the event\n",
    "# selections from northern to southern samples\n",
    "hor = np.sin(np.deg2rad(30))\n",
    "sindec_bins = np.unique(np.concatenate([\n",
    "                        np.linspace(-1., -hor, 3 + 1),    # south\n",
    "                        np.linspace(-hor, +hor, 14 + 1),  # horizon\n",
    "                        np.linspace(+hor, 1., 3 + 1),     # north\n",
    "                        ]))\n",
    "rate_rebins = np.linspace(exp_[\"timeMJD\"].min(), exp_[\"timeMJD\"].max(), 12)\n",
    "# Choose spl_s so that the spline sticks a little more to the data\n",
    "bg_inj_args = {\"sindec_bins\": sindec_bins, \"rate_rebins\": rate_rebins,\n",
    "               \"spl_s\": len(sindec_bins) // 2, \"n_scan_bins\": 25}\n",
    "bg_inj = TimeDecDependentBGDataInjector(bg_inj_args=bg_inj_args, rndgen=rndgen)\n",
    "bg_inj.fit(X=exp_, srcs=srcs_, run_dict=run_dict_)\n",
    "\n",
    "# Build and fit sig injector\n",
    "ts = UniformTimeSampler(random_state=None)\n",
    "sig_inj = SignalFluenceInjector(power_law_flux, time_sampler=ts)\n",
    "sig_inj.fit(srcs_, MC=MC_, exp_names=bg_inj.provided_data)\n",
    "\n",
    "# Build and fit llh\n",
    "pdf = GRBPDF(exp_, MC_, srcs_)\n",
    "llh_args = None\n",
    "llh = GRBLLH(model_pdf=pdf, llh_args=llh_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ana = GRBLLHAnalysis(llh, bg_inj, sig_inj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Rate allsky model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Redo the allsky rate fit for testing\n",
    "recs = make_rate_records(T=exp_[\"timeMJD\"], run_dict=run_dict_)\n",
    "rates, new_bins, stddev, _ = rebin_rate_rec(rate_rec=recs, bins=rate_rebins,\n",
    "                                     ignore_zero_runs=True)\n",
    "mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "\n",
    "rate_func = SinusFixedConstRateFunction(p_fix=365.)\n",
    "allsky_res = rate_func.fit(rate=rates, srcs=srcs_, t=mids, w=1. / stddev)\n",
    "\n",
    "t0_fix = allsky_res.x[1]\n",
    "print(\"Best fit t0 before first event: \",\n",
    "      t0_fix - exp_[\"timeMJD\"].min(), \"days\")\n",
    "\n",
    "rate_func = SinusFixedConstRateFunction(p_fix=365., t0_fix=t0_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### BG splines and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Show build spline models for timedependent injector\n",
    "x = np.linspace(-1, 1, 100)\n",
    "bins = bg_inj_args[\"sindec_bins\"]\n",
    "mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "allsky_pars = bg_inj._spl_info[\"allsky_best_params\"]\n",
    "print(\"Allsky best params: \" + arr2str(allsky_pars))\n",
    "\n",
    "TEST = True\n",
    "\n",
    "for n in [\"amp\", \"base\"]:\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    spl = bg_inj._spl_info[\"param_splines\"][n]\n",
    "    vals = np.copy(bg_inj._spl_info[\"best_pars_norm\"][n])\n",
    "    err = np.copy(bg_inj._spl_info[\"best_stddevs_norm\"][n])\n",
    "   \n",
    "    ax.plot(x, spl(x), color=\"k\")\n",
    "    ax.plot(mids, vals, color=\"C7\", ls=\"--\")\n",
    "    ax.errorbar(mids, vals, yerr=err, fmt=\"o\", color=\"C1\")\n",
    "        \n",
    "    # Quickly switch smoothing for testing\n",
    "    if TEST:\n",
    "        w = 1. / err\n",
    "        vals_, pts_, w = make_spl_edges(vals=vals, bins=sindec_bins, w=w)\n",
    "        stop = False\n",
    "        s_ = bg_inj_args[\"spl_s\"]\n",
    "        while not stop:\n",
    "            spl_ = sci.UnivariateSpline(pts_, vals_, w=w, s=s_)\n",
    "            norm_ = (allsky_pars[0] if n == \"amp\" else allsky_pars[-1])\n",
    "\n",
    "            spl2_ = spl_.derivative(n=2)\n",
    "            stop = np.all(np.abs(spl2_(x)) < 1.)\n",
    "            if not stop:\n",
    "                s_ = s_ * 0.9\n",
    "                print(\"Degraded s_. 2nd derivative was \",\n",
    "                      np.abs(spl2_(x)).max())\n",
    "        # Renorm to allsky for comparison\n",
    "        scale_ = norm_ / spl_.integral(-1, 1)\n",
    "        ax.plot(x, spl_(x) * scale_, color=\"C0\", ls=\"--\")\n",
    "    \n",
    "    if n == \"amp\":\n",
    "        ax.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "    else:\n",
    "        ax.set_ylim(0, None)\n",
    "\n",
    "    ax.set_xlabel(\"sindec\")\n",
    "    ax.set_ylabel(n)\n",
    "    ax.set_title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "    # Show sindec bin borders\n",
    "    ylim = ax.get_ylim()\n",
    "    ax.vlines(sindec_bins, ylim[0], ylim[1],\n",
    "               linestyles=\":\", colors=\"C7\")\n",
    "    ylim = ax.set_ylim(ylim)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compare hist to allsky model\n",
    "x = np.linspace(-1, 1, 200)\n",
    "bins = 100\n",
    "plt.vlines(sindec_bins, 0, 1, linestyles=\"--\", colors=\"C7\", zorder=-1)\n",
    "plt.hist(np.sin(exp_[\"dec\"]), bins=bins, density=True)\n",
    "plt.plot(x, bg_inj._spl_info[\"data_spl\"](x))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make multiple trials and concat to compare to spline with large stats\n",
    "# Use internal debug var to get samples per source to compare to splines\n",
    "nsrcs = len(bg_inj.srcs)\n",
    "sam = [list() for _ in range(nsrcs)]\n",
    "for _ in range(200):\n",
    "    sami = bg_inj.sample()\n",
    "    src_idx = bg_inj._sample_idx[\"src_idx\"]\n",
    "    for j in range(nsrcs):\n",
    "        sam[j].append(sami[src_idx == j])\n",
    "        \n",
    "sam = [np.concatenate(sami) for sami in sam]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 200)\n",
    "bins = 40\n",
    "# bins = np.linspace(-1, 1, 17 + 1)\n",
    "for j, sami in enumerate(sam):\n",
    "    plt.vlines(sindec_bins, 0, 1, linestyles=\"--\", colors=\"C7\", zorder=-1)\n",
    "    # Plot allyear sample for comparison\n",
    "    plt.hist(np.sin(exp_[\"dec\"]), bins=bins, density=True, color=\"0.75\")\n",
    "    plt.plot(x, bg_inj._spl_info[\"data_spl\"](x), color=\"C0\", ls=\":\", lw=3)\n",
    "    # Drawn sample per source. Red hist should approx. follow black spline\n",
    "    plt.hist(np.sin(sami[\"dec\"]), bins=bins, density=True,\n",
    "             histtype=\"step\", lw=2.5, color=\"C3\")\n",
    "    plt.plot(x, bg_inj._spl_info[\"sin_dec_splines\"][j](x), color=\"k\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### MC Injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Testing signal injector\n",
    "sam = sig_inj.sample(n_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sampled MC hist\n",
    "n = \"logE\"\n",
    "\n",
    "# Compare to full MC pool distribution\n",
    "w = sig_inj._MC[\"ow\"] * sig_inj.flux_model(sig_inj._MC[\"trueE\"])\n",
    "_ = plt.hist(sig_inj._MC[n], weights=w, density=True, bins=100, alpha=.5)\n",
    "plt.title(n)\n",
    "\n",
    "# Show sampled data-like attributes\n",
    "if n in sig_inj.provided_data:\n",
    "    _ = plt.hist(sam[n], density=True, bins=100, histtype=\"step\", lw=3)\n",
    "    if n in [\"ra\", \"dec\"]:\n",
    "        plt.vlines(sig_inj.srcs[n], 0, 1)\n",
    "        plt.yscale(\"log\", nonposy=\"clip\")\n",
    "        plt.show()\n",
    "    elif n == \"timeMJD\":\n",
    "        plt.vlines(sig_inj.srcs[\"t\"], 0, 1)\n",
    "        plt.vlines(sig_inj.srcs[\"t\"] + sig_inj.srcs[\"dt0\"] / 86400.,\n",
    "                   0, 1, linestyles=\"--\")\n",
    "        plt.vlines(sig_inj.srcs[\"t\"] + sig_inj.srcs[\"dt1\"] / 86400.,\n",
    "                   0, 1, linestyles=\"--\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LLH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Test LLH scan instead of hess_inv from fitres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     35
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_llh_scan(bfs, stds, llh, grid):\n",
    "    \"\"\"\n",
    "    Plot the llh scan with errors and contours\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bfs : array-like, shape (2)\n",
    "        Best fit result parameters, around which the LLH was scanned.\n",
    "    stds : array-like, shape (2)\n",
    "        Approximate standard deviations (symmetric) for each fit parameter,\n",
    "        obtained using Wilks' theorem on the scanned space.\n",
    "    llh : array-like, shape (nbins, nbins)\n",
    "        Scanned LLH values.\n",
    "    grid : list\n",
    "        X, Y grid, same shape as ``llh``.\n",
    "    \"\"\"\n",
    "    bf_x, bf_y = bfs\n",
    "    std_x, std_y = stds\n",
    "    x, y = grid\n",
    "    \n",
    "    # Plot scan\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    img = ax.pcolormesh(x, y, llh)\n",
    "    fig.colorbar(img, ax=ax)\n",
    "\n",
    "    # Plot 1, 2, 3 sigma contours\n",
    "    vals = np.amin(llh) - scs.chi2.logsf(df=2, x=[1**2, 2**2, 3**2])\n",
    "    ax.contour(x, y, llh, vals, linestyles=[\"--\", \"-.\", \"--\"], colors=\"w\")\n",
    "    \n",
    "    # Plot best fit with symmetric errors\n",
    "    ax.errorbar(bf_x, bf_y, xerr=std_x, yerr=std_y, fmt=\"o\", c=\"w\", capsize=5)   \n",
    "    \n",
    "    ax.xlabel = (\"amplitude\")\n",
    "    ax.ylabel = (\"baseline\")\n",
    "\n",
    "def get_stddev_from_scan(func, args, bfs, rngs, nbins=50):\n",
    "    \"\"\"\n",
    "    Scan the rate_func chi2 fit LLH to get stddevs for the best fit params a, d.\n",
    "    Using matplotlib contours and averaging to approximately get the variances.\n",
    "    Note: This is not a true LLH profile scan in both variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        Loss function to be scanned, used to obtain the best fit. Function\n",
    "        is called as done with a scipy fitter, ``func(x, *args)``.\n",
    "    args : tuple\n",
    "        Args passed to the loss function ``func``. For a rate function, this is\n",
    "        ``(mids, rates, weights)``.\n",
    "    bfs : array-like, shape (2)\n",
    "        Best fit result parameters.\n",
    "    rngs : list\n",
    "        Parameter ranges to scan: ``[bf[i] - rng[i], bf[i] + rng[i]]``.\n",
    "    nbins : int, optional\n",
    "        Number of bins in each dimension to scan. (Default: 100)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    stds : array-like, shape (2)\n",
    "        Approximate standard deviations (symmetric) for each fit parameter,\n",
    "        obtained using Wilks' theorem on the scanned space.\n",
    "    llh : array-like, shape (nbins, nbins)\n",
    "        Scanned LLH values.\n",
    "    grid : list\n",
    "        X, Y grid, same shape as ``llh``.\n",
    "    \"\"\"\n",
    "    def _scan_llh(bf_x, rng_x, bf_y, rng_y):\n",
    "        \"\"\" Scan LLH and return contour vertices \"\"\"\n",
    "        x_bins = np.linspace(bf_x - rng_x, bf_x + rng_x, nbins)\n",
    "        y_bins = np.linspace(bf_y - rng_y, bf_y + rng_y, nbins)   \n",
    "        x, y = np.meshgrid(x_bins, y_bins)\n",
    "        AA, DD = map(np.ravel, [x, y])\n",
    "        llh = np.empty_like(AA)\n",
    "        for i, (ai, di) in enumerate(zip(AA, DD)):\n",
    "            llh[i] = func((ai, di), *args)\n",
    "        llh = llh.reshape(x.shape)\n",
    "        # Get the contour points and average over min, max per parameter\n",
    "        one_sigma_level = np.amin(llh) - scs.chi2.logsf(df=2, x=[1**2])\n",
    "\n",
    "        # https://stackoverflow.com/questions/5666056\n",
    "        cntr = plt.contour(x, y, llh, one_sigma_level)\n",
    "        plt.close(\"all\")\n",
    "        paths = [lcol.vertices for lcol in cntr.collections[0].get_paths()]\n",
    "        # Call undocumented base of plt.contour, to avoid creating a figure.\n",
    "        # Not working for mpl 2.2.2 any more, because _cntr was deleted.\n",
    "        # cntr = contour.Cntr(x, y, llh)\n",
    "        # paths = cntr.trace(level0=one_sigma_level)\n",
    "        # paths = paths[:len(paths) // 2]  # First half of list has the vertices\n",
    "        return paths, llh, [x, y]\n",
    "\n",
    "    def _is_path_closed(paths, rng_x, rng_y):\n",
    "        \"\"\"\n",
    "        We want the contour to be fully contained. Means there is only one path\n",
    "        and the first and last point are close together.\n",
    "        Returns ``True`` if contour is closed.\n",
    "        \"\"\"\n",
    "        closed = False\n",
    "        if len(paths) == 1:\n",
    "            vertices = paths[0]\n",
    "            # If no contour is made, only 1 vertex is returned -> invalid\n",
    "            if len(vertices) > 1:\n",
    "                max_bin_dist = np.amax([rng_x / float(nbins),\n",
    "                                        rng_y / float(nbins)])\n",
    "                closed = np.allclose(vertices[0], vertices[-1],\n",
    "                                     atol=max_bin_dist, rtol=0.)\n",
    "        return closed\n",
    "    \n",
    "    def _get_stds_from_path(path):\n",
    "        \"\"\" Create symmetric stddevs from the path vertices \"\"\"\n",
    "        x, y = path[:, 0], path[:, 1]\n",
    "        # Average asymmetricities in both direction\n",
    "        x_min, x_max = np.amin(x), np.amax(x)\n",
    "        y_min, y_max = np.amin(y), np.amax(y)\n",
    "        return 0.5 * (x_max - x_min), 0.5 * (y_max - y_min)\n",
    "           \n",
    "    # Scan the LLH, adapt scan range if contour is not closed\n",
    "    bf_x, bf_y = bfs\n",
    "    rng_x, rng_y = rngs\n",
    "    closed = False\n",
    "    while not closed:\n",
    "        # Default is scaling up, when range is too small\n",
    "        scalex, scaley = 10., 10.\n",
    "        # Get contour from scanned LLH space\n",
    "        paths, llh, grid = _scan_llh(bf_x, rng_x, bf_y, rng_y)\n",
    "        closed = _is_path_closed(paths, rng_x, rng_y)       \n",
    "        if closed:\n",
    "            vertices = paths[0]\n",
    "            # Estimate scale factors to get contour in optimum resolution\n",
    "            diffx = np.abs(np.amax(vertices[:, 0]) - np.amin(vertices[:, 0]))\n",
    "            diffy = np.abs(np.amax(vertices[:, 1]) - np.amin(vertices[:, 1]))\n",
    "            scalex = diffx / rng_x\n",
    "            scaley = diffy / rng_y\n",
    "            # Contour can be closed, but extremely zoomed out in only one param\n",
    "            if not np.allclose([scalex, scaley], 1., atol=0.5, rtol=0.):\n",
    "                print(\"Contour is very distorted in one direction\")\n",
    "                closed = False\n",
    "            else:\n",
    "                # Rescan valid contour to use optimal scan resolution\n",
    "                for i in range(2):\n",
    "                    std_x, std_y = _get_stds_from_path(vertices)\n",
    "                    rng_x = std_x * 1.05  # Allow a little padding\n",
    "                    rng_y = std_y * 1.05\n",
    "                    paths, llh, grid = _scan_llh(bf_x, rng_x, bf_y, rng_y)\n",
    "                    # Recheck if path is still valid\n",
    "                    closed = _is_path_closed(paths, rng_x, rng_y)\n",
    "        # Must be seperated if, because path can get invalid in rescaling step\n",
    "        if not closed:\n",
    "            print(\"Open or no contour, rescale\")\n",
    "            rng_x *= scalex\n",
    "            rng_y *= scaley\n",
    "\n",
    "    vertices = paths[0]\n",
    "    stds = np.array(_get_stds_from_path(vertices))\n",
    "    return stds, llh, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sindec = exp_[\"sinDec\"]\n",
    "t_ = np.linspace(exp_[\"timeMJD\"].min(), exp_[\"timeMJD\"].max(), 200)\n",
    "\n",
    "allres = []\n",
    "errs = []\n",
    "for j, (lo, hi) in enumerate(zip(sindec_bins[:-1], sindec_bins[1:])[:]):\n",
    "    mask = (sindec >= lo) & (sindec <= hi)\n",
    "\n",
    "    recs = make_rate_records(T=exp_[\"timeMJD\"][mask], run_dict=run_dict_)\n",
    "    rates, new_bins, stddev, _ = rebin_rate_rec(rate_rec=recs, bins=rate_rebins,\n",
    "                                                ignore_zero_runs=True)\n",
    "    new_mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "    weights = 1. / stddev\n",
    "    res = rate_func.fit(rate=rates, srcs=srcs_, t=new_mids, w=weights)\n",
    "    bfs = np.array([res.x[0], res.x[1]])\n",
    "    allres.append(res)\n",
    "    \n",
    "    plt.errorbar(recs[\"start_mjd\"], recs[\"rate\"], yerr=recs[\"rate_std\"],\n",
    "                 fmt=\",\", alpha=0.2, color=\"C0\")\n",
    "    plt.plot(recs[\"start_mjd\"], recs[\"rate\"], marker=\".\", ls=\"\", color=\"C0\")\n",
    "    plt.plot(new_bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "    plt.plot(t_, rate_func.fun(t=t_, pars=bfs), color=\"C3\")\n",
    "    plt.ylim(0, 3. * bfs[1])\n",
    "    plt.show()\n",
    "    \n",
    "    # Empirical seed estimates for amplitude and baseline scan range\n",
    "    args = (new_mids, rates, weights)\n",
    "    rngs = np.array([bfs[0], bfs[1] / 10.])\n",
    "    stds, llh, grid = get_stddev_from_scan(\n",
    "        func=rate_func._lstsq, args=args, bfs=bfs, rngs=rngs, nbins=20)\n",
    "    \n",
    "    plot_llh_scan(bfs, stds, llh, grid)\n",
    "    plt.show()\n",
    "    \n",
    "    errs.append(stds)\n",
    "\n",
    "errs = np.array(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 0 = amp, 1 = base\n",
    "# Note: The spline is not renormalized here, so there might be differences in\n",
    "#       scale to the one from the module\n",
    "for idx in [0, 1]:\n",
    "    x = np.linspace(-1, 1, 100)\n",
    "    mids = 0.5 * (sindec_bins[:-1] + sindec_bins[1:])\n",
    "    norm = np.diff(sindec_bins)\n",
    "\n",
    "    vals = np.array([res.x[idx] for res in allres]) / norm\n",
    "    err_ = errs.T[idx] / norm\n",
    "\n",
    "    # Prepare for spl fit\n",
    "    w = 1. / err_\n",
    "    spl, vals, pts, w = fit_spl_to_hist(h=vals, bins=sindec_bins, w=w, s=10)\n",
    "    \n",
    "    plt.plot(pts, vals, color=\"C7\", ls=\"--\")\n",
    "    plt.errorbar(pts, vals, yerr=1. / w, fmt=\"o\", color=\"C1\")\n",
    "    plt.plot(x, spl(x), color=\"k\")\n",
    "    plt.title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "\n",
    "    if idx == 0:\n",
    "        plt.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "        plt.ylabel(\"amp\")\n",
    "    else:\n",
    "        plt.ylim(0, None)\n",
    "        plt.ylabel(\"base\")\n",
    "    plt.xlabel(\"sindec\")\n",
    " \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi containers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hor = np.sin(np.deg2rad(30))\n",
    "sindec_bins = np.unique(np.concatenate([\n",
    "                        np.linspace(-1., -hor, 3 + 1),    # south\n",
    "                        np.linspace(-hor, +hor, 14 + 1),  # horizon\n",
    "                        np.linspace(+hor, 1., 3 + 1),     # north\n",
    "                        ]))\n",
    "\n",
    "# llhs = {}\n",
    "# for key in exp_names.keys():\n",
    "#     print(\"Preparing LLH {}\".format(key))\n",
    "#     pdf_i = GRBPDF(exp_[key], MC_[key], srcs_[key])\n",
    "#     llh_args = None\n",
    "#     llh_i = GRBLLH(model_pdf=pdf_i, llh_args=llh_args)\n",
    "#     llhs[key] = llh_i\n",
    "# multi_llh = MultiGRBLLH()\n",
    "# multi_llh.fit(llhs=llhs)\n",
    "\n",
    "bg_injs = {}\n",
    "bg_inj_args = {}\n",
    "for key in exp_.keys():\n",
    "    print(\"Fitting BGInj {}\".format(key))\n",
    "    if key == \"86II_III\":\n",
    "        n_rate_bins = 24\n",
    "    else:\n",
    "        n_rate_bins = 12\n",
    "    rate_rebins = np.linspace(exp_[key][\"timeMJD\"].min(),\n",
    "                              exp_[key][\"timeMJD\"].max(), n_rate_bins)\n",
    "    bg_inj_args[key] = {\"sindec_bins\": sindec_bins, \"rate_rebins\": rate_rebins,\n",
    "                        \"spl_s\": len(sindec_bins) // 2, \"n_scan_bins\": 25}\n",
    "\n",
    "    bg_inj_i = TimeDecDependentBGDataInjector(bg_inj_args=bg_inj_args[key],\n",
    "                                              rndgen=rndgen)\n",
    "    bg_inj_i.fit(X=exp_[key], srcs=srcs_[key], run_dict=run_dict_[key])\n",
    "    bg_injs[key] = bg_inj_i\n",
    "multi_bg_inj = MultiBGDataInjector()\n",
    "multi_bg_inj.fit(bg_injs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_injs = {}\n",
    "for key in exp_.keys():\n",
    "    print(\"Fitting SigInj {}\".format(key))\n",
    "    ts = UniformTimeSampler(random_state=None)\n",
    "    sig_inj_i = SignalFluenceInjector(power_law_flux, time_sampler=ts)\n",
    "    sig_inj_i.fit(srcs_, MC=MC_, exp_names=multi_bg_inj.provided_data[key])\n",
    "    sig_injs[key] = sig_inj_i\n",
    "\n",
    "multi_sig_inj = MultiSignalFluenceInjector()\n",
    "multi_sig_inj.fit(sig_injs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_ana = GRBLLHAnalysis(multi_llh, multi_bg_inj, multi_sig_inj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### BG splines and sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test if each g sampler is correctly sampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "multi_bg_sam_ = [multi_bg_inj.sample() for i in range(n_samples)]\n",
    "multi_bg_sam = {}\n",
    "for key in multi_bg_inj.names:\n",
    "    multi_bg_sam[key] = np.concatenate([sam_i[key] for sam_i in multi_bg_sam_])\n",
    "nsam = map(len, multi_bg_sam.values())\n",
    "for i, key in enumerate(multi_bg_inj.names):\n",
    "    print(\"{:8s} : {}\".format(key, nsam[i]))\n",
    "    \n",
    "nbins = 100\n",
    "for key in multi_bg_inj.names:\n",
    "    plt.hist(multi_bg_sam[key][\"dec\"], bins=nbins)\n",
    "    plt.title(key)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show build spline models for timedependent injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TEST = False\n",
    "x = np.linspace(-1, 1, 100)\n",
    "for key, bg_inj in multi_bg_inj._injs.items():\n",
    "    print(\"Plotting for sample '{}'\".format(key))\n",
    "\n",
    "    bins = bg_inj_args[key][\"sindec_bins\"]\n",
    "    mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "    print(\"Allsky best params: \" + arr2str(\n",
    "        bg_inj._spl_info[\"allsky_best_params\"]))\n",
    "\n",
    "    for n in [\"amp\", \"base\"]:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        spl = bg_inj._spl_info[\"param_splines\"][n]\n",
    "        vals = np.copy(bg_inj._spl_info[\"best_pars_norm\"][n])\n",
    "        err = np.copy(bg_inj._spl_info[\"best_stddevs_norm\"][n])\n",
    "\n",
    "        ax.plot(x, spl(x), color=\"k\")\n",
    "        ax.plot(mids, vals, color=\"C7\", ls=\"--\")\n",
    "        ax.errorbar(mids, vals, yerr=err, fmt=\"o\", color=\"C1\")\n",
    "\n",
    "        # Quickly switch smoothing for testing\n",
    "        if TEST:\n",
    "            w = 1. / err\n",
    "            vals_, pts_, w = make_spl_edges(vals=vals, bins=sindec_bins, w=w)\n",
    "            stop = False\n",
    "            s_ = bg_inj_args[\"spl_s\"]\n",
    "            while not stop:\n",
    "                spl_ = sci.UnivariateSpline(pts_, vals_, w=w, s=s_)\n",
    "                norm_ = (bg_inj._spl_info[\"allsky_best_params\"][0] if n == \"amp\"\n",
    "                         else bg_inj._spl_info[\"allsky_best_params\"][-1])\n",
    "\n",
    "                spl2_ = spl_.derivative(n=2)\n",
    "                stop = np.all(np.abs(spl2_(x)) < 1.)\n",
    "                if not stop:\n",
    "                    s_ = s_ * 0.9\n",
    "                    print(\"Degraded s_. 2nd derivative was \",\n",
    "                          np.abs(spl2_(x)).max())\n",
    "            # Renorm to allsky for comparison\n",
    "            scale_ = norm_ / spl_.integral(-1, 1)\n",
    "            ax.plot(x, spl_(x) * scale_, color=\"C0\", ls=\"--\")\n",
    "\n",
    "        if n == \"amp\":\n",
    "            ax.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "        else:\n",
    "            ax.set_ylim(0, None)\n",
    "\n",
    "        ax.set_xlabel(\"sindec\")\n",
    "        ax.set_ylabel(n)\n",
    "        ax.set_title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "        # Show sindec bin borders\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.vlines(sindec_bins, ylim[0], ylim[1],\n",
    "                   linestyles=\":\", colors=\"C7\")\n",
    "        ylim = ax.set_ylim(ylim)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot rates vs rate model for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, bg_inj in sorted(multi_bg_inj._injs.items())[:]:\n",
    "    recs = make_rate_records(run_dict=run_dict_[key], T=exp_[key][\"timeMJD\"])   \n",
    "    rebin = rebin_rate_rec(rate_rec=recs, bins=bg_inj_args[key][\"rate_rebins\"],\n",
    "                           ignore_zero_runs=True)\n",
    "    rates, bins, rate_std, _ = rebin\n",
    "\n",
    "    mids = 0.5 * (recs[\"start_mjd\"] + recs[\"stop_mjd\"])\n",
    "    diff = recs[\"stop_mjd\"] - recs[\"start_mjd\"]\n",
    "    t = np.linspace(bins[0], bins[-1], 200)\n",
    "    \n",
    "    # Plot it\n",
    "    plt.errorbar(mids, recs[\"rate\"], xerr=diff, yerr=recs[\"rate_std\"], fmt=\",\",\n",
    "                 color=\"C0\", alpha=0.5)\n",
    "    plt.plot(bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "    plt.plot(t, bg_inj._spl_info[\"allsky_rate_func\"].bf_fun(t),\n",
    "             color=\"C3\", lw=2.5)\n",
    "        \n",
    "    plt.ylim(0, 0.01)\n",
    "    plt.xlabel(\"time in MJD days\")\n",
    "    plt.ylabel(\"Rate in mHz\")\n",
    "    plt.title(\"Allsky rate model for sample {}\".format(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot rate model for each sindec bin per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, bg_inj in sorted(multi_bg_inj._injs.items())[:]:\n",
    "    T = exp_[key][\"timeMJD\"]\n",
    "    sindec = np.sin(exp_[key][\"dec\"])\n",
    "    sd_bins = bg_inj_args[key][\"sindec_bins\"]\n",
    "    rate_fun = bg_inj._spl_info[\"allsky_rate_func\"]\n",
    "\n",
    "    nplots, nrows, ncols = 20, 4, 5\n",
    "    assert ncols * nrows == nplots\n",
    "    assert nplots == len(sindec_bins) - 1\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(24, 13.5),\n",
    "                           sharex=True, sharey=True)\n",
    "    \n",
    "    for i, (lo, hi) in enumerate(zip(sd_bins[:-1], sd_bins[1:])):\n",
    "        mask = (sindec >= lo) & (sindec < hi)              \n",
    "        recs = make_rate_records(run_dict=run_dict_[key], T=T[mask])\n",
    "        rebin = rebin_rate_rec(\n",
    "            rate_rec=recs, bins=bg_inj_args[key][\"rate_rebins\"],\n",
    "            ignore_zero_runs=True)\n",
    "        rates, bins, rate_std, _ = rebin\n",
    "        \n",
    "        mids = 0.5 * (recs[\"start_mjd\"] + recs[\"stop_mjd\"])\n",
    "        diff = recs[\"stop_mjd\"] - recs[\"start_mjd\"]\n",
    "        t = np.linspace(bins[0], bins[-1], 200)\n",
    "        \n",
    "        amp, base = bg_inj._spl_info[\"best_pars\"][i]\n",
    "        pars = (amp, bg_inj._spl_info[\"allsky_best_params\"][1], base)\n",
    "        lab = \"{:.2f} <= sindec < {:.2f}\".format(lo, hi)\n",
    "        \n",
    "        # Plot it\n",
    "        row, col = idx2rowcol(i, ncols=ncols)\n",
    "        ax_ = ax[row, col]\n",
    "        ax_.errorbar(mids, recs[\"rate\"], xerr=diff, yerr=recs[\"rate_std\"],\n",
    "                     fmt=\",\", color=\"C0\", alpha=0.5, label=lab)\n",
    "        ax_.plot(bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "        ax_.plot(t, rate_fun.fun(t, pars), color=\"C3\", lw=2.5)\n",
    "\n",
    "        ax_.set_ylim(0, 0.001)\n",
    "        ax_.legend(loc=\"upper right\")\n",
    "    ax[0, 0].text(s=\"Sample: '{}'\".format(key), x=bins[0], y=0.0009,\n",
    "                  bbox={\"facecolor\": \"w\", \"alpha\": 0.5}, fontsize=12)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compare hist to allsky model\n",
    "x = np.linspace(-1, 1, 200)\n",
    "bins = 100\n",
    "for key, bg_inj in sorted(multi_bg_inj._injs.items())[:]:\n",
    "    plt.vlines(bg_inj_args[key][\"sindec_bins\"], 0, 1, linestyles=\"--\",\n",
    "               colors=\"C7\", zorder=-1)\n",
    "    plt.hist(np.sin(exp_[key][\"dec\"]), bins=bins, density=True)\n",
    "    plt.plot(x, bg_inj._spl_info[\"data_spl\"](x))\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MC injector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test splitting of signal samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_sig_sam = multi_sig_inj.sample(n_samples=10000.)\n",
    "print(map(len, multi_sig_sam.values()))\n",
    "print(multi_sig_inj._distribute_weights)\n",
    "\n",
    "multi_sig_inj.flux2mu(1., per_source=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = \"timeMJD\"\n",
    "for sami in multi_sig_sam.values():\n",
    "    plt.hist(sami[n], bins=100, density=True,\n",
    "             histtype=\"step\", lw=2.5)\n",
    "\n",
    "if n == \"timeMJD\":\n",
    "    ylim = plt.gca().get_ylim()\n",
    "    plt.vlines(multi_sig_inj.srcs[0][\"t\"], ylim[0], ylim[1],\n",
    "               colors=\"C7\", linestyles=\"--\")\n",
    "    plt.ylim(ylim)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialisation Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2 (OSX)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

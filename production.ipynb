{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the whole production using package methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "import os\n",
    "from copy import deepcopy\n",
    "import sys\n",
    "import math\n",
    "from time import time\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mpldates\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import LogNorm, Normalize, ListedColormap\n",
    "gray_c = ListedColormap(plt.cm.gray(np.arange(100, 257, 1)), name=\"gray_c\")\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.interpolate as sci\n",
    "import scipy.optimize as sco\n",
    "import scipy.integrate as scint\n",
    "import scipy.stats as scs\n",
    "import scipy.signal as scsignal\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "import healpy as hp\n",
    "from astropy.time import Time as astrotime\n",
    "from corner import corner\n",
    "\n",
    "import sklearn.neighbors as skn\n",
    "import sklearn.model_selection as skms  # Newer version of grid_search\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "import anapymods3.plots.astro as amp_plt\n",
    "from anapymods3.plots import (split_axis, get_binmids, hist_marginalize, dg,\n",
    "                              hist_from_counts, ps_cmap, cartzoom,\n",
    "                              make_astro_xaxis, reconstruct_cartzoom_data)\n",
    "from anapymods3.stats import rejection_sampling, json2kde, sigma2prob\n",
    "from anapymods3.general import fill_dict_defaults\n",
    "from anapymods3.healpy import (wrap_theta_phi_range, gaussian_on_a_sphere,\n",
    "                               DecRaToThetaPhi, ThetaPhiToDecRa,\n",
    "                               norm_healpy_map, get_binned_healpy_map)\n",
    "\n",
    "import tdepps.bg_injector as BGInj\n",
    "import tdepps.bg_rate_injector as BGRateInj\n",
    "import tdepps.rate_function as RateFunc\n",
    "import tdepps.llh as LLH\n",
    "import tdepps.analysis as Analysis\n",
    "import tdepps.signal_injector as SigInj\n",
    "from tdepps.utils import rejection_sampling, func_min_in_interval, rotator\n",
    "\n",
    "import helper as hlp\n",
    "secinday = 24. * 60. * 60.\n",
    "print(\"Executed on \", astrotime.now())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load IC86 data from epinat, which should be the usual IC86-I (2011) PS sample, but pull corrected and OneWeights corrected by number of events generated.\n",
    "\n",
    "We apply a sigma cut, to remove badly reconstructed events.\n",
    "Use `_exp`and `_mc` for the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp = np.load(\"data/IC86_I_data.npy\")\n",
    "mc = np.load(\"data/IC86_I_mc.npy\")\n",
    "# Use the officially stated livetime, not the ones from below\n",
    "livetime = 332.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a global sigma cut (only removes a handful of badly reconstructed evts)\n",
    "_mc = mc[mc[\"sigma\"] < np.deg2rad(20)]\n",
    "_exp = exp[exp[\"sigma\"] < np.deg2rad(20)]\n",
    "\n",
    "# `sample` is used as a wrapper for plotting, where it is sometimes easier to\n",
    "# have a normal array. Shape is (nevts, nfeatures), each row is a data point\n",
    "sample = np.vstack((_exp[\"logE\"], _exp[\"dec\"], _exp[\"sigma\"], _exp[\"ra\"])).T\n",
    "mc_sample = np.vstack((_mc[\"logE\"], _mc[\"dec\"], _mc[\"sigma\"], _mc[\"ra\"])).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Production Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if the modules work correctly.\n",
    "They contain the same code as in the main test notebook, but can be used as classes.\n",
    "This should simplyfy production.\n",
    "\n",
    "Currently each submodul only does a very special task:\n",
    "\n",
    "- `bg_injector`: Samples (\"injects\") backgorund events for trials\n",
    "- `bg_rate_injector`: Samples (\"injects\") the number of BG events to be injected per trial.\n",
    "- `rate_function`: Describes the time depence of the background rate.\n",
    "- `llh`: Implements the likelihood function and signal and background PDFs.\n",
    "- `signal_injector`: Same as `bg_injector` but injecting signal evts from MC.\n",
    "- `analysis`: Main module pulling it all together, making trials, fitting llhs, provides methods for advanced tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BG Injector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Injects information for background-like events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setup for tests in this chapter\n",
    "n_samples = int(1e5)\n",
    "rndgen = np.random.RandomState(7353)\n",
    "\n",
    "xlabel = [\"logE\", \"dec\", \"logE\", \"dec\"]\n",
    "ylabel = [\"dec\", \"sigma\", \"sigma\", \"ra\"]\n",
    "\n",
    "axes = [[0, 1], [1, 2], [0,2], [1, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_inj = BGInj.DataBGInjector(random_state=rndgen)\n",
    "data_inj.fit(_exp)\n",
    "data_sam = data_inj.sample(n_samples)\n",
    "X_names = data_inj._X_names + [\"ra\"]\n",
    "\n",
    "# shape (n_samples, n_features) for plotting\n",
    "_d_sam = np.vstack((data_sam[n] for n in X_names)).T\n",
    "for i, axis in enumerate(axes):\n",
    "    fig, (al, ar) = hlp.hist_comp(sample[:, axis], _d_sam[:, axis])\n",
    "    al.set_xlabel(xlabel[i])\n",
    "    ar.set_xlabel(xlabel[i])\n",
    "    al.set_ylabel(ylabel[i])\n",
    "    ar.set_ylabel(ylabel[i])\n",
    "    al.set_title(\"Data\")\n",
    "    ar.set_title(\"Data sample: {} evts from original Data\".format(\n",
    "        len(_d_sam)))\n",
    "    # if i == 0:\n",
    "    #     plt.savefig(\"./data/figs/bg_inj_data_{}_{}.png\".format(\n",
    "    #         xlabel[i], ylabel[i]), dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Adaptive Width KDE sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Assign model from CV, which has already evaluated adaptive kernels.\n",
    "# Otherwise we would have to reevaluate which takes a long time.\n",
    "kde_model = json2kde(\"data/awKDE_CV/CV10_glob_bw_alpha_EXP_IC86I_\" +\n",
    "                     \"CUT_sig.ll.20_PARS_diag_True_pass2.json\")\n",
    "    \n",
    "# Make an arbitrary shell and just overwrite the whole KDE\n",
    "kde_inj = BGInj.KDEBGInjector(random_state=rndgen)\n",
    "kde_inj._kde_model = kde_model\n",
    "\n",
    "# Note: The original order cannot be changed now [logE, dec, sigma]\n",
    "bounds = np.array([[None, None], [-np.pi / 2. , np.pi / 2.], [0, None]])\n",
    "# Fitter uses values from already fitted KDE model\n",
    "kde_inj.fit(None, bounds)\n",
    "\n",
    "# Sample (bounds are preventing spillover in undefined regions)\n",
    "kde_sam = kde_inj.sample(n_samples)\n",
    "X_names = kde_inj._X_names + [\"ra\"]\n",
    "_kde_sam = np.vstack((kde_sam[n] for n in X_names)).T\n",
    "\n",
    "for i, axis in enumerate(axes):\n",
    "    fig, (al, ar) = hlp.hist_comp(sample[:, axis], _kde_sam[:, axis])\n",
    "    al.set_xlabel(xlabel[i])\n",
    "    ar.set_xlabel(xlabel[i])\n",
    "    al.set_ylabel(ylabel[i])\n",
    "    ar.set_ylabel(ylabel[i])\n",
    "    al.set_title(\"Data\")\n",
    "    ar.set_title(\"KDE sample: {} evts\".format(len(_kde_sam)))\n",
    "    # if i == 0:\n",
    "    #    plt.savefig(\"./data/figs/bg_inj_kde_{}_{}.png\".format(\n",
    "    #        xlabel[i], ylabel[i]), dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### GRBLLH style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# If False, only sample where data was\n",
    "# If True sample in global min/max bounding box per feature\n",
    "minmax = True\n",
    "\n",
    "mrinj = BGInj.MRichmanBGInjector(random_state=rndgen)\n",
    "ax0_bins, ax1_bins, ax2_bins = mrinj.fit(_exp, nbins=10, minmax=minmax)\n",
    "mr_sam = mrinj.sample(n_samples=n_samples)\n",
    "X_names = mrinj._X_names + [\"ra\"]\n",
    "_mr_sam = np.vstack((mr_sam[n] for n in X_names)).T\n",
    "\n",
    "for i, axis in enumerate(axes):\n",
    "    fig, (al, ar) = hlp.hist_comp(sample[:, axis], _mr_sam[:, axis])\n",
    "    al.set_xlabel(xlabel[i])\n",
    "    ar.set_xlabel(xlabel[i])\n",
    "    al.set_ylabel(ylabel[i])\n",
    "    ar.set_ylabel(ylabel[i])\n",
    "    al.set_title(\"Data\")\n",
    "    ar.set_title(\"Pseudo MR sample: {} evts\".format(len(_mr_sam)))\n",
    "    # if i == 0:\n",
    "        # plt.savefig(\"./data/figs/bg_inj_mr_{}_{}_minmax={}.png\".format(\n",
    "        # xlabel[i], ylabel[i], minmax), dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Pseudo Data (uniform) sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uni_inj = BGInj.UniformBGInjector(random_state=rndgen)\n",
    "uni_sam = uni_inj.sample(n_samples)\n",
    "X_names = uni_inj._X_names + [\"ra\"]\n",
    "_uni_sam = np.vstack([uni_sam[n] for n in X_names]).T\n",
    "\n",
    "for i, axis in enumerate(axes):\n",
    "    fig, (al, ar) = hlp.hist_comp(sample[:, axis], _uni_sam[:, axis])\n",
    "    al.set_xlabel(xlabel[i])\n",
    "    ar.set_xlabel(xlabel[i])\n",
    "    al.set_ylabel(ylabel[i])\n",
    "    ar.set_ylabel(ylabel[i])\n",
    "    al.set_title(\"Data\")\n",
    "    ar.set_title(\"Pseudo (uniform) sample: {} evts\".format(len(_uni_sam)))\n",
    "    # if i == 0:\n",
    "    #     plt.savefig(\"./data/figs/bg_inj_pseudo_{}_{}.png\".format(\n",
    "    #         xlabel[i], ylabel[i]), dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sample per source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sample for various numbers of injected events to simulate mutiple sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "MR = True\n",
    "if MR:  # Choose MR injector\n",
    "    bg_inj = BGInj.MRichmanBGInjector(random_state=rndgen)\n",
    "    bg_inj.fit(_exp, nbins=10, minmax=False)\n",
    "else:  # Choose data\n",
    "    bg_inj = BGInj.DataBGInjector(random_state=rndgen)\n",
    "    bg_inj.fit(_exp)\n",
    "\n",
    "nsrcs = 5\n",
    "nevts_per_source = 1000 * np.arange(1, nsrcs + 1)\n",
    "nevts = np.sum(nevts_per_source)\n",
    "\n",
    "X = []\n",
    "for i in range(nsrcs):\n",
    "    X.append(bg_inj.sample(nevts_per_source[i]))\n",
    "\n",
    "# Show sampled events per src for all trials\n",
    "colors = plt.cm.inferno_r(np.linspace(0.1, 0.9, nsrcs))\n",
    "labels = [\"{}\".format(str(ni)) for ni in nevts_per_source]\n",
    "\n",
    "# ra, dec skymap\n",
    "skymap = amp_plt.skymap()\n",
    "fig, ax = skymap.figure(tex=False, gal_plane=True)\n",
    "for Xi, c, l in zip(X, colors, labels):\n",
    "    x, y = skymap.EquCoordsToMapCoords(Xi[\"ra\"], Xi[\"dec\"])\n",
    "    ax.plot(x, y, ls=\"\", marker=\".\", ms=2, color=c, alpha=0.5, label=l)\n",
    "ax.legend(loc=\"upper right\")\n",
    "plt.show()\n",
    "\n",
    "# 1D hists\n",
    "fig, ((axtl, axtr), (axbl, axbr)) = plt.subplots(2, 2, figsize=(12, 6))\n",
    "for Xi, c, l in zip(X, colors, labels):\n",
    "    axtl.hist(Xi[\"ra\"], bins=10, range=[0, 2 * np.pi], histtype=\"step\",\n",
    "              color=c)\n",
    "    axtr.hist(Xi[\"sinDec\"], bins=20, range=[-1, +1], histtype=\"step\",\n",
    "              color=c)\n",
    "    axbl.hist(Xi[\"logE\"], bins=20, range=[2, 6], histtype=\"step\", color=c)\n",
    "    axbr.hist(np.rad2deg(Xi[\"sigma\"]), bins=20, range=[0, 10],\n",
    "              histtype=\"step\", color=c, label=l)\n",
    "\n",
    "axtl.set_xlabel(\"ra\")\n",
    "axtl.set_ylabel(\"number of events\")\n",
    "axtr.set_xlabel(\"sin(dec)\")\n",
    "axtr.set_ylabel(\"number of events\")\n",
    "axbl.set_xlabel(\"logE\")\n",
    "axbl.set_ylabel(\"number of events\")\n",
    "axbr.set_xlabel(\"sigma in deg\")\n",
    "axbr.set_ylabel(\"number of events\")\n",
    "axbr.legend(loc=\"upper right\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BG Rate Injector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This module injects times of background like events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Injector created from runlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First step is always to fit a RateFunction to rates from detector runs.\n",
    "Here we use a Sinus1yrRateFunction with fixed period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now parse the rundict and make the fitted injector from that\n",
    "def filter_runs(run):\n",
    "    \"\"\"\n",
    "    Filter runs as stated in jfeintzig's doc.\n",
    "    \"\"\"\n",
    "    exclude_runs = [120028, 120029, 120030, 120087, 120156, 120157]\n",
    "    if ((run[\"good_i3\"] == True) & (run[\"good_it\"] == True) &\n",
    "        (run[\"run\"] not in exclude_runs)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# Create a rate function. We fix the period to 1 year here\n",
    "rndgen = np.random.RandomState(7353)\n",
    "rate_func_obj = RateFunc.Sinus1yrRateFunction(random_state=rndgen)\n",
    "    \n",
    "# Let's create an injector using a goodrun list. This creates a run dict\n",
    "runlist = \"data/runlists/ic86-i-goodrunlist.json\"\n",
    "with open(runlist, \"r\") as f:\n",
    "    runlist_dict = json.load(f)\n",
    "runlist_inj = BGRateInj.RunlistBGRateInjector(rate_func_obj, runlist_dict,\n",
    "                                              filter_runs, rndgen)\n",
    "\n",
    "# Fit function to exp times to runlist bins\n",
    "times = exp[\"timeMJD\"]\n",
    "rate_func = runlist_inj.fit(T=times, x0=None, remove_zero_runs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Rebin (donglians proposal)\n",
    "rates = runlist_inj._rate_rec\n",
    "start_mjd = rates[\"start_mjd\"]\n",
    "stop_mjd = rates[\"stop_mjd\"]\n",
    "\n",
    "tmin, tmax = np.amin(start_mjd), np.amax(stop_mjd)\n",
    "ntbins = 12\n",
    "tbins = np.linspace(tmin, tmax, ntbins + 1)\n",
    "\n",
    "# Get bin idx in which the runs fall\n",
    "# This is not a 100% correct, because runs may be right over bin edges\n",
    "idx = np.digitize(stop_mjd, tbins) - 1\n",
    "rates_per_bin = np.zeros(ntbins, dtype=np.float)\n",
    "\n",
    "evts_in_run = rates[\"nevts\"]\n",
    "dts = (stop_mjd - start_mjd) * secinday\n",
    "for i in range(ntbins):\n",
    "    rates_per_bin[i] = np.sum(evts_in_run[idx == i]) / np.sum(dts[idx == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot runs (zorder, because errorbar seems to have high zorder for centers)\n",
    "xerr = 0.5 * (stop_mjd - start_mjd)\n",
    "yerr = rates[\"rate_std\"]\n",
    "binmids = 0.5 * (stop_mjd + start_mjd)\n",
    "\n",
    "plt.errorbar(binmids, rates[\"rate\"], xerr=xerr, yerr=yerr,\n",
    "             fmt=\",\", alpha=0.25, zorder=0)\n",
    "plt.ylim(0, None);\n",
    "\n",
    "# Plot fit\n",
    "t = np.linspace(start_mjd[0], stop_mjd[-1], 1000)\n",
    "y = rate_func(t)\n",
    "plt.plot(t, y, zorder=3, lw=3, color=\"C1\")\n",
    "\n",
    "# Plot y shift dashed to see baseline or years average\n",
    "avg = runlist_inj.best_pars[2]\n",
    "plt.axhline(avg, 0, 1, color=\"k\", ls=\"--\", label=\"\", lw=1)\n",
    "\n",
    "plt.xlim(start_mjd[0], stop_mjd[-1])\n",
    "plt.xlabel(\"MJD\")\n",
    "plt.ylabel(\"Rate in Hz\")\n",
    "\n",
    "# Show rebinned (as expected you see nothing new)\n",
    "m = get_binmids([tbins])[0]\n",
    "plt.errorbar(m, rates_per_bin, xerr=np.diff(tbins),\n",
    "             fmt=\",\", lw=3, color=dg, zorder=5)\n",
    "\n",
    "# plt.savefig(\"./data/figs/time_rate_sinus_rebinned.png\", dpi=200)\n",
    "plt.ylim(0, 0.009)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Best fit params:\")\n",
    "for par, name in zip(runlist_inj.best_pars, [\"amp\", \"toff\", \"base\"]):\n",
    "    print(\" {:5} : {:+.3g}\".format(name, par))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sample some trials for a single src and time with the poisson=True keyword to see if we sample correctly for each trial.\n",
    "\n",
    "Also compare with poisson=False to see if it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rates = runlist_inj._rate_rec\n",
    "start_mjd = rates[\"start_mjd\"]\n",
    "\n",
    "# Pick some random time and time frame\n",
    "t = rndgen.choice(start_mjd, size=1)\n",
    "trange = np.array([-120, 220])\n",
    "\n",
    "# This is a list of times per trial\n",
    "ntrials = int(1e4)\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trial = runlist_inj.sample(t, trange, poisson=True)\n",
    "    # Make one array of times, because we have only one src here\n",
    "    trials.append(np.concatenate(trial))\n",
    "\n",
    "nevents = np.array(list(map(len, trials)))\n",
    "print(\"Sampled total of {:d} events in {:d} trials.\".format(\n",
    "        np.sum(nevents), ntrials))\n",
    "\n",
    "# Plot poisson distribution of nevents with expectation from integral\n",
    "expect = runlist_inj.best_estimator_integral(t, trange)\n",
    "_ = plt.hist(nevents, bins=np.arange(10), normed=True)\n",
    "plt.axvline(expect, 0, 1, color=\"C1\", ls=\"--\", lw=2, label=\"expect\")\n",
    "x = np.arange(0, 10)\n",
    "y = scs.poisson.pmf(x, mu=expect)\n",
    "_ = plt.plot(x, y, \"C1\", lw=2, drawstyle=\"steps-post\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Now the same for possion=False as a crosscheck\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trial = runlist_inj.sample(t, trange, poisson=False)\n",
    "    # Make one array of times, because we have only one src here\n",
    "    trials.append(np.concatenate(trial))\n",
    "\n",
    "nevents = np.array(list(map(len, trials)))\n",
    "print(\"Sampled total of {:d} events in {:d} trials.\".format(\n",
    "        np.sum(nevents), ntrials))\n",
    "\n",
    "# Plot poisson distribution of nevents with expectation from integral, here\n",
    "# for comparison to the previous case only\n",
    "expect = runlist_inj.best_estimator_integral(t, trange)\n",
    "_ = plt.hist(nevents, bins=np.arange(10), normed=True)\n",
    "plt.axvline(expect, 0, 1, color=\"C1\", ls=\"--\", lw=2, alpha=0.5,\n",
    "            label=\"expect\")\n",
    "plt.axvline(np.round(expect), 0, 1, color=\"C1\", ls=\"--\", lw=2,\n",
    "            label=\"round expect\")\n",
    "x = np.arange(0, 10)\n",
    "y = scs.poisson.pmf(x, mu=expect)\n",
    "_ = plt.plot(x, y, \"C1\", lw=2, drawstyle=\"steps-post\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we do the same, but with multiple sources.\n",
    "Each src gets a larger time window, so the expectation gets higher and we can compare different poisson distributions at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rates = runlist_inj._rate_rec\n",
    "start_mjd = rates[\"start_mjd\"]\n",
    "\n",
    "# Pick random times and make increasing time frames per source\n",
    "nsrcs = 3\n",
    "t = rndgen.choice(start_mjd, size=nsrcs)\n",
    "trange = np.vstack((np.repeat([-100], nsrcs),\n",
    "                    500 * np.arange(1, 3 * nsrcs + 1, 3))).T\n",
    "\n",
    "# This is a list of times per trial\n",
    "ntrials = int(1e4)\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trial = runlist_inj.sample(t, trange, poisson=True)\n",
    "    # Make one array of times, because we have only one src here\n",
    "    trials.append(trial)\n",
    "\n",
    "# The format of `trials` is list(array_src1, array_src2, ...) for each trial.\n",
    "# We want the number of events sampled per src per trial\n",
    "nevents = []\n",
    "for i in range(nsrcs):\n",
    "    nevents.append([len(trial[i]) for trial in trials])\n",
    "    print(\"Sampled {:d} events in {:d} trials for src {:d}.\".format(\n",
    "          np.sum(nevents[i]), ntrials, i))\n",
    "\n",
    "# Plot poisson distributions of nevents with expectations from integrals\n",
    "expect = runlist_inj.best_estimator_integral(t, trange)\n",
    "colors = [\"C0\", \"C1\", \"C3\"]\n",
    "for i in range(nsrcs):\n",
    "    _ = plt.hist(nevents[i], bins=np.arange(np.amax(nevents)), normed=True,\n",
    "                 color=colors[i], alpha=.25)\n",
    "    plt.axvline(expect[i], 0, 1, ls=\"--\", lw=2, label=\"mu src {}\".format(i),\n",
    "                color=colors[i])\n",
    "    x = np.arange(0, np.amax(nevents))\n",
    "    y = scs.poisson.pmf(x, mu=expect[i])\n",
    "    _ = plt.plot(x, y, lw=2, drawstyle=\"steps-post\", color=colors[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we want to look at the actual sampled times in each trial.\n",
    "First we sample a single in a small timeframe.\n",
    "It should be approximately uniformly distributed, respectively not to distinguish by eye from a constant PDF, because the sine is way to broad to be resolved on such a small time scale.\n",
    "We also show the bg and signal pdf for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# First the small time frame\n",
    "# Arbitrary start date from data\n",
    "nsrcs = 1\n",
    "t0 = np.random.choice(start_mjd, size=nsrcs)\n",
    "t0_sec = t0 * secinday\n",
    "\n",
    "# dt from t0 in seconds, clip at 4 sigma\n",
    "dt = 200\n",
    "nsig = 4.\n",
    "\n",
    "# Make t values for plotting in MJD around t0\n",
    "clip = np.clip(dt, 2, 30) * nsig\n",
    "trange = np.array([-clip, dt + clip]).reshape(nsrcs, 2)\n",
    "ntrials = int(1e4)\n",
    "\n",
    "# Sample times for each trial and flatten to single array with all trials\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trials += runlist_inj.sample(t0, trange, poisson=True)\n",
    "trials = np.concatenate(trials)\n",
    "\n",
    "# Plot them in together with the PDFs\n",
    "def time_bg_pdf(t, t0, a, b):\n",
    "    # Normalize relative to t0 in seconds (first multiply avoids rounding?)\n",
    "    _t = t * secinday - t0 * secinday\n",
    "  \n",
    "    pdf = np.zeros_like(_t, dtype=np.float)\n",
    "    uni = (_t >= a) & (_t <= b)\n",
    "    pdf[uni] = 1. / (b - a)\n",
    "    return pdf\n",
    "\n",
    "def time_sig_pdf(t, t0, dt, nsig=4):\n",
    "    if dt < 0:\n",
    "        raise ValueError(\"dt must not be negative.\")\n",
    "\n",
    "    # Normalize relative to t0 in seconds (first multiply avoids rounding?)\n",
    "    _t = t * secinday - t0 * secinday\n",
    "    \n",
    "    # Constrain sig_t to [2, 30]s regardless of uniform time window\n",
    "    sig_t = np.clip(dt, 2, 30)\n",
    "    sig_t_clip = nsig * sig_t\n",
    "    gaus_norm = (np.sqrt(2 * np.pi) * sig_t)\n",
    "    \n",
    "    # Split in def regions gaus rising, uniform, gaus falling and zero\n",
    "    gr = (_t < 0) & (_t >= -sig_t_clip)\n",
    "    gf = (_t > dt) & (_t <= dt + sig_t_clip)\n",
    "    uni = (_t >= 0) & (_t <= dt)\n",
    "    \n",
    "    pdf = np.zeros_like(t, dtype=np.float)\n",
    "    pdf[gr] = scs.norm.pdf(_t[gr], loc=0, scale=sig_t)\n",
    "    pdf[gf] = scs.norm.pdf(_t[gf], loc=dt, scale=sig_t)\n",
    "    # Connect smoothly with the gaussians\n",
    "    pdf[uni] = 1. / gaus_norm\n",
    "    \n",
    "    # Normalize whole distribtuion\n",
    "    dcdf = (scs.norm.cdf(dt + sig_t_clip, loc=dt, scale=sig_t) -\n",
    "            scs.norm.cdf(-sig_t_clip, loc=0., scale=sig_t))\n",
    "    norm = dcdf + dt / gaus_norm\n",
    "    \n",
    "    return pdf / norm\n",
    "\n",
    "\n",
    "# Plot the pdfs\n",
    "t = np.linspace(t0_sec + trange[:, 0], t0_sec + trange[:, 1], 200) / secinday\n",
    "bg_pdf = time_bg_pdf(t, t0, -clip, dt + clip)\n",
    "sig_pdf = time_sig_pdf(t, t0, dt, nsig)\n",
    "\n",
    "# Plot in normalized time\n",
    "_t = t * secinday - t0 * secinday\n",
    "plt.plot(_t, bg_pdf, \"C0-\")\n",
    "plt.plot(_t, sig_pdf, \"C1-\")\n",
    "plt.axvline(dt, 0, 1, color=\"C3\", ls=\"--\")\n",
    "plt.axvline(0, 0, 1, color=\"C2\", ls=\"--\")\n",
    "\n",
    "# Plot injected events from all trials, relative times\n",
    "times = (trials - t0) * secinday\n",
    "_ = plt.hist(times, bins=50, normed=True, color=dg, alpha=.25)\n",
    "\n",
    "plt.xlabel(\"Time relative to t0 in sec\")\n",
    "plt.ylim(0, None);\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"./data/figs/bg_events_time_sampled_narrow.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now the really large time frame, over the whole time range\n",
    "t0 = start_mjd[0]\n",
    "t0_sec = t0 * secinday\n",
    "\n",
    "# Maximum dt over all runs\n",
    "dt = (stop_mjd[-1] - start_mjd[0]) * secinday\n",
    "nsig = 4.\n",
    "\n",
    "# Make t values for plotting in MJD around t0\n",
    "clip = np.clip(dt, 2, 30) * nsig\n",
    "trange = [-clip, dt + clip]\n",
    "ntrials = 100  # More trials mean smaller errors, better see the sinus shape \n",
    "\n",
    "# Sample times\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trials += runlist_inj.sample(t0, trange, poisson=True)\n",
    "trials = np.concatenate(trials)\n",
    "\n",
    "# We choose the same style as in the intial rate plot further above\n",
    "h, b = np.histogram(trials, bins=1081)\n",
    "m = get_binmids([b])[0]\n",
    "scale = np.diff(b) * secinday * ntrials\n",
    "yerr = np.sqrt(h) / scale\n",
    "h = h / scale\n",
    "\n",
    "plt.errorbar(m, h, yerr=yerr, fmt=\",\")\n",
    "\n",
    "# Plot normalized rate function to compare\n",
    "t = np.linspace(start_mjd[0], stop_mjd[-1], 100)\n",
    "r = runlist_inj.best_estimator(t)\n",
    "plt.plot(t, r, lw=2, zorder=5)\n",
    "plt.axhline(runlist_inj.best_pars[2], 0, 1, color=\"C1\",\n",
    "            ls=\"--\", label=\"\", zorder=5)\n",
    "\n",
    "plt.xlim(start_mjd[0], stop_mjd[-1])\n",
    "plt.ylim(0.004, 0.006)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"./data/figs/bg_events_time_sampled_wide.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Injector from binned rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we use the sampled rate from above to create a new injector.\n",
    "Everything else is staying the same.\n",
    "So we just reproduce the plot last plot above.\n",
    "Also see the note about the livetime further below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make up ten bins with a total live time of 100 days, but the difference between first and last event time is 365 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dt = 365.\n",
    "start_mjd = np.amin(_exp[\"timeMJD\"])\n",
    "stop_mjd = start_mjd + dt\n",
    "\n",
    "nruns = 10\n",
    "tbins_start = np.linspace(start_mjd, stop_mjd, nruns)\n",
    "# Runs are 10 days long\n",
    "tbins_stop = tbins_start + 10.\n",
    "\n",
    "# Make approximately the same rates as in the real sample\n",
    "mids = 0.5 * (tbins_start + tbins_stop)\n",
    "rate = -0.0005 * np.sin(2 * np.pi / dt * (mids - start_mjd)) + 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a rate function. We fix the period to 1 year here\n",
    "rndgen = np.random.RandomState(7353)\n",
    "rate_func_obj = RateFunc.Sinus1yrRateFunction(random_state=rndgen)\n",
    "    \n",
    "binned_inj = BGRateInj.BinnedBGRateInjector(rate_func_obj)\n",
    "\n",
    "# Fit function to the sampled times from the above runlist injector\n",
    "# tbins = [start_mjd_arr, stop_mjd_arr], shape = (2, nruns)\n",
    "tbins = np.vstack((tbins_start, tbins_stop)).T\n",
    "\n",
    "rate_func = binned_inj.fit(tbins, rate, x0=None)\n",
    "\n",
    "# Livetime should be 100 days by construction\n",
    "print(\"Livetime is: {:.2f} days\".format(binned_inj.livetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trange = [0, (stop_mjd - start_mjd) * secinday]\n",
    "ntrials = 10\n",
    "\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trials += binned_inj.sample(start_mjd, trange, poisson=True)\n",
    "trials = np.concatenate(trials)\n",
    "\n",
    "# We choose the same style as in the intial rate plot further above\n",
    "h, b = np.histogram(trials, bins=1081)\n",
    "m = get_binmids([b])[0]\n",
    "scale = np.diff(b) * secinday * ntrials\n",
    "yerr = np.sqrt(h) / scale\n",
    "h = h / scale\n",
    "\n",
    "plt.errorbar(m, h, yerr=yerr, fmt=\",\")\n",
    "\n",
    "# Plot normalized rate function to compare\n",
    "t = np.linspace(start_mjd, stop_mjd, 100)\n",
    "r = binned_inj.best_estimator(t)\n",
    "plt.plot(t, r, lw=2, zorder=5)\n",
    "plt.axhline(binned_inj.best_pars[2], 0, 1, color=\"C1\",\n",
    "            ls=\"--\", label=\"\", zorder=5)\n",
    "\n",
    "plt.errorbar(mids, rate, xerr=(tbins_stop - tbins_start), color=\"w\",\n",
    "             fmt=\",\", zorder=5, lw=3)\n",
    "\n",
    "plt.xlim(start_mjd, stop_mjd)\n",
    "plt.ylim(0.004, 0.006)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"./data/figs/bg_events_time_sampled_wide_100days.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# First the small time frame. Arbitrary start date from data\n",
    "nsrcs = 1\n",
    "t0 = start_mjd\n",
    "t0_sec = t0 * secinday\n",
    "\n",
    "# dt from t0 in seconds, clip at 4 sigma\n",
    "dt = 200\n",
    "nsig = 4.\n",
    "\n",
    "# Make t values for plotting in MJD around t0\n",
    "clip = np.clip(dt, 2, 30) * nsig\n",
    "trange = np.array([-clip, dt + clip]).reshape(nsrcs, 2)\n",
    "ntrials = int(1e4)\n",
    "\n",
    "# Sample times for each trial and flatten to single array with all trials\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trials += binned_inj.sample(t0, trange, poisson=True)\n",
    "trials = np.concatenate(trials)\n",
    "\n",
    "# Plot them in together with the PDFs\n",
    "def time_bg_pdf(t, t0, a, b):\n",
    "    # Normalize relative to t0 in seconds (first multiply avoids rounding?)\n",
    "    _t = t * secinday - t0 * secinday\n",
    "  \n",
    "    pdf = np.zeros_like(_t, dtype=np.float)\n",
    "    uni = (_t >= a) & (_t <= b)\n",
    "    pdf[uni] = 1. / (b - a)\n",
    "    return pdf\n",
    "\n",
    "def time_sig_pdf(t, t0, dt, nsig=4):\n",
    "    if dt < 0:\n",
    "        raise ValueError(\"dt must not be negative.\")\n",
    "\n",
    "    # Normalize relative to t0 in seconds (first multiply avoids rounding?)\n",
    "    _t = t * secinday - t0 * secinday\n",
    "    \n",
    "    # Constrain sig_t to [2, 30]s regardless of uniform time window\n",
    "    sig_t = np.clip(dt, 2, 30)\n",
    "    sig_t_clip = nsig * sig_t\n",
    "    gaus_norm = (np.sqrt(2 * np.pi) * sig_t)\n",
    "    \n",
    "    # Split in def regions gaus rising, uniform, gaus falling and zero\n",
    "    gr = (_t < 0) & (_t >= -sig_t_clip)\n",
    "    gf = (_t > dt) & (_t <= dt + sig_t_clip)\n",
    "    uni = (_t >= 0) & (_t <= dt)\n",
    "    \n",
    "    pdf = np.zeros_like(t, dtype=np.float)\n",
    "    pdf[gr] = scs.norm.pdf(_t[gr], loc=0, scale=sig_t)\n",
    "    pdf[gf] = scs.norm.pdf(_t[gf], loc=dt, scale=sig_t)\n",
    "    # Connect smoothly with the gaussians\n",
    "    pdf[uni] = 1. / gaus_norm\n",
    "    \n",
    "    # Normalize whole distribtuion\n",
    "    dcdf = (scs.norm.cdf(dt + sig_t_clip, loc=dt, scale=sig_t) -\n",
    "            scs.norm.cdf(-sig_t_clip, loc=0., scale=sig_t))\n",
    "    norm = dcdf + dt / gaus_norm\n",
    "    \n",
    "    return pdf / norm\n",
    "\n",
    "\n",
    "# Plot the pdfs\n",
    "t = np.linspace(t0_sec + trange[:, 0], t0_sec + trange[:, 1], 200) / secinday\n",
    "bg_pdf = time_bg_pdf(t, t0, -clip, dt + clip)\n",
    "sig_pdf = time_sig_pdf(t, t0, dt, nsig)\n",
    "\n",
    "# Plot in normalized time\n",
    "_t = t * secinday - t0 * secinday\n",
    "plt.plot(_t, bg_pdf, \"C0-\")\n",
    "plt.plot(_t, sig_pdf, \"C1-\")\n",
    "plt.axvline(dt, 0, 1, color=\"C3\", ls=\"--\")\n",
    "plt.axvline(0, 0, 1, color=\"C2\", ls=\"--\")\n",
    "\n",
    "# Plot injected events from all trials, relative times\n",
    "times = (trials - t0) * secinday\n",
    "_ = plt.hist(times, bins=50, normed=True, color=dg, alpha=.25)\n",
    "\n",
    "plt.xlabel(\"Time relative to t0 in sec\")\n",
    "plt.ylim(0, None);\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"./data/figs/bg_events_time_sampled_narrow.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sample per source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Setup cell\n",
    "rndgen = np.random.RandomState(7353)\n",
    "\n",
    "# Create some srcs we want to test, with some different properties.\n",
    "nsrcs = 5\n",
    "dt = np.vstack((np.repeat([-20.], nsrcs), 100. * np.arange(1, nsrcs + 1))).T\n",
    "\n",
    "names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "dtype = [(_n, _t) for _n, _t in zip(names, len(names) * [np.float])]\n",
    "srcs = np.empty((nsrcs, ), dtype=dtype)\n",
    "\n",
    "mint, maxt = np.amin(_exp[\"timeMJD\"]), np.amax(_exp[\"timeMJD\"])\n",
    "srcs[\"t\"] = np.linspace(mint, maxt, nsrcs + 2)[1:-1]\n",
    "srcs[\"dt0\"], srcs[\"dt1\"] = dt[:, 0], dt[:, 1]\n",
    "srcs[\"ra\"] = np.linspace(0, 2 * np.pi, nsrcs + 1)[:-1]\n",
    "srcs[\"dec\"] = np.arcsin(np.linspace(-1, 1, nsrcs + 2)[1:-1])\n",
    "srcs[\"w_theo\"] = np.ones(nsrcs, dtype=np.float)\n",
    "\n",
    "# And we need functions from the LLH module\n",
    "spatial_pdf_args = {\"bins\": np.linspace(-1, 1, 40)}\n",
    "energy_pdf_args = {\"bins\": [np.linspace(-1, 1, 40),\n",
    "                            np.linspace(0, 10, 40)], \"gamma\": 2.}\n",
    "llh = LLH.GRBLLH(_exp, _mc, spatial_pdf_args, energy_pdf_args)\n",
    "\n",
    "# And we need a rate injector\n",
    "def filter_runs(run):\n",
    "    exclude_runs = [120028, 120029, 120030, 120087, 120156, 120157]\n",
    "    if ((run[\"good_i3\"] == True) & (run[\"good_it\"] == True) &\n",
    "        (run[\"run\"] not in exclude_runs)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "rate_func_obj = RateFunc.Sinus1yrRateFunction(random_state=rndgen)\n",
    "runlist = \"data/runlists/ic86-i-goodrunlist.json\"\n",
    "runlist_dict = json.load(open(runlist, \"r\"))\n",
    "bg_rate_inj = BGRateInj.RunlistBGRateInjector(rate_func_obj, runlist_dict,\n",
    "                                              filter_runs, rndgen)\n",
    "_ = bg_rate_inj.fit(T=_exp[\"timeMJD\"], x0=None, remove_zero_runs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Prepare fixed source parameters for injector arguments\n",
    "src_t = srcs[\"t\"]\n",
    "src_dt = np.vstack((srcs[\"dt0\"], srcs[\"dt1\"])).T\n",
    "\n",
    "# First step: Get the injection time windows per source in seconds centered\n",
    "# around each source position\n",
    "trange = llh.time_pdf_def_range(src_t, src_dt)\n",
    "\n",
    "print(\"dt in sec\\n\", dt)\n",
    "print(\"\")\n",
    "print(\"trange in sec\\n\", trange)\n",
    "\n",
    "# Compare to our expectation by calculcating manually trange:\n",
    "#   trange = diff(dt) + 2 * nsig * clip_t, which were setup for the LLH\n",
    "print(\"\")\n",
    "clip = np.clip(np.diff(dt).flatten(), llh._time_pdf_args[\"sigma_t_min\"],\n",
    "               llh._time_pdf_args[\"sigma_t_max\"])\n",
    "nsig = llh._time_pdf_args[\"nsig\"]\n",
    "_trange = np.copy(dt)\n",
    "_trange[:, 0] = dt[:, 0] - clip * nsig\n",
    "_trange[:, 1] = dt[:, 1] + clip * nsig\n",
    "print(\"manual\\n\", _trange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the number of expected background events in each given time frame from\n",
    "# the bg_rate_injector which gets it from the integral over the rate_function\n",
    "nb = bg_rate_inj.get_nb(src_t, trange)\n",
    "args = {\"nb\": nb}\n",
    "\n",
    "print(\"nb from integral\\n\", nb)\n",
    "print(\"\")\n",
    "print(\"args wrapper\\n\", args)\n",
    "\n",
    "# We compare that with a naive integration by just using trange * mean_rate\n",
    "# directly from the fit params of the rate_function. These are approximately\n",
    "# the same when our time windows are not too large and not constant.\n",
    "if type(rate_func_obj) == RateFunc.SinusRateFunction:\n",
    "    print(\"\\n# Used a SinusRateFunction\")\n",
    "    mean_rate = bg_rate_inj.best_pars[3]\n",
    "if type(rate_func_obj) == RateFunc.Sinus1yrRateFunction:\n",
    "    print(\"\\n# Used a Sinus1yrRateFunction\")\n",
    "    mean_rate = bg_rate_inj.best_pars[2]\n",
    "if type(rate_func_obj) == RateFunc.ConstantRateFunction:\n",
    "    print(\"\\n# Used a ConstantRateFunction, values must be excatly the same\")\n",
    "    mean_rate = bg_rate_inj.best_pars[0]\n",
    "if type(rate_func_obj) == RateFunc.Sinus1yrConstRateFunction:\n",
    "    print(\"\\n# Used a Sinus1YrConstRateFunction\")\n",
    "    mean_rate = bg_rate_inj.best_pars[2]\n",
    "    \n",
    "intgrls = mean_rate * np.diff(trange)\n",
    "print(\"\")\n",
    "print(\"Naive mean_rate * diff(trange)\\n\", intgrls.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now we sample times for a few trials, just to get some more events\n",
    "ntrials = 100\n",
    "times = []\n",
    "for i in range(ntrials):\n",
    "    times.append(bg_rate_inj.sample(src_t, trange, poisson=True))\n",
    "    \n",
    "# This is now a list of lists of arrays\n",
    "flat_times_per_src = []\n",
    "for i in range(nsrcs):\n",
    "    flat_times_per_src.append(np.concatenate([ti[i] for ti in times]))\n",
    "\n",
    "flat_times = np.concatenate(flat_times_per_src)\n",
    "\n",
    "# First all times in MJD in the global position. Won't see much, just to\n",
    "# check if no stray times are generated\n",
    "plt.vlines(flat_times, 0, 1, linestyles=\"--\", colors=\"C7\")\n",
    "plt.vlines(src_t - trange[:, 0] / secinday, 0, 0.25,  # only 1/4 to see all\n",
    "           linestyles=\"--\", colors=\"C3\")\n",
    "plt.vlines(src_t - trange[:, 1] / secinday, 0.25, 0.5,  # only 1/4 to see all\n",
    "           linestyles=\"--\", colors=\"C2\")\n",
    "plt.xlim(mint, maxt)\n",
    "plt.xlabel(\"Each time sample in MJD\")\n",
    "plt.ylabel(\"Just vlines, no real unit\")\n",
    "plt.title(\"Time windows too small to see evts, just to check for stray evts\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"data/figs/background_events_time_sampled_large.png\", dpi=200)\n",
    "plt.show()\n",
    "\n",
    "# Now each times in the centered time frame in seconds together with the\n",
    "# signal PDFs\n",
    "vline_scale = 20.\n",
    "for i, ti in enumerate(flat_times_per_src):\n",
    "    t_sec = ti * secinday - src_t[i] * secinday\n",
    "    _t = np.linspace(trange[i, 0], trange[i, 1], 100)\n",
    "    _t_mjd = _t / secinday + src_t[i]\n",
    "    _pdf = llh._soverb_time(_t_mjd, src_t[i], dt[i]).flatten()\n",
    "    if i == 0:\n",
    "        _max = 1.05 * np.amax(_pdf)\n",
    "    # Small ticks for event positions below the 0 line\n",
    "    plt.vlines(t_sec, -i * _max / vline_scale, -(i+1) * _max / vline_scale,\n",
    "               linestyles=\"-\", colors=\"C{:1d}\".format(i))\n",
    "    plt.vlines(trange[i], 0, -nsrcs * _max / vline_scale, linestyles=\":\",\n",
    "               colors=\"C{:1d}\".format(i))\n",
    "    plt.plot(_t, _pdf, \"C{:1d}-\".format(i),\n",
    "             label=\"{:d} evts\".format(len(ti)))\n",
    "\n",
    "plt.axhline(0, 0, 1, color=\"C7\")\n",
    "plt.xlim(1.1 * trange[-1, 0], trange[-1, 1] - 0.1 * trange[-1, 0])\n",
    "plt.ylim(-nsrcs * _max / vline_scale, _max)\n",
    "plt.xlabel(\"time in sec, centered at src t0\")\n",
    "plt.title(\"Individual samples in each window, \" +\n",
    "          \"combined of {} trials.\".format(ntrials))\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"data/figs/background_events_time_sampled_windows.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Utils -- rejection_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test the utils.py rejection sampler.\n",
    "We generate trials for multiple sources at once and check how fast this is.\n",
    "Currently the method just loops over sources, rejection sampling for each interval, but it seems fast enough.\n",
    "\n",
    "A short note on the test below:\n",
    "We make nsrcs, each with ordered center times and increasing time windows.\n",
    "Then we sample an increasing number of samples per source.\n",
    "This is the same as a single trial.\n",
    "\n",
    "In the histogram we expect 2 things:\n",
    "\n",
    "1. If the time windows are smaller than 1 day, which is the bin size, then we just get a nice lineraly increaing bin content (triangle shaped, with hard cut at the right edge).\n",
    "2. If the time windows increase, we get spillover resulting in a way more spread distribution. Also the time windows are only widened to to the right, so the spillover occurs only to the right edges. When the time windows are really large, we even begin to see the underlying oscillation of the sinusodial test function we generate samples from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sample_test_sin(t):\n",
    "    \"\"\"Simple sinus, similar to fitted rate function\"\"\"\n",
    "    return 0.001 * np.sin(2 * np.pi / 365. * (t - 50000)) + 0.005\n",
    "\n",
    "rndgen = np.random.RandomState(7353)\n",
    "\n",
    "# Make some srcs and incresing time windows\n",
    "nsrcs = 100\n",
    "t = np.arange(0, nsrcs) + 50000\n",
    "scaler = 2 * secinday  # Time window scaler: Increase to see spillover\n",
    "dts = np.vstack((np.zeros(nsrcs), scaler * np.arange(1, nsrcs + 1))).T\n",
    "dts = t.reshape(nsrcs, 1) + dts / secinday\n",
    "\n",
    "# Sample increasing number of events in time windows\n",
    "n_samples = 100 * np.arange(1, nsrcs + 1)\n",
    "sample = rejection_sampling(sample_test_sin, dts,\n",
    "                            n_samples=n_samples, rndgen=rndgen)\n",
    "\n",
    "flatsam = np.concatenate(sample)\n",
    "\n",
    "# If the time windows are larger than one day (the binning) we get spillover\n",
    "_ = plt.hist(flatsam, bins=nsrcs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Let's look at the distribution in the largest time window.\n",
    "# It should be sinusodial\n",
    "_ = plt.hist(sample[-1], bins=20, normed=True)\n",
    "# Plot sampled function as comparison\n",
    "t = np.linspace(dts[-1, 0],dts[-1, 1], 100)\n",
    "intgrl = scint.quad(sample_test_sin, dts[-1, 0],dts[-1, 1])[0]\n",
    "y = sample_test_sin(t) / intgrl\n",
    "plt.plot(t, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Quickly check how fast we are. Set nsrcs to 100 above for many srcs\n",
    "rejection_sampling(sample_test_sin, dts, n_samples=n_samples, rndgen=rndgen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cache fmax values and measure the time agian. We should get significantly faster because we don't have to find the maximum in each step.\n",
    "\n",
    "**Attention:** Be sure that the values match with the used time windows. If they're off or not matching we either don't produce the correct distribution or are getting very inefficient because we start to reject almost everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def negpdf(t):\n",
    "    return -1. * sample_test_sin(t)\n",
    "\n",
    "rndgen = np.random.RandomState(7353)\n",
    "\n",
    "f0 = []\n",
    "fmax = []\n",
    "for bound in dts:\n",
    "    # Repeat some code from func_min_in_interval to get the seed\n",
    "    x_scan = np.linspace(bound[0], bound[1], 7)[1:-1]\n",
    "    max_idx = np.argmin(negpdf(x_scan))\n",
    "    x0 = x_scan[max_idx]\n",
    "    f0.append(-1 * negpdf(x0))\n",
    "\n",
    "    fmax.append(-1. * func_min_in_interval(negpdf, bound))\n",
    "\n",
    "fmax = np.concatenate(fmax)\n",
    "\n",
    "# Time windows get so large, that the maximium is always in the windows\n",
    "start_dts = dts[:, 0].flatten()\n",
    "plt.plot(start_dts, sample_test_sin(start_dts), label=\"fun\")\n",
    "plt.plot(start_dts, fmax, label=\"fit\")\n",
    "plt.plot(start_dts, f0, label=\"seed\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Should be faster than before\n",
    "rejection_sampling(sample_test_sin, dts, n_samples=n_samples,\n",
    "                   rndgen=rndgen, max_fvals=fmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Utils -- rotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test correct rotation of circle points across the sky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here do the following:\n",
    "\n",
    "1. Target point is (ra2, dec2)\n",
    "2. Points (r3, dec3) to be rotated are random and the same as the ones\n",
    "   (ra2, dec2) defining the rotation angles.\n",
    "3. After rotation they should be all exactly at (ra2, dec2)\n",
    "\"\"\"\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "npts = 10000\n",
    "# Coordinates to rotate to\n",
    "ra2 = np.repeat(np.deg2rad(250.), npts)\n",
    "dec2 = np.repeat(np.deg2rad(30.), npts)\n",
    "\n",
    "# Positions that shall be rotated to (ra2, dec2)\n",
    "ra3 = np.random.uniform(0, 2 * np.pi, npts)\n",
    "# Get more at the poles, else use: np.arcsin(rndgen.uniform(-1, 1, npts))\n",
    "dec3 = np.random.uniform(-np.pi / 2., np.pi / 2., npts)\n",
    "# Add some special cases for dec3, as it is not periodical\n",
    "dec3_spec = np.deg2rad([-90, -60, -30, 0, 30, 60, 90])\n",
    "ra3_spec = np.ones_like(dec3_spec) * 2 * np.pi\n",
    "nspec = len(dec3_spec)\n",
    "dec3[-nspec:] = dec3_spec\n",
    "ra3[-nspec:] = ra3_spec\n",
    "\n",
    "# Here the point defining the rotation angles dra, dtheta are the same as the\n",
    "# point that get rotated, so they end up all on (ra2, dec2)\n",
    "ra1 = ra3\n",
    "dec1 = dec3\n",
    "\n",
    "# Rotate\n",
    "ra3t, dec3t = rotator(ra1, dec1, ra2, dec2, ra3, dec3)\n",
    "\n",
    "# Plot original points, highlight special cases\n",
    "plt.plot(ra3, dec3, \"C0.\")\n",
    "plt.plot(ra3[-nspec:], dec3[-nspec:], \"kx\", ms=10)\n",
    "\n",
    "# Plot intdermediate steps\n",
    "plt.plot(ra3t, dec3, \"C2.\")\n",
    "plt.plot(ra3, dec3t, \"C3.\")\n",
    "\n",
    "# Plot fixed target point (ra2, dec2)\n",
    "plt.plot(ra2, dec2, \"wo\", ms=10, mec=\"k\")\n",
    "\n",
    "# Plot all transformed\n",
    "plt.plot(ra3t, dec3t, \"C4x\")\n",
    "plt.plot(ra3t[-nspec:], dec3t[-nspec:], \"k+\")\n",
    "\n",
    "# Check if we ended up in target point\n",
    "print(\"All points where they should be: \", np.allclose(ra3t, ra2))\n",
    "print(\"All points where they should be: \", np.allclose(dec3t, dec2))\n",
    "\n",
    "# ra guides\n",
    "plt.axvline(0, 0, 1, color=\"#353132\", ls=\"--\")\n",
    "plt.axvline(np.pi, 0, 1, color=\"#353132\", ls=\"-\")\n",
    "plt.axvline(2 * np.pi, 0, 1, color=\"#353132\", ls=\"--\")\n",
    "# dec guides\n",
    "plt.axhline(-np.pi / 2., 0, 1, color=\"#353132\", ls=\"--\")\n",
    "plt.axhline(0, 0, 1, color=\"#353132\", ls=\"-\")\n",
    "plt.axhline(np.pi / 2., 0, 1, color=\"#353132\", ls=\"--\")\n",
    "\n",
    "plt.xlabel(\"ra\")\n",
    "plt.ylabel(\"dec\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here do the following:\n",
    "\n",
    "1. Target points are ra2, dec2\n",
    "2. Initial point is a circle center at ra1, dec1\n",
    "3. Points to be rotated are (ra3, dec3) in a circle around (ra1, dec1)\n",
    "4. After rotation they should be in a circla around (ra2, dec2)\n",
    "\n",
    "Test with multiple targets (ra2, dec2)\n",
    "\"\"\"\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Fixed coordinates to rotate to. Try 5 different places\n",
    "npts = 20\n",
    "ntarget = 5\n",
    "\n",
    "ra2_all = np.deg2rad(np.linspace(5, 355, ntarget))\n",
    "dec2_all = np.deg2rad(np.linspace(-85, 85, ntarget))\n",
    "\n",
    "# Center of the fixed initial circle\n",
    "radius = np.deg2rad(10)\n",
    "ra1 = np.repeat(np.deg2rad(90), npts)\n",
    "dec1 = np.repeat(np.deg2rad(30), npts)\n",
    "theta1 = np.pi / 2. - dec1\n",
    "\n",
    "# Plot circle dots with squential cmap to see correct order\n",
    "cmap = plt.cm.get_cmap(\"viridis\", npts + 2)\n",
    "colors = cmap.colors[1:-1]\n",
    "\n",
    "# Fixed initial center point\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(ra1, dec1, \"C2o\", label=\"orig\")\n",
    "\n",
    "# Fixed positions around (ra1, dec1) that shall be rotated around (ra2, dec2)\n",
    "t = np.linspace(0, 2 * np.pi, npts)\n",
    "ra3 = radius * np.cos(t) + ra1\n",
    "dec3 = radius * np.sin(t) + dec1\n",
    "\n",
    "for i in range(npts):\n",
    "    ax.plot(ra3[i], dec3[i], marker=\".\", ls=\"\", color=colors[i])\n",
    "\n",
    "\n",
    "# Now rotate to various places\n",
    "for ra2, dec2 in zip(ra2_all, dec2_all):\n",
    "    # Rotate\n",
    "    ra3t, dec3t = rotator(ra1, dec1,\n",
    "                          np.repeat([ra2], npts), np.repeat([dec2], npts),\n",
    "                          ra3, dec3)\n",
    "\n",
    "    ax.plot(ra2, dec2, \"C1o\")\n",
    "    ax.arrow(ra1[0], dec1[0], (ra2 - ra1[0]), (dec2 - dec1[0]),\n",
    "             fc=\"C7\", ec=\"C7\", length_includes_head=True,\n",
    "             head_width=0.05, head_length=0.1)\n",
    "\n",
    "    for i in range(npts):\n",
    "        ax.plot(ra3t[i], dec3t[i], marker=\".\", ls=\"\", color=colors[i])\n",
    "\n",
    "# ra guides\n",
    "plt.axvline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.axvline(np.pi, 0, 1, color=\"C7\", ls=\"-\")\n",
    "plt.axvline(2 * np.pi, 0, 1, color=\"C7\", ls=\"--\")\n",
    "# dec guides\n",
    "plt.axhline(-np.pi / 2., 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.axhline(0, 0, 1, color=\"C7\", ls=\"-\")\n",
    "plt.axhline(np.pi / 2., 0, 1, color=\"C7\", ls=\"--\")\n",
    "\n",
    "plt.xlabel(\"ra\")\n",
    "plt.ylabel(\"dec\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here do the following:\n",
    "\n",
    "1. Target point is ra0, dec0\n",
    "2. Initial point is ra1, dec1\n",
    "3. Points to be rotated are in a circle around (ra1, dec1)\n",
    "4. After rotation they should be in a circla around (ra0, dec0)\n",
    "\n",
    "Test with multiple targets (ra0, dec0)\n",
    "\"\"\"\n",
    "\n",
    "# Fixed coordinates to rotate to. Try 5 different places\n",
    "ntarget = 5\n",
    "npts = 20\n",
    "\n",
    "ra2_all = np.deg2rad(np.linspace(5, 355, ntarget))\n",
    "dec2_all = np.deg2rad(np.linspace(-85, 85, ntarget))\n",
    "\n",
    "# Center of the initial circle\n",
    "radius = np.deg2rad(15)\n",
    "ra1 = np.repeat(np.deg2rad(90), npts)\n",
    "dec1 = np.repeat(np.deg2rad(30), npts)\n",
    "\n",
    "# Plot circle dots with squential cmap to see correct order\n",
    "cmap = plt.cm.get_cmap(\"viridis\", npts)\n",
    "colors = cmap.colors\n",
    "sm = amp_plt.skymap()\n",
    "fig, ax = sm.figure(tex=False)\n",
    "\n",
    "# Fixed initial center point\n",
    "x1, y1 = amp_plt.EquCoordsToMapCoords(ra1, dec1)\n",
    "ax.plot(x1, y1, \"C2o\", label=\"orig\")\n",
    "\n",
    "# Fixed positions around (ra1, dec1) that shall be rotated to (ra0, dec0)\n",
    "t = np.linspace(0, 2 * np.pi, npts)\n",
    "ra3 = radius * np.cos(t) + ra1\n",
    "dec3 = radius * np.sin(t) + dec1\n",
    "x3, y3 = amp_plt.EquCoordsToMapCoords(ra3, dec3)\n",
    "\n",
    "for i in range(npts):\n",
    "    ax.plot(x3[i], y3[i], marker=\".\", ls=\"\", color=colors[i])\n",
    "\n",
    "# Now rotate to various places\n",
    "for ra2, dec2 in zip(ra2_all, dec2_all):\n",
    "    ra3t, dec3t = rotator(ra1, dec1,\n",
    "                          np.repeat([ra2], npts), np.repeat([dec2], npts),\n",
    "                          ra3, dec3)\n",
    "\n",
    "    x2, y2 = amp_plt.EquCoordsToMapCoords(ra2, dec2)\n",
    "    ax.plot(x2, y2, \"C1o\")\n",
    "\n",
    "    ax.arrow(x1[0], y1[0], (x2 - x1)[0], (y2 - y1)[0], fc=\"C7\", ec=\"C7\",\n",
    "             length_includes_head=True, head_width=0.05, head_length=0.1)\n",
    "\n",
    "    x3t, y3t = amp_plt.EquCoordsToMapCoords(ra3t, dec3t)\n",
    "\n",
    "    for i in range(npts):\n",
    "        ax.plot(x3t[i], y3t[i], marker=\".\", ls=\"\", color=colors[i])\n",
    "\n",
    "ax.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BG Rate Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test if fit, sample and integral works, with a simple example.\n",
    "First for only a single source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### SinusRateFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define parameters for the test function\n",
    "period_days = 300.\n",
    "b = 2 * np.pi / period_days  # Period in 1/MJD\n",
    "c = 0  # t-Offset in MJD\n",
    "d = 1  # Rate offset in Hz = 1 evt/sec is average -> 86400 evts/day\n",
    "a = d / 2.  # Amplitude in Hz = +- 0.5 evts / per second\n",
    "pars = np.array([a, b, c, d])\n",
    "\n",
    "sinfun = RateFunc.SinusRateFunction()\n",
    "\n",
    "# Plot function\n",
    "t0, t1 = c, c + period_days\n",
    "t = np.linspace(0, t1, 200)  # In MJD days\n",
    "y = sinfun.fun(t, pars)\n",
    "\n",
    "_ = plt.plot(t, y, lw=2, label=\"fun\")\n",
    "\n",
    "# Plot integral\n",
    "intgrl = np.zeros_like(t)\n",
    "for i, ti in enumerate(t):\n",
    "    intgrl[i] = sinfun.integral(t=t0, trange=[t0, ti*secinday], pars=pars)\n",
    "    \n",
    "# Scale integral, we expect 24*3600=86400 evts/day * (period_days days)\n",
    "print(\"Expect   : \", secinday * t1)\n",
    "print(\"Integral : \", intgrl[-1])\n",
    "_ = plt.plot(t, intgrl / 1e7, lw=2, label=\"integral/1e7\")\n",
    "\n",
    "# Sample from whole range and scale normed hist with time scale to match rate\n",
    "nsam = [int(1e4),]\n",
    "trange = np.array([[t0, t1],]) * secinday\n",
    "sam = sinfun.sample(t=t0, trange=trange,\n",
    "                    pars=pars, n_samples=nsam)\n",
    "h, b = np.histogram(sam, range=[t0, t1], bins=50, density=True)\n",
    "m = get_binmids([b])[0]\n",
    "_ = plt.hist(m, bins=b, weights=h * (t1 - t0), color=\"C0\",\n",
    "             alpha=0.5, label=\"sampled\")\n",
    "\n",
    "# Finally fit the sampled points again\n",
    "runtime = (t1 - t0)\n",
    "p0 = None  # Test default args\n",
    "bf_pars = sinfun.fit(t=m, rate=h * (t1 - t0), w=None, p0=p0)\n",
    "yfit = sinfun.fun(t, bf_pars)\n",
    "_ = plt.plot(t, yfit, lw=2, color=\"C3\", ls=\"--\", label=\"fitted\")\n",
    "p0 = sinfun._get_default_seed(t=m, rate=h * (t1 - t0),\n",
    "                              w=np.ones_like(m))\n",
    "yseed = sinfun.fun(t, p0)\n",
    "_ = plt.plot(t, yseed, lw=2, color=\"C3\", ls=\"-\", alpha=0.3,\n",
    "             label=\"default seed\")\n",
    "\n",
    "plt.xlabel(\"time in MJD\")\n",
    "plt.ylabel(\"rate in Hz\")\n",
    "_ = plt.ylim(0, None)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"data/figs/rate_function_sinus.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sinus1yrRateFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The same as above, but now with fixed period of 1 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define parameters for the test function\n",
    "period_days = 365.25\n",
    "c = 0  # t-Offset in MJD\n",
    "d = 1  # Rate offset in Hz = 1 evt/sec is average -> 86400 evts/day\n",
    "a = d / 2.  # Amplitude in Hz = +- 0.5 evts / per second\n",
    "pars = np.array([a, c, d])\n",
    "\n",
    "sinfun = RateFunc.Sinus1yrRateFunction()\n",
    "\n",
    "# Plot function\n",
    "t0, t1 = c, c + period_days\n",
    "t = np.linspace(0, t1, 200)  # In MJD days\n",
    "y = sinfun.fun(t, pars)\n",
    "\n",
    "_ = plt.plot(t, y, lw=2, label=\"fun\")\n",
    "\n",
    "# Plot integral\n",
    "intgrl = np.zeros_like(t)\n",
    "for i, ti in enumerate(t):\n",
    "    intgrl[i] = sinfun.integral(t=t0, trange=[t0, ti*secinday], pars=pars)\n",
    "    \n",
    "# Scale integral, we expect 24*3600=86400 evts/day * (period_days days)\n",
    "print(\"Expect   : \", secinday * t1)\n",
    "print(\"Integral : \", intgrl[-1])\n",
    "_ = plt.plot(t, intgrl / 1e7, lw=2, label=\"integral/1e7\")\n",
    "\n",
    "# Sample from whole range and scale normed hist with time scale to match rate\n",
    "nsam = int(1e4)\n",
    "sam = sinfun.sample(t=t0, trange=[t0, t1*secinday], pars=pars, n_samples=nsam)\n",
    "h, b = np.histogram(sam, range=[t0, t1], bins=50, density=True)\n",
    "m = get_binmids([b])[0]\n",
    "_ = plt.hist(m, bins=b, weights=h * (t1 - t0), color=\"C0\",\n",
    "             alpha=0.5, label=\"sampled\")\n",
    "\n",
    "# Finally fit the sampled points again\n",
    "runtime = (t1 - t0)\n",
    "p0 = None  # Test default args\n",
    "bf_pars = sinfun.fit(t=m, rate=h * (t1 - t0), w=None, p0=p0)\n",
    "yfit = sinfun.fun(t, bf_pars)\n",
    "_ = plt.plot(t, yfit, lw=2, color=\"C3\", ls=\"--\", label=\"fitted\")\n",
    "p0 = sinfun._get_default_seed(t=m, rate=h * (t1 - t0),\n",
    "                              w=np.ones_like(m))\n",
    "yseed = sinfun.fun(t, p0)\n",
    "_ = plt.plot(t, yseed, lw=2, color=\"C3\", ls=\"-\", alpha=0.3,\n",
    "             label=\"default seed\")\n",
    "\n",
    "plt.xlabel(\"time in MJD\")\n",
    "plt.ylabel(\"rate in Hz\")\n",
    "_ = plt.ylim(0, None)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"data/figs/rate_function_sinus1yr.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ConstantRateFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use constant rate function but leave the sinus to see how the fit behaves.\n",
    "Otherwise it would be boring to just see 3 flat lines over another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define sinus parameters\n",
    "period_days = 365.25\n",
    "c = 0  # t-Offset in MJD\n",
    "d = 1  # Rate offset in Hz = 1 evt/sec is average -> 86400 evts/day\n",
    "a = d / 2.  # Amplitude in Hz = +- 0.5 evts / per second\n",
    "sinpars = np.array([a, c, d])\n",
    "\n",
    "# Same for the constant function.\n",
    "constpars = (d,)\n",
    "\n",
    "sinfun = RateFunc.Sinus1yrRateFunction()\n",
    "constfun = RateFunc.ConstantRateFunction()\n",
    "\n",
    "# Plot sinus and constant function\n",
    "t0, t1 = c, c + period_days\n",
    "t = np.linspace(0, t1, 200)  # In MJD days\n",
    "y = sinfun.fun(t, sinpars)\n",
    "yc = constfun.fun(t, constpars)\n",
    "\n",
    "_ = plt.plot(t, y, color=\"C0\", lw=2, ls=\"--\")\n",
    "_ = plt.plot(t, yc, lw=2, label=\"fun\")\n",
    "\n",
    "# Plot integral\n",
    "intgrl = np.zeros_like(t)\n",
    "for i, ti in enumerate(t):\n",
    "    intgrl[i] = constfun.integral(t=t0, trange=[t0, ti*secinday],\n",
    "                                  pars=constpars)\n",
    "    \n",
    "# Scale integral, we expect 24*3600=86400 evts/day * (period_days days)\n",
    "print(\"Expect   : \", secinday * t1)\n",
    "print(\"Integral : \", intgrl[-1])\n",
    "_ = plt.plot(t, intgrl / 1e7, lw=2, label=\"integral/1e7\")\n",
    "\n",
    "# Sample from whole range and scale normed hist with time scale to match rate\n",
    "nsam = int(1e4)\n",
    "sam = sinfun.sample(t=t0, trange=[t0, t1*secinday], pars=sinpars,\n",
    "                      n_samples=nsam)\n",
    "h, b = np.histogram(sam, range=[t0, t1], bins=50, density=True)\n",
    "m = get_binmids([b])[0]\n",
    "_ = plt.hist(m, bins=b, weights=h * (t1 - t0), color=\"C0\",\n",
    "             alpha=0.5, label=\"sampled\")\n",
    "\n",
    "# Finally fit the sampled points again\n",
    "runtime = (t1 - t0)\n",
    "p0 = None  # Test default args\n",
    "bf_pars = constfun.fit(t=m, rate=h * (t1 - t0), w=None, p0=p0)\n",
    "yfit = constfun.fun(t, bf_pars)\n",
    "_ = plt.plot(t, yfit, lw=2, color=\"C3\", ls=\"--\", label=\"fitted\")\n",
    "p0 = constfun._get_default_seed(t=m, rate=h * (t1 - t0),\n",
    "                                w=np.ones_like(m))\n",
    "yseed = constfun.fun(t, p0)\n",
    "_ = plt.plot(t, yseed, lw=2, color=\"C3\", ls=\"-\", alpha=0.3,\n",
    "             label=\"default seed\")\n",
    "\n",
    "plt.xlabel(\"time in MJD\")\n",
    "plt.ylabel(\"rate in Hz\")\n",
    "_ = plt.ylim(0, None)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"data/figs/rate_function_const.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sinus fit with constant sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The fit is done with a sinus function to describe the bg rate properly.\n",
    "But the sampling is just uniform in each time window to skip rejection sampling and to mimic older analysis.\n",
    "\n",
    "So if we choose some windows small enought, then we basically can not differentiate between this methof and the true rejection sampling, because the sinus is pretty flat.\n",
    "\n",
    "If we increase the time windows we see, that we sample truly uniformly and do not follow the sinus shape anymore.\n",
    "\n",
    "We leave the integral and the fit out this time, because they are all derived from the Sinus1yrRateFunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define sinus parameters\n",
    "period_days = 365.25\n",
    "c = 0  # t-Offset in MJD\n",
    "d = 1  # Rate offset in Hz = 1 evt/sec is average -> 86400 evts/day\n",
    "a = d / 2.  # Amplitude in Hz = +- 0.5 evts / per second\n",
    "sinpars = np.array([a, c, d])\n",
    "\n",
    "rndgen = np.random.RandomState(7353)\n",
    "sinfun = RateFunc.Sinus1yrConstRateFunction(random_state=rndgen)\n",
    "\n",
    "# Plot true sinus function defining the rate\n",
    "t0, t1 = c, c + period_days\n",
    "t = np.linspace(0, t1, 200)  # In MJD days\n",
    "y = sinfun.fun(t, sinpars)\n",
    "_ = plt.plot(t, y, lw=2, label=\"fun\")\n",
    "\n",
    "# 1. Sample from whole range: See the unifrom samples averaging the sine\n",
    "nsam = int(1e4)\n",
    "sam = sinfun.sample(t=t0, trange=[t0, t1*secinday], pars=sinpars,\n",
    "                      n_samples=[nsam])\n",
    "h, b = np.histogram(sam, range=[t0, t1], bins=50, density=True)\n",
    "m = get_binmids([b])[0]\n",
    "_ = plt.hist(m, bins=b, weights=h * (t1 - t0), color=\"C0\",\n",
    "             alpha=0.5, label=\"full range\")\n",
    "\n",
    "# 2. Make finer sampling windows: See how the rate matches the sines better\n",
    "t0s = np.linspace(t0, t1, 20)[:-1]\n",
    "dts = np.repeat([[0., np.diff(t0s)[0]]], len(t0s), axis=0) * secinday\n",
    "# Get the integral to see how many we must sample (as in bg_rate_injector)\n",
    "expect = sinfun.integral(t0s, dts, sinpars)\n",
    "expect = np.round(expect).astype(int)  # Keep it easy: No poisson sampling\n",
    "\n",
    "fine_sam = sinfun.sample(t=t0s, trange=dts, pars=sinpars, n_samples=expect)\n",
    "fine_sam = np.concatenate(fine_sam)\n",
    "h, b = np.histogram(fine_sam, range=[t0, t1], bins=50, density=True)\n",
    "m = get_binmids([b])[0]\n",
    "_ = plt.hist(m, bins=b, weights=h * (t1 - t0), color=\"C1\",\n",
    "             alpha=0.5, label=\"small windows\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"time in MJD\")\n",
    "plt.ylabel(\"rate in Hz\")\n",
    "_ = plt.ylim(0, None)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"data/figs/rate_function_sinus_uniform_sample.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "See how it gets faster with uniform sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fun(t):\n",
    "    return sinfun.fun(t, sinpars)\n",
    "\n",
    "bound = [[0, 10]]\n",
    "fmax = fun(bound[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "rejection_sampling(fun, bounds=bound, n_samples=100, max_fvals=fmax, rndgen=rndgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sinfun.sample(0., bound, sinpars, n_samples=[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LLH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test the LLH module.\n",
    "\n",
    "It contains all functions for a specific LLH we want to use in our analysis.\n",
    "Currently GRBLLH is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sin_dec_bins = np.linspace(-1, 1, 50)\n",
    "\n",
    "min_logE = 0  #  min(np.amin(_exp[\"logE\"]), np.amin(mc[\"logE\"]))\n",
    "max_logE = 10 #  max(np.amax(_exp[\"logE\"]), np.amax(mc[\"logE\"]))\n",
    "logE_bins = np.linspace(min_logE, max_logE, 40)\n",
    "\n",
    "spatial_pdf_args = {\"bins\": sin_dec_bins, \"k\": 3, \"kent\": True}\n",
    "\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": 2.,\n",
    "                   \"fillval\": \"minmax\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": True,\n",
    "                   \"smooth_sigma\": [[0., 0.], [0., 0.]]}\n",
    "\n",
    "time_pdf_args = {\"nsig\": 4., \"sigma_t_min\": 2., \"sigma_t_max\": 30.}\n",
    "\n",
    "llh_args = {\"sob_rel_eps\": 0., \"sob_abs_eps\": 1e-4}\n",
    "\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Time PDF Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Reproduce the paper plot.\n",
    "\n",
    "Note that we get the PDFs for all srcs at once.\n",
    "Their times are just all the same here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a plot with ratios for different time windows as in the paper\n",
    "# dt from t0 in seconds, clip at 4 sigma\n",
    "dts = np.array([[-1, 5], [-5, 50], [-20, 200]])\n",
    "nsrcs = len(dts)\n",
    "nsig = 4.\n",
    "\n",
    "# Arbitrary start date. Choose t0 all the same for plotting\n",
    "t0 = 50500.\n",
    "t0_sec = t0 * secinday\n",
    "\n",
    "# Make t values for plotting in MJD around t0, to fit all in one plot\n",
    "max_dt, min_dt = np.amax(dts), np.amin(dts)\n",
    "dt_tot = max_dt - min_dt\n",
    "clip = np.clip(dt_tot, 2, 30) * nsig\n",
    "plt_range = np.array([min_dt - clip, max_dt + clip])\n",
    "\n",
    "npts = 1000\n",
    "t = np.linspace(t0_sec + 1.2 * plt_range[0],\n",
    "                t0_sec + 1.2 * plt_range[1], npts) / secinday\n",
    "\n",
    "_t = t * secinday - t0 * secinday\n",
    "\n",
    "# Mark t0 = 0 = rel. src time\n",
    "plt.axvline(0, 0, 1, c=\"k\", ls=\"--\", lw=2, alpha=0.8)\n",
    "\n",
    "# # Get all at once\n",
    "SoB = grbllh._soverb_time(t=t, src_t=np.repeat([t0], nsrcs), dt=dts)\n",
    "assert len(SoB) == nsrcs\n",
    "\n",
    "colors = [\"C0\", \"C3\", \"C2\"]\n",
    "for i in range(nsrcs):\n",
    "    # Plot seperately to give colors and labels\n",
    "    plt.plot(_t, SoB[i], lw=2, c=colors[i],\n",
    "             label=r\"$T_\\mathrm{{uni}}$: {:>3d}s, {:>3d}s\".format(*dts[i]))\n",
    "\n",
    "# Make it look like the paper plot, but with slightly extended borders\n",
    "plt.xlim(1.2 * plt_range)\n",
    "plt.ylim(0, np.amax(SoB) * 1.05)\n",
    "plt.xlabel(\"t - t0 in sec\")\n",
    "plt.ylabel(\"S / B\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(ls=\"--\", lw=1)\n",
    "\n",
    "# plt.savefig(\"./data/figs/time_pdf_ratio.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get the injection time window.\n",
    "This is needed for the injector, so only events in regions with non-zero PDF are injected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"dts:\\n\", dts)\n",
    "print(\"\\nclip range:\\n\", np.hstack((dts[:, [0]] - clip, dts[:, [1]] + clip)))\n",
    "print(\"\\nsigma clips:\\n\", grbllh.time_pdf_def_range(np.repeat([t0], nsrcs),\n",
    "                                                    dts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Spatial background spline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the same technique as used in skylab, but with an extra step of adding the outermost bin edges to the spline gridpoints.\n",
    "This way, the spline behaves reasonable at the edges and doesn't overshoot.\n",
    "\n",
    "We could extend this by using the KDE integrated over every variable and then fitting a spline to that.\n",
    "Or we could sample from the KDE and bin finely and fit a splien again.\n",
    "\n",
    "For now we leave only the option to use data directly.\n",
    "The spline fit is depending on the binning anyway.\n",
    "Only the finely binned KDE version could resolve that issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sin_dec = np.linspace(-1.05, 1.05, 200)\n",
    "y = np.exp(grbllh._spatial_bg_spl(sin_dec))\n",
    "_ = plt.hist(np.sin(_exp[\"dec\"]), bins=50, normed=True)\n",
    "plt.plot(sin_dec, y, lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Spatial background pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Should be identical to calling the spline directly, except that the BG PDF is normalized to the whole sphere.\n",
    "So we multiply the values by 2pi to account for that.\n",
    "\n",
    "Here we see the difference to just calling the spline directly: The PDF is zero outside the definition range, the spline extrapolated.\n",
    "We raise an error if that happens, because we can expect that this is not wanted and caused by carelessness of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(np.sin(_exp[\"dec\"]), bins=grbllh.spatial_pdf_args[\"bins\"],\n",
    "             normed=True)\n",
    "# sin_dec = np.linspace(-1.05, 1.05, 200)  # Will throw an error, as wanted\n",
    "sin_dec = np.linspace(-1., 1., 200)\n",
    "y = 2 * np.pi * grbllh._pdf_spatial_background(ev_sin_dec=sin_dec)\n",
    "plt.plot(sin_dec, y, lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Spatial signal PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Compare signal and BG pdf.\n",
    "\n",
    "First we create multiple sources and a single event and scan the event PDF by moving the event along the declination axis.\n",
    "All PDFs have the height, because the same sigma is used.\n",
    "\n",
    "Note that BG is here usually very small compared to the signal, because we sample the ev positions within 1 sigma around the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LOG = False\n",
    "\n",
    "nsrcs = 4\n",
    "# Choose the event sigma from data\n",
    "ev_sigma = np.random.choice(_exp[\"sigma\"], size=1)\n",
    "\n",
    "# Make nsrcs, same ra, but different dec. decs are distributed uniformly in\n",
    "# the range of the largest sigma from the events (for illustration only)\n",
    "src_dec = np.random.uniform(-ev_sigma, ev_sigma, size=nsrcs)\n",
    "src_ra = np.ones_like(src_dec) * np.pi\n",
    "plt_rnge = [np.amin(src_dec) - ev_sigma, np.amax(src_dec) + ev_sigma]\n",
    "\n",
    "# Scan signal PDF for event declination\n",
    "ev_dec = np.sin(np.linspace(plt_rnge[0], plt_rnge[1], 200))\n",
    "ev_sin_dec = np.sin(ev_dec)\n",
    "ev_ra = src_ra[0] * np.ones_like(ev_sin_dec)\n",
    "ev_sig = np.ones_like(ev_sin_dec) * ev_sigma\n",
    "\n",
    "# y has shape (nsrcs, nevts), where nevts are the ev_sin_dec values here (scan)\n",
    "y = grbllh._pdf_spatial_signal(src_ra, src_dec, ev_ra, ev_sin_dec, ev_sig)\n",
    "\n",
    "if LOG:\n",
    "    y = np.log10(y)\n",
    "\n",
    "plt.plot(ev_dec, y.T, lw=2)\n",
    "plt.vlines(src_dec, 0, np.amax(y), color=\"C7\", linestyles=\"--\", lw=2,\n",
    "           label=\"srcs pos\")\n",
    "\n",
    "# Plot BG PDF to compare\n",
    "bg = grbllh._pdf_spatial_background(ev_sin_dec=ev_sin_dec)\n",
    "plt.plot(ev_dec, bg, lw=2, label=\"BG\")\n",
    "\n",
    "plt.xlim(*plt_rnge)\n",
    "if LOG:\n",
    "    plt.ylim(1e-5, 1.1 * np.amax(y))\n",
    "else:\n",
    "    plt.ylim(0, 1.1 * np.amax(y))\n",
    "    \n",
    "    \n",
    "plt.xlabel(\"dec\")\n",
    "plt.ylabel(\"PDF per src\")\n",
    "plt.legend()\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we use multiple events with different sigmas and scan again in declination by moving a single possible src position.\n",
    "We get different heights, because of the different sigmas.\n",
    "\n",
    "The PDFs each peak where the event position is.\n",
    "If we had a single source, we would just read off the values at that position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LOG = True\n",
    "# Make nevts, same ra, but different dec. sigmas chosen from data\n",
    "nevts = 4\n",
    "ev_sigma = np.random.choice(_exp[\"sigma\"], size=nevts)\n",
    "# Sample some evt decs uniformly around the horizon with spread of the largest \n",
    "# sigma to get some variation\n",
    "max_sig = np.amax(ev_sigma)\n",
    "ev_dec = np.random.uniform(-max_sig, max_sig, size=nevts)\n",
    "ev_sin_dec = np.sin(ev_dec)\n",
    "ev_ra = np.ones_like(ev_dec) * np.pi\n",
    "\n",
    "# Plot margin PDF scanned for each src position for each event position\n",
    "src_dec = np.linspace(-2. * max_sig, 2 * max_sig, 200)\n",
    "src_ra = ev_ra[0] * np.ones_like(src_dec)\n",
    "\n",
    "# This has shape (nsrcs, nevts)\n",
    "y = grbllh._pdf_spatial_signal(src_ra, src_dec, ev_ra, ev_sin_dec, ev_sigma)\n",
    "\n",
    "if LOG:\n",
    "    y = np.log10(y)\n",
    "\n",
    "plt.plot(src_dec, y, lw=2)\n",
    "\n",
    "plt.vlines(ev_dec, 0, np.amax(y) * 1.1, color=\"C7\",\n",
    "           linestyles=\"--\", label=\"evts pos\")\n",
    "\n",
    "# Plot BG PDF to compare\n",
    "bg = grbllh._pdf_spatial_background(ev_sin_dec=np.sin(src_dec))\n",
    "plt.plot(src_dec, bg, lw=2, label=\"BG\")\n",
    "\n",
    "plt.xlim(src_dec[[0, -1]])\n",
    "if LOG:\n",
    "    plt.ylim(1e-5, 1.1 * np.amax(y))\n",
    "else:\n",
    "    plt.ylim(0, 1.1 * np.amax(y))\n",
    "    \n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Spatial PDF ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_dec_vs_signal(S, ev_dec, src_ra, src_dec, weights, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "    # Plot signal per source for each event\n",
    "    for i, (sra, sdec) in enumerate(zip(src_ra, src_dec)):\n",
    "        ax.plot(np.rad2deg(ev_dec), S[i], ls=\"-\")\n",
    "        ax.plot(np.rad2deg(sdec), -10, \"k|\")\n",
    "\n",
    "    # Simulate a simple stacking, one weight per source\n",
    "    ax.plot(np.rad2deg(ev_dec), np.sum(weights * S, axis=0) / np.sum(weights),\n",
    "             ls=\"--\", c=dg, label=\"stacked\")\n",
    "\n",
    "    ax.set_xlim([-1 + smin, smax + 1])\n",
    "    ax.set_xlabel(\"DEC in \")\n",
    "    ax.set_ylabel(\"Signal pdf\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We make 4 plots to test everything:\n",
    "\n",
    "1. [Top left] We place densely packed srcs at the declination range and scan the PDFs by varying the event declinations.\n",
    "   Sigma is fixed to 1 for illustration.\n",
    "   We expect just a row of gaussians along the dec range.\n",
    "   The stacked signal is the weighted sum of all signal contributions at a single event dec position.\n",
    "   \n",
    "2. [Bottom left] We plot just the background PDF and its inverse for the dec range.\n",
    "   The inverse PDF is what modulates the signal PDF.\n",
    "   \n",
    "3. [Top right] This modulation can be seen in this plot.\n",
    "   It is basically the same as the first one, but now it's signal over background.\n",
    "   So the signal peaks are modulated with the inverse BG PDF.\n",
    "   \n",
    "4. [Bottom right] This is the same plot as the third one, but this time we use the real data declination values instead of nicely spaced ones.\n",
    "   The effect is the same but not reall visible, because each event has a different sigma, so the PDFs all have different heights and widths.\n",
    "   It becomes more similar when using an 1 sigma for all events (just comment that line in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make srcs across the dec range. The hull of SoB should be shaped like the\n",
    "# 1/(sinDec BG distribtuion). With a single source we couldn't see that,\n",
    "# because it drops to zero far from the src position\n",
    "smin, smax, step = -90, +90, 10\n",
    "src_ra = np.deg2rad(np.arange(smin, smax + step, step))\n",
    "src_dec = np.deg2rad(np.arange(smin, smax + step, step))\n",
    "\n",
    "# Scan in dec by varying the evts dec\n",
    "ev_ra = np.deg2rad(np.linspace(smin, smax, 1000))\n",
    "ev_dec = np.deg2rad(np.linspace(smin, smax, 1000))\n",
    "ev_sin_dec = np.sin(ev_dec)\n",
    "ev_sig = np.deg2rad(np.ones_like(ev_ra))\n",
    "\n",
    "# Some pseudo weights to simulate stacking\n",
    "weights = np.arange(1, len(src_dec) + 1)[:, np.newaxis]\n",
    "\n",
    "fig, ((axtl, axtr), (axbl, axbr)) = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Signal only (kent vs. gaus should look the same here)\n",
    "grbllh.spatial_pdf_args[\"kent\"] = True\n",
    "S = grbllh._pdf_spatial_signal(src_ra, src_dec, ev_ra, ev_sin_dec, ev_sig)\n",
    "_ = plot_dec_vs_signal(S, ev_dec, src_ra, src_dec, weights, ax=axtl)\n",
    "axtl.set_xlim(-90, 90)\n",
    "\n",
    "# Background only\n",
    "bins = grbllh.spatial_pdf_args[\"bins\"]\n",
    "h, b = np.histogram(np.sin(_exp[\"dec\"]), bins=bins, density=True)\n",
    "m = 0.5 * (b[:-1] + b[1:])\n",
    "_ = axbl.hist(m, bins=bins, weights=h / 2 / np.pi, alpha=0.5)\n",
    "_sin_dec = np.linspace(-1, 1, 1000)\n",
    "bg_pdf = grbllh._pdf_spatial_background(_sin_dec)\n",
    "axbl.plot(_sin_dec, bg_pdf, lw=2, label=\"pdf\")\n",
    "axbl.set_ylim(0, 0.2)\n",
    "# 1 / BG PDF on second axis\n",
    "axbl2 = axbl.twinx()\n",
    "axbl2.plot(_sin_dec, 1. / bg_pdf, c=\"C2\", lw=2, ls=\"--\", label=\"1/pdf\")\n",
    "axbl2.set_ylim(0, (1 / bg_pdf).max())\n",
    "axbl.set_xlabel(\"sinus DEC\")\n",
    "axbl.set_xlim(-1, 1)\n",
    "axbl.legend(loc=\"upper left\")\n",
    "axbl2.legend(loc=\"upper center\")\n",
    "\n",
    "# SoB on example + BG PDF\n",
    "SoB = grbllh._soverb_spatial(src_ra, src_dec, ev_ra, ev_sin_dec, ev_sig)\n",
    "weights = np.arange(1, len(src_dec) + 1)[:, np.newaxis]\n",
    "_ = plot_dec_vs_signal(SoB, ev_dec, src_ra, src_dec, weights, ax=axtr)\n",
    "axtr.plot(np.rad2deg(np.arcsin(_sin_dec)), bg_pdf, lw=3, label=\"BG pdf\", c=dg)\n",
    "axtr.set_xlim(-90, 90)\n",
    "axtr.set_yscale(\"log\")\n",
    "axtr.set_ylim(np.amin(bg_pdf), 1e5)\n",
    "axtr.legend(loc=\"upper left\")\n",
    "\n",
    "# Now with the real data. Sort first in dec to show with nice lines + BG PDF\n",
    "idx = np.argsort(exp[\"dec\"])\n",
    "ev_ra = exp[\"ra\"][idx]\n",
    "ev_dec = exp[\"dec\"][idx]\n",
    "ev_sin_dec = np.sin(ev_dec)\n",
    "ev_sig = exp[\"sigma\"][idx]\n",
    "# Comment in to match the simple example (all events have sigma 1)\n",
    "# ev_sig = np.deg2rad(np.ones_like(ev_ra))\n",
    "SoB = grbllh._soverb_spatial(src_ra, src_dec, ev_ra, ev_sin_dec, ev_sig)\n",
    "\n",
    "_ = plot_dec_vs_signal(SoB, ev_dec, src_ra, src_dec, weights, ax=axbr)\n",
    "axbr.plot(np.rad2deg(np.arcsin(_sin_dec)), bg_pdf,\n",
    "          lw=3, label=\"BG pdf\", c=\"C0\")\n",
    "axbr.set_yscale(\"log\")\n",
    "axbr.set_ylim(np.amin(bg_pdf), 1e5)\n",
    "axbr.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Energy ratio spline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the creation of the signal over background ratio for the energy PDF.\n",
    "It is resolved in sinDec and logE to account for different positions on the sky and energies.\n",
    "\n",
    "Missing values, where no data or MC is present is filled with interpolation values, conttrolled by the \"fillval\" option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test col vs minmax. Also try different interpolations in linear or\n",
    "# logspace. Log interpolation falls off more quickly to the edge values.\n",
    "fig, (al, ar) = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": 2.,\n",
    "                   \"fillval\": \"col\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": False,\n",
    "                   \"smooth_sigma\": [[0., 0.], [0., 0.]]}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)\n",
    "\n",
    "# Ratio spline with 'col' filling\n",
    "x = np.linspace(-1.1, 1.1, num=1000 + 1)\n",
    "y = np.linspace(logE_bins[0] - 0.5, logE_bins[-1] + 0.5, num=1000 + 1)\n",
    "XX, YY = np.meshgrid(x, y)\n",
    "xx, yy = map(np.ravel, [XX, YY])\n",
    "gpts = np.vstack((xx, yy)).T\n",
    "zz = np.exp(grbllh._energy_interpol(gpts))\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "# Plotting with hist creates strange effects... Use pcolormesh instead\n",
    "img = al.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "al.set_title(\"Spline interpolation: 'col'\")\n",
    "plt.colorbar(ax=al, mappable=img)\n",
    "\n",
    "# With 'minmax' filling. Note: The small values in the lower row are due to\n",
    "# plotting in log. We interpolate in linear space, so in log, the jump is\n",
    "# very steep for small values.\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": 2.,\n",
    "                   \"fillval\": \"minmax\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": False,\n",
    "                   \"smooth_sigma\": [[0., 0.], [0., 0.]]}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)\n",
    "\n",
    "zz = np.exp(grbllh._energy_interpol(gpts))\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "img = ar.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "ar.set_title(\"Spline interpolation: 'minmax'\")\n",
    "plt.colorbar(ax=ar, mappable=img)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now the same thing but with the PDF forced to be strictly increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, (al, ar) = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "# With 'col' filling. (min makes no sense when PDF sis forced to increase)\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": 2.,\n",
    "                   \"fillval\": \"col\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": True,\n",
    "                   \"smooth_sigma\": [[0., 0.], [0., 0.]]}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)\n",
    "\n",
    "x = np.linspace(-1.1, 1.1, num=1000 + 1)\n",
    "y = np.linspace(logE_bins[0] - 0.5, logE_bins[-1] + 0.5, num=1000 + 1)\n",
    "XX, YY = np.meshgrid(x, y)\n",
    "xx, yy = map(np.ravel, [XX, YY])\n",
    "gpts = np.vstack((xx, yy)).T\n",
    "zz = np.exp(grbllh._energy_interpol(gpts))\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "img = al.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "al.set_title(\"Spline interpolation: 'col'\")\n",
    "plt.colorbar(ax=al, mappable=img)\n",
    "\n",
    "# With 'minmax' filling.\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": 2.,\n",
    "                   \"fillval\": \"minmax\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": True,\n",
    "                   \"smooth_sigma\": [[0., 0.], [0., 0.]]}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)\n",
    "\n",
    "zz = np.exp(grbllh._energy_interpol(gpts))\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "img = ar.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "ar.set_title(\"Spline interpolation: 'minmax'\")\n",
    "plt.colorbar(ax=ar, mappable=img)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now with some smoothing applied to both hists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, (al, ar) = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "# Unsmoothed\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": 2.,\n",
    "                   \"fillval\": \"minmax\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": True,\n",
    "                   \"smooth_sigma\": [[0., 0.], [0., 0.]]}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)\n",
    "\n",
    "x = np.linspace(-1.1, 1.1, num=1000 + 1)\n",
    "y = np.linspace(logE_bins[0] - 0.5, logE_bins[-1] + 0.5, num=1000 + 1)\n",
    "XX, YY = np.meshgrid(x, y)\n",
    "xx, yy = map(np.ravel, [XX, YY])\n",
    "gpts = np.vstack((xx, yy)).T\n",
    "zz = np.exp(grbllh._energy_interpol(gpts))\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "img = al.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "al.set_title(\"No smoothing\")\n",
    "plt.colorbar(ax=al, mappable=img)\n",
    "\n",
    "# Smoothed_ Units of kernel sigma are array indices\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": 2.,\n",
    "                   \"fillval\": \"minmax\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": True,\n",
    "                   \"smooth_sigma\": [[1, 0.5], [1, 0.5]]}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)\n",
    "\n",
    "zz = np.exp(grbllh._energy_interpol(gpts))\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "img = ar.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "ar.set_title(\"Smoothed with sigma [[{}, {}], [{}, {}]]\".format(\n",
    "    *np.array(energy_pdf_args[\"smooth_sigma\"]).flatten()))\n",
    "plt.colorbar(ax=ar, mappable=img)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Energy PDF ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we see again the difference to the direct spline evaluation.\n",
    "The ratio function set's values outside to zero probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (al, ar) = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": 2.,\n",
    "                   \"fillval\": \"col\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": True,\n",
    "                   \"smooth_sigma\": [[0., 0.], [0., 0.]]}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)\n",
    "\n",
    "# Ratio spline with 'col' filling\n",
    "x = np.linspace(-1.1, 1.1, num=1000 + 1)\n",
    "y = np.linspace(logE_bins[0] - 0.5, logE_bins[-1] + 0.5, num=1000 + 1)\n",
    "XX, YY = np.meshgrid(x, y)\n",
    "xx, yy = map(np.ravel, [XX, YY])\n",
    "gpts = np.vstack((xx, yy)).T\n",
    "zz = grbllh._soverb_energy(xx, yy)\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "img = al.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "al.set_title(\"Spline interpolation: 'col'\")\n",
    "plt.colorbar(ax=al, mappable=img)\n",
    "\n",
    "# With 'minmax' filling.\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": 2.,\n",
    "                   \"fillval\": \"minmax\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": True,\n",
    "                   \"smooth_sigma\": [[0., 0.], [0., 0.]]}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)\n",
    "\n",
    "zz = grbllh._soverb_energy(xx, yy)\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "img = ar.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "ar.set_title(\"Spline interpolation: 'minmax'\")\n",
    "plt.colorbar(ax=ar, mappable=img)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Detector weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Detector normed source weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use the same spline method to create a spline describing the sinDec dependence of a signal MC weighted to a specific astrophysical flux modell (usually unbroken power law).\n",
    "\n",
    "Depending on the src position, we expect more or less signal from that src.\n",
    "This is equivalent to folding with the detector exposure function.\n",
    "\n",
    "Our stacking form is described by a multi position search where the signal term gets modified to:\n",
    "\n",
    "$$\n",
    "    S^\\text{tot} = \\sum_{j=1}^{N_\\text{srcs}} w_j S_{ij} \\quad\\text{with}\\quad\n",
    "    \\sum_j w_j = 1 \\quad\\text{with}\\quad w_j = w_j^\\text{theo}\\cdot w_j^\\text{det}\n",
    "$$\n",
    "\n",
    "The weights are a combination of the exposure weights and a-priori fixed intrinsic source weights, eg. from a known gamma flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Small hack to change the gamma without recreating the grbllh object\n",
    "gamma_override = 2.13\n",
    "\n",
    "grbllh.energy_pdf_args[\"gamma\"] = gamma_override\n",
    "mc_sin_dec = np.sin(mc[\"dec\"])\n",
    "mc_bins = grbllh.energy_pdf_args[\"bins\"][0]\n",
    "gamma = grbllh.energy_pdf_args[\"gamma\"]\n",
    "mc_w = mc[\"ow\"] * mc[\"trueE\"]**(-gamma)\n",
    "\n",
    "grbllh._spatial_signal_spl = grbllh._normed_sin_dec_spline(\n",
    "    sin_dec=mc_sin_dec, bins=mc_bins, weights=mc_w)\n",
    "\n",
    "sin_dec = np.linspace(-1.05, 1.05, 200)\n",
    "y = np.exp(grbllh._spatial_signal_spl(sin_dec))\n",
    "\n",
    "# MC needs proper weighting\n",
    "mc_bins = energy_pdf_args[\"bins\"][0]\n",
    "h, b = np.histogram(np.sin(mc[\"dec\"]), bins=mc_bins, weights=mc_w, normed=True)\n",
    "\n",
    "# Smooth it, charge it, odd it, quick truncate it\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.savgol_filter.html\n",
    "m = get_binmids([b])[0]\n",
    "redux = 10  # Window len is nearest odd number to (number of bins / redux)\n",
    "window_len = int(2 * np.floor((len(b) / redux) / 2) + 1)  # Must be odd\n",
    "_h = scsignal.savgol_filter(h, window_len, 3, mode=\"mirror\")\n",
    "plt.hist(m, bins=b, weights=_h, histtype=\"step\", lw=2, color=\"C1\", ls=\"--\")\n",
    "plt.hist(m, bins=b, weights=h, histtype=\"step\", lw=2, color=\"C3\")\n",
    "\n",
    "# Plot spline (fitted to unsmoothed)\n",
    "plt.plot(sin_dec, y, lw=2, color=\"C2\")\n",
    "\n",
    "# Get weights for some srcs\n",
    "src_sin_dec = np.linspace(-1, 1, 11)\n",
    "src_dec = np.arcsin(src_sin_dec)\n",
    "src_w_theo = np.ones_like(src_dec)\n",
    "w = grbllh.src_weights(src_dec=src_dec, src_w_theo=src_w_theo)\n",
    "\n",
    "# Revoke norm for plotting to see if weights are on the curve\n",
    "src_dec_w = np.exp(grbllh._spatial_signal_spl(src_sin_dec))\n",
    "_w = w * np.sum(src_dec_w * src_w_theo)\n",
    "\n",
    "plt.plot(src_sin_dec, _w, \"wo\", ms=7, mew=1.5, mec=\"k\")\n",
    "plt.vlines(np.sin(src_dec), 0, 1.05 * np.amax(y), colors=\"C7\",\n",
    "           lw=1, linestyles=\"--\")\n",
    "\n",
    "plt.xlabel(\"sin(dec)\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.title(\"$\\gamma = {:.1f}$\".format(gamma))\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(0, 1.05 * np.amax(y))\n",
    "plt.tight_layout()\n",
    "\n",
    "print(w)\n",
    "print(w.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we just use some ascending theoretical weights in both directions.\n",
    "\n",
    "- w1 should resemble the sindec curve from above\n",
    "- w2 should rise overall to the right (less steep or reversed from w1)\n",
    "- w3 should fall overall to the right (steeper than w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_src_dec = np.arcsin(np.linspace(-1, 1, 21))\n",
    "\n",
    "# Compare for different theoretical weights\n",
    "src_w_theo = np.ones_like(_src_dec)\n",
    "w1 = grbllh.src_weights(src_dec=_src_dec, src_w_theo=src_w_theo)\n",
    "\n",
    "src_w_theo = np.arange(len(_src_dec)) + 1\n",
    "w2 = grbllh.src_weights(src_dec=_src_dec, src_w_theo=src_w_theo)\n",
    "\n",
    "src_w_theo = (np.arange(len(_src_dec)) + 1)[::-1]\n",
    "w3 = grbllh.src_weights(src_dec=_src_dec, src_w_theo=src_w_theo)\n",
    "\n",
    "plt.plot(np.sin(_src_dec), w1, \"o\", label=\"theo = 1 (orig)\")\n",
    "plt.plot(np.sin(_src_dec), w2, \"o\", label=\"theo = arange\")\n",
    "plt.plot(np.sin(_src_dec), w3, \"o\", label=\"theo = arange[::-1]\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Check if weights are the same when using event density (skylab style) instead.\n",
    "It should make no difference because the weights are normalized anyway.\n",
    "\n",
    "**This will be included, if we get to fitting multiple years.\n",
    "We can then use the same weights for the stacking and for normalizing ns per year.**\n",
    "\n",
    "Note: The normalization and the pivot will not be included in the end, because they are constant for every source and for every dataset/year, so they get normalized out anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Weight with numu diffuse 6yr flux norm, but same index as above\n",
    "index = gamma_override\n",
    "norm = 0.9 * 1e-18  # (GeV s sr cm^2)^-1, valid at 100 TeV = 1e5 GeV\n",
    "pivot = 1e5\n",
    "flux = norm * (mc[\"trueE\"] / pivot)**(-index)\n",
    "mc_w = mc[\"ow\"] * flux * livetime * secinday\n",
    "mc_bins = energy_pdf_args[\"bins\"][0]\n",
    "\n",
    "density = True\n",
    "h, b = np.histogram(np.sin(mc[\"dec\"]), bins=mc_bins, weights=mc_w,\n",
    "                    density=density)\n",
    "\n",
    "# Normalize (same as density=True)\n",
    "if not density:\n",
    "    h /= np.diff(b) * np.sum(h)\n",
    "\n",
    "# PDF * Number of total events = Event densitiy\n",
    "_h = h * mc_w.sum()  \n",
    "\n",
    "mids = get_binmids([mc_bins])[0]\n",
    "_ = plt.hist(mids, bins=mc_bins, weights=_h)\n",
    "\n",
    "# Make spline, use also outermost edges\n",
    "x = np.concatenate((b[[0]], mids, b[[-1]]))\n",
    "y = np.log(_h)\n",
    "y = np.concatenate((y[[0]], y, y[[-1]]))\n",
    "spl = sci.InterpolatedUnivariateSpline(x, y, k=3, ext=\"extrapolate\")\n",
    "\n",
    "x = np.linspace(-1, 1, 100)\n",
    "y = np.exp(spl(x))\n",
    "plt.plot(x, y, \"C1-\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"sindec\")\n",
    "plt.ylabel(\"Event density Nevts / sindec\")\n",
    "\n",
    "# Total events by integrating _h: Ntot = sum_i (_h_i * diff(bins)_i)\n",
    "plt.title(\"Gamma = {:.2f}: Ntot = {:.2f}\".format(\n",
    "        index, np.sum(_h * np.diff(mc_bins))))\n",
    "\n",
    "# Check the weight, deviation from float error I guess\n",
    "src_w_dec = np.exp(spl(src_sin_dec[1:-1]))\n",
    "src_w_theo = np.ones_like(src_dec[1:-1])\n",
    "src_w = src_w_dec * src_w_theo / np.sum(src_w_dec * src_w_theo)\n",
    "\n",
    "plt.plot(src_sin_dec[1:-1], src_w_dec, \"wo\", ms=7, mew=1.5, mec=\"k\")\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"Spline from PDF only\")\n",
    "print(w[1:-1])\n",
    "\n",
    "print(\"\\nSpline from event density with livetime\")\n",
    "print(src_w.reshape(len(src_w), 1))\n",
    "\n",
    "print(\"\\nRatio\")\n",
    "for ratio in w[1:-1] / np.sum(w[1:-1]) / src_w.reshape(len(src_w), 1):\n",
    "    print(\"[ {:.6f} ]\".format(*ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Detector unnormed expected events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "These are almost the same as above, but only normalized to bin area.\n",
    "So they are a signal event epxectation per time and solid angle.\n",
    "$$\n",
    "w_j = \\frac{n_\\text{obs}}{T\\Delta \\Omega}\n",
    "$$\n",
    "\n",
    "Note:\n",
    "    In skylab this is calculated in the `_effA` function in `ps_model`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "eargs = energy_pdf_args.copy()\n",
    "eargs[\"gamma\"] = 2.13\n",
    "grbllh = LLH.GRBLLH(_exp, _mc, spatial_pdf_args, eargs,\n",
    "                    time_pdf_args, llh_args)\n",
    "\n",
    "# Get the spline\n",
    "sin_dec = np.linspace(-1.05, 1.05, 200)\n",
    "y = np.exp(grbllh._nexpected_signal_spl(sin_dec))\n",
    "\n",
    "# Plot against MC hist the spline was made from\n",
    "mc_bins = energy_pdf_args[\"bins\"][0]\n",
    "mc_w = 0.5 * _mc[\"ow\"] * _mc[\"trueE\"]**-eargs[\"gamma\"]\n",
    "h, b = np.histogram(_mc[\"sinDec\"], bins=mc_bins, weights=mc_w, density=False)\n",
    "h /= np.diff(b) * 2. * np.pi  # RA solid angle normalization\n",
    "\n",
    "# Plot spline and hist\n",
    "plt.plot(sin_dec, y, lw=1, color=\"C3\", label=\"spline\")\n",
    "plt.plot(mc_bins, np.r_[h[0], h], c=dg, drawstyle=\"steps-pre\", label=\"hist\")\n",
    "\n",
    "plt.xlabel(\"sin(dec)\")\n",
    "plt.ylabel(r\"$\\frac{n}{T\\Delta\\Omega}$ in $\\frac{1}{\\mathrm{s\\ sr}}$\")\n",
    "plt.title(\"$\\gamma = {:.2f}$\".format(eargs[\"gamma\"]))\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(0, 1.05 * np.amax(y))\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Integrate over solid angle to get the rate of the sample without normalization.\n",
    "Integral and sum of weigths must be the same per construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _int(d):\n",
    "    \"\"\"Integrate over solid angle, 2pi for RA and cos for jacobi factor\"\"\"\n",
    "    return 2. * np.pi * grbllh.expect_weights(d) * np.cos(d)\n",
    "\n",
    "intgrl = scint.quad(_int, -np.pi / 2., np.pi / 2., limit=500)[0]\n",
    "sumw = np.sum(.5*_mc[\"ow\"]*_mc[\"trueE\"]**-eargs[\"gamma\"])\n",
    "\n",
    "print(\"Int over sr:\", intgrl)\n",
    "print(\"Weight     :\", sumw)\n",
    "print(\"Difference :\", intgrl - sumw)\n",
    "\n",
    "# Multiply with normlization to get signal rate and livetime for nevents\n",
    "print(\"Rate   : {:.2g} Hz\".format(intgrl * 0.9e-8))\n",
    "print(\"Events : {:.1f}\".format(intgrl * 0.9e-8 * livetime * 86400.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ln-LLH ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot llh and gradient.\n",
    "The gradient is calculated analytically.\n",
    "With this test, we simply want to check, if the gradient is OK and the likelihood behaves correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Snippet to plot lnLLH ratio and gradient next each other\n",
    "def plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax, lw=2):\n",
    "    fig, (al, ar) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    al.plot(ns, lnllh, lw=lw)\n",
    "    al.set_xlim(xmin, xmax)\n",
    "    if np.amax(lnllh) == 0.:\n",
    "        al.set_ylim(np.amin(lnllh), 1)\n",
    "    else:\n",
    "        al.set_ylim(0, 1.05 * np.amax(lnllh))\n",
    "    al.axvline(ns_max, 0, 1, ls=\"--\", lw=2, color=\"C7\")\n",
    "    al.set_title(\"LLH\")\n",
    "\n",
    "    ar.plot(ns, lnllh_grad, lw=lw)\n",
    "    ar.axhline(0, 0, 1, ls=\"--\", lw=2, color=\"C7\")\n",
    "    ar.axvline(ns_max, 0, 1, ls=\"--\", lw=2, color=\"C7\")\n",
    "    al.set_xlim(xmin, xmax)\n",
    "    ar.set_ylim(-5, 5)\n",
    "    ar.set_title(\"LLH gradient in ns\")\n",
    "    fig.tight_layout()\n",
    "    return fig, (al, ar)\n",
    "\n",
    "names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "rndgen = np.random.RandomState(7353)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### No Events given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Quickly check if the LLH handles an empty array of events correctly.\n",
    "\n",
    "If no events given, then the per event terms should all be zero.\n",
    "Then the test statistic, which is $\\Lambda = 2 \\cdot \\ln(\\mathcal{L}_1-\\mathcal{L}_0)$ reduces simply to $\\Lambda = -2n_s$.\n",
    "\n",
    "The gradient is then trivially $\\partial_{ns}\\Lambda = -2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make up some setup\n",
    "nsrcs = 1\n",
    "src_t = np.random.choice(_exp[\"timeMJD\"], size=nsrcs)\n",
    "dt = np.array([-20, 200])\n",
    "\n",
    "# Expected background with rate 5mHz, kind of realistic.\n",
    "# Increase nb scale to test different BG expectations.\n",
    "scale = 1e5\n",
    "nb = 0.005 * np.diff(dt) * scale\n",
    "src_ra = np.deg2rad([180])  # Arbitrarily placed single source\n",
    "src_dec = np.deg2rad([10])\n",
    "src_w_theo = np.ones_like(src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((src_t, [dt[0]], [dt[1]],\n",
    "                  [src_ra], [src_dec], src_w_theo))\n",
    "names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                       formats=len(names) * [\"float64\"])\n",
    "args = {\"nb\": nb, \"srcs\": srcs}\n",
    "\n",
    "# Setup zero events = empty array\n",
    "X = np.empty((0,), dtype=[(n, np.float) for n in _exp.dtype.names])\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "xmin, xmax = 0, 20\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "lnllh = np.empty(n_ns)\n",
    "lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    _lnllh, _lnllh_grad = grbllh.lnllh_ratio(X, ns[i], args)\n",
    "    lnllh[i], lnllh_grad[i] = _lnllh, _lnllh_grad[0]\n",
    "    \n",
    "# Manual \"fit\" by scanning the maximum\n",
    "ns_max = ns[np.argmax(lnllh)]\n",
    "\n",
    "_, (al, ar) = plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax, lw=4)\n",
    "\n",
    "# Cross check with expected result:\n",
    "lnllh_exp = -2 * ns\n",
    "lnllh_grad_exp = -2 * np.ones_like(ns)\n",
    "al.plot(ns, lnllh_exp, \"C1--\", lw=2, label=\"expect\")\n",
    "ar.plot(ns, lnllh_grad_exp, \"C1--\", lw=2, label=\"expect\")\n",
    "\n",
    "al.legend(loc=\"upper right\")\n",
    "ar.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Single Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First with only one source.\n",
    "\n",
    "Note: We test here \"super-signal-like\" events. Every event is exactly at the src position and every time is exactly in the time window, where the ratio is max.\n",
    "Only the energy is distributed as background.\n",
    "So only for really large time windows (really large) which have insanely high background rates we drop lower than the injected ns in our prediction.\n",
    "This is because the background term can only counter background-like events, which have a low signal over background ratio.\n",
    "For the events injected here, this rate is super high, so we always \"fit\" the exact amount of injected events.\n",
    "\n",
    "For this setup each events SoB is equal and we can calculate the sum over the events directly by replacing it with N*SoB.\n",
    "In this cse, the gradient is zero at:\n",
    "\n",
    "\\begin{align}\n",
    "    0 &= -1 + \\sum_i \\frac{S}{n_b B}\\cdot \\frac{1}{n_s \\frac{S}{n_b B} + 1}\n",
    "       = -1 + N \\frac{S}{n_b B}\\cdot \\frac{1}{n_s \\frac{S}{n_b B} + 1} \\\\\n",
    "    \\Leftrightarrow \\frac{1}{N} &= \\frac{1}{n_s + \\frac{n_b B}{S}} \\\\\n",
    "    \\Leftrightarrow N &= n_s + \\frac{n_b B}{S}\n",
    "\\end{align}\n",
    "\n",
    "So now if the signal is super large (and that's what we ensured by using our super-signal-like events) the term $\\frac{n_b B}{S} \\rightarrow 0$ and we get $\\hat{n}_S = N$ which is exactly what we observe.\n",
    "\n",
    "Only if we set super high $n_B$, our $\\hat{n}_S$ shrinks as $\\frac{n_b B}{S}$ gets larger and larger and in the end $\\hat{n}_S$ even turns negative, when the 1 / SoB ratio is larger than N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make up some setup\n",
    "nsrcs = 1\n",
    "src_t = rndgen.choice(_exp[\"timeMJD\"], size=nsrcs)\n",
    "dt = np.array([-20, 200])\n",
    "\n",
    "# Increase nb scale to see ns best fit shrink.\n",
    "scale = 1e4\n",
    "# Expected background with rate 5mHz, kind of realistic.\n",
    "nb = 0.005 * np.diff(dt) * scale\n",
    "src_ra = np.deg2rad([180])  # Arbitrarily placed single source\n",
    "src_dec = np.deg2rad([10])\n",
    "src_w_theo = np.ones_like(src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((src_t, [dt[0]], [dt[1]],\n",
    "                  [src_ra], [src_dec], src_w_theo))\n",
    "srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                       formats=len(names) * [\"float64\"])\n",
    "args = {\"nb\": nb, \"srcs\": srcs}\n",
    "\n",
    "# Set the events artificially where the srcs are in space and nicely spaced\n",
    "# times inside the search window, where time sob is large. Otherwise the llh\n",
    "# is almost always peaked at 0\n",
    "N = 10\n",
    "mint, maxt = src_t + dt / secinday  # In MJD\n",
    "timeMJD = np.linspace(mint, maxt, N)\n",
    "X = rndgen.choice(_exp, size=N)  # Only to copy the recarray structure\n",
    "X[\"timeMJD\"] = timeMJD\n",
    "X[\"ra\"] = np.ones_like(timeMJD) * src_ra\n",
    "X[\"sinDec\"] = np.ones_like(timeMJD) * np.sin(src_dec)\n",
    "X[\"sigma\"] = np.deg2rad(np.ones_like(timeMJD))\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "xmin, xmax = 0, 2 * N\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "lnllh = np.empty(n_ns)\n",
    "lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    _lnllh, _lnllh_grad = grbllh.lnllh_ratio(X, ns[i], args)\n",
    "    lnllh[i], lnllh_grad[i] = _lnllh, _lnllh_grad[0]\n",
    "\n",
    "# Manual \"fit\" by scanning the maximum\n",
    "ns_max = ns[np.argmax(lnllh)]\n",
    "\n",
    "plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Quick comparison to finite element gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(ns[1:], np.diff(lnllh) / np.diff(ns))\n",
    "plt.plot(ns, lnllh_grad, ls=\"--\")\n",
    "plt.axvline(ns_max, 0, 1, c=\"C7\", ls=\"--\")\n",
    "plt.axhline(0, 0, 1, c=\"C7\", ls=\"--\")\n",
    "plt.grid(ls=\"--\")\n",
    "plt.ylim(-5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Multiple Sources -- All at same position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This time we use multiple sources, but all at the exact same location and with the exact same properties.\n",
    "We expect the very same result as in the single source case above, because the weighted sum of the signal terms reduces to\n",
    "\n",
    "\\begin{align}\n",
    "    S^\\text{tot} &= \\sum_{j=1}^{N_\\text{srcs}} w_j S_{ij}\n",
    "                 = S_{i} \\sum_{j=1}^{N_\\text{srcs}} \\frac{1}{N_\\text{srcs}}\n",
    "                 = S_i \\\\\n",
    "    \\Lambda &= -2\\ln\\left(\\frac{\\mathcal{L}_0}{\\mathcal{L}_1}\\right)\n",
    "             = -n_S + \\sum_{i=1}^N\\ln\\left(\\frac{n_S\\ S^\\text{tot}}{\\langle n_B\\rangle B_i} + 1\\right)\n",
    "             = -n_S + \\sum_{i=1}^N\\ln\\left(\\frac{n_S\\ S_i}{\\langle n_B\\rangle B_i} + 1\\right)\n",
    "\\end{align}\n",
    "\n",
    "as all signal terms are exaxtly the same and no further background locations are introduced.\n",
    "\n",
    "We only have to scale the BG manually because we do not treat overlapping windows correctly in the code.\n",
    "So we just scale the nb expecation down by 1/nsrcs manually before feeding it into the llh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Repeat sources exactly as the single one from above\n",
    "nsrcs = 100\n",
    "_src_t = np.repeat(src_t, repeats=nsrcs, axis=0)\n",
    "_dt = np.repeat(dt.reshape(1, 2), axis=0, repeats=nsrcs)\n",
    "# Attention here: 100% overlapping windows so total BG is unchanged. To work\n",
    "# in the stacking framework, we just split the expectation equally\n",
    "\n",
    "# Increase nb scale as in single src case above to see ns best fit shrink\n",
    "_nb = 0.005 * np.diff(_dt, axis=1).flatten() / nsrcs * scale\n",
    "\n",
    "_src_ra = np.repeat(src_ra, repeats=nsrcs, axis=0)\n",
    "_src_dec = np.repeat(src_dec, repeats=nsrcs, axis=0)\n",
    "_src_w_theo = np.ones_like(_src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((_src_t, _dt[:, 0], _dt[:, 1],\n",
    "                  _src_ra, _src_dec, _src_w_theo))\n",
    "_srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                       formats=len(names) * [\"float64\"])\n",
    "_args = {\"nb\": _nb, \"srcs\": _srcs}\n",
    "\n",
    "# Also use the very same events for all sources here\n",
    "_X = np.copy(X)\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "_lnllh = np.empty(n_ns)\n",
    "_lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    __lnllh, __lnllh_grad = grbllh.lnllh_ratio(_X, ns[i], _args)\n",
    "    _lnllh[i], _lnllh_grad[i] = __lnllh, __lnllh_grad[0]\n",
    "\n",
    "# Manual \"fit\" by scanning the maximum\n",
    "_ns_max = ns[np.argmax(_lnllh)]\n",
    "\n",
    "plot_llh(ns, _lnllh, _lnllh_grad, _ns_max, xmin, xmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Multiple Sources -- Different Right-Ascensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now the almost same thing, but with changed src right ascensions.\n",
    "We distribute them equally around a fixed declination.\n",
    "Everything else is left as before, except for giving an equally distributed number of events the same right ascension as the sources.\n",
    "\n",
    "This case is a bit more tricky, and we don't expect the same TS here, because:\n",
    "We inject the same number of events (N) but we get nsrcs times the BG (because the windows don't overlap anymore).\n",
    "Each event only contributes to the window where it spatially is placed, so per source only N / nsrcs events (we choosed them so the number distribute nicely) have a SoB > 0.\n",
    "\n",
    "This means, that the total signal term is reduced by a factor of nsrcs, as the zero signal terms can't compensate the unaffected backgound which is still the same for all events.\n",
    "\n",
    "So even though our stacked signal term is reduced by a factor of nsrcs  we still get the same fit result for super signal like events, because the signal term is still huge and we still satisfy the condition $\\frac{n_b B}{S}\\rightarrow 0$.\n",
    "But we need slightly less cranked up background rate to let the best fit ns shrink as in the previous cases because the signal term is reduced by 1/Nsrc.\n",
    "\n",
    "So with the same scale factor as above the TS should end up lower in every case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Repeat sources exactly as the single one from above\n",
    "nsrcs = 5\n",
    "_src_t = np.repeat(src_t, repeats=nsrcs, axis=0)\n",
    "_dt = np.repeat(dt.reshape(1, 2), axis=0, repeats=nsrcs)\n",
    "\n",
    "# Windows don't overlap anymore, so use full BG for each window\n",
    "# Increase nb scale to see ns best fit shrink\n",
    "scale = 1e3\n",
    "_nb = 0.005 * np.diff(_dt) * scale\n",
    "\n",
    "# Handpick to let regions not overlap\n",
    "_src_ra = np.deg2rad([0, 30, 60, 90, 120])\n",
    "_src_dec = np.repeat(src_dec, repeats=nsrcs, axis=0)\n",
    "_src_w_theo = np.ones_like(_src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((_src_t, _dt[:, 0], _dt[:, 1],\n",
    "                  _src_ra, _src_dec, _src_w_theo))\n",
    "\n",
    "_srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                       formats=len(names) * [\"float64\"])\n",
    "_args = {\"nb\": _nb, \"srcs\": _srcs}\n",
    "\n",
    "# We used 5 srcs and 10 events, so we just repeat the ras once\n",
    "# This is not very obvious on how to scale to arbirary Ns and nsrcs\n",
    "# I'm not very sure here, how many events to inject to exactly match the cases\n",
    "# above.\n",
    "# Here we just have 2 evts per window and still have ns of 10, even though\n",
    "# signal should get downweighted to 1/5 of the two cases above per source.\n",
    "_X = np.copy(X)\n",
    "_X[\"ra\"] = np.repeat(_src_ra, repeats=2)\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "xmin, xmax = 0, 2 * N\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "_lnllh = np.empty(n_ns)\n",
    "_lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    __lnllh, __lnllh_grad = grbllh.lnllh_ratio(_X, ns[i], _args)\n",
    "    _lnllh[i], _lnllh_grad[i] = __lnllh, __lnllh_grad[0]\n",
    "\n",
    "# Manual \"fit\" by scanning the maximum\n",
    "_ns_max = ns[np.argmax(_lnllh)]\n",
    "\n",
    "plot_llh(ns, _lnllh, _lnllh_grad, _ns_max, xmin, xmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Quick comparison to finite element gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot(ns[1:], np.diff(_lnllh) / np.diff(ns))\n",
    "plt.plot(ns, _lnllh_grad, ls=\"--\")\n",
    "plt.axvline(_ns_max, 0, 1, c=\"C7\", ls=\"--\")\n",
    "plt.axhline(0, 0, 1, c=\"C7\", ls=\"--\")\n",
    "plt.grid(ls=\"--\")\n",
    "plt.ylim(-5, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### SoB Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "See if the absolute and relative thresholds are working to reduce the amount of points we need to calculate in the LLH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Just see the absolute threshold = 0.001 in action. Everything below is cut\n",
    "# so with high enough nb the ratio drops below that value. When nb=2e9 all\n",
    "# Events are gone, try it.\n",
    "thresh = 1e-3\n",
    "grbllh.llh_args[\"sob_abs_eps\"] = thresh\n",
    "\n",
    "# Just vary this between [0, 1]. The closer to 1 the less evts survive.\n",
    "# At 1 only the highest sob evt survives the relativ cut. At 0 all survive\n",
    "grbllh.llh_args[\"sob_rel_eps\"] = 1e-4\n",
    "\n",
    "nsurvive = []\n",
    "sobs = []\n",
    "nbs = np.linspace(6, 10, 100)\n",
    "for _nb in nbs:\n",
    "    args[\"nb\"] = np.array([[int(10**_nb)]])\n",
    "    _sob = grbllh._soverb(X, args)\n",
    "    sobs.append(_sob)\n",
    "    nsurvive.append(len(_sob))\n",
    "    if len(_sob) == 1:\n",
    "        last_sob = _sob[0]\n",
    "    \n",
    "plt.plot(nbs, nsurvive)\n",
    "plt.hlines(np.arange(1, 11, 1), 6, 10, linestyles=\"--\", colors=\"C7\")\n",
    "plt.xlabel(\"log10(nb)\")\n",
    "plt.ylabel(\"nr. of surviving evts\")\n",
    "plt.title(\"Highest surviving sob: {:.5f} > {:.5f} (abs thresh)\".format(\n",
    "    last_sob, thresh))\n",
    "plt.xlim(6, 10)\n",
    "plt.ylim(0, 10.5)\n",
    "plt.show()\n",
    "\n",
    "# Now show the actual sob values dropping below abs thresh.\n",
    "# See the dashed dropping below the threshold being at the same nb as the\n",
    "# steps in the first plot.\n",
    "for i, _nb in enumerate(nbs):\n",
    "    x = np.ones(nsurvive[i]) * _nb\n",
    "    y = np.sort(np.log10(sobs[i]))\n",
    "    plt.plot(x, y, marker=\".\", ls=\"\", color=\"C7\")\n",
    "plt.axhline(np.log10(thresh), 0, 1)\n",
    "plt.xlim(6, 10)\n",
    "plt.title(\"sob values dropping below thresh when nb is increased\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Getting the Test Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The LLH evaluates it's Test Statistic.\n",
    "Even if this is not quite the logic way to go here, it is imporving speed, because trivial cases (no, 1 or 2 evts given) can be solved analytically to skip the minimization.\n",
    "\n",
    "It would be nicer to have that in the analysis module, so we could choose which hypotheses to test, but we fit only one parameter anyway (ns) so here that doesn't really matter, if we put everything in the LLH.\n",
    "Things just don't have to be that flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Snippet to plot lnLLH ratio and gradient next each other\n",
    "def plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax, lw=2):\n",
    "    fig, (al, ar) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    al.plot(ns, lnllh, lw=lw)\n",
    "    al.set_xlim(xmin, xmax)\n",
    "    if np.amax(lnllh) == 0.:\n",
    "        al.set_ylim(np.amin(lnllh), 1)\n",
    "    else:\n",
    "        al.set_ylim(0, 1.05 * np.amax(lnllh))\n",
    "    al.axvline(ns_max, 0, 1, ls=\"--\", lw=2, color=\"C7\")\n",
    "    al.set_title(\"LLH\")\n",
    "\n",
    "    ar.plot(ns, lnllh_grad, lw=lw)\n",
    "    ar.axhline(0, 0, 1, ls=\"--\", lw=2, color=\"C7\")\n",
    "    ar.axvline(ns_max, 0, 1, ls=\"--\", lw=2, color=\"C7\")\n",
    "    al.set_xlim(xmin, xmax)\n",
    "    ar.set_ylim(-5, 5)\n",
    "    ar.set_title(\"LLH gradient in ns\")\n",
    "    fig.tight_layout()\n",
    "    return fig, (al, ar)\n",
    "\n",
    "names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "rndgen = np.random.RandomState(7353)\n",
    "\n",
    "bounds = [[0, None]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Analytic ns best fit and TS for nevts = [0, 1, 2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Compare the analytic best fits with the ones from the fitter (here just scanned LLH) just to be sure.\n",
    "\n",
    "Just choose some upper number for nevts and see how the fitter and the scan are just the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _get_best_fit(sob):\n",
    "    \"\"\"\n",
    "    Copied from code, otherwise we'd have to setup sources again and wouldn't\n",
    "    have direct control on the SoB values.\n",
    "    \"\"\"\n",
    "    def _neglnllh(ns):\n",
    "        lnllh, lnllh_grad = grbllh._lnllh_ratio(ns, sob)\n",
    "        return -1. * lnllh, -1. * lnllh_grad\n",
    "\n",
    "    # Get the best fit parameter and TS. Analytic cases are handled:\n",
    "    # For nevts = [1 | 2] we get a [linear | quadratic] equation to solve.\n",
    "    nevts = len(sob)\n",
    "    # Test again, because we applied some threshold cuts\n",
    "    if nevts == 0:\n",
    "        return 0., 0.\n",
    "    if nevts == 1:\n",
    "        # Use scalar math functions, they're faster than numpy\n",
    "        sob = sob[0]\n",
    "        ns = 1. - (1. / sob)\n",
    "        if ns <= 0:\n",
    "            return 0., 0.\n",
    "        else:\n",
    "            TS = -ns + math.log(sob)\n",
    "        return ns, 2. * TS\n",
    "    elif nevts == 2:\n",
    "        a = 1. / (sob[0] * sob[1])\n",
    "        c = (sob[0] + sob[1]) * a\n",
    "        ns = 1. - 0.5 * c + math.sqrt(c * c / 4. - a + 1.)\n",
    "        if ns <= 0:\n",
    "            return 0., 0.\n",
    "        else:\n",
    "            TS, _ = grbllh._lnllh_ratio(ns, sob)\n",
    "        return ns, TS\n",
    "    else:\n",
    "        # Fit other cases\n",
    "        res = sco.minimize(fun=_neglnllh, x0=[10], jac=True, bounds=bounds)\n",
    "\n",
    "        return res.x[0], -1. * res.fun[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just use a sob value directly (see how ns gets more accurate with high sob)\n",
    "_sob = 2.1\n",
    "\n",
    "nevts = np.arange(0, 6 + 1)\n",
    "nscan = 100\n",
    "\n",
    "for i, ni in enumerate(nevts): \n",
    "    sob = np.array(ni * [_sob])\n",
    "    ns = np.linspace(0, 1.5 * np.amax(nevts), nscan)\n",
    "    TS = np.empty(nscan, dtype=np.float)\n",
    "    grad = np.empty(nscan, dtype=np.float)\n",
    "    for j, nsj in enumerate(ns):\n",
    "        TS[j], grad_j = grbllh._lnllh_ratio(nsj, sob)\n",
    "        grad[j] = grad_j[0]\n",
    "\n",
    "    ns_bf = ns[np.argmax(TS)]\n",
    "    _, ax = plot_llh(ns, TS, grad, ns_bf, ns[0], ns[-1])\n",
    "    for axi in ax:\n",
    "        axi.set_xlabel(\"ns\")\n",
    "        axi.axvline(_get_best_fit(sob)[0], 0, 1, ls=\"--\", lw=3, color=\"C1\")\n",
    "    plt.suptitle(\"Number of events: {:d}. SoB = {:.1f}\".format(ni, _sob))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Single source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First we test if the module simply wrapps the LLH module correctly.\n",
    "This should reproduce same results (not regarding random fluctuations of course) as in the section ln-llh ratio, as we test the same setup as above here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make up some setup\n",
    "nsrcs = 1\n",
    "src_t = np.random.choice(_exp[\"timeMJD\"], size=nsrcs)\n",
    "dt = np.array([-20, 200])\n",
    "\n",
    "# Expected background with rate 5mHz, kind of realistic.\n",
    "# Increase nb scale to see ns best fit shrink.\n",
    "scale = 1e4\n",
    "nb = 0.005 * np.diff(dt) * scale\n",
    "src_ra = np.deg2rad([180])  # Arbitrarily placed single source\n",
    "src_dec = np.deg2rad([10])\n",
    "src_w_theo = np.ones_like(src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((src_t, [dt[0]], [dt[1]],\n",
    "                  [src_ra], [src_dec], src_w_theo))\n",
    "names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                       formats=len(names) * [\"float64\"])\n",
    "args = {\"nb\": nb, \"srcs\": srcs}\n",
    "\n",
    "# Set the events artificially where the srcs are in space and nicely spaced\n",
    "# times inside the search window, where time sob is large. Otherwise the llh\n",
    "# is almost always peaked at 0\n",
    "N = 10\n",
    "mint, maxt = src_t + dt / secinday  # In MJD\n",
    "timeMJD = np.linspace(mint, maxt, N)\n",
    "X = np.random.choice(_exp, size=N)  # Only to copy the recarray structure\n",
    "X[\"timeMJD\"] = timeMJD\n",
    "X[\"ra\"] = np.ones_like(timeMJD) * src_ra\n",
    "X[\"sinDec\"] = np.ones_like(timeMJD) * np.sin(src_dec)\n",
    "X[\"sigma\"] = np.deg2rad(np.ones_like(timeMJD))\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "xmin, xmax = 0, 2 * N\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "lnllh = np.empty(n_ns)\n",
    "lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    lnllh[i], lnllh_grad[i] = grbllh.lnllh_ratio(X, ns[i], args)\n",
    "\n",
    "# Manual \"fit\" by scanning the maximum\n",
    "ns_max = ns[np.argmax(lnllh)]\n",
    "\n",
    "_, ax = plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax)\n",
    "ax[0].set_title(\"LLH. ns best fit {:.3f}\".format(ns_max))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Also let's quickly see, how the times are distributed within the time PDF\n",
    "inj_trange = grbllh.time_pdf_def_range(src_t=srcs[\"t\"], dt=dt)\n",
    "inj_trange = src_t + inj_trange.flatten() / secinday\n",
    "\n",
    "x = np.linspace(inj_trange[0], inj_trange[1], 100)\n",
    "y = grbllh._soverb_time(t=x, src_t=srcs[\"t\"], dt=dt)\n",
    "\n",
    "plt.plot(x, y.reshape(len(x)))\n",
    "plt.vlines(X[\"timeMJD\"], 0, np.amax(y), colors=\"C7\", linestyles=\"--\", lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test if we can do the same as above, but using the scipy fitter this time to get the maximum.\n",
    "The LLH curve and the maximum should be identical to the ones above (except for small errors in scanning vs fitting ns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seed for the fitter\n",
    "ns0 = 1\n",
    "\n",
    "ns_bf, TS = grbllh.fit_lnllh_ratio(X, ns0, args, bounds, {})\n",
    "\n",
    "_, ax = plot_llh(ns, lnllh, lnllh_grad, ns_bf, xmin, xmax)\n",
    "ax[0].set_title(\"LLH. ns best fit {:.3f}\".format(ns_bf))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Multiple Sources -- All at same position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Repeat sources exactly as the single one from above\n",
    "nsrcs = 5\n",
    "_src_t = np.repeat(src_t, repeats=nsrcs, axis=0)\n",
    "_dt = np.repeat(dt.reshape(1, 2), axis=0, repeats=nsrcs)\n",
    "# Attention here: 100% overlapping windows so total BG is unchanged. To work\n",
    "# in the stacking framework, we just split the expectation equally\n",
    "\n",
    "# Increase nb scale to see ns best fit shrink\n",
    "scale = 1e4\n",
    "nb = 0.005 * np.diff(_dt, axis=1).flatten() / nsrcs  * scale\n",
    "\n",
    "_src_ra = np.repeat(src_ra, repeats=nsrcs, axis=0)\n",
    "_src_dec = np.repeat(src_dec, repeats=nsrcs, axis=0)\n",
    "src_w_theo = np.ones_like(_src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((_src_t, _dt[:, 0], _dt[:, 1], _src_ra, _src_dec, src_w_theo))\n",
    "\n",
    "srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                  formats=len(names) * [\"float64\"])\n",
    "args = {\"nb\": nb, \"srcs\": srcs}\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "xmin, xmax = 0, 2 * N\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "lnllh = np.empty(n_ns)\n",
    "lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    lnllh[i], lnllh_grad[i] = grbllh.lnllh_ratio(X, ns[i], args)\n",
    "\n",
    "# Manual \"fit\" by scanning the maximum\n",
    "ns_max = ns[np.argmax(lnllh)]\n",
    "\n",
    "_, ax = plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax)\n",
    "ax[0].set_title(\"LLH. ns best fit {:.3f}\".format(ns_max))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Again check using the class function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seed for the fitter\n",
    "ns0 = 1\n",
    "\n",
    "ns_bf, TS = grbllh.fit_lnllh_ratio(X, ns0, args, bounds, {})\n",
    "\n",
    "_, ax = plot_llh(ns, lnllh, lnllh_grad, ns_bf, xmin, xmax)\n",
    "ax[0].set_title(\"LLH. ns best fit {:.3f}\".format(ns_bf))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Multiple Sources -- Different Right-Ascencions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Repeat sources exactly as the single one from above\n",
    "nsrcs = 5\n",
    "_src_t = np.repeat(src_t, repeats=nsrcs, axis=0)\n",
    "_dt = np.repeat(dt.reshape(1, 2), axis=0, repeats=nsrcs)\n",
    "\n",
    "# Windows don't overlap anymore, so use full BG for each window\n",
    "# Increase nb scale to see ns best fit shrink\n",
    "scale = 1e4\n",
    "nb = 0.005 * np.diff(_dt) * scale\n",
    "\n",
    "# Do not let windows overlap\n",
    "src_ra = np.deg2rad(np.linspace(0, 2 * np.pi, nsrcs + 1)[:-1])\n",
    "_src_dec = np.repeat(src_dec, repeats=nsrcs, axis=0)\n",
    "src_w_theo = np.ones_like(_src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((_src_t, _dt[:, 0], _dt[:, 1], src_ra, _src_dec, src_w_theo))\n",
    "\n",
    "srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                       formats=len(names) * [\"float64\"])\n",
    "args = {\"nb\": nb, \"srcs\": srcs}\n",
    "\n",
    "# We used 5 srcs and 10 events, so we just repeat the ras once\n",
    "# This is not very obvious on how to scale to arbirary Ns and nsrcs\n",
    "# I'm not very sure here, how many events to inject to exactly match the cases\n",
    "# above.\n",
    "# Here we just have 2 evts per window and still have ns of 10, even though\n",
    "# signal should get donwweighted to 1/5 of the two cases above per source.\n",
    "X[\"ra\"] = np.repeat(src_ra, repeats=2)\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "xmin, xmax = 0, 2 * N\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "lnllh = np.empty(n_ns)\n",
    "lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    lnllh[i], lnllh_grad[i] = grbllh.lnllh_ratio(X, ns[i], args)\n",
    "\n",
    "# Manual \"fit\" by scanning the maximum\n",
    "ns_max = ns[np.argmax(lnllh)]\n",
    "\n",
    "_, ax = plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax)\n",
    "ax[0].set_title(\"LLH. ns best fit {:.3f}\".format(ns_max))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Again check with the class function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seed for the fitter\n",
    "ns0 = 1\n",
    "\n",
    "ns_bf, TS = grbllh.fit_lnllh_ratio(X, ns0, args, bounds, {})\n",
    "\n",
    "_, ax = plot_llh(ns, lnllh, lnllh_grad, ns_bf, xmin, xmax)\n",
    "ax[0].set_title(\"LLH. ns best fit {:.3f}\".format(ns_bf))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Signal Injector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Injection bands and omega calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define a simple stripped version of injector for single method tests\n",
    "dec = np.deg2rad([-60., -30., 0, 30., 60.])\n",
    "sin_dec = np.sin(dec)\n",
    "srcs = np.core.records.fromarrays([dec], names=\"dec\")\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "sig_inj = SigInj.SignalInjector(gamma=2., mode=\"band\",\n",
    "                               inj_width=np.deg2rad(5.))\n",
    "sig_inj._srcs = srcs\n",
    "sig_inj._nsrcs = len(srcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Mode \"band\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sig_inj._inj_width = np.deg2rad(5.)\n",
    "sig_inj._mode = \"band\"\n",
    "sig_inj._set_solid_angle()\n",
    "\n",
    "_min_dec = sig_inj._min_dec\n",
    "_max_dec = sig_inj._max_dec\n",
    "_omega = sig_inj._omega\n",
    "\n",
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Dec\n",
    "axl.hlines(dec, 0, 2 * np.pi, linestyles=\"-\", colors=\"C1\")\n",
    "axl.hlines(_min_dec, 0, 2 * np.pi, linestyles=\"--\", colors=\"#353132\")\n",
    "axl.hlines(_max_dec, 0, 2 * np.pi, linestyles=\"--\", colors=\"#353132\")\n",
    "\n",
    "_x = np.array([0, 2 * np.pi])\n",
    "for mind, maxd in zip(_min_dec, _max_dec):\n",
    "    axl.fill_between(_x, [mind, mind], [maxd, maxd], color=\"C7\", alpha=.25)\n",
    "\n",
    "axl.set_xlim(0, 2 * np.pi)\n",
    "axl.set_ylim(-np.pi / 2., np.pi / 2.)\n",
    "axl.set_title(\"dec bands\")\n",
    "\n",
    "# Sindec\n",
    "axr.hlines(np.sin(dec), 0, 2 * np.pi, linestyles=\"-\", colors=\"C1\")\n",
    "axr.hlines(np.sin(_min_dec), 0, 2 * np.pi, linestyles=\"--\", colors=\"#353132\")\n",
    "axr.hlines(np.sin(_max_dec), 0, 2 * np.pi, linestyles=\"--\", colors=\"#353132\")\n",
    "\n",
    "_x = np.array([0, 2 * np.pi])\n",
    "for mind, maxd in zip(np.sin(_min_dec), np.sin(_max_dec)):\n",
    "    axr.fill_between(_x, [mind, mind], [maxd, maxd], color=\"C7\", alpha=.25)\n",
    "\n",
    "axr.set_xlim(0, 2 * np.pi)\n",
    "axr.set_ylim(-1., 1.)\n",
    "axr.set_title(\"sin dec bands\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Mode \"circle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Only for printing the values below, plot is not able to test correctness\n",
    "r = np.deg2rad(15.)\n",
    "sig_inj._mode = \"circle\"\n",
    "sig_inj._inj_width = r\n",
    "sig_inj._set_solid_angle()\n",
    "_omega = sig_inj._omega\n",
    "\n",
    "# Now make the circles with wrapping\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ra = np.linspace(0, 2. * np.pi, len(dec))\n",
    "t = np.linspace(0, 2. * np.pi, 100)\n",
    "for deci, rai in zip(dec, ra):    \n",
    "    x = r * np.cos(t) + rai\n",
    "    y = r * np.sin(t) + deci\n",
    "    \n",
    "    ax.hlines(dec, 0, 2 * np.pi, linestyles=\"--\", colors=\"C1\")\n",
    "    ax.hlines(dec - r, 0, 2 * np.pi, linestyles=\"--\", colors=\"#353132\")\n",
    "    ax.hlines(dec + r, 0, 2 * np.pi, linestyles=\"--\", colors=\"#353132\")\n",
    "    \n",
    "    hlp.circle_on_skymap(rai, deci, r, ax, flat=True, color=\"C0\", lw=3)\n",
    "\n",
    "ax.set_xlim(0, 2 * np.pi)\n",
    "ax.set_ylim(-np.pi / 2., np.pi / 2.)\n",
    "ax.set_title(\"circles around sources\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Omegas are\\n\", _omega)\n",
    "print(\"  in percent of the sky\\n\", _omega / 4. / np.pi * 100, \"%\")\n",
    "# Manual calculation crosscheck\n",
    "test = 2 * np.pi * (1. - np.cos(r))\n",
    "print(\"Omegas should be\\n\", test)\n",
    "print(\"  in percent of the sky\\n\", test / 4. / np.pi * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Sun and Moon\n",
    "\n",
    "Test sun, moon and obvious cases of half and full sphere.\n",
    "Sun and moon from https://en.wikipedia.org/wiki/Solid_angle#Sun_and_Moon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sig_inj._mode = \"circle\"\n",
    "\n",
    "print(\"\")\n",
    "sun = 9.35e-3 / 2.\n",
    "sig_inj._inj_width = sun\n",
    "sig_inj._set_solid_angle()\n",
    "print(\"Sun has   : {:.5g}\".format(sig_inj._omega[0]))\n",
    "print(\"Wiki says : 6.87105 sr\")\n",
    "moon = 9.22e-3 / 2.\n",
    "sig_inj._inj_width = moon\n",
    "sig_inj._set_solid_angle()\n",
    "print(\"Moon has  : {:.5g}\".format(sig_inj._omega[0]))\n",
    "print(\"Wiki says : 6.67105 sr\")\n",
    "\n",
    "# Half and full sphere\n",
    "half = np.pi / 2.\n",
    "full = np.pi\n",
    "sig_inj._inj_width = half\n",
    "sig_inj._set_solid_angle()\n",
    "print(\"Half sphere 4pi: \", sig_inj._omega[0] / 4. / np.pi)\n",
    "sig_inj._inj_width = full\n",
    "sig_inj._set_solid_angle()\n",
    "print(\"Full sphere in 4pi: \", sig_inj._omega[0] / 4. / np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Time signal sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define a simple stripped version of injector for single method tests\n",
    "dec = np.deg2rad([-60., -30., 0, 30., 60.])\n",
    "sin_dec = np.sin(dec)\n",
    "srcs = np.core.records.fromarrays([dec], names=\"dec\")\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "sig_inj = SigInj.SignalInjector(gamma=2., mode=\"band\",\n",
    "                               inj_width=np.deg2rad(5.))\n",
    "sig_inj._srcs = srcs\n",
    "sig_inj._nsrcs = len(srcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Time sampling - Check multiple window sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make some src times and tranges (repeated to get multiple times in there)\n",
    "dt = 100. * np.vstack((np.arange(0, 39, 4), np.arange(1, 40, 4))).T\n",
    "src_t = np.repeat(50000. + 100 * np.arange(0, len(dt)), 2)\n",
    "dt = np.repeat(dt, 2, axis=0)\n",
    "rndgen = check_random_state(3537)\n",
    "\n",
    "times = sig_inj._sample_times(src_t, dt)\n",
    "\n",
    "print(\"dt.T\\n\", dt.T)\n",
    "print(\"src_t\\n\", src_t)\n",
    "print(\"sampled times\\n\", times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Time sampling - Check against time signal pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Attention:** Signal is sampled in the uniform region only.\n",
    "Signal PDF is defined only in unifrom region of the signal PDF.\n",
    "So the normalized heights don't really match because the gaussian edges steal normalization.\n",
    "\n",
    "This is OK, as the time PDF has no real seperation power.\n",
    "It acts more like a theta function, cutting out the region around a source.\n",
    "Only if we would assume, that the signal PDF had a different shape from uniform (and thus from the BG PDF) we would have real seperation power in subregions of the on time intervall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make some src times and tranges (repeated to get multiple times in there)\n",
    "dt = 100. * np.vstack((np.arange(0, 39, 4), np.arange(1, 40, 4))).T\n",
    "src_t = np.repeat(50000. + 100 * np.arange(0, len(dt)), 2)\n",
    "dt = np.repeat(dt, 2, axis=0)\n",
    "rndgen = check_random_state(3537)\n",
    "\n",
    "# Arbitrary start date from data\n",
    "nsrcs = 1\n",
    "t0 = 50000.\n",
    "t0_sec = t0 * secinday\n",
    "\n",
    "# dt from t0 in seconds, clip at 4 sigma\n",
    "dt = 200\n",
    "nsig = 4.\n",
    "\n",
    "# Make t values for plotting in MJD around t0\n",
    "clip = np.clip(dt, 2, 30) * nsig\n",
    "trange = np.array([-clip, dt + clip]).reshape(nsrcs, 2)\n",
    "ntrials = int(1e4)\n",
    "\n",
    "_src_t = np.repeat(t0, ntrials)\n",
    "_dt = np.repeat([[0., dt]], ntrials, axis=0)\n",
    "trials = sig_inj._sample_times(_src_t, _dt)\n",
    "\n",
    "# Plot them in together with the PDFs\n",
    "def time_bg_pdf(t, t0, a, b):\n",
    "    # Normalize relative to t0 in seconds (first multiply avoids rounding?)\n",
    "    _t = t * secinday - t0 * secinday\n",
    "  \n",
    "    pdf = np.zeros_like(_t, dtype=np.float)\n",
    "    uni = (_t >= a) & (_t <= b)\n",
    "    pdf[uni] = 1. / (b - a)\n",
    "    return pdf\n",
    "\n",
    "def time_sig_pdf(t, t0, dt, nsig=4):\n",
    "    if dt < 0:\n",
    "        raise ValueError(\"dt must not be negative.\")\n",
    "\n",
    "    # Normalize relative to t0 in seconds (first multiply avoids rounding?)\n",
    "    _t = t * secinday - t0 * secinday\n",
    "    \n",
    "    # Constrain sig_t to [2, 30]s regardless of uniform time window\n",
    "    sig_t = np.clip(dt, 2, 30)\n",
    "    sig_t_clip = nsig * sig_t\n",
    "    gaus_norm = (np.sqrt(2 * np.pi) * sig_t)\n",
    "    \n",
    "    # Split in def regions gaus rising, uniform, gaus falling and zero\n",
    "    gr = (_t < 0) & (_t >= -sig_t_clip)\n",
    "    gf = (_t > dt) & (_t <= dt + sig_t_clip)\n",
    "    uni = (_t >= 0) & (_t <= dt)\n",
    "    \n",
    "    pdf = np.zeros_like(t, dtype=np.float)\n",
    "    pdf[gr] = scs.norm.pdf(_t[gr], loc=0, scale=sig_t)\n",
    "    pdf[gf] = scs.norm.pdf(_t[gf], loc=dt, scale=sig_t)\n",
    "    # Connect smoothly with the gaussians\n",
    "    pdf[uni] = 1. / gaus_norm\n",
    "    \n",
    "    # Normalize whole distribtuion\n",
    "    dcdf = (scs.norm.cdf(dt + sig_t_clip, loc=dt, scale=sig_t) -\n",
    "            scs.norm.cdf(-sig_t_clip, loc=0., scale=sig_t))\n",
    "    norm = dcdf + dt / gaus_norm\n",
    "    \n",
    "    return pdf / norm\n",
    "\n",
    "\n",
    "# Plot the pdfs\n",
    "t = np.linspace(t0_sec + trange[:, 0], t0_sec + trange[:, 1], 200) / secinday\n",
    "bg_pdf = time_bg_pdf(t, t0, -clip, dt + clip)\n",
    "sig_pdf = time_sig_pdf(t, t0, dt, nsig)\n",
    "\n",
    "# Plot in normalized time\n",
    "_t = t * secinday - t0 * secinday\n",
    "plt.plot(_t, bg_pdf, \"C0-\")\n",
    "plt.plot(_t, sig_pdf, \"C1-\")\n",
    "plt.axvline(dt, 0, 1, color=\"C3\", ls=\"--\")\n",
    "plt.axvline(0, 0, 1, color=\"C2\", ls=\"--\")\n",
    "\n",
    "# Plot injected events from all trials, relative times\n",
    "times = (trials - t0) * secinday\n",
    "_ = plt.hist(times, bins=50, normed=True, color=dg, alpha=.25)\n",
    "\n",
    "plt.xlabel(\"Time relative to t0 in sec\")\n",
    "plt.ylim(0, None);\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"./data/figs/signal_events_time_sampled.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Compare to skylab raw_flux and event selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Compare the weights to the SVN skylab trunk in the stacking and non-stacking case.\n",
    "\n",
    "The conversion from flux in tdepps to flux is simply the lack of livetime in the weights.\n",
    "So we obtain a comparable skylab flux by removing the livetime factor from the weights.\n",
    "The event selection is not affected by the livetime, so we don't have to modify the code itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Global settings, equal event selection for both injectors\n",
    "inj_width = np.deg2rad(1)\n",
    "sin_dec_bw = np.sin(inj_width)\n",
    "\n",
    "# Load the current SVN skylab injector\n",
    "sys.path.insert(1, \"/Users/tmenne/icecube/software/skylab/trunk/\")\n",
    "from skylab.ps_injector import PointSourceInjector as skinj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Single source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrc = 1\n",
    "src_ra = np.asarray(0.)\n",
    "src_dec = np.asarray(0.)\n",
    "src_t = np.asarray(50000)\n",
    "dt0 = np.asarray(0.)\n",
    "dt1 = np.asarray(200.)\n",
    "w_theo = np.ones(nsrc)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "sig_inj = SigInj.SignalInjector(gamma=2., mode=\"band\", inj_width=inj_width)\n",
    "\n",
    "# Simulate skylab's band selection (debug flag only)\n",
    "sig_inj._skylab_band = True\n",
    "\n",
    "# tdepps uses ow per type, typeweight is 0.5 for standard nugen\n",
    "mc_ptype = np.copy(mc)\n",
    "mc_ptype[\"ow\"] /= 0.5\n",
    "\n",
    "sig_inj.fit(srcs=srcs, MC=mc_ptype, exp_names=exp.dtype.names)\n",
    "\n",
    "single_src_raw_flux = sig_inj._raw_flux\n",
    "print(\"\\nRaw Flux: {}\".format(single_src_raw_flux))\n",
    "\n",
    "del mc_ptype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sk_inj = skinj(gamma=2., sinDec_bandwidth=sin_dec_bw)\n",
    "sk_inj.fill(src_dec=src_dec, exp=exp, mc=mc, livetime=livetime)\n",
    "\n",
    "sk_raw_flux = sk_inj._raw_flux / livetime / secinday\n",
    "\n",
    "print(\"Selected {0:d} events in total.\".format(len(sk_inj.mc_arr)))\n",
    "print(\"\\nRaw Flux           : {}\".format(sk_inj._raw_flux))\n",
    "print(\"\\nRaw Flux / livetime: {}\".format(sk_raw_flux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Are both raw_fluences and number of events equal?\n",
    "print(\"# selected events equal : {}\".format(len(sig_inj.mc_arr) ==\n",
    "                                            len(sk_inj.mc_arr)))\n",
    "print(\"Raw fluxes equal        : {}\".format(np.isclose(sig_inj._raw_flux,\n",
    "                                                       sk_raw_flux)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Multiple sources - Stacking case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrc = 5\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrc)\n",
    "src_dec = np.deg2rad([-60., -30., 0, 30., 60.])\n",
    "src_t = np.linspace(50000, 50300, nsrc)\n",
    "dt0 = np.zeros(nsrc, dtype=np.float)\n",
    "dt1 = np.zeros(nsrc, dtype=np.float) + 200.\n",
    "w_theo = np.ones(nsrc)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "sig_inj = SigInj.SignalInjector(gamma=2., mode=\"band\", inj_width=inj_width)\n",
    "sig_inj._skylab_band = True\n",
    "mc_ptype = np.copy(mc)\n",
    "mc_ptype[\"ow\"] /= 0.5\n",
    "\n",
    "sig_inj.fit(srcs=srcs, MC=mc_ptype, exp_names=exp.dtype.names)\n",
    "\n",
    "multi_src_raw_flux = sig_inj._raw_flux\n",
    "print(\"\\nRaw Flux: {}\".format(multi_src_raw_flux))\n",
    "\n",
    "del mc_ptype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sk_inj = skinj(gamma=2., sinDec_bandwidth=sin_dec_bw)\n",
    "sk_inj.fill(src_dec=src_dec, exp=exp, mc=mc, livetime=livetime, src_w=w_theo)\n",
    "\n",
    "sk_raw_flux = sk_inj._raw_flux / livetime / secinday\n",
    "\n",
    "print(\"Selected {0:d} events in total.\".format(len(sk_inj.mc_arr)))\n",
    "print(\"\\nRaw Flux           : {}\".format(sk_inj._raw_flux))\n",
    "print(\"\\nRaw Flux / livetime: {}\".format(sk_raw_flux))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Are both raw_fluences and number of events equal?\n",
    "print(\"# selected events equal : {}\".format(len(sig_inj.mc_arr) ==\n",
    "                                            len(sk_inj.mc_arr)))\n",
    "print(\"Raw fluxes equal        : {}\".format(np.isclose(sig_inj._raw_flux,\n",
    "                                                       sk_raw_flux)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Turn off all sources but the single source with the weights and the injected flux is equal to the single source case as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrc = 5\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrc)\n",
    "src_dec = np.deg2rad([-60., -30., 0, 30., 60.])\n",
    "src_t = np.linspace(50000, 50300, nsrc)\n",
    "dt0 = np.zeros(nsrc, dtype=np.float)\n",
    "dt1 = np.zeros(nsrc, dtype=np.float) + 200.\n",
    "w_theo = np.array([0, 0, 1, 0, 0])\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "sig_inj = SigInj.SignalInjector(gamma=2., mode=\"band\", inj_width=inj_width)\n",
    "sig_inj._skylab_band = True\n",
    "mc_ptype = np.copy(mc)\n",
    "mc_ptype[\"ow\"] /= 0.5\n",
    "\n",
    "sig_inj.fit(srcs=srcs, MC=mc_ptype, exp_names=exp.dtype.names)\n",
    "\n",
    "print(\"\\nRaw Flux: {}\".format(sig_inj._raw_flux))\n",
    "print(\"\\nRaw Flux: {}\".format(single_src_raw_flux), \" (single src)\")\n",
    "\n",
    "del mc_ptype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Multiple files - Single source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use the same dataset, but one with less statistics.\n",
    "We get double the raw flux as for a single source because we inject from 2 years (some deviation from summing up less statistics in sample 2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrc = 1\n",
    "src_ra = np.asarray(0.)\n",
    "src_dec = np.asarray(0.)\n",
    "src_t = np.asarray(50000)\n",
    "dt0 = np.asarray(0.)\n",
    "dt1 = np.asarray(200.)\n",
    "w_theo = np.ones(nsrc)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "sig_inj = SigInj.SignalInjector(gamma=2., mode=\"band\", inj_width=inj_width)\n",
    "\n",
    "# Simulate skylab's band selection (debug flag only)\n",
    "sig_inj._skylab_band = True\n",
    "\n",
    "# tdepps uses ow per type, typeweight is 0.5 for standard nugen\n",
    "mc_ptype = np.copy(mc)\n",
    "mc_ptype[\"ow\"] /= 0.5\n",
    "\n",
    "# Simulate set with less statistics\n",
    "mc_ptype2 = np.copy(mc_ptype[::10])\n",
    "mc_ptype2[\"ow\"] *= 10.  # To compensate the loss in generated events\n",
    "\n",
    "sig_inj.fit(srcs=srcs, MC={0: mc_ptype, 1: mc_ptype2},\n",
    "            exp_names=exp.dtype.names)\n",
    "\n",
    "print(\"\\nRaw Flux: {}\".format(sig_inj._raw_flux))\n",
    "try:\n",
    "    print(\"\\nRaw Flux: {}\".format(single_src_raw_flux), \" (single src)\")\n",
    "    print(\"\\nRatio   : {}\".format(sig_inj._raw_flux / single_src_raw_flux))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "del mc_ptype\n",
    "del mc_ptype2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Both samples should have the approx. 50:50 of events injected.\n",
    "gen = sig_inj.sample(mean_mu=10000, poisson=False)\n",
    "ninj, sam, idx = next(gen)\n",
    "\n",
    "print(\"Injected for sample 1: {}\".format(np.sum(idx[\"enum\"] == 0)))\n",
    "print(\"Injected for sample 2: {}\".format(np.sum(idx[\"enum\"] == 1)))\n",
    "print(\"Ratio: {:.4}\".format(np.sum(idx[\"enum\"] == 0) /\n",
    "                            np.sum(idx[\"enum\"] == 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mc2 = np.copy(mc[::10])\n",
    "mc2[\"ow\"] *= 10.\n",
    "\n",
    "sk_inj = skinj(gamma=2., sinDec_bandwidth=sin_dec_bw)\n",
    "sk_inj.fill(src_dec=src_dec, exp={0: exp, 1: exp}, mc={0: mc, 1: mc2},\n",
    "            livetime={0: livetime, 1: livetime})\n",
    "\n",
    "# Here, we need to invest a bit more to remove the livetime per sample\n",
    "# Luckily the sample ids per selected event are saved in mc_arr\n",
    "sk_raw_flux = 0\n",
    "for sid, lti in zip(np.unique(sk_inj.mc_arr[\"enum\"]), [livetime, livetime]):\n",
    "    m = (sid == sk_inj.mc_arr[\"enum\"])\n",
    "    sk_raw_flux += np.sum(sk_inj.mc_arr[\"ow\"][m] / lti / secinday)\n",
    "\n",
    "print(\"Selected {0:d} events in total.\".format(len(sk_inj.mc_arr)))\n",
    "print(\"\\nRaw Flux           : {}\".format(sk_inj._raw_flux))\n",
    "print(\"\\nRaw Flux / livetime: {}\".format(sk_raw_flux))\n",
    "\n",
    "del mc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Are both raw_fluences and number of events equal?\n",
    "print(\"# selected events equal : {}\".format(len(sig_inj.mc_arr) ==\n",
    "                                            len(sk_inj.mc_arr)))\n",
    "print(\"Raw fluxes equal        : {}\".format(np.isclose(sig_inj._raw_flux,\n",
    "                                                       sk_raw_flux)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Multiple files - Stacking case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrc = 5\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrc)\n",
    "src_dec = np.deg2rad([-60., -30., 0, 30., 60.])\n",
    "src_t = np.linspace(50000, 50300, nsrc)\n",
    "dt0 = np.zeros(nsrc, dtype=np.float)\n",
    "dt1 = np.zeros(nsrc, dtype=np.float) + 200.\n",
    "w_theo = np.ones(nsrc)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "sig_inj = SigInj.SignalInjector(gamma=2., mode=\"band\", inj_width=inj_width)\n",
    "\n",
    "# Simulate skylab's band selection (debug flag only)\n",
    "sig_inj._skylab_band = True\n",
    "\n",
    "# tdepps uses ow per type, typeweight is 0.5 for standard nugen\n",
    "mc_ptype = np.copy(mc)\n",
    "mc_ptype[\"ow\"] /= 0.5\n",
    "\n",
    "# Simulate set with less statistics\n",
    "mc_ptype2 = np.copy(mc_ptype[::10])\n",
    "mc_ptype2[\"ow\"] *= 10.  # To compensate the loss in generated events\n",
    "\n",
    "sig_inj.fit(srcs=srcs, MC={0: mc_ptype, 1: mc_ptype2},\n",
    "            exp_names=exp.dtype.names)\n",
    "\n",
    "print(\"\\nRaw Flux: {}\".format(sig_inj._raw_flux))\n",
    "try:\n",
    "    print(\"\\nRaw Flux: {}\".format(multi_src_raw_flux), \" (single src)\")\n",
    "    print(\"\\nRatio   : {}\".format(sig_inj._raw_flux / multi_src_raw_flux))\n",
    "except:\n",
    "    pass\n",
    "\n",
    "del mc_ptype\n",
    "del mc_ptype2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Both samples should have the approx. 50:50 of events injected, both total\n",
    "# and per source\n",
    "gen = sig_inj.sample(mean_mu=100000, poisson=False)\n",
    "ninj, sam, idx = next(gen)\n",
    "\n",
    "idx0 = idx[idx[\"enum\"] == 0]\n",
    "idx1 = idx[idx[\"enum\"] == 1]\n",
    "\n",
    "print(\"Injected for sample 1: {}\".format(len(idx0)))\n",
    "print(\"Injected for sample 2: {}\".format(len(idx1)))\n",
    "print(\"Ratio: {:.4f}\".format(len(idx1) / len(idx0)))\n",
    "for src_idx in np.unique(idx[\"src_idx\"]):\n",
    "    src0 = np.sum(idx0[\"src_idx\"] == src_idx)\n",
    "    src1 = np.sum(idx1[\"src_idx\"] == src_idx)\n",
    "    print(\"- src {:d}: {:5d} / {:5d} = {:.3f}\".format(src_idx, src1, src0,\n",
    "                                                      src1 / src0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mc2 = np.copy(mc[::10])\n",
    "mc2[\"ow\"] *= 10.\n",
    "\n",
    "sk_inj = skinj(gamma=2., sinDec_bandwidth=sin_dec_bw)\n",
    "sk_inj.fill(src_dec=src_dec, exp={0: exp, 1: exp[::10]}, mc={0: mc, 1: mc2},\n",
    "            livetime={0: livetime, 1: livetime})\n",
    "\n",
    "# Here, we need to invest a bit more to remove the livetime per sample\n",
    "# Luckily the sample ids per selected event are saved in mc_arr\n",
    "sk_raw_flux = 0\n",
    "for sid, lti in zip(np.unique(sk_inj.mc_arr[\"enum\"]), [livetime, livetime]):\n",
    "    m = (sid == sk_inj.mc_arr[\"enum\"])\n",
    "    sk_raw_flux += np.sum(sk_inj.mc_arr[\"ow\"][m] / lti / secinday)\n",
    "\n",
    "print(\"Selected {0:d} events in total.\".format(len(sk_inj.mc_arr)))\n",
    "print(\"\\nRaw Flux           : {}\".format(sk_inj._raw_flux))\n",
    "print(\"\\nRaw Flux / livetime: {}\".format(sk_raw_flux))\n",
    "\n",
    "del mc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Are both raw_fluences and number of events equal?\n",
    "print(\"# selected events equal : {}\".format(len(sig_inj.mc_arr) ==\n",
    "                                            len(sk_inj.mc_arr)))\n",
    "print(\"Raw fluxes equal        : {}\".format(np.isclose(sig_inj._raw_flux,\n",
    "                                                       sk_raw_flux)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Fill Events - Plot positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### First: Band mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "src_dec = np.deg2rad([-60., -30., 0, 30., 60.])\n",
    "nsrc = len(src_dec)\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrc)\n",
    "src_t = np.linspace(50000, 50300, nsrc)\n",
    "dt0 = np.zeros(nsrc, dtype=np.float)\n",
    "dt1 = np.zeros(nsrc, dtype=np.float) + 200.\n",
    "w_theo = np.ones(nsrc)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "bandwidth = 0.1\n",
    "gamma = 2.\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=\"band\",\n",
    "                               inj_width=np.arcsin(bandwidth))\n",
    "skip = 50  # Just that it plots faster\n",
    "sig_inj.fit(srcs, {0: mc[::skip], 1:mc[::skip]}, exp.dtype.names)\n",
    "\n",
    "\n",
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot each src in a different color\n",
    "cmap = plt.cm.get_cmap(\"viridis\", nsrc + 2)\n",
    "colors = cmap.colors[1:-1]\n",
    "bins = np.linspace(-1., 1., 101)\n",
    "\n",
    "# Plot all MC: Selected parts must be equally filles\n",
    "weights = mc[\"ow\"] * mc[\"trueE\"]**(-sig_inj.gamma)\n",
    "h, b, _ = axl.hist(np.sin(mc[::skip][\"trueDec\"]), bins=bins,\n",
    "                   weights=weights[::skip], alpha=0.2, color=\"C7\")\n",
    "\n",
    "for i in range(nsrc):\n",
    "    # Get all events from all samples\n",
    "    for enum, mc_i in sig_inj._MC.items():\n",
    "        _enum = sig_inj.mc_arr[sig_inj.mc_arr[\"enum\"] == enum]\n",
    "        _src_m = _enum[\"src_idx\"] == i\n",
    "        _ev_idx = _enum[\"ev_idx\"]\n",
    "\n",
    "        _mc_i = mc_i[_ev_idx][_src_m]\n",
    "        weights = _mc_i[\"ow\"] * _mc_i[\"trueE\"]**(-sig_inj.gamma)\n",
    "        axl.hist(np.sin(_mc_i[\"trueDec\"]), bins=bins, weights=weights,\n",
    "                 color=colors[i])\n",
    "        axr.scatter(_mc_i[\"trueRa\"], _mc_i[\"trueDec\"], c=colors[i])\n",
    "\n",
    "    axl.axvline(np.sin(src_dec[i]), 0, 1, color=\"k\", ls=\"--\")\n",
    "    axl.axvline(np.sin(sig_inj._min_dec[i]), 0, 1, color=\"k\")\n",
    "    axl.axvline(np.sin(sig_inj._max_dec[i]), 0, 1, color=\"k\")\n",
    "    axr.axhline(src_dec[i], 0, 1, color=\"k\", ls=\"--\")\n",
    "    axr.axhline(sig_inj._min_dec[i], 0, 1, color=\"k\")\n",
    "    axr.axhline(sig_inj._max_dec[i], 0, 1, color=\"k\")\n",
    "\n",
    "# Plot outline to show that nothing is hidden\n",
    "m = 0.5 * (b[:-1] + b[1:])\n",
    "axl.hist(m, bins=bins, weights=h, color=\"k\", histtype=\"step\", linewidth=2)\n",
    "    \n",
    "axl.set_xlim(-1., 1.)\n",
    "axr.set_xlim(0., 2. * np.pi)\n",
    "axr.set_ylim(-np.pi/2., np.pi/2.)\n",
    "\n",
    "axl.set_xlabel(\"sin dec\")\n",
    "axr.set_xlabel(\"right-ascension\")\n",
    "axr.set_ylabel(\"dec\")\n",
    "\n",
    "axl.set_title(\"gamma = {:.2f}\".format(gamma))\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"data/figs/sig_inj_ev_selection_bands.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Second: Circle mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrc = 5\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrc)\n",
    "src_dec = np.deg2rad([-80., -30., 0, 30., 80.])\n",
    "src_t = np.linspace(50000, 50300, nsrc)\n",
    "dt0 = np.zeros(nsrc, dtype=np.float)\n",
    "dt1 = np.zeros(nsrc, dtype=np.float) + 200.\n",
    "w_theo = np.ones(nsrc)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "inj_width = np.deg2rad(10)\n",
    "gamma = 2.\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=\"circle\",\n",
    "                               inj_width=inj_width)\n",
    "skip = 50  # Just that it goes faster\n",
    "sig_inj.fit(srcs, {0: mc[::skip], 1:mc[::skip]}, exp.dtype.names)\n",
    "\n",
    "\n",
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"viridis\", nsrc + 2)\n",
    "colors = cmap.colors[1:-1]\n",
    "\n",
    "# Plot all MC: Selected parts must be equally filles\n",
    "weights = mc[\"ow\"] * mc[\"trueE\"]**(-sig_inj.gamma)\n",
    "h, b, _ = axl.hist(np.sin(mc[::skip][\"trueDec\"]), bins=bins, log=True,\n",
    "                   weights=weights[::skip], alpha=0.2, color=\"C7\")\n",
    "\n",
    "# Plot each src in a different color\n",
    "for i in range(nsrc):\n",
    "    # Get all events from all samples\n",
    "    for enum, mc_i in sig_inj._MC.items():\n",
    "        _enum = sig_inj.mc_arr[sig_inj.mc_arr[\"enum\"] == enum]\n",
    "        _src_m = _enum[\"src_idx\"] == i\n",
    "        _ev_idx = _enum[\"ev_idx\"]\n",
    "\n",
    "        _mc_i = mc_i[_ev_idx][_src_m]\n",
    "        axr.scatter(_mc_i[\"trueRa\"], _mc_i[\"trueDec\"], c=colors[i])\n",
    "        \n",
    "        _mc_i = mc_i[_ev_idx][_src_m]\n",
    "        weights = _mc_i[\"ow\"] * _mc_i[\"trueE\"]**(-sig_inj.gamma)\n",
    "        axl.hist(np.sin(_mc_i[\"trueDec\"]), bins=bins, weights=weights,\n",
    "                 log=True, color=colors[i])\n",
    "        axr.scatter(_mc_i[\"trueRa\"], _mc_i[\"trueDec\"], c=colors[i])\n",
    "\n",
    "    axl.axvline(np.sin(src_dec[i]), 0, 1, color=\"k\", ls=\"--\")\n",
    "    axl.axvline(np.sin(src_dec[i] - inj_width), 0, 1, color=\"k\")\n",
    "    axl.axvline(np.sin(src_dec[i] + inj_width), 0, 1, color=\"k\")\n",
    "        \n",
    "    axr.axhline(max(-np.pi / 2., srcs[\"dec\"][i] - sig_inj.inj_width),\n",
    "               0, 1, color=\"C7\", ls=\"--\")\n",
    "    axr.axhline(min(np.pi / 2., srcs[\"dec\"][i] + sig_inj.inj_width),\n",
    "               0, 1, color=\"C7\", ls=\"--\")\n",
    "    \n",
    "    hlp.circle_on_skymap(srcs[\"ra\"][i], srcs[\"dec\"][i], inj_width, axr,\n",
    "                         flat=True, color=\"k\", ls=\"-\", marker=\"\")  \n",
    "       \n",
    "axr.scatter(src_ra, src_dec, color=\"k\", marker=\"o\", edgecolor=\"k\",\n",
    "           facecolor=\"w\")\n",
    "\n",
    "m = 0.5 * (b[:-1] + b[1:])\n",
    "axl.hist(m, bins=bins, weights=h, color=\"k\", histtype=\"step\",\n",
    "         linewidth=2, log=True)\n",
    "\n",
    "axl.set_xlim(-1., 1.)\n",
    "axr.set_xlim(0., 2. * np.pi)\n",
    "axr.set_ylim(-np.pi/2., np.pi/2.)\n",
    "\n",
    "axl.set_xlabel(\"sin dec\")\n",
    "axr.set_xlabel(\"right-ascension\")\n",
    "axr.set_ylabel(\"dec\")\n",
    "axl.set_title(\"gamma = {:.2f}\".format(gamma))\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"data/figs/sig_inj_ev_selection_circle.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrc = 5\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrc)\n",
    "np.random.shuffle(src_ra)\n",
    "src_dec = np.deg2rad([-60., -30., 0, 30., 60.])\n",
    "src_t = np.linspace(50000, 50300, nsrc)\n",
    "dt0 = np.zeros(nsrc, dtype=np.float)\n",
    "dt1 = np.zeros(nsrc, dtype=np.float) + 200.\n",
    "w_theo = np.ones(nsrc)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "inj_width = np.deg2rad(11)\n",
    "gamma = 2.\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=\"circle\",\n",
    "                               inj_width=inj_width)\n",
    "skip = 50  # Just that it goes faster\n",
    "sig_inj.fit(srcs, {0: mc[::skip], 1:mc[::skip]}, exp.dtype.names)\n",
    "\n",
    "\n",
    "sm = amp_plt.skymap()\n",
    "fig, ax = sm.figure(tex=False)\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"viridis\", nsrc + 2)\n",
    "colors = cmap.colors[1:-1]\n",
    "\n",
    "# Plot each src in a different color\n",
    "for i in range(nsrc):\n",
    "    # Get all events from all samples\n",
    "    for enum, mc_i in sig_inj._MC.items():\n",
    "        _enum = sig_inj.mc_arr[sig_inj.mc_arr[\"enum\"] == enum]\n",
    "        _src_m = _enum[\"src_idx\"] == i\n",
    "        _ev_idx = _enum[\"ev_idx\"]\n",
    "\n",
    "        _mc_i = mc_i[_ev_idx][_src_m]\n",
    "        x, y = amp_plt.EquCoordsToMapCoords(_mc_i[\"trueRa\"],\n",
    "                                            _mc_i[\"trueDec\"])\n",
    "        ax.scatter(x, y, c=colors[i])\n",
    "\n",
    "    hlp.circle_on_skymap(srcs[\"ra\"][i], srcs[\"dec\"][i], inj_width, ax,\n",
    "                         flat=False, color=\"k\", ls=\"-\", marker=\"\")  \n",
    "\n",
    "x, y = amp_plt.EquCoordsToMapCoords(src_ra, src_dec)\n",
    "ax.scatter(x, y, color=\"k\", marker=\"o\", edgecolor=\"k\",\n",
    "           facecolor=\"w\")\n",
    "\n",
    "ax.set_title(\"gamma = {:.2f}\".format(gamma))\n",
    "\n",
    "# fig.savefig(\"data/figs/sig_inj_ev_selection_circle_skymap.png\", dpi=200)\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Inject events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "src_dec = np.deg2rad([-80., -30., 0, 30., 80.])\n",
    "nsrcs = len(src_dec)\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrcs)\n",
    "src_t = np.linspace(50000, 50300, nsrcs)\n",
    "# Use start = 0 only, plotter can't handle negative start times\n",
    "dt = np.vstack((np.repeat([0.], nsrcs), 100. * np.arange(1, nsrcs + 1))).T\n",
    "dt0 = dt[:, 0]\n",
    "dt1 = dt[:, 1]\n",
    "w_theo = np.ones(nsrcs)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "gamma = 2.\n",
    "mode = \"band\"  # Change here to switch circle vs. band mode below\n",
    "if mode == \"band\":\n",
    "    inj_width = np.deg2rad(5.)\n",
    "elif mode == \"circle\":\n",
    "    inj_width = np.deg2rad(10.)\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=mode,\n",
    "                               inj_width=inj_width)\n",
    "sig_inj.fit(srcs, mc, exp.dtype.names)\n",
    "\n",
    "ngen = 10000\n",
    "gen = sig_inj.sample(ngen, poisson=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Spatial - Compare using band and circle with the same bandwidth\n",
    "\n",
    "In circle it looks like we selected way more events than in band mode, but we have way more MC than we select.\n",
    "So we just select the same amount of evts, but in a much denser region so the plot looks crowded in the circle case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extract injected events per source\n",
    "ninj, inj, idx = next(gen)\n",
    "\n",
    "evts_per_src = []\n",
    "trueRa_per_src = []\n",
    "trueDec_per_src = []\n",
    "for j in range(nsrcs):\n",
    "    per_src_ev_ids = idx[idx[\"src_idx\"] == j][\"ev_idx\"]\n",
    "    trueRa_per_src.append(sig_inj._MC[-1][per_src_ev_ids][\"trueRa\"])\n",
    "    trueDec_per_src.append(sig_inj._MC[-1][per_src_ev_ids][\"trueDec\"])\n",
    "    evts_per_src.append(inj[idx[\"src_idx\"] == j])\n",
    "    \n",
    "print(\"[true] Injected per src: \", list(map(len, trueRa_per_src)))\n",
    "print(\"[meas] Injected per src: \", list(map(len, evts_per_src)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cmap = plt.cm.get_cmap(\"viridis\", nsrcs + 2)\n",
    "colors = cmap.colors[1:-1]\n",
    "\n",
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "if mode == \"band\":\n",
    "    _min_dec = sig_inj._min_dec\n",
    "    _max_dec = sig_inj._max_dec\n",
    "elif mode == \"circle\":\n",
    "    _min_dec = src_dec - np.repeat(sig_inj.inj_width, nsrcs)\n",
    "    _max_dec = src_dec + np.repeat(sig_inj.inj_width, nsrcs)\n",
    "else:\n",
    "    raise ValueError(\"Choose 'band' or 'circle'.\")\n",
    "    \n",
    "\n",
    "for i in range(nsrcs):\n",
    "    trueRa = trueRa_per_src[i]\n",
    "    trueDec = trueDec_per_src[i]\n",
    "    _ev = evts_per_src[i]\n",
    "    n_sel = len(_ev)\n",
    "    \n",
    "    # Rotate again to if all all truths are at the src positions\n",
    "    ra3, dec3 = rotator(trueRa, trueDec,\n",
    "                        np.repeat(src_ra[i], n_sel),\n",
    "                        np.repeat(src_dec[i], n_sel),\n",
    "                        trueRa, trueDec)\n",
    "    \n",
    "    axl.scatter(_ev[\"ra\"], _ev[\"dec\"], marker=\".\", color=colors[i], alpha=0.1)\n",
    "    axr.scatter(trueRa, trueDec, marker=\".\", color=colors[i], alpha=0.1)\n",
    "\n",
    "    axl.scatter(ra3, dec3, marker=\".\", color=\"w\", edgecolor=\"k\", s=100)\n",
    "    axr.scatter(ra3, dec3, marker=\".\", color=\"w\", edgecolor=\"k\", s=100)\n",
    "    \n",
    "    \n",
    "    axl.axhline(src_dec[i], 0, 1, color=\"k\", ls=\"--\")\n",
    "    axl.axhline(_min_dec[i], 0, 1, color=\"k\")\n",
    "    axl.axhline(_max_dec[i], 0, 1, color=\"k\")\n",
    "    axr.axhline(src_dec[i], 0, 1, color=\"k\", ls=\"--\")\n",
    "    axr.axhline(_min_dec[i], 0, 1, color=\"k\")\n",
    "    axr.axhline(_max_dec[i], 0, 1, color=\"k\")\n",
    "    \n",
    "axl.set_xlabel(\"right-ascension\")\n",
    "axl.set_ylabel(\"dec\")\n",
    "axr.set_xlabel(\"right-ascension\")\n",
    "axr.set_ylabel(\"dec\")\n",
    "axl.set_title(\"Rotated measured and true positions\")\n",
    "axr.set_title(\"Rotated true and true positions\")\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"data/figs/signal_events_radec_sampled_\" +\n",
    "#             \"rotated_{}.png\".format(mode), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cos_dist(src_ra, src_dec, ev_ra, ev_dec):\n",
    "    cos_dist = (np.cos(src_ra - ev_ra) *\n",
    "                np.cos(src_dec) * np.cos(ev_dec) +\n",
    "                np.sin(src_dec) * np.sin(ev_dec))\n",
    "\n",
    "    return np.clip(cos_dist, -1., 1.)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "# Pool of MC event to select from\n",
    "ra = sig_inj._MC[-1][\"ra\"]\n",
    "dec = sig_inj._MC[-1][\"dec\"]\n",
    "trueRa = sig_inj._MC[-1][\"trueRa\"]\n",
    "trueDec = sig_inj._MC[-1][\"trueDec\"]\n",
    "w = sig_inj._sample_w\n",
    "dist = cos_dist(trueRa, trueDec, ra, dec)\n",
    "_ = plt.hist(np.rad2deg(np.arccos(dist)), bins=100, weights=w,\n",
    "             range=[0., 180.], log=True, label=\"All selected\")\n",
    "\n",
    "# All currently injected events\n",
    "ev_idx = idx[\"ev_idx\"]  # Select only injected from all\n",
    "ra = ra[ev_idx]\n",
    "dec = dec[ev_idx]\n",
    "trueRa = trueRa[ev_idx]\n",
    "trueDec = trueDec[ev_idx]\n",
    "w = w[ev_idx]\n",
    "dist = cos_dist(trueRa, trueDec, ra, dec)\n",
    "_ = plt.hist(np.rad2deg(np.arccos(dist)), bins=100, weights=w,\n",
    "             range=[0., 180.], log=True, label=\"Injected\")\n",
    "plt.title(\"Space angle distribution between true and measured direction.\" +\n",
    "          \" Currently injected: {} evts\". format(ngen))\n",
    "\n",
    "plt.xlabel(\"delta Psi in degree\")\n",
    "plt.ylabel(\"sum of sample weights per bin\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"data/figs/signal_events_delta_psi_comp_{}.png\".format(mode,\n",
    "#                                                                    dpi=150))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Times\n",
    "\n",
    "**Note:** The number of times per window (= events drawn per source) are distributed like the signal declination distribution, because we made up sources which are distributed linearly ascending in time and in declination, so they simply correlate.\n",
    "It's a nice double check in plot.\n",
    "But also compare to the histograms in the \"Fill Event\" cells above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create the GRBLLH object but only for the time pdf\n",
    "sin_dec_bins = np.linspace(-1, 1, 50)\n",
    "logE_bins = np.linspace(0, 10, 40)\n",
    "\n",
    "spatial_pdf_args = {\"bins\": sin_dec_bins, \"k\": 3, \"kent\": True}\n",
    "\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": 2.,\n",
    "                   \"fillval\": \"minmax\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": True,\n",
    "                   \"smooth_sigma\": [[0., 0.], [0., 0.]]}\n",
    "\n",
    "time_pdf_args = {\"nsig\": 4., \"sigma_t_min\": 2., \"sigma_t_max\": 30.}\n",
    "\n",
    "llh_args = {\"sob_rel_eps\": 0., \"sob_abs_eps\": 1e-4}\n",
    "\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extract injected events per source\n",
    "ninj, inj, idx = next(gen)\n",
    "\n",
    "times_per_src = []\n",
    "for j in range(nsrcs):\n",
    "    times_per_src.append(inj[idx[\"src_idx\"] == j][\"timeMJD\"])\n",
    "    \n",
    "print(\"[true] Injected per src: \", list(map(len, times_per_src)))\n",
    "\n",
    "\n",
    "# Now each times in the centered time frame in seconds together with the\n",
    "# signal PDFs\n",
    "vline_scale = 20.\n",
    "\n",
    "nsig = 4.\n",
    "clip = np.clip(np.diff(dt, axis=1), 2, 30) * nsig\n",
    "trange = np.hstack((dt[:, [0]] - clip, dt[:, [1]] + clip))\n",
    "\n",
    "for i, ti in enumerate(times_per_src):\n",
    "    t_sec = ti * secinday - src_t[i] * secinday\n",
    "    _t = np.linspace(trange[i, 0], trange[i, 1], 100)\n",
    "    _t_mjd = _t / secinday + src_t[i]\n",
    "#     _pdf = time_sig_pdf(_t_mjd, src_t[i],\n",
    "#                         dt[i, 1] - dt[i, 0]).flatten()\n",
    "    _pdf = grbllh._soverb_time(_t_mjd, src_t[i], dt[i]).ravel()\n",
    "    if i == 0:\n",
    "        _max = 1.05 * np.amax(_pdf)\n",
    "    # Small ticks for event positions below the 0 line\n",
    "    plt.vlines(t_sec, -i * _max / vline_scale, -(i+1) * _max / vline_scale,\n",
    "               linestyles=\"-\", colors=\"C{:1d}\".format(i))\n",
    "    plt.vlines(dt[i], _max, -nsrcs * _max / vline_scale, linestyles=\":\",\n",
    "               colors=\"C{:1d}\".format(i))\n",
    "    plt.plot(_t, _pdf, \"C{:1d}-\".format(i),\n",
    "             label=\"{:d} evts\".format(len(ti)))\n",
    "\n",
    "plt.axhline(0, 0, 1, color=\"C7\")\n",
    "plt.xlim(1.1 * trange[1, 0], trange[-1, 1] - 0.1 * trange[-1, 0])\n",
    "plt.ylim(-nsrcs * _max / vline_scale, _max)\n",
    "plt.xlabel(\"time in sec, centered at src t0\")\n",
    "plt.title(\"Injected evts per window, total of {} signal evts.\".format(ninj))\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"data/figs/signal_events_time_sampled_multi.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Check expected vs injected evts per src\n",
    "\n",
    "We inject events and comnpare the fraction of events injected per source with the total src weight, which is detector acceptance (signal weighted) and intrinsic weight.\n",
    "If we sample in a narrow band around each src we expect the fraction of sampled events to match the total source weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Note:** Circle mode doesn't match when the radius is very small.\n",
    "That is because we inject from less events and are very dominated by initial mc fluctuations, inserting only a tiny fraction of events.\n",
    "If we increase the circle size (0.1 in sindec) we get similarly stable results as in band mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "src_dec = np.deg2rad([-80.,- 60., -45., -30., -15., 0,\n",
    "                      15., 30., 45., 60., 80.])\n",
    "nsrcs = len(src_dec)\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrcs)\n",
    "src_t = np.linspace(50000, 50300, nsrcs)\n",
    "# Use start = 0 only, plotter can't handle negative start times\n",
    "dt = np.vstack((np.repeat([0.], nsrcs), 100. * np.arange(1, nsrcs + 1))).T\n",
    "dt0 = dt[:, 0]\n",
    "dt1 = dt[:, 1]\n",
    "\n",
    "w_theo = np.ones(nsrcs)\n",
    "# Try non equal, to see the deviation from the MC, but not from injected evts\n",
    "# w_theo = np.arange(nsrcs, dtype=np.float) + 1.\n",
    "\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "gamma = 2.\n",
    "mode = \"band\"\n",
    "# Make it narrow so only events in close proximity to the srcs are selected\n",
    "# so the fraction matches the  total src weight.\n",
    "inj_width = np.arcsin(np.deg2rad(0.1))\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=mode,\n",
    "                                inj_width=inj_width)\n",
    "sig_inj.fit(srcs, _mc, exp.dtype.names)\n",
    "\n",
    "ngen = 10000\n",
    "gen = sig_inj.sample(ngen, poisson=False)\n",
    "\n",
    "# Extract injected events per source\n",
    "ninj, inj, idx = next(gen)\n",
    "\n",
    "trueDec_per_src = []\n",
    "for j in range(nsrcs):\n",
    "    per_src_ev_ids = idx[idx[\"src_idx\"] == j][\"ev_idx\"]\n",
    "    trueDec_per_src.append(sig_inj._MC[-1][per_src_ev_ids][\"dec\"])\n",
    "    \n",
    "evts_per_src = list(map(len, trueDec_per_src))\n",
    "print(\"[true] Injected per src: \", evts_per_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sin_dec_bins = np.linspace(-1, 1, 50)\n",
    "logE_bins = np.linspace(0, 10, 40)\n",
    "\n",
    "spatial_pdf_args = {\"bins\": sin_dec_bins, \"k\": 3, \"kent\": True}\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": 2.,\n",
    "                   \"fillval\": \"minmax\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": True,\n",
    "                   \"smooth_sigma\": [[0., 0.], [0., 0.]]}\n",
    "time_pdf_args = {\"nsig\": 4., \"sigma_t_min\": 2., \"sigma_t_max\": 30.}\n",
    "llh_args = {\"sob_rel_eps\": 0., \"sob_abs_eps\": 1e-4}\n",
    "\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)\n",
    "\n",
    "\n",
    "norm_src_w = grbllh.src_weights(srcs[\"dec\"], src_w_theo=w_theo).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "sin_dec = np.linspace(-1., 1., 201)\n",
    "bins = np.linspace(-1., 1., 201)\n",
    "\n",
    "# Normed src weights, sum=1\n",
    "ax.plot(np.sin(srcs[\"dec\"]), norm_src_w, ls=\"\", marker=\"o\", color=\"#353132\",\n",
    "        label=\"norm. src_w = acc_w * theo_w\")\n",
    "\n",
    "# Spline must be pseudo weighted to match the single weights (PMF style)\n",
    "pseudo_norm = np.sum(np.exp(grbllh._spatial_signal_spl(np.sin(srcs[\"dec\"]))))\n",
    "y = np.exp(grbllh._spatial_signal_spl(sin_dec)) / pseudo_norm\n",
    "ax.plot(sin_dec, y, color=\"#353132\")\n",
    "\n",
    "# Make MC hist (origin of spline)\n",
    "weights = _mc[\"ow\"] * _mc[\"trueE\"]**(-sig_inj.gamma)\n",
    "h, b = np.histogram(np.sin(_mc[\"trueDec\"]), bins=bins, weights=weights,\n",
    "                    normed=True)\n",
    "m = 0.5 * (b[:-1] + b[1:])\n",
    "_ = ax.hist(m, bins=b, weights=h / pseudo_norm, alpha=0.2, color=\"C7\")\n",
    "\n",
    "# Make fraction of sampled events per band\n",
    "frac = evts_per_src / np.sum(evts_per_src)\n",
    "ax.plot(np.sin(srcs[\"dec\"]), frac, ls=\"\", marker=\"_\",\n",
    "        color=\"C1\", mew=2, ms=10, label=\"Fraction of inj. events\")\n",
    "ax.vlines(np.sin(srcs[\"dec\"]), np.zeros_like(frac), frac, zorder=5,\n",
    "           color=\"C1\", linestyle=\"-\", lw=3)\n",
    "\n",
    "ax.set_xlabel(\"sin_dec\")\n",
    "ax.set_ylabel(\"fraction of inj events\")\n",
    "ax.set_xlim(-1., 1.)\n",
    "# ax.semilogy()\n",
    "ax.legend()\n",
    "ax.set_title(\"{} injected events, mode='{}'\".format(ngen, mode))\n",
    "\n",
    "# plt.savefig(\"./data/figs/sig_inj_src_w_vs_inj_fraction.png\", dpi=150)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The analysis module grabs all the stuf from before and creates trial calculation from it.\n",
    "So we test here, if everything wrapped up correctly and if we get OK looking test statistics from our trials.\n",
    "\n",
    "A genreal note on how our experimental is handled:\n",
    "\n",
    "Before we start out analysis, we split our data in off-time and on-time data.\n",
    "On-time data is data around a a-priori fixed time frame around our sources we want to test.\n",
    "We exclude this data until the very end, because we don't want to bias ourselfes as there is the possibility that the signal we want to find is in that on-time data.\n",
    "\n",
    "The off-time data is everything else and is assumed to not contain the sought after signal.\n",
    "The on-time time frame should be choosen large enough to account for that.\n",
    "It should definitely be larger than the time frames we test for in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _percentile_nzeros(vals, nzeros, q):\n",
    "    \"\"\"\n",
    "    Returns the percentile q for a dataset with `vals` > 0 and `nzeros`\n",
    "    entries that are zero.\n",
    "\n",
    "    Alternatively do `np.percentile(np.r_[np.zeros(nzeros), vals], q)`, which\n",
    "    gives the same result when choosing ``interpolation='lower'``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vals : array-like\n",
    "        Non-zero values.\n",
    "    nzeros : int\n",
    "        Number of zero trials.\n",
    "    q : float\n",
    "        Percentile in [0, 100].\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    percentile : float\n",
    "        The percentile at level q.\n",
    "    \"\"\"\n",
    "    q /= 100.\n",
    "    nonzero = len(vals)\n",
    "    ntot = nonzero + nzeros\n",
    "    idx = int(q * ntot) - nzeros - 1\n",
    "    vals = np.sort(vals)\n",
    "\n",
    "    if idx < 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        return vals[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_trials(vals, ntrials, bins, ax=None,\n",
    "                CHI2=True, GEN=False, SIGMA=True, **kwargs):\n",
    "    if len(vals) == 0:\n",
    "        raise ValueError(\"No values given. Maybe sample more trials.\")\n",
    "\n",
    "    def prop_in_1d_sigma(sigma):\n",
    "        # To draw the sigma lines\n",
    "        if sigma < 0:\n",
    "            raise ValueError(\"'sigma' must be >= 0\")\n",
    "        return scs.norm.cdf(sigma) - scs.norm.cdf(-sigma)\n",
    "\n",
    "    # Compare with generated chi2 with df=1 and same nzeros\n",
    "    if GEN:\n",
    "        eta = float(len(vals)) / ntrials  # Fraction of non-zeros\n",
    "        nonzero = np.random.binomial(ntrials, p=eta, size=1)\n",
    "        vals = np.random.chisquare(df=1, size=int(nonzero))\n",
    "        fname = \"gen_chi2_df=1\"\n",
    "    else:\n",
    "        fname = \"trials\"\n",
    "        \n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    # Add nzeros to first bin manually\n",
    "    nzeros = ntrials - len(vals)\n",
    "    h, b = np.histogram(vals, bins=bins)\n",
    "    h[0] += nzeros\n",
    "\n",
    "    m = 0.5 * (b[:-1] + b[1:])\n",
    "    _ = ax.hist(m, b, weights=h, normed=True, log=True, **kwargs)\n",
    "\n",
    "    if CHI2:\n",
    "        # Fit delta-chi2 PDF to TS\n",
    "        (df, loc, scale) = scs.chi2.fit(vals, floc=0)\n",
    "        chi2fit = scs.chi2(df, loc, scale)\n",
    "        eta = len(vals) / ntrials\n",
    "        x = np.linspace(0.1, bins[-1], 200)\n",
    "        y = chi2fit.pdf(x) * eta\n",
    "        ydf1 = scs.chi2.pdf(x, df=1, loc=0, scale=1) * eta\n",
    "\n",
    "        # Plot fitted and dof=1 chi2 for comparison\n",
    "        ax.plot(x, y, \"C1-\")\n",
    "        ax.plot(x, ydf1, \"C2--\")\n",
    "        ax.set_title(\"Percent non-zero trials: \" +\n",
    "                     \"{:.1f} (=eta). df={:.2f}, scale={:.2f}\".format(\n",
    "                      100 * len(vals) / ntrials, df, scale))\n",
    "    else:\n",
    "        ax.set_title(\"Percent non-zero trials: {:.1f} (=eta).\".format(\n",
    "            100 * len(vals) / ntrials))\n",
    "        \n",
    "    ax.set_ylabel(\"PDF\")\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're going through the full steps here:\n",
    "\n",
    "1. Create bg_rate_injector with a specific rate_function.\n",
    "2. Create a bg_injector injecting random data events.\n",
    "3. Create LLH which is used to test our hypthesis.\n",
    "4. Create some src hyptheses to test against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rndgen = np.random.RandomState(7353)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create some srcs we want to test, with some different properties.\n",
    "# We don't use randomness here to have full control\n",
    "nsrcs = 5\n",
    "dt = np.vstack((np.repeat([-20.], nsrcs), 100. * np.arange(1, nsrcs + 1))).T\n",
    "\n",
    "names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "types = len(names) * [np.float]\n",
    "dtype = [(_n, _t) for _n, _t in zip(names, types)]\n",
    "srcs = np.empty((nsrcs, ), dtype=dtype)\n",
    "\n",
    "# Choose times equally spaced, but away from borders\n",
    "mint, maxt = np.amin(_exp[\"timeMJD\"]), np.amax(_exp[\"timeMJD\"])\n",
    "srcs[\"t\"] = np.linspace(mint, maxt, nsrcs + 2)[1:-1]\n",
    "\n",
    "srcs[\"dt0\"] = dt[:, 0]\n",
    "srcs[\"dt1\"] = dt[:, 1]\n",
    "\n",
    "# Don't let them overlap by choosing 0 and 2pi\n",
    "srcs[\"ra\"] = np.linspace(0, 2 * np.pi, nsrcs + 1)[:-1]\n",
    "\n",
    "# Same as with time here, do not select directly at poles\n",
    "srcs[\"dec\"] = np.arcsin(np.linspace(-1, 1, nsrcs + 2)[1:-1])\n",
    "\n",
    "# These are just ones, they shouldn't cause problems\n",
    "srcs[\"w_theo\"] = np.ones(nsrcs, dtype=np.float)\n",
    "\n",
    "print(\"t   : \" + \", \".join(\"{:.2f}\".format(_t) for _t in srcs[\"t\"]))\n",
    "print(\"dt0 : \", srcs[\"dt0\"])\n",
    "print(\"dt1 : \", srcs[\"dt1\"])\n",
    "print(\"RA  : \" + \", \".join(\"{:.2f}\".format(_ra) for _ra\n",
    "                           in np.rad2deg(srcs[\"ra\"])))\n",
    "print(\"DEC : \" + \", \".join(\"{:.2f}\".format(_dec) for _dec\n",
    "                           in np.rad2deg(srcs[\"dec\"])))\n",
    "print(\"wt  : \", srcs[\"w_theo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create the GRBLLH object with all the PDF settings\n",
    "sin_dec_bins = np.linspace(-1, 1, 50)\n",
    "\n",
    "min_logE = 0  \n",
    "max_logE = 10 \n",
    "logE_bins = np.linspace(min_logE, max_logE, 40)\n",
    "\n",
    "spatial_pdf_args = {\"bins\": sin_dec_bins, \"k\": 3, \"kent\": True}\n",
    "\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": 2.,\n",
    "                   \"fillval\": \"col\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": True,\n",
    "                   \"smooth_sigma\": [[0., 0.], [0., 0.]]}\n",
    "\n",
    "time_pdf_args = {\"nsig\": 4., \"sigma_t_min\": 2., \"sigma_t_max\": 30.}\n",
    "\n",
    "llh_args = {\"sob_rel_eps\": 0., \"sob_abs_eps\": 1e-4}\n",
    "\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)\n",
    "\n",
    "# print(grbllh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a bg rate injector model\n",
    "def filter_runs(run):\n",
    "    \"\"\"\n",
    "    Filter runs as stated in jfeintzig's doc.\n",
    "    \"\"\"\n",
    "    exclude_runs = [120028, 120029, 120030, 120087, 120156, 120157]\n",
    "    if ((run[\"good_i3\"] == True) & (run[\"good_it\"] == True) &\n",
    "        (run[\"run\"] not in exclude_runs)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Create an injector using a goodrun list, use a sinus rate function with\n",
    "# fixed period of 1yr\n",
    "runlist_dict = json.load(open(\"data/runlists/ic86-i-goodrunlist.json\", \"r\"))\n",
    "\n",
    "# Choose your rate function\n",
    "RFUNC = \"SINCONST\"  # \"SIN1YR\", \"CONST\", \"SIN\", \"SINCONST\"\n",
    "print(\"Choosing '{}' function\".format(RFUNC))\n",
    "\n",
    "if RFUNC == \"SIN\" or RFUNC == \"SIN1YR\":\n",
    "    # Give fixed srs, to use caching\n",
    "    t = srcs[\"t\"]\n",
    "    trange = grbllh.time_pdf_def_range(src_t=srcs[\"t\"], dt=dt)\n",
    "    if RFUNC == \"SIN\":\n",
    "        rate_func_obj = RateFunc.SinusRateFunction(t, trange, rndgen)\n",
    "    else:\n",
    "        rate_func_obj = RateFunc.Sinus1yrRateFunction(t, trange, rndgen)\n",
    "elif RFUNC == \"CONST\":\n",
    "    rate_func_obj = RateFunc.ConstantRateFunction(rndgen)\n",
    "elif RFUNC == \"SINCONST\":\n",
    "    rate_func_obj = RateFunc.Sinus1yrConstRateFunction(rndgen)\n",
    "\n",
    "bg_rate_inj = BGRateInj.RunlistBGRateInjector(rate_func_obj, runlist_dict,\n",
    "                                              filter_runs, rndgen)\n",
    "\n",
    "# Fit the injector to make it usable\n",
    "times = _exp[\"timeMJD\"]\n",
    "rate_func = bg_rate_inj.fit(T=times, x0=None, remove_zero_runs=True)\n",
    "\n",
    "if (RFUNC == \"SIN\") or (RFUNC == \"SIN1YR\"):\n",
    "    print(\"RateFunction uses cached fmax vals:\\n  - \", rate_func_obj._fmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Choose your bg injector\n",
    "BGINJ = \"KDE\"  # \"KDE\", \"MR\", \"DATA\", \"UNI\"\n",
    "print(\"Choosing '{}' injector\".format(BGINJ))\n",
    "\n",
    "if BGINJ == \"DATA\":\n",
    "    bg_inj = BGInj.DataBGInjector(rndgen)\n",
    "    bg_inj.fit(_exp)\n",
    "    \n",
    "elif BGINJ == \"KDE\":\n",
    "    # We use precahced KDE values, because the model is fixed\n",
    "    # Note: The original order cannot be changed now [logE, dec, sigma]\n",
    "    kde_model = json2kde(\"data/awKDE_CV/CV10_glob_bw_alpha_EXP_IC86I_\" +\n",
    "                       \"CUT_sig.ll.20_PARS_diag_True_pass2.json\")\n",
    "    bg_inj = BGInj.KDEBGInjector(rndgen)\n",
    "    bg_inj._kde_model = kde_model\n",
    "    # We could still change the alpha, but the global bandwidth must stay fixed\n",
    "    # bg_inj.kde_model.alpha = 0.3\n",
    "    bounds = np.array([[None, None], [-np.pi / 2. , np.pi / 2.], [0, None]])\n",
    "    bg_inj.fit(None, bounds)\n",
    "\n",
    "elif BGINJ == \"UNI\":\n",
    "    bg_inj = BGInj.UniformBGInjector(rndgen)\n",
    "    \n",
    "elif BGINJ == \"MR\":\n",
    "    bg_inj = BGInj.MRichmanBGInjector(rndgen)\n",
    "    bg_inj.fit(_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# And now the analysis object\n",
    "ana = Analysis.TransientsAnalysis(srcs=srcs, llh=grbllh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### BG only Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Using all the modules from above we can run trials with pure background now.\n",
    "\n",
    "A trial is a single pseudo experiment we perform and evaluate to get an idea of the underlying statistical distribtuion and to build our test statistic from which we can infer the significance of real data later.\n",
    "For that we need to generate sets of pseudo-data which has background-like properties.\n",
    "The `bg_injector`, `bg_rate_injector` and `rate_function` classes are used to generate these properties.\n",
    "\n",
    "So each trial consist of the following steps, in which the source positions are always fixed and a-priori known:\n",
    "\n",
    "1. Determine the expected number background events per source time window we test.\n",
    "   This is derived from the `bg_rate_injector` which returns a list of sampled times for each time window.\n",
    "   It knows the expected rate from the given `rate_function`\n",
    "2. In addition to our sampled times, we need all the other event features we have on real data (positions, energy, uncertainty) , because our sampled pseudo-data should have the same properties as real data.\n",
    "   These missing properties are generated by the `bg_injector` class.\n",
    "3. When we sampled our pseudo-events we need to fit the LLH to this set of events and see what best fit we get.\n",
    "4. We do that a lot of times and see how our best fits are distributed which gives us a so called test statistic which describes the distribution of LLH firs using BG only.\n",
    "\n",
    "On background-like events we expect to get a null fit result most of the times, because no signal is present.\n",
    "But out of chance, we sometimes get a combination of background-like events, that has very signal-like properties.\n",
    "\n",
    "The so build test statistic is then used to see how unlikely the single fit to our on-time data was and how lucky we'd have to get to observe that result out of chance from pure background.\n",
    "\n",
    "Note on the ns distribution:\n",
    "As we sample the number of events per trial from a poisson distribution, we see the fitted ns peaked at integer numbers.\n",
    "The main peak is of course at 0 because most of our events are not even close to the sources.\n",
    "The second peak is the next likely number of events, 1 and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ns0 = 0.5  # The closer to small number of evts, the faster\n",
    "minopts = {\"bounds\": [[0, None],]}\n",
    "n_bg_trials = int(1e5)\n",
    "\n",
    "res, nzeros = ana.do_trials(n_bg_trials, ns0, bg_inj=bg_inj,\n",
    "                            bg_rate_inj=bg_rate_inj, signal_inj=None,\n",
    "                            minimizer_opts=minopts, verb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = \"TS\"\n",
    "bins = np.arange(0, 20, 0.5)\n",
    "ax = plot_trials(res[name], ntrials=n_bg_trials, bins=bins, CHI2=True, GEN=False)\n",
    "ax.set_xlabel(name)\n",
    "\n",
    "ax.axvline(_percentile_nzeros(res[name], n_bg_trials, sigma2prob(3) * 100),\n",
    "           0, 1, ls=\"--\", color=\"k\", alpha=.5, label=r\"$3\\sigma$\")\n",
    "ax.axvline(_percentile_nzeros(res[name], n_bg_trials, sigma2prob(4) * 100),\n",
    "           0, 1, ls=\"--\", color=\"k\", alpha=.7, label=r\"$4\\sigma$\")\n",
    "ax.axvline(_percentile_nzeros(res[name], n_bg_trials, sigma2prob(5) * 100),\n",
    "           0, 1, ls=\"--\", color=\"k\", alpha=.9, label=r\"$5\\sigma$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Signal trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Setup signal injector.\n",
    "Use the same srcs as in the analysis setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Only set the src params we need here manually\n",
    "gamma = 2.\n",
    "mode = \"band\"\n",
    "inj_width = np.deg2rad(2.)\n",
    "\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=mode, inj_width=inj_width)\n",
    "sig_inj.fit(srcs, _mc, _exp.dtype.names)\n",
    "\n",
    "ngen = 2\n",
    "gen = sig_inj.sample(ngen, poisson=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Detune seed from injected number events\n",
    "ns0 = np.random.uniform(ngen - 1, ngen + 1, size=None)\n",
    "minopts = {\"bounds\": [[0, None],]}\n",
    "ntrials = int(1e4)\n",
    "\n",
    "res_sig, nzeros_sig = ana.do_trials(ntrials, ns0,\n",
    "                                    bg_inj=bg_inj, bg_rate_inj=bg_rate_inj,\n",
    "                                    signal_inj=gen,\n",
    "                                    minimizer_opts=minopts, verb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot TS and ns distribution\n",
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "name = \"TS\"\n",
    "axl = plot_trials(res[name], ntrials, bins, ax=axl, CHI2=False, GEN=False)\n",
    "\n",
    "axl.axvline(_percentile_nzeros(res[name], nzeros, sigma2prob(3) * 100),\n",
    "            0, 1, ls=\"--\", color=\"k\", alpha=.5, label=r\"$3\\sigma$\")\n",
    "axl.axvline(_percentile_nzeros(res[name], nzeros, sigma2prob(4) * 100),\n",
    "            0, 1, ls=\"--\", color=\"k\", alpha=.7, label=r\"$4\\sigma$\")\n",
    "axl.axvline(_percentile_nzeros(res[name], nzeros, sigma2prob(5) * 100),\n",
    "            0, 1, ls=\"--\", color=\"k\", alpha=.9, label=r\"$5\\sigma$\")\n",
    "\n",
    "axl.set_title(axl.get_title() + \" n_inj = {}\".format(ngen))\n",
    "axl.set_xlabel(name)\n",
    "axl.legend(loc=\"upper right\")\n",
    "\n",
    "name = \"ns\"\n",
    "axr = plot_trials(res[name], ntrials, np.linspace(0, np.amax(res[name]), 20),\n",
    "                  ax=axr, CHI2=False, GEN=False)\n",
    "axr.axvline(_percentile_nzeros(res[name], nzeros, 50), 0, 1, color=\"C1\",\n",
    "           ls=\"--\")\n",
    "axr.set_title(\"ntrials = {}, n_inj = {}\".format(ntrials, ngen))\n",
    "axr.set_xlabel(name)\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig(\"data/figs/SIGT_ntrials={}_ninj={}.png\".format(ntrials, ngen),\n",
    "#             dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Do BG + Signal in same plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bg_res = res\n",
    "bg_nzeros = nzeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Only set the src params we need here manually\n",
    "gamma = 2.\n",
    "mode = \"band\"\n",
    "inj_width = np.deg2rad(2.)\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=mode, inj_width=inj_width)\n",
    "sig_inj.fit(srcs, _mc, exp.dtype.names)\n",
    "\n",
    "minopts = {\"bounds\": [[0, None],]}\n",
    "n_sig_trials = int(1e4)\n",
    "\n",
    "sig_res = []\n",
    "sig_nzeros = []\n",
    "\n",
    "n_inj = [0.5, 1., 1.5]\n",
    "for n_inj_i in n_inj:\n",
    "    print(\"{} Trials with {} injected events.\".format(n_sig_trials, n_inj_i))\n",
    "    gen = sig_inj.sample(n_inj_i, poisson=True)\n",
    "    res_i, nzeros_i = ana.do_trials(n_sig_trials, n_inj_i + 1.,\n",
    "                                    bg_inj=bg_inj, bg_rate_inj=bg_rate_inj,\n",
    "                                    signal_inj=gen, verb=True,\n",
    "                                    minimizer_opts=minopts)\n",
    "    sig_res.append(res_i)\n",
    "    sig_nzeros.append(nzeros_i)\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(\"BG only      -> eta = {:.3%}\".format(1 - bg_nzeros / n_bg_trials))\n",
    "\n",
    "for n_inj_i, nzerosi in zip(n_inj, sig_nzeros):\n",
    "    print(\"n_inj = {:.2f} -> eta = {:.3%}\".format(n_inj_i, 1 - nzerosi /\n",
    "                                                   n_sig_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "colors = plt.cm.inferno(np.linspace(0.1, 0.9, len(sig_res)))\n",
    "bins = np.linspace(0, 70, 70)\n",
    "\n",
    "for resi, nzerosi, ci in zip(sig_res, sig_nzeros, colors):\n",
    "    _ = plot_trials(resi[\"TS\"], n_sig_trials, bins, ax=ax,\n",
    "                    CHI2=False, GEN=False, color=ci,\n",
    "                    histtype=\"step\")\n",
    "    ax.axvline(_percentile_nzeros(resi[\"TS\"], nzerosi, 50), 0, 1,\n",
    "               color=ci, ls=\"--\")\n",
    "    \n",
    "_ = plot_trials(bg_res[\"TS\"], n_bg_trials, bins, ax=ax,\n",
    "                CHI2=False, GEN=False, color=\"C7\",\n",
    "                histtype=\"step\")\n",
    "\n",
    "ax.set_title(\"\")\n",
    "\n",
    "fig.tight_layout()\n",
    "# plt.savefig(\"data/figs/SIGT_BGT_ninj=0.01_0.1_1.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prepare Data - On/Offtime Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we train to split data in on- and off-time part, like it would be done later in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrcs = 5\n",
    "\n",
    "# Make up some srcs\n",
    "dt = np.vstack((np.repeat([-20.], nsrcs), 100. * np.arange(1, nsrcs + 1))).T\n",
    "\n",
    "# Choose times equally spaced, but away from borders\n",
    "mint, maxt = np.amin(_exp[\"timeMJD\"]), np.amax(_exp[\"timeMJD\"])\n",
    "src_t = np.linspace(mint, maxt, nsrcs + 2)[1:-1].reshape(nsrcs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Seed set to we get some evts in the windows\n",
    "rndgen = np.random.RandomState(seed=5)\n",
    "mint, maxt = np.amin(_exp[\"timeMJD\"]), np.amax(_exp[\"timeMJD\"])\n",
    "exp_rnd = np.copy(_exp)\n",
    "exp_rnd[\"timeMJD\"] = rndgen.uniform(mint, maxt, len(_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get time windows in MJD and mask the data\n",
    "dt_MJD = src_t + dt / secinday\n",
    "evt_t = exp_rnd[\"timeMJD\"]\n",
    "\n",
    "# This assumes no time window overlap\n",
    "ontime_per_src = np.logical_and(evt_t >= dt_MJD[:, [0]],\n",
    "                                evt_t <= dt_MJD[:, [1]])\n",
    "ontime_tot = np.any(ontime_per_src, axis=0)\n",
    "\n",
    "nevts_per_src = np.sum(ontime_per_src, axis=1)\n",
    "nevts = np.sum(ontime_tot)\n",
    "\n",
    "print(\"Ontime events in each dt\\n\", nevts_per_src)\n",
    "print(\"Total Ontime events\\n\", nevts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This always plots all event times but places dt as the plot lims.\n",
    "# So we can double check the number of on time events.\n",
    "fig, ax = plt.subplots(nsrcs, 1)\n",
    "y = np.zeros_like(evt_t)\n",
    "for i, axi in enumerate(ax):\n",
    "    axi.plot(evt_t, y, color=\"C{}\".format(i), ls=\"\", marker=\"|\",\n",
    "             mew=2, ms=10, label=\"{} evts\".format(nevts_per_src[i]))\n",
    "    axi.set_xlim(dt_MJD[i])\n",
    "    axi.set_ylim(-1, 1)\n",
    "    axi.set_yticklabels([])\n",
    "    axi.set_xticklabels([])\n",
    "\n",
    "    # Steal space for legend. Stackoverflow: 4700614 :+1:\n",
    "    box = axi.get_position()\n",
    "    axi.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    axi.legend(loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "               title=\"window {}\".format(i))\n",
    "\n",
    "ax[-1].set_xlabel(\"Time MJD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cut events out and see they're gone from the ontime windows\n",
    "_exp_cut = exp_rnd[~ontime_tot]\n",
    "\n",
    "# Now all events should be gone\n",
    "fig, ax = plt.subplots(nsrcs, 1)\n",
    "y = np.zeros_like(_exp_cut[\"timeMJD\"])\n",
    "for i, axi in enumerate(ax):\n",
    "    axi.plot(_exp_cut[\"timeMJD\"], y, color=\"C{}\".format(i), ls=\"\", marker=\"|\",\n",
    "             mew=2, ms=10, label=\"had {} evts\".format(nevts_per_src[i]))\n",
    "    axi.set_xlim(dt_MJD[i])\n",
    "    axi.set_ylim(-1, 1)\n",
    "    axi.set_yticklabels([])\n",
    "    axi.set_xticklabels([])\n",
    "\n",
    "    # Steal space for legend. Stackoverflow: 4700614 :+1:\n",
    "    box = axi.get_position()\n",
    "    axi.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    axi.legend(loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "               title=\"window {}\".format(i))\n",
    "\n",
    "ax[-1].set_xlabel(\"Time MJD\")\n",
    "fig.suptitle(\"All gone\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Healpy Signal Injector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First make some srcs and priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "src_ras = np.deg2rad([20, 40, 165, 200, 280, 350, 355])\n",
    "src_decs = np.deg2rad([0, 80, 5, -15, -75, 20, -50])\n",
    "nsrcs = len(src_ras)\n",
    "src_t = np.ones_like(src_ras, dtype=float)\n",
    "src_dt0 = np.array(nsrcs * [-100.])\n",
    "src_dt1 = np.array(nsrcs * [1000.])\n",
    "\n",
    "assert nsrcs == len(src_decs) ==len(src_t) == len(src_dt0) == len(src_dt1)\n",
    "\n",
    "names = [\"t\", \"ra\", \"dec\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "dtype = [(n, float) for n in names]\n",
    "srcs = np.empty((nsrcs,), dtype=dtype)\n",
    "\n",
    "srcs[\"t\"] = src_t\n",
    "srcs[\"ra\"] = src_ras\n",
    "srcs[\"dec\"] = src_decs\n",
    "srcs[\"dt0\"] = src_dt0\n",
    "srcs[\"dt1\"] = src_dt1\n",
    "srcs[\"w_theo\"] = np.ones_like(src_t)\n",
    "\n",
    "# Create priors\n",
    "NSIDE = 512\n",
    "sigma = np.deg2rad(1.2)  # About the size of smoothed HESE priors\n",
    "prior_maps = []\n",
    "for src_i in srcs:\n",
    "    th, phi = DecRaToThetaPhi(src_i[\"dec\"], src_i[\"ra\"])\n",
    "    m, _ = gaussian_on_a_sphere(NSIDE=NSIDE, mean_phi=phi, mean_th=th,\n",
    "                                sigma=sigma, log=False, clip=False)\n",
    "    m = norm_healpy_map(m)\n",
    "    prior_maps.append(m)\n",
    "print(\"Done. Created {} prior maps and sources.\".format(len(prior_maps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "init_cell": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "GAMMA = 2.19\n",
    "sig_inj = SigInj.HealpySignalInjector(gamma=GAMMA, inj_sigma=3.,\n",
    "                                      inj_width=np.deg2rad(2))\n",
    "\n",
    "sig_inj.fit(srcs, prior_maps, MC=mc, exp_names=mc.dtype.names)\n",
    "print(\"Flux of 1 event: \", sig_inj.mu2flux(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### Helper Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_ev_from_idx(idx, data, names, key2enum, unique=False, concat=False):\n",
    "    \"\"\"\n",
    "    The idea is, that the data array only stores unique events per sample and\n",
    "    the index array can select events from that, maybe also multiple times.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    idx : recarray\n",
    "        Index array with names ``ev_idx, src_idx, enum``.\n",
    "    data : dict of recarrays\n",
    "        Dictionary with keys ``key2enum.keys()`` for each sample.\n",
    "    names : list\n",
    "        List of names to return from the ``data`` dict recarrays.\n",
    "    key2enum : dict\n",
    "        Mapping dict keys to ``idx`` enums. ``enum = key2enum[key]``.\n",
    "    unique : bool\n",
    "        If ``True`` returned data may include an event multiple times, if it was\n",
    "        selected for multiple sources. Otherwise only returns unique events, so\n",
    "        flattened arrays per sample.\n",
    "    concat : bool\n",
    "        If ``True`` also the sample dimension is flattened. If ``True`` and used\n",
    "        together with ``unqiue=False`` than the source information is also\n",
    "        discarded and all arrays per ``name`` are concatenated.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    out : dict of dict of arrays\n",
    "        For each ``key`` a dict with the sample key is created under which the\n",
    "        corresponding event data arrays hang for each source. If unique is\n",
    "        ``True`` this last axis is flattened and only the uniquely selected\n",
    "        events per sample are included:\n",
    "        \n",
    "        - ``unique=False`` and ``concat=False``:\n",
    "        ``out = {\"nam1\": {\"sam1\": [[src1], , ...], \"sam2\": [...], ...}, ...}``\n",
    "\n",
    "        - ``unique=True`` and ``concat=False``:\n",
    "        ``out = {\"nam1\": {\"sam1\": unique_ev_sam1, \"sam2\": ..., ...}, ...}``\n",
    "            \n",
    "        - ``unique=False`` and ``concat=True``:\n",
    "        ``out = {\"nam1\": all_ev_all_sam, \"nam2\": all_ev_all_sam, ...}``\n",
    "        \n",
    "        - ``unique=True`` and ``concat=True``:\n",
    "        ``out = {\"nam1\": unique_ev_all_sam, \"nam2\": ..., ...}``\n",
    "    \"\"\"\n",
    "    if (not isinstance(data, dict) and len(list(key2enum.keys())) == 1 and\n",
    "            list(key2enum.keys())[0] == -1):\n",
    "        data = {-1: data}\n",
    "        \n",
    "    out = {name: {sam: [] for sam in key2enum.keys()} for name in names}\n",
    "    nsrcs = {sam: -1 for sam in key2enum.keys()}\n",
    "    # `enum` is the integer mapping to `key`\n",
    "    for key, enum in key2enum.items():\n",
    "        # Select events per sample\n",
    "        enum_m = (idx[\"enum\"] == enum)\n",
    "        enum_idx = idx[enum_m]  # This is in [0, len(data[key])] per sample\n",
    "        enum_data = np.copy(data[key])\n",
    "        if unique:\n",
    "            # Store only unique events, regardless if they were selected\n",
    "            # multiple times.\n",
    "            uni_ev_idx = np.unique(enum_idx[\"ev_idx\"])\n",
    "            for name in names:\n",
    "                out[name][key] = enum_data[uni_ev_idx][name]\n",
    "            nsrcs = None  # Not used and counted\n",
    "        else:\n",
    "            # Select events per source, as stored. One event could have been\n",
    "            # selected for multiple sources, so the index array can be longer\n",
    "            # than the data array, which should store only unique events.\n",
    "            nsrcs[key] = np.amax(enum_idx[\"src_idx\"]) + 1  # src_idx starts at 0\n",
    "            for j in range(nsrcs[key]):\n",
    "                src_m = (enum_idx[\"src_idx\"] == j)\n",
    "                ev_idx = enum_idx[src_m][\"ev_idx\"]\n",
    "                for name in names:\n",
    "                    out[name][key].append(enum_data[ev_idx][name])\n",
    "    if concat:\n",
    "        if unique:\n",
    "            # This should be the same as just using all events from all samples\n",
    "            # but deleting doubles\n",
    "            for name in names:\n",
    "                out[name] = np.concatenate([out[name][sam] for\n",
    "                                            sam in key2enum.keys()])\n",
    "        else:\n",
    "            # In principle same as above, but double events can occur if\n",
    "            # selected for multiple sources\n",
    "            for name in names:\n",
    "                ll = np.ravel(list(out[name].values()))  # (nkeys, nsrcs)\n",
    "                out[name] = np.concatenate(ll, axis=0)\n",
    "            # Previous behaviour:\n",
    "                # print(\"unique is False, but concat is True, so assume sources \" +\n",
    "                #       \"are the same across samples.\")\n",
    "                # nsrcs_max = np.amax(list(nsrcs.values()))\n",
    "                # prnt = True\n",
    "                # for name in names:\n",
    "                # Pad missing entries, where the event might not have been\n",
    "                # selected (low stat sampels) for sub lists\n",
    "                # for key, val in out[name].items():\n",
    "                #     if len(val) < nsrcs_max:\n",
    "                #         if prnt:\n",
    "                #             print(\"  Need to pad \" +\n",
    "                #                   \"{} empty slice(s) for '{}'.\".format(\n",
    "                #                       nsrcs_max - len(val), key))\n",
    "                #             prnt = False\n",
    "                #         for i in range(nsrcs_max - len(val)):\n",
    "                #             out[name][key].append(np.empty(0, dtype=float))\n",
    "                # Now concatenate src arrays. Array of list of arrays:\n",
    "                # ll = np.array(list(out[name].values()))  # (nkeys, nsrcs)\n",
    "                # assert np.all(map(len, ll) == nsrcs_max)\n",
    "                # We want to concatenate along nkeys, so per source is conserved\n",
    "                # out[name] = np.concatenate(ll, axis=0)\n",
    "                \n",
    "    return out, nsrcs\n",
    "\n",
    "\n",
    "def pdf_from_cumsum_cdf(CDF):\n",
    "    \"\"\"\n",
    "    Get the PDF from a CDF array created by ``np.cumsum`` by differentiating it.\n",
    "    \"\"\"\n",
    "    return np.diff(np.r_[0., CDF])\n",
    "\n",
    "\n",
    "def cos_dist(src_ra, src_dec, ev_ra, ev_dec):\n",
    "    \"\"\"\n",
    "    Cosine of angular distance in equatorial coordinate convention.\n",
    "    \"\"\"\n",
    "    cos_dist = (np.cos(src_ra - ev_ra) *\n",
    "                np.cos(src_dec) * np.cos(ev_dec) +\n",
    "                np.sin(src_dec) * np.sin(ev_dec))\n",
    "\n",
    "    return np.clip(cos_dist, -1., 1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Plot sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Overview of injected sources and created priors\n",
    "priors = np.sum(prior_maps, axis=0)\n",
    "hp.mollview(priors)\n",
    "hp.graticule(verbose=False)\n",
    "hp.projplot(np.pi / 2. - srcs[\"dec\"], srcs[\"ra\"], \"wo\", mfc=\"none\", ms=10)\n",
    "plt.show()\n",
    "\n",
    "fig, ax, img = cartzoom(priors)\n",
    "ax.plot(srcs[\"ra\"], srcs[\"dec\"], \"wo\", mfc=\"none\", ms=10)\n",
    "make_astro_xaxis(ax, time_xax=False)\n",
    "ax.grid(alpha=.5, color=\"w\")\n",
    "plt.show()\n",
    "\n",
    "assert np.isclose(np.sum(priors) * hp.nside2pixarea(NSIDE), len(prior_maps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Check injection bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Overview of the created bands and priors\n",
    "min_dec = sig_inj._min_dec[-1]\n",
    "max_dec = sig_inj._max_dec[-1]\n",
    "fig, ax, img = cartzoom(np.sum(prior_maps, axis=0), cmap=ps_cmap)\n",
    "for i, src_i in enumerate(sig_inj._srcs[-1]):\n",
    "    ax.plot(src_i[\"ra\"], src_i[\"dec\"], marker=\"+\", c=\"C{}\".format(i))\n",
    "    ax.axhline(min_dec[i], c=\"C{}\".format(i), alpha=.5)\n",
    "    ax.axhline(max_dec[i], c=\"C{}\".format(i), alpha=.5)\n",
    "    ax.axhspan(min_dec[i], max_dec[i], color=\"C{}\".format(i), alpha=.2)\n",
    "\n",
    "ax.set_xlim(0, 2. * np.pi)\n",
    "ax.set_ylim(-np.pi / 2., np.pi / 2.)\n",
    "make_astro_xaxis(ax)\n",
    "# plt.savefig(\"./data/figs/prior_injector_prior_bands_all.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Zoom close to sources, only showing the n sigma band\n",
    "zoom = np.deg2rad(4)\n",
    "for i, p in enumerate(sig_inj._src_map_CDFs[-1]):\n",
    "    p = pdf_from_cumsum_cdf(p)\n",
    "    min_dec, max_dec = sig_inj.get_nsigma_dec_band(p, sig_inj._inj_sigma)\n",
    "    _ra, _dec = sig_inj._srcs[-1][\"ra\"][i], sig_inj._srcs[-1][\"dec\"][i]\n",
    "    ra_rng = [_ra - zoom / np.cos(_dec), _ra + zoom / np.cos(_dec)]\n",
    "    dec_rng = [_dec - zoom, _dec + zoom]\n",
    "    fig, ax, img = cartzoom(p, ra_rng=ra_rng, dec_rng=dec_rng)\n",
    "    \n",
    "    xx, yy, zz = reconstruct_cartzoom_data(img, smooth=5.)\n",
    "    levels = np.amax(p) * scs.chi2.sf([1, 4, 9], df=2)[::-1]\n",
    "    ax.contour(xx, yy, zz, levels, colors=\"w\", linestyles=[\"--\", \"-.\", \"-\"])\n",
    "    \n",
    "    ax.plot(_ra, _dec, marker=\"o\", c=\"k\")\n",
    "    ax.axhline(min_dec, c=\"w\", alpha=.5)\n",
    "    ax.axhline(max_dec, c=\"w\", alpha=.5)\n",
    "    ax.axhspan(min_dec, max_dec, color=\"w\", alpha=.2)\n",
    "    make_astro_xaxis(ax)\n",
    "    # plt.savefig(\"./data/figs/prior_injector_prior_bands_{:d}.png\".format(i),\n",
    "    #             dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Compare flux and selection to normal injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Turn of minimum size, because it's effeective in sin(dec) and sigma in dec\n",
    "hp_sig_inj = SigInj.HealpySignalInjector(gamma=2.19, inj_sigma=3.,\n",
    "                                         inj_width=np.deg2rad(0.01))\n",
    "\n",
    "hp_sig_inj.fit(srcs, prior_maps, MC=mc, exp_names=mc.dtype.names)\n",
    "print(\"Flux of 1 event: \", hp_sig_inj.mu2flux(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Approximately compare to normal injector flux\n",
    "inj_w = np.amin(sig_inj._max_dec[-1] - sig_inj._min_dec[-1]) / 2.\n",
    "sig2_inj = SigInj.SignalInjector(gamma=2.19, inj_width=inj_w)\n",
    "\n",
    "sig2_inj.fit(srcs, MC=mc, exp_names=mc.dtype.names)\n",
    "print(\"Mean injection band from priors: \", np.rad2deg(inj_w))\n",
    "print(\"Flux of 1 event: \", sig2_inj.mu2flux(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Fill Events - Plot positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "skip = 50  # Just that it plots faster\n",
    "\n",
    "keys = [\"a\", \"b\"]\n",
    "sig_inj.fit({k: srcs for k in keys}, {k: prior_maps for k in keys},\n",
    "            {k: mc[::skip] for k in keys}, {k: exp.dtype.names for k in keys})\n",
    "\n",
    "# sig_inj.fit(srcs, prior_maps, mc[::skip], exp.dtype.names)\n",
    "\n",
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot each srcs in a different color\n",
    "cmap = plt.cm.get_cmap(\"viridis\", nsrcs + 2)\n",
    "colors = cmap.colors[1:-1]\n",
    "bins = np.linspace(-1., 1., 101)\n",
    "\n",
    "# Plot all MC: Selected parts must be equally filled\n",
    "weights = mc[\"ow\"] * mc[\"trueE\"]**(-sig_inj.gamma)\n",
    "# Uncomment for unweighted, to see how events we actually can inject\n",
    "# weights = np.ones_like(mc[\"ow\"])\n",
    "h, b, _ = axl.hist(np.sin(mc[::skip][\"trueDec\"]), bins=bins,\n",
    "                   weights=weights[::skip], alpha=0.2, color=\"C7\")\n",
    "\n",
    "for i in range(nsrcs):\n",
    "    # Get all events from all samples\n",
    "    for key, mc_i in sig_inj._MC.items():\n",
    "        enum = sig_inj._key2enum[key]\n",
    "        \n",
    "        src_dec = sig_inj._srcs[key][\"dec\"]\n",
    "        min_dec = sig_inj._min_dec[key]\n",
    "        max_dec = sig_inj._max_dec[key]\n",
    "        \n",
    "        _enum = sig_inj.mc_arr[sig_inj.mc_arr[\"enum\"] == enum]\n",
    "        _src_m = (_enum[\"src_idx\"] == i)\n",
    "        _ev_idx = _enum[\"ev_idx\"]\n",
    "\n",
    "        _mc_i = mc_i[_ev_idx][_src_m]\n",
    "        weights = _mc_i[\"ow\"] * _mc_i[\"trueE\"]**(-sig_inj.gamma)\n",
    "        # Uncomment for unweighted, to see how events we actually can inject\n",
    "        # weights = np.ones_like(_mc_i[\"ow\"])\n",
    "\n",
    "        axl.hist(np.sin(_mc_i[\"trueDec\"]), bins=bins, weights=weights,\n",
    "                 color=colors[i])\n",
    "        axr.scatter(_mc_i[\"trueRa\"], _mc_i[\"trueDec\"], c=colors[i])\n",
    "\n",
    "    axl.axvline(np.sin(src_dec[i]), 0, 1, color=\"k\", ls=\"--\")\n",
    "    axl.axvline(np.sin(min_dec[i]), 0, 1, color=\"k\")\n",
    "    axl.axvline(np.sin(max_dec[i]), 0, 1, color=\"k\")\n",
    "    axr.axhline(src_dec[i], 0, 1, color=\"k\", ls=\"--\")\n",
    "    axr.axhline(min_dec[i], 0, 1, color=\"k\")\n",
    "    axr.axhline(max_dec[i], 0, 1, color=\"k\")\n",
    "\n",
    "# Plot outline to show that nothing is hidden\n",
    "m = 0.5 * (b[:-1] + b[1:])\n",
    "axl.hist(m, bins=bins, weights=h, color=\"k\", histtype=\"step\", linewidth=2)\n",
    "    \n",
    "axl.set_xlim(-1., 1.)\n",
    "axr.set_xlim(0., 2. * np.pi)\n",
    "axr.set_ylim(-np.pi/2., np.pi/2.)\n",
    "\n",
    "axl.set_xlabel(\"sin dec\")\n",
    "axr.set_xlabel(\"right-ascension\")\n",
    "axr.set_ylabel(\"dec\")\n",
    "\n",
    "if np.all(weights == 1.):\n",
    "    axl.set_title(\"Unweighted\")\n",
    "    _t = \"_unweighted\"\n",
    "else:\n",
    "    axl.set_title(\"gamma = {:.2f}\".format(sig_inj._gamma))\n",
    "    _t = \"_weighted\"\n",
    "axr.set_title(\"Unweighted available events\")\n",
    "make_astro_xaxis(axr)\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"data/figs/prior_injector_ev_selection_bands\"+_t+\".png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Inject events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Show true, rotated and rotated measured positions for all sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Because the sampling weights include the flux, the injection follows the weighted MC sample, not the unweighted one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Select a single sample or a two sample example\n",
    "TYPE = \"SINGLE\"  # \"SINGLE\", \"DOUBLE\"\n",
    "if TYPE == \"SINGLE\":\n",
    "    sig_inj.fit(srcs, prior_maps, MC=mc, exp_names=mc.dtype.names)\n",
    "    _txt = \"_single\"\n",
    "elif TYPE == \"DOUBLE\":\n",
    "    keys = [\"a\", \"b\"]\n",
    "    sig_inj.fit({k: srcs for k in keys}, {k: prior_maps for k in keys},\n",
    "                {k: mc for k in keys}, {k: exp.dtype.names for k in keys})\n",
    "    _txt = \"_double\"\n",
    "else:\n",
    "    raise ValueError(\"Type can be signle or double\")\n",
    "print(\"Type is \", _txt)\n",
    "\n",
    "# Make an injector generator\n",
    "ngen = 10000\n",
    "gen = sig_inj.sample(ngen, poisson=False)\n",
    "\n",
    "# Generate sample\n",
    "ninj, inj, idx = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extract true direction for injected events per source from original MC\n",
    "evts_per_src = {}\n",
    "trueRa_per_src = {}\n",
    "trueDec_per_src = {}\n",
    "\n",
    "# If only a single array was given, returned events are bare recarray, not dicts\n",
    "if (len(list(sig_inj._key2enum.keys())) == 1 and\n",
    "        sig_inj._key2enum.keys()[0] == -1):\n",
    "    single = True\n",
    "else:\n",
    "    single = False\n",
    "    \n",
    "for key, enum in sig_inj._key2enum.items():\n",
    "    enum_id = idx[idx[\"enum\"] == enum]\n",
    "    enum_MC = sig_inj._MC[key]\n",
    "\n",
    "    evts_per_src[key] = []\n",
    "    trueRa_per_src[key] = []\n",
    "    trueDec_per_src[key] = []\n",
    "    for j in range(sig_inj._nsrcs[key]):\n",
    "        src_m = (enum_id[\"src_idx\"] == j)\n",
    "        ev_id = enum_id[src_m][\"ev_idx\"]\n",
    "        ev_MC = enum_MC[ev_id]\n",
    "        # Store injected events' MC information selected from the original MC\n",
    "        trueRa_per_src[key].append(ev_MC[\"trueRa\"])\n",
    "        trueDec_per_src[key].append(ev_MC[\"trueDec\"])\n",
    "        # Store injected events\n",
    "        if single:\n",
    "            evts_per_src[key].append(inj[src_m])\n",
    "        else:\n",
    "            evts_per_src[key].append(inj[key][src_m])\n",
    "    \n",
    "# See how for two identical sources and samples, the sampled number of events\n",
    "# are very similar repeated, as expected\n",
    "tot_nevts = 0\n",
    "for key in sig_inj._key2enum.keys():\n",
    "    print(\"\\n\", key)\n",
    "    true_nevts = list(map(len, trueRa_per_src[key]))\n",
    "    meas_nevts = list(map(len, evts_per_src[key]))\n",
    "    print(\"[true] Injected per src: \", true_nevts)\n",
    "    print(\"[meas] Injected per src: \", meas_nevts)\n",
    "    print(\"[true] Injected events : \", np.sum(true_nevts))\n",
    "    print(\"[meas] Injected events : \", np.sum(meas_nevts))\n",
    "    assert np.sum(true_nevts) == np.sum(meas_nevts)\n",
    "    tot_nevts += np.sum(true_nevts)\n",
    "    \n",
    "assert tot_nevts == ngen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "cmaps = [\"inferno\", \"viridis\", \"cool\", \"spring\"]\n",
    "\n",
    "for key, enum in sig_inj._key2enum.items():\n",
    "    _min_dec = sig_inj._min_dec[key]\n",
    "    _max_dec = sig_inj._max_dec[key]\n",
    "    src_ra = sig_inj._srcs[key][\"ra\"]\n",
    "    src_dec = sig_inj._srcs[key][\"dec\"]\n",
    "\n",
    "    nsrcs = sig_inj._nsrcs[key]\n",
    "    if enum < 0:\n",
    "        enum = -enum\n",
    "    cmap = plt.cm.get_cmap(cmaps[enum % len(cmaps)])\n",
    "    c = cmap(np.linspace(0, 1, nsrcs + 2)[1:-1])\n",
    "    for j in range(nsrcs):\n",
    "        trueRa = trueRa_per_src[key][j]\n",
    "        trueDec = trueDec_per_src[key][j]\n",
    "        _ev = evts_per_src[key][j]\n",
    "        n_sel = len(_ev)\n",
    "\n",
    "        # Rotate again to see if all truths are at the src positions\n",
    "        ra3, dec3 = rotator(trueRa, trueDec,\n",
    "                            np.repeat(src_ra[j], n_sel),\n",
    "                            np.repeat(src_dec[j], n_sel),\n",
    "                            trueRa, trueDec)\n",
    "\n",
    "        axl.scatter(_ev[\"ra\"], _ev[\"dec\"], marker=\".\", color=c[j], alpha=0.75)\n",
    "        axr.scatter(trueRa, trueDec, marker=\".\", color=c[j], alpha=0.75)\n",
    "\n",
    "        axl.scatter(ra3, dec3, marker=\".\", color=\"w\", edgecolor=\"k\", s=100)\n",
    "        axr.scatter(ra3, dec3, marker=\".\", color=\"w\", edgecolor=\"k\", s=100)\n",
    "\n",
    "\n",
    "        axl.axhline(src_dec[j], 0, 1, color=\"k\", alpha=0.5, ls=\"--\")\n",
    "        axl.axhline(_min_dec[j], 0, 1, color=\"k\", alpha=0.5)\n",
    "        axl.axhline(_max_dec[j], 0, 1, color=\"k\", alpha=0.5)\n",
    "        axr.axhline(src_dec[j], 0, 1, color=\"k\", alpha=0.5, ls=\"--\")\n",
    "        axr.axhline(_min_dec[j], 0, 1, color=\"k\", alpha=0.5)\n",
    "        axr.axhline(_max_dec[j], 0, 1, color=\"k\", alpha=0.5)\n",
    "    \n",
    "make_astro_xaxis(axl)\n",
    "make_astro_xaxis(axr)\n",
    "axl.set_title(\"Rotated measured and rotated true positions\")\n",
    "axr.set_title(\"Rotated true and original true positions\")\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"data/figs/prior_injector_sampled_and_rotated\"+_txt+\".png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Show distribution of all events and sampled ones, to see how large angular distances are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We expect to draw evenly from the total pool of sampling weighted MC events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Select a single sample or a two sample example\n",
    "TYPE = \"DOUBLE\"  # \"SINGLE\", \"DOUBLE\"\n",
    "if TYPE == \"SINGLE\":\n",
    "    sig_inj.fit(srcs, prior_maps, MC=mc, exp_names=mc.dtype.names)\n",
    "    _txt = \"_single\"\n",
    "elif TYPE == \"DOUBLE\":\n",
    "    keys = [\"a\", \"b\"]\n",
    "    sig_inj.fit({k: srcs for k in keys}, {k: prior_maps for k in keys},\n",
    "                {k: mc for k in keys}, {k: exp.dtype.names for k in keys})\n",
    "    _txt = \"_double\"\n",
    "else:\n",
    "    raise ValueError(\"Type can be signle or double\")\n",
    "print(\"Type is \", _txt)\n",
    "\n",
    "# Make an injector generator\n",
    "ngen = 10000\n",
    "gen = sig_inj.sample(ngen, poisson=False)\n",
    "\n",
    "# Generate sample\n",
    "ninj, inj, idx = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "# Pool of all MC events from all samples to select from\n",
    "names = [\"ra\", \"dec\", \"trueRa\", \"trueDec\"]\n",
    "pool, _ = get_ev_from_idx(sig_inj._mc_arr, sig_inj._MC, names,\n",
    "                          sig_inj._key2enum, unique=False, concat=True)\n",
    "\n",
    "# Use sampling weights here to show correct distribtion\n",
    "w = pdf_from_cumsum_cdf(sig_inj._sample_w_CDF)\n",
    "dist = cos_dist(pool[\"trueRa\"], pool[\"trueDec\"], pool[\"ra\"], pool[\"dec\"])\n",
    "assert len(w) == len(dist)\n",
    "_ = plt.hist(np.rad2deg(np.arccos(dist)), bins=180, range=[0., 180.], alpha=.75,\n",
    "             weights=w, log=True, normed=True, label=\"All selected\")\n",
    "\n",
    "# All currently injected events\n",
    "names = [\"ra\", \"dec\", \"trueRa\", \"trueDec\"]\n",
    "cur_inj, _ = get_ev_from_idx(idx, sig_inj._MC, names,\n",
    "                             sig_inj._key2enum, unique=False, concat=True)\n",
    "\n",
    "# No weights here, because we drew weighted from the pool\n",
    "dist = cos_dist(cur_inj[\"trueRa\"], cur_inj[\"trueDec\"],\n",
    "                cur_inj[\"ra\"], cur_inj[\"dec\"])\n",
    "_ = plt.hist(np.rad2deg(np.arccos(dist)), bins=180, range=[0., 180.],\n",
    "             normed=True, log=True, label=\"Injected\", alpha=.75, color=\"C7\")\n",
    "plt.title(\"Space angle distribution between true and measured direction.\" +\n",
    "          \" Currently injected: {} evts\". format(ngen))\n",
    "\n",
    "plt.xlabel(\"delta Psi in degree\")\n",
    "plt.ylabel(\"sum of sample weights per bin\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"data/figs/prior_injector_delta_psi_comp.png\".format(dpi=150))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Check expected vs injected evts per srs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We inject events and compare the fraction of events injected per source with the total src weight, which is detector acceptance (signal weighted) and intrinsic weight.\n",
    "If we sample in a narrow band around each src we expect the fraction of sampled events to match the total source weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Select a single sample or a two sample example\n",
    "TYPE = \"SINGLE\"  # \"SINGLE\", \"DOUBLE\"\n",
    "if TYPE == \"SINGLE\":\n",
    "    sig_inj.fit(srcs, prior_maps, MC=mc, exp_names=mc.dtype.names)\n",
    "    _txt = \"_single\"\n",
    "elif TYPE == \"DOUBLE\":\n",
    "    keys = [\"a\", \"b\"]\n",
    "    sig_inj.fit({k: srcs for k in keys}, {k: prior_maps for k in keys},\n",
    "                {k: mc for k in keys}, {k: exp.dtype.names for k in keys})\n",
    "    _txt = \"_double\"\n",
    "else:\n",
    "    raise ValueError(\"Type can be signle or double\")\n",
    "print(\"Type is \", _txt)\n",
    "\n",
    "# Make an injector generator\n",
    "ngen = 10000\n",
    "gen = sig_inj.sample(ngen, poisson=False)\n",
    "\n",
    "# Extract injected events per source\n",
    "ninj, inj, idx = next(gen)\n",
    "\n",
    "pool, _ = get_ev_from_idx(idx, sig_inj._MC, names=[\"trueDec\"], unique=False,\n",
    "                          key2enum=sig_inj._key2enum, concat=False)\n",
    "# Concat samples, but preserve src info per sample, len is sum nsrcs per sample\n",
    "trueDec_per_src = []\n",
    "for val in pool[\"trueDec\"].values():\n",
    "    trueDec_per_src += val\n",
    "    \n",
    "evts_per_src = list(map(len, trueDec_per_src))\n",
    "print(\"[true] Injected per src: \", evts_per_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make a LLH to get the src weights\n",
    "sin_dec_bins = np.linspace(-1, 1, 50)\n",
    "logE_bins = np.linspace(0, 10, 40)\n",
    "\n",
    "spatial_pdf_args = {\"bins\": sin_dec_bins, \"k\": 3, \"kent\": True}\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins], \"gamma\": GAMMA,\n",
    "                   \"fillval\": \"minmax\", \"interpol_log\": False,\n",
    "                   \"mc_bg_weights\": None, \"logE_asc\": True,\n",
    "                   \"smooth_sigma\": [[0., 0.], [0., 0.]]}\n",
    "time_pdf_args = {\"nsig\": 4., \"sigma_t_min\": 2., \"sigma_t_max\": 30.}\n",
    "llh_args = {\"sob_rel_eps\": 0., \"sob_abs_eps\": 1e-4}\n",
    "\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)\n",
    "\n",
    "w_theo = srcs[\"w_theo\"]\n",
    "norm_src_w = grbllh.src_weights(srcs[\"dec\"], src_w_theo=w_theo).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "sin_dec = np.linspace(-1., 1., 201)\n",
    "bins = np.linspace(-1., 1., 201)\n",
    "\n",
    "# Normed src weights, sum=1\n",
    "ax.plot(np.sin(srcs[\"dec\"]), norm_src_w, ls=\"\", marker=\"o\", color=\"#353132\",\n",
    "        label=\"norm. src_w = acc_w * theo_w\")\n",
    "\n",
    "# Spline must be pseudo weighted to match the single weights (PMF style)\n",
    "pseudo_norm = np.sum(np.exp(grbllh._spatial_signal_spl(np.sin(srcs[\"dec\"]))))\n",
    "y = np.exp(grbllh._spatial_signal_spl(sin_dec)) / pseudo_norm\n",
    "ax.plot(sin_dec, y, color=\"#353132\")\n",
    "\n",
    "# Make MC hist (origin of spline)\n",
    "weights = _mc[\"ow\"] * _mc[\"trueE\"]**(-sig_inj.gamma)\n",
    "h, b = np.histogram(np.sin(_mc[\"trueDec\"]), bins=bins, weights=weights,\n",
    "                    normed=True)\n",
    "m = 0.5 * (b[:-1] + b[1:])\n",
    "_ = ax.hist(m, bins=b, weights=h / pseudo_norm, alpha=0.2, color=\"C7\")\n",
    "\n",
    "# Make fraction of sampled events per band\n",
    "frac = evts_per_src / np.sum(evts_per_src)\n",
    "ax.plot(np.sin(srcs[\"dec\"]), frac, ls=\"\", marker=\"_\",\n",
    "        color=\"C1\", mew=2, ms=10, label=\"Fraction of inj. events\")\n",
    "ax.vlines(np.sin(srcs[\"dec\"]), np.zeros_like(frac), frac, zorder=5,\n",
    "           color=\"C1\", linestyle=\"-\", lw=3)\n",
    "\n",
    "ax.set_xlabel(\"sin_dec\")\n",
    "ax.set_ylabel(\"fraction of inj events\")\n",
    "ax.set_xlim(-1., 1.)\n",
    "# ax.semilogy()\n",
    "ax.legend()\n",
    "ax.set_title(\"{} injected events\".format(ngen))\n",
    "\n",
    "# plt.savefig(\"./data/figs/prior_injector_src_w_vs_inj_fraction.png\", dpi=150)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Check if source positions get sampled correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Select a single sample or a two sample example\n",
    "TYPE = \"SINGLE\"  # \"SINGLE\", \"DOUBLE\"\n",
    "if TYPE == \"SINGLE\":\n",
    "    sig_inj.fit(srcs, prior_maps, MC=mc, exp_names=mc.dtype.names)\n",
    "    _txt = \"_single\"\n",
    "elif TYPE == \"DOUBLE\":\n",
    "    keys = [\"a\", \"b\"]\n",
    "    sig_inj.fit({k: srcs for k in keys}, {k: prior_maps for k in keys},\n",
    "                {k: mc for k in keys}, {k: exp.dtype.names for k in keys})\n",
    "    _txt = \"_double\"\n",
    "else:\n",
    "    raise ValueError(\"Type can be signle or double\")\n",
    "print(\"Type is \", _txt)\n",
    "\n",
    "# Make an injector generator. Only need a few events because we are interested\n",
    "# in the source positions\n",
    "ngen = 10\n",
    "gen = sig_inj.sample(ngen, poisson=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loop over single injections and only record the source positions\n",
    "n_inj = 10000\n",
    "src_ra, src_dec = np.empty((2, n_inj, np.sum(sig_inj._nsrcs.values())),\n",
    "                           dtype=float)\n",
    "for i in range(n_inj):\n",
    "    ninj, inj, idx = next(gen)\n",
    "    src_ra[i], src_dec[i] = sig_inj._src_ra, sig_inj._src_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make a binned healpy map version from the injected positions\n",
    "inj_maps = []\n",
    "ths, phis = DecRaToThetaPhi(src_dec, src_ra)\n",
    "for i, (th, phi) in enumerate(zip(ths.T, phis.T)):\n",
    "    inj_maps.append(get_binned_healpy_map(NSIDE=NSIDE, phi=phi, theta=th))\n",
    "    inj_maps[i] = norm_healpy_map(inj_maps[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Overview of the created bands and priors\n",
    "min_dec = sig_inj._min_dec[-1]\n",
    "max_dec = sig_inj._max_dec[-1]\n",
    "fig, ax, img = cartzoom(np.sum(inj_maps, axis=0), cmap=ps_cmap)\n",
    "for i, src_i in enumerate(sig_inj._srcs[-1]):\n",
    "    ax.plot(src_i[\"ra\"], src_i[\"dec\"], marker=\"+\", c=\"C{}\".format(i))\n",
    "    ax.axhline(min_dec[i], c=\"C{}\".format(i), alpha=.5)\n",
    "    ax.axhline(max_dec[i], c=\"C{}\".format(i), alpha=.5)\n",
    "    ax.axhspan(min_dec[i], max_dec[i], color=\"C{}\".format(i), alpha=.2)\n",
    "\n",
    "ax.set_xlim(0, 2. * np.pi)\n",
    "ax.set_ylim(-np.pi / 2., np.pi / 2.)\n",
    "make_astro_xaxis(ax)\n",
    "plt.savefig(\"./data/figs/prior_injector_src_injected_srcs_all.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Zoom close to sources, only showing the original n sigma band\n",
    "for i, inj_map_i in enumerate(inj_maps):\n",
    "    fig, (axl, axr) = plt.subplots(1, 2, figsize=(12, 5), sharex=True)\n",
    "    min_dec, max_dec = sig_inj.get_nsigma_dec_band(inj_map_i,\n",
    "                                                   sig_inj._inj_sigma)\n",
    "    _ra, _dec = sig_inj._srcs[-1][\"ra\"][i], sig_inj._srcs[-1][\"dec\"][i]\n",
    "    _d_min_dec = 1.1 * (min_dec - _dec)\n",
    "    _d_max_dec = 1.1 * (max_dec - _dec)\n",
    "    _d_dec = (max_dec - min_dec) / 2.\n",
    "    ra_rng = [_ra + _d_dec / np.cos(_dec), _ra - _d_dec / np.cos(_dec)]\n",
    "    dec_rng = [max(_dec + _d_min_dec, -np.pi / 2.),\n",
    "               min(_dec + _d_max_dec, np.pi / 2.)]\n",
    "    fig, axl, img = cartzoom(inj_map_i, ra_rng=ra_rng, dec_rng=dec_rng, ax=axl)\n",
    "    \n",
    "    xx, yy, zz = reconstruct_cartzoom_data(img, smooth=5.)\n",
    "    levels = np.amax(inj_map_i) * scs.chi2.sf([1, 4, 9], df=2)[::-1]\n",
    "    axl.contour(xx, yy, zz, levels, colors=\"w\", linestyles=[\"--\", \"-.\", \"-\"])\n",
    "    \n",
    "    # Plot sampled positions (subset to stil see something)\n",
    "    axl.scatter(src_ra.T[i], src_dec.T[i], color=\"w\", marker=\".\", s=8,\n",
    "                alpha=0.1)\n",
    "    \n",
    "    axl.plot(_ra, _dec, marker=\"o\", c=\"k\")\n",
    "    axl.axhline(min_dec, c=\"w\", alpha=.5)\n",
    "    axl.axhline(max_dec, c=\"w\", alpha=.5)\n",
    "    axl.axhspan(min_dec, max_dec, color=\"w\", alpha=.2)\n",
    "    make_astro_xaxis(axl)\n",
    "    \n",
    "    # Prior map sampled from in the right panel with same zoom to compare\n",
    "    fig, axr, img = cartzoom(prior_maps[i], ra_rng=ra_rng,\n",
    "                            dec_rng=dec_rng, ax=axr)\n",
    "    \n",
    "    xx, yy, zz = reconstruct_cartzoom_data(img, smooth=5.)\n",
    "    levels = np.amax(prior_maps[i]) * scs.chi2.sf([1, 4, 9], df=2)[::-1]\n",
    "    axr.contour(xx, yy, zz, levels, colors=\"w\", linestyles=[\"--\", \"-.\", \"-\"])\n",
    "    \n",
    "    axr.plot(_ra, _dec, marker=\"o\", c=\"k\")\n",
    "    axr.axhline(min_dec, c=\"w\", alpha=.5)\n",
    "    axr.axhline(max_dec, c=\"w\", alpha=.5)\n",
    "    axr.axhspan(min_dec, max_dec, color=\"w\", alpha=.2)\n",
    "    make_astro_xaxis(axr)\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.savefig(\"./data/figs/prior_injector_injected_srcs_zoom_\" +\n",
    "                \"{:d}_NSIDE{:d}.png\".format(i, NSIDE), dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###  Check if events are injected around current src positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Select a single sample or a two sample example\n",
    "TYPE = \"SINGLE\"  # \"SINGLE\", \"DOUBLE\"\n",
    "if TYPE == \"SINGLE\":\n",
    "    sig_inj.fit(srcs, prior_maps, MC=mc, exp_names=exp.dtype.names)\n",
    "    _txt = \"_single\"\n",
    "elif TYPE == \"DOUBLE\":\n",
    "    keys = [\"a\", \"b\"]\n",
    "    sig_inj.fit({k: srcs for k in keys}, {k: prior_maps for k in keys},\n",
    "                {k: mc for k in keys}, {k: exp.dtype.names for k in keys})\n",
    "    _txt = \"_double\"\n",
    "else:\n",
    "    raise ValueError(\"Type can be signle or double\")\n",
    "print(\"Type is \", _txt)\n",
    "\n",
    "# Make an injector generator. Only need a few events because we are interested\n",
    "# in the source positions\n",
    "ngen = 1000\n",
    "gen = sig_inj.sample(ngen, poisson=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loop over single injections and only record the source positions\n",
    "n_inj = 5\n",
    "src_ra, src_dec = np.empty((2, n_inj, np.sum(sig_inj._nsrcs.values())),\n",
    "                           dtype=float)\n",
    "# Now also store the injected events to see if they are around the sources\n",
    "inj, idx = [], []\n",
    "for i in range(n_inj):\n",
    "    _, inj_i, idx_i = next(gen)\n",
    "    src_ra_i, src_dec_i = sig_inj._src_ra, sig_inj._src_dec\n",
    "    if isinstance(src_ra_i, dict):  # Concat all samples for multi sample inj\n",
    "        src_ra[i] = np.concatenate(list(src_ra_i.values()))\n",
    "        src_dec[i] = np.concatenate(list(src_dec_i.values()))\n",
    "        inj.append(np.concatenate(list(inj_i.values())))\n",
    "    else:\n",
    "        src_ra[i] = src_ra_i\n",
    "        src_dec[i] = src_dec_i\n",
    "        inj.append(inj_i)\n",
    "\n",
    "    idx.append(idx_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "zoom = np.deg2rad(5.)\n",
    "for j, (src_ra_j, src_dec_j) in enumerate(zip(src_ra.T, src_dec.T)):\n",
    "    # Original best fit source position\n",
    "    _ra, _dec = srcs[\"ra\"][j], srcs[\"dec\"][j]\n",
    "    ra_rng = [_ra - zoom / np.cos(_dec), _ra + zoom / np.cos(_dec)]\n",
    "    dec_rng = [_dec -zoom, _dec + zoom]\n",
    "    # Prior map\n",
    "    fig, ax, img = cartzoom(prior_maps[j], ra_rng=ra_rng, dec_rng=dec_rng,\n",
    "                            cmap=gray_c, alpha=0.25)\n",
    "    xx, yy, zz = reconstruct_cartzoom_data(img, smooth=5.)\n",
    "    levels = np.amax(prior_maps[j]) * scs.chi2.sf([1, 4, 9], df=2)[::-1]\n",
    "    ax.contour(xx, yy, zz, levels, colors=\"k\", linestyles=[\"--\", \"-.\", \"-\"])\n",
    "    \n",
    "    # Drawn sources in different colors\n",
    "    for i in range(n_inj):\n",
    "        # Add in drawn events to see if they scatter around the sources\n",
    "        src_m = (idx[i][\"src_idx\"] == j)\n",
    "        ax.scatter(inj[i][src_m][\"ra\"], inj[i][src_m][\"dec\"], marker=\".\",\n",
    "                   color=\"C{}\".format(i))\n",
    "        # Drawn source position the evtns should scatter around\n",
    "        plt.plot(src_ra_j[i], src_dec_j[i], ls=\"\", marker=\"*\", ms=12,\n",
    "                 mfc=\"C{}\".format(i), mec=\"w\", mew=1)\n",
    "        \n",
    "    # Original source position\n",
    "    ax.plot(_ra, _dec, ls=\"\", marker=\"*\", ms=15, mfc=\"w\".format(i),\n",
    "            mec=\"k\", mew=2,)\n",
    "        \n",
    "    make_astro_xaxis(ax)\n",
    "    plt.savefig(\"./data/figs/prior_injector_inj_evets_and_srcs_\" +\n",
    "                \"{}.png\".format(j), dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Optimized version of random.choice without checking the weights every time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In signal_injector all sampling CDFs are precomputed on calling `fit` and are fixed when the sample generator is created.\n",
    "So we don't need to make `np.random.choice` check the input sanity each time we sample.\n",
    "For large maps this can get significantly slower.\n",
    "So we steal the actual sampling part without replacement from the numpy code and use it directly on prechecked arguments.\n",
    "It's only looking up a uniform number in the CDF with searchsorted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This can be pre-computed from the priors as they are fixed\n",
    "PDF = prior_maps[0]\n",
    "# Normalize CDF to 1 for sampling weights\n",
    "CDF = np.cumsum(PDF)\n",
    "CDF = CDF / CDF[-1]\n",
    "\n",
    "# We can check that this is the same as normalizing the PDFs\n",
    "PDF = PDF / np.sum(PDF)\n",
    "CDF2 = np.cumsum(PDF)\n",
    "\n",
    "assert np.allclose(CDF, CDF2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "u = np.random.uniform(size=None)\n",
    "# Select the correct position in the CDF to get the index for the drawn weight\n",
    "idx = np.searchsorted(CDF, u, side='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Check return value, int or array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "u = np.random.uniform(size=None)\n",
    "idx = np.searchsorted(CDF, u, side='right')\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Compare against `choice`, which does a lot of checks on p every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "idxs = np.arange(len(PDF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "idx = np.random.choice(idxs, size=None, p=PDF, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D time vs declination PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndgen = np.random.RandomState(7353)\n",
    "make_rundict = BGRateInj.RunlistBGRateInjector.create_goodrun_dict\n",
    "\n",
    "# Make sources\n",
    "nsrcs = 5\n",
    "src_t = rndgen.choice(exp[\"timeMJD\"], size=nsrcs)\n",
    "src_dt0 = nsrcs * [-100.]\n",
    "src_dt1 = nsrcs * [+200.]\n",
    "src_ra = rndgen.uniform(0, 2. * np.pi, size=nsrcs)\n",
    "src_dec = np.arccos(rndgen.uniform(-1., 1., size=nsrcs))\n",
    "\n",
    "names = [\"t\", \"ra\", \"dec\", \"dt0\", \"dt1\"]\n",
    "srcs = np.rec.fromarrays([src_t, src_ra, src_dec, src_dt0, src_dt1],\n",
    "                         dtype=[(n, float) for n in names])\n",
    "\n",
    "# For runlist processing, filter runs as stated on 86I wiki page\n",
    "def filter_runs(run):\n",
    "    \"\"\"\n",
    "    Filter runs as stated in jfeintzig's doc.\n",
    "    \"\"\"\n",
    "    exclude_runs = [120028, 120029, 120030, 120087, 120156, 120157]\n",
    "    if ((run[\"good_i3\"] == True) & (run[\"good_it\"] == True) &\n",
    "        (run[\"run\"] not in exclude_runs)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "runlist = \"data/runlists/ic86-i-goodrunlist.json\"\n",
    "with open(runlist, \"r\") as f:\n",
    "    runlist_dict = json.load(f)\n",
    "    \n",
    "# Make the rate function and the rate injector object\n",
    "# rate_func = RateFunc.SinusRateFunction(random_state=rndgen)\n",
    "# rate_func = RateFunc.ConstantRateFunction(random_state=rndgen)\n",
    "p_fix = 365.\n",
    "t0_fix = np.amin(exp[\"timeMJD\"])\n",
    "rate_func = RateFunc.SinusFixedRateFunction(p_fix=p_fix, t0_fix=t0_fix,\n",
    "                                            random_state=rndgen)\n",
    "# rate_func = RateFunc.SinusRateFunction(random_state=rndgen)\n",
    "\n",
    "rate_inj = BGRateInj.RunlistBGRateInjector(srcs=srcs, rate_func=rate_func,\n",
    "                                           runlist=runlist_dict,\n",
    "                                           random_state=rndgen,\n",
    "                                           filter_runs=filter_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make a dec binning and fit for every bin, then try to interpolate between function parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     74,
     95
    ]
   },
   "outputs": [],
   "source": [
    "def rebin_rate_rec(rate_rec, bins, ignore_zero_runs=True):\n",
    "    \"\"\"\n",
    "    Rebin rate per run information. The binning is right exclusice on the start\n",
    "    time of an run:\n",
    "      ``bins[i] <= rate_rec[\"start_mjd\"] < bins[i+1]``.\n",
    "    Therefore the bin borders are not 100% exact, but the included rates are.\n",
    "    New bin borders adjustet to start at the first included run are returned, to\n",
    "    miniimize the error, but we still shouldn't calculate the event numbers by\n",
    "    multiplying bin widths with rates.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rate_rec : record-array\n",
    "        Rate information as coming out of RunlistBGRateInjector._rate_rec.\n",
    "        Needs names ``'start_mjd', 'stop_mjd', 'rate'``.\n",
    "    bins : array-like or int\n",
    "        New time binning used to rebin the rates.\n",
    "    ignore_zero_runs : bool, optional\n",
    "        If ``True`` runs with zero events are ignored. This method of BG\n",
    "        estimation doesn't work well, if we have many zero events runs because\n",
    "        the baseline gets biased towards zero. If this is an effect of the\n",
    "        events selection then a different method should be used. (Default: True)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    rates : array-like\n",
    "        Rebinned rates per bin.\n",
    "    bins : array-like\n",
    "        Adjusted bins so that the left borders always start at the first\n",
    "        included run and the last right bin at the end of the last included run.\n",
    "    rate_std : array-like\n",
    "        Poisson ``sqrt(N)`` standard error of the rates per bin.\n",
    "    deadtime : array-like\n",
    "        How much livetime is 'dead' in the given binning, because runs do not\n",
    "        start immideiately one after another or there are bad runs that got\n",
    "        filtered out. Subtracting the missing livetime from the bin width\n",
    "        enables us to use the resulting time to recreate the event numbers.\n",
    "\n",
    "    \"\"\"\n",
    "    rates = rate_rec[\"rate\"]\n",
    "    start = rate_rec[\"start_mjd\"]\n",
    "    stop = rate_rec[\"stop_mjd\"]\n",
    "\n",
    "    bins = np.atleast_1d(bins)\n",
    "    if len(bins) == 1:\n",
    "        # Use min max and equidistant binning if only a number is given\n",
    "        bins = np.linspace(np.amin(start), np.amax(stop), int(bins[0]) + 1)\n",
    "        \n",
    "    new_bins = np.empty_like(bins)\n",
    "    rate = np.empty(len(bins) - 1, dtype=float)\n",
    "    rate_std = np.empty(len(bins) - 1, dtype=float)\n",
    "    livetime_per_bin = np.empty_like(rate)\n",
    "    \n",
    "    assert np.allclose(rate_rec[\"nevts\"],\n",
    "                       rate_rec[\"rate\"] * (stop - start) * secinday)\n",
    "    \n",
    "    for i, (lo, hi) in enumerate(zip(bins[:-1], bins[1:])):\n",
    "        mask = (lo <= start) & (start < hi)\n",
    "        if ignore_zero_runs:\n",
    "            mask = mask & (rates > 0)\n",
    "        livetime_per_bin[i] = np.sum(stop[mask] - start[mask])\n",
    "        # New mean rate: sum(all events in runs) / sum(real livetimes in runs)\n",
    "        nevts = np.sum(rates[mask] * (stop[mask] - start[mask]))\n",
    "        rate[i] = nevts / livetime_per_bin[i]\n",
    "        rate_std[i] = np.sqrt(nevts * secinday) / livetime_per_bin[i] / secinday\n",
    "        # rate[i] = np.average(rate_rec[mask][\"rate\"],\n",
    "        #                      weights=rate_rec[mask][\"rate_std\"])\n",
    "        # Adapt bin edges\n",
    "        new_bins[i] = np.amin(start[mask])\n",
    "    new_bins[-1] = np.amax(stop[mask])\n",
    "    \n",
    "    deadtime = np.diff(new_bins) - livetime_per_bin  \n",
    "    return rate, np.atleast_1d(new_bins), rate_std, deadtime\n",
    "\n",
    "def make_spl_edges(vals, bins):\n",
    "    \"\"\"\n",
    "    Make nicely behaved edge conditions for a spline fit.\n",
    "    \"\"\"\n",
    "    vals = np.atleast_1d(vals)\n",
    "    bins = np.atleast_1d(bins)\n",
    "\n",
    "    # Model outermost bin edges to avoid uncontrolled behaviour at the edges\n",
    "    if len(vals) > 2:\n",
    "        # Subtract mean of 1st and 2nd bins from 1st to use as height 0\n",
    "        val_l = (3. * vals[0] - vals[1]) / 2.\n",
    "        # The same for the right edge\n",
    "        val_r = (3. * vals[-1] - vals[-2]) / 2.\n",
    "    else:  # Just repeat if we have only 2 bins\n",
    "        val_l = vals[0]\n",
    "        val_r = vals[-1]\n",
    "\n",
    "    vals = np.concatenate(([val_l], vals, [val_r]))\n",
    "    pts = np.concatenate((bins[[0]], 0.5 * (bins[:-1] + bins[1:]), bins[[-1]]))\n",
    "    return vals, pts\n",
    "\n",
    "def _get_def_seed(rate_inj):\n",
    "    \"\"\"\n",
    "    Wrapper to get the seed values from a rate injector.\n",
    "    \"\"\"\n",
    "    _t = 0.5 * (rate_inj._rate_rec[\"start_mjd\"] +\n",
    "                rate_inj._rate_rec[\"stop_mjd\"])\n",
    "    _r = rate_inj._rate_rec[\"rate\"]\n",
    "\n",
    "    _w = np.zeros_like(_r)\n",
    "    mask = (_r > 0)\n",
    "    _w[mask] = 1. / _r[mask]\n",
    "\n",
    "    return rate_inj._rate_func._get_default_seed(rate=_r, t=_t, w=_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_bins = np.linspace(np.amin(exp[\"timeMJD\"]), np.amax(exp[\"timeMJD\"]), 12 + 1)\n",
    "_hor = np.deg2rad(20)\n",
    "sindec_bins = np.unique(np.concatenate([\n",
    "                        np.linspace(-1., 0., 5 + 1),  # south\n",
    "                        np.linspace(0., _hor, 2 + 1), # horizon\n",
    "                        np.linspace(_hor, 1., 3 + 1), # north\n",
    "                        ]))\n",
    "sindec_bins = np.linspace(-1, 1, 20 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allsky rate function\n",
    "# Plot all runs\n",
    "rate_inj.fit(exp[\"timeMJD\"], x0=None, w=None)\n",
    "_r = rate_inj._rate_rec\n",
    "plt.errorbar(_r[\"start_mjd\"], _r[\"rate\"], yerr=_r[\"rate_std\"], c=\"C7\", fmt=\",\",\n",
    "             alpha=.5, zorder=-5)\n",
    "# plt.plot(_r[\"start_mjd\"], _r[\"rate\"], marker=\".\", ls=\"\", c=\"C7\", alpha=0.5)\n",
    "\n",
    "# Fit all runs\n",
    "t = np.linspace(np.amin(_r[\"start_mjd\"]), np.amax(_r[\"stop_mjd\"]), 200)\n",
    "y = rate_inj._best_estimator(t=t)\n",
    "plt.plot(t, y, ls=\"--\", c=\"C1\")\n",
    "\n",
    "# Rebinned plot\n",
    "rates, new_bins, rates_std, _ = rebin_rate_rec(_r, bins=t_bins,\n",
    "                                               ignore_zero_runs=True)\n",
    "_t_mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "plt.plot(new_bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\",\n",
    "         lw=2.5)\n",
    "plt.errorbar(_t_mids, rates, fmt=\",\", color=\"k\", lw=2.5)\n",
    "\n",
    "# Rebinned fit\n",
    "# Make a rebinned rate function fit to compare\n",
    "brate_inj = BGRateInj.BinnedBGRateInjector(srcs=srcs, rate_func=rate_func,\n",
    "                                           random_state=rndgen)\n",
    "brate_inj.fit(_t_mids, rates, x0=None, w=1. / rates_std)\n",
    "y = brate_inj._best_estimator(t=t)\n",
    "plt.plot(t, y, c=\"C3\")\n",
    "\n",
    "print(\"Rate Inj Seed: \", _get_def_seed(rate_inj))\n",
    "print(\"Rate Inj BF  : \", rate_inj._best_pars)\n",
    "print(\"BRate Inj BF : \", brate_inj._best_pars)\n",
    "\n",
    "plt.title(\"Amplitude: {:.3f} in mHz\".format(rate_inj._best_pars[0] * 1e3))\n",
    "plt.ylim(0, None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a rate function for multiple declinations bins.\n",
    "Then construct a background sinDec PDF for a speficic time from all rate functions.\n",
    "This can be used to improve the sensitivity in the LLH model as it gets better SoB ratios for sources measured at times with lower background than on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Per declination bin\n",
    "_sindec = exp[\"sinDec\"]\n",
    "\n",
    "best_pars = []\n",
    "sindec_mids = []\n",
    "res = []\n",
    "stds = []\n",
    "\n",
    "for i, (lo, hi) in enumerate(zip(sindec_bins[:-1], sindec_bins[1:])[:]):\n",
    "    mask = (_sindec >= lo) & (_sindec < hi)\n",
    "    \n",
    "    rate_inj.fit(T=exp[mask][\"timeMJD\"], x0=None, w=None)    \n",
    "    _r = rate_inj._rate_rec\n",
    "    plt.plot(_r[\"start_mjd\"], _r[\"rate\"], marker=\".\", ms=4, ls=\"\", c=\"C0\",\n",
    "             label=r\"{:.2f}$<\\sin\\delta<${:.2f}\".format(lo, hi))\n",
    "    plt.errorbar(_r[\"start_mjd\"], _r[\"rate\"], yerr=_r[\"rate_std\"], fmt=\",\",\n",
    "                 c=\"C0\", alpha=.25)\n",
    "    \n",
    "    # Fit\n",
    "    t = np.linspace(np.amin(_r[\"start_mjd\"]), np.amax(_r[\"stop_mjd\"]), 200)\n",
    "    y = rate_inj._best_estimator(t=t)\n",
    "    plt.plot(t, y, c=\"C1\", lw=2.5)\n",
    "    \n",
    "    # Rebinned\n",
    "    rates, new_bins, rates_std, _ = rebin_rate_rec(_r, bins=t_bins,\n",
    "                                                   ignore_zero_runs=True)\n",
    "    _t_mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "    plt.plot(new_bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\",\n",
    "             lw=2.5)\n",
    "    plt.errorbar(_t_mids, rates, yerr=rates_std, fmt=\",\", color=\"k\", lw=2.5)\n",
    "    \n",
    "    # Rebinned fit ((f-y)/std) is unitless and should be the correct weights\n",
    "    # to get the parameter weights for the spline fit.\n",
    "    brate_inj.fit(_t_mids, rates, x0=None, w=1. / rates_std)\n",
    "    y = brate_inj._best_estimator(t=t)\n",
    "    plt.plot(t, y, c=\"C3\", lw=2.5)\n",
    "\n",
    "    _inj = brate_inj\n",
    "    sindec_mids.append(0.5 * (lo + hi))\n",
    "    res.append(_inj._rate_func._res)\n",
    "    stds.append(np.sqrt(np.diag(_inj._rate_func._res.hess_inv)))\n",
    "    best_pars.append(_inj._best_pars)\n",
    "\n",
    "    plt.title(\"Amplitude: {:.3f} in mHz\".format(brate_inj._best_pars[0] * 1e3))\n",
    "    plt.legend()\n",
    "    plt.ylim(0, None)\n",
    "    plt.show()\n",
    "    \n",
    "best_pars = np.array(best_pars).T\n",
    "sindec_mids = np.array(sindec_mids)\n",
    "stds = np.array(stds).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allsky again to check against\n",
    "# Allsky\n",
    "rate_inj.fit(T=exp[\"timeMJD\"], x0=None, w=None)\n",
    "_r = rate_inj._rate_rec\n",
    "rates, new_bins, rates_std, _ = rebin_rate_rec(_r, bins=t_bins,\n",
    "                                               ignore_zero_runs=True)\n",
    "_t_mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "brate_inj.fit(_t_mids, rates, x0=None, w=1. / rates_std)\n",
    "\n",
    "x = np.linspace(sindec_bins[0], sindec_bins[-1], 200)\n",
    "# names = [\"Amplitude\", \"Period\", \"t-offset\", \"Baseline\"]\n",
    "names = [\"Amplitude\", \"Baseline\"]\n",
    "splines = {}\n",
    "for i, (bp, n, std) in enumerate(zip(best_pars, names, stds)):\n",
    "    # Amplitude and baseline must be in units HZ/dec, so that the integral over\n",
    "    # Declination gives back the allsky values\n",
    "    norm = np.diff(sindec_bins)\n",
    "    _bp = bp / norm\n",
    "    _std = std / norm\n",
    "    _std = np.minimum(_std, np.sort(_std)[-2])\n",
    "    \n",
    "    vals, pts = make_spl_edges(_bp, sindec_bins)\n",
    "    \n",
    "    w = 1. / np.concatenate((_std[[0]], _std, _std[[-1]]))\n",
    "    spl = sci.UnivariateSpline(pts, vals, w=w, k=3, s=len(_bp),\n",
    "                               ext=\"extrapolate\")\n",
    "    \n",
    "    plt.errorbar(pts[1:-1], vals[1:-1], yerr=_std, c=\"C0\", marker=\"o\", ls=\":\")\n",
    "    plt.plot(pts[[0, -1]], vals[[0, -1]], c=\"C0\", marker=\"o\", mfc=\"w\", ls=\"\")\n",
    "\n",
    "    plt.axhline(0, c=\"C7\")\n",
    "    plt.axvline(0, c=\"C7\", ls=\"--\")\n",
    "    plt.axvline(sindec_bins[0], c=\"C7\")\n",
    "    plt.axvline(sindec_bins[-1], c=\"C7\")\n",
    "    \n",
    "    plt.xlabel(\"sinDec\")\n",
    "    plt.ylabel(n + \" / dec\")\n",
    "    plt.title(n)\n",
    "    \n",
    "    # Check norms and renormlaize to match allsky params\n",
    "    if n not in [\"Period\", \"t-offset\"]:\n",
    "        def spl_normed_factory(spl, best_pars):\n",
    "            spl_norm = scint.quad(spl, a=-1., b=1.)[0]\n",
    "            def spl_normed(x):\n",
    "                return best_pars / spl_norm * spl(x)\n",
    "            return spl_normed\n",
    "        splines[n] = spl_normed_factory(spl, brate_inj._best_pars[i])\n",
    "        print(n + \"\\n  Allsky: {:.6g}, Integrated: {:.6g}, Sum: {:.6g}\".format(\n",
    "            brate_inj._best_pars[i], scint.quad(spl, a=-1., b=1.)[0], np.sum(bp)))\n",
    "        print(\"  Renormed: {:.6g}\".format(scint.quad(splines[n], a=-1., b=1.)[0]))\n",
    "        plt.plot(x, splines[n](x), \"r-\")\n",
    "    plt.plot(x, spl(x), \"k:\")\n",
    "    \n",
    "    # plt.savefig(\"/Users/tmenne/Downloads/spline_\" + n + \".png\", dpi=150)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a specific time, evaluate the rate function with the parameters given by the splines.\n",
    "From the values build a declination PDF per source time.\n",
    "We should see a variation in the PDFs that is strongest in the declinations where the most fluctuations occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "sindecs = np.linspace(-1., 1., 100)\n",
    "source_ts = (np.amin(exp[\"timeMJD\"]) + np.linspace(0, 1, 5) *\n",
    "             (np.amax(exp[\"timeMJD\"]) - np.amin(exp[\"timeMJD\"])))[1:-1]\n",
    "\n",
    "rate_vals = np.empty((len(source_ts), len(sindecs)), dtype=float)\n",
    "\n",
    "for j, tj in enumerate(source_ts):\n",
    "        amp = splines[\"Amplitude\"](sindecs)\n",
    "        base = splines[\"Baseline\"](sindecs)\n",
    "        rate_vals[j] = brate_inj._rate_func.fun(t=tj, pars=(amp, base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.cm.jet(np.linspace(0.1, 0.9, len(source_ts)))\n",
    "for ci, rvi, ti in zip(colors, rate_vals, source_ts):\n",
    "    plt.plot(sindecs, rvi, c=ci, label=\"t = {:.2f}\".format(ti))\n",
    "    \n",
    "plt.xlabel(\"sindec\")\n",
    "plt.ylabel(\"BG rate in mHz / dec\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now normed to a sinDec PDF\n",
    "\n",
    "# First the allsky average (integral over sine is baseline, so we can simply\n",
    " # plot the spline)\n",
    "plt.hist(exp[\"sinDec\"], sindec_bins, normed=True, color=\"C7\", alpha=0.5)\n",
    "rvi = splines[\"Baseline\"](sindecs)\n",
    "norm = np.diff(sindecs)[0] * np.sum(rvi)\n",
    "plt.plot(sindecs, rvi / norm, c=\"C7\", lw=3, ls=\"-\", label=\"yr avrg.\")\n",
    "\n",
    "colors = plt.cm.jet(np.linspace(0.1, 0.9, len(source_ts)))\n",
    "for ci, rvi, ti in zip(colors, rate_vals, source_ts):\n",
    "    norm = np.diff(sindecs)[0] * np.sum(rvi)\n",
    "    plt.plot(sindecs, rvi / norm, c=ci, label=\"t = {:.2f}\".format(ti))\n",
    "    \n",
    "plt.xlabel(\"sindec\")\n",
    "plt.ylabel(\"BG PDF in sindec\")\n",
    "plt.legend(loc=\"lower center\")\n",
    "\n",
    "plt.ylim(0, 0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample weighted data events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ts = (np.amin(exp[\"timeMJD\"]) + np.linspace(0, 1, 5) *\n",
    "             (np.amax(exp[\"timeMJD\"]) - np.amin(exp[\"timeMJD\"])))[1:-1]\n",
    "\n",
    "# To build the sample weights we need to divide by the baseline spline, because\n",
    "# the data events already have a sindec distribtuion\n",
    "_sindec_exp = np.sort(exp[\"sinDec\"])\n",
    "\n",
    "# Baseline spline PDF values relative to the others\n",
    "baseline = splines[\"Baseline\"](_sindec_exp)\n",
    "norm = np.diff(sindecs)[0] * np.sum(baseline)\n",
    "\n",
    "# _sindec_exp = np.linspace(-1, 1, 10000)\n",
    "# np.random.shuffle(_sindec_exp)\n",
    "\n",
    "CDFs = np.empty((len(source_ts), len(_sindec_exp)), dtype=float)\n",
    "for j, tj in enumerate(source_ts):\n",
    "    amp = splines[\"Amplitude\"](_sindec_exp)\n",
    "    base = splines[\"Baseline\"](_sindec_exp)\n",
    "    CDFs[j] = brate_inj._rate_func.fun(t=tj, pars=(amp, base))\n",
    "    CDFs[j] = CDFs[j] / baseline\n",
    "\n",
    "CDFs_norm = np.cumsum(CDFs, axis=1)\n",
    "CDFs_norm = CDFs_norm / CDFs_norm[:, [-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the sampling CDFs\n",
    "for i, CDFi in enumerate(CDFs_norm):\n",
    "    plt.plot(_sindec_exp, CDFi, c=\"C{}\".format(i + 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_choice(CDF, n=None):\n",
    "    u = np.random.uniform(size=n)\n",
    "    return np.searchsorted(CDF, v=u, side=\"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsam = len(exp) * 10\n",
    "sam = np.empty((len(CDFs_norm), nsam), dtype=float)\n",
    "for j, CDFi in enumerate(CDFs_norm):\n",
    "    sam[j] = _sindec_exp[rand_choice(CDFi, n=nsam)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.cm.jet(np.linspace(0.1, 0.9, len(source_ts)))\n",
    "for sami, ti, rvi, ci in zip(sam, source_ts, rate_vals, colors):\n",
    "    plt.hist(_sindec_exp, bins=sindec_bins, normed=True, histtype=\"step\",\n",
    "             color=\"k\", alpha=.5, lw=2.5)\n",
    "    plt.hist(sami, bins=sindec_bins, normed=True, histtype=\"step\",\n",
    "             color=ci, alpha=.5, lw=2.5)\n",
    "    norm = np.diff(sindecs)[0] * np.sum(rvi)\n",
    "    plt.plot(sindecs, rvi / norm, c=ci, label=\"t = {:.2f}\".format(ti))\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialisation Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2 (OSX)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

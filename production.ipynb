{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the whole production using package methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from importlib import reload\n",
    "import os\n",
    "import math\n",
    "import helper as hlp\n",
    "from IPython.display import FileLink\n",
    "from time import time\n",
    "import numpy as np\n",
    "import numpy.lib.recfunctions\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mpldates\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "%matplotlib inline\n",
    "\n",
    "import scipy.interpolate as sci\n",
    "import scipy.optimize as sco\n",
    "import scipy.integrate as scint\n",
    "import scipy.stats as scs\n",
    "import scipy.signal as scsignal\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json\n",
    "import datetime\n",
    "import pickle\n",
    "from astropy.time import Time as astrotime\n",
    "from corner import corner\n",
    "\n",
    "import sklearn.neighbors as skn\n",
    "import sklearn.model_selection as skms  # Newer version of grid_search\n",
    "from sklearn.utils import check_random_state\n",
    "\n",
    "from anapymods3.plots.general import (split_axis, get_binmids, dg,\n",
    "                                      hist_marginalize, hist_from_counts)\n",
    "from anapymods3.stats.sampling import rejection_sampling\n",
    "from anapymods3.general.misc import (fill_dict_defaults,\n",
    "                                     flatten_list_of_1darrays)\n",
    "import anapymods3.plots.astro as amp_plt\n",
    "from anapymods3.healpy import wrap_theta_phi_range\n",
    "\n",
    "import tdepps.bg_injector as BGInj\n",
    "import tdepps.bg_rate_injector as BGRateInj\n",
    "import tdepps.rate_function as RateFunc\n",
    "import tdepps.llh as LLH\n",
    "import tdepps.analysis as Analysis\n",
    "import tdepps.signal_injector as SigInj\n",
    "from tdepps.utils import rejection_sampling, func_min_in_interval, rotator\n",
    "\n",
    "# from corner_hist import corner_hist\n",
    "# from skylab.utils import FitDeltaChi2\n",
    "secinday = 24. * 60. * 60."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Load IC86 data from epinat, which should be the usual IC86-I (2011) PS sample, but pull corrected and OneWeights corrected by number of events generated.\n",
    "\n",
    "We applay a sigma cut, to remove badly reconstructed events.\n",
    "Use `_exp`and `_mc` for the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp = np.load(\"data/IC86_I_data.npy\")\n",
    "mc = np.load(\"data/IC86_I_mc.npy\")\n",
    "# Use the officially stated livetime, not the ones from below\n",
    "livetime = 332.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "init_cell": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make a global sigma cut (only removes a handful of badly reconstructed evts)\n",
    "_mc = mc[mc[\"sigma\"] < np.deg2rad(20)]\n",
    "_exp = exp[exp[\"sigma\"] < np.deg2rad(20)]\n",
    "\n",
    "# `sample` is used as a wrapper for plotting, where it is sometimes easier to\n",
    "# have a normal array. Shape is (nevts, nfeatures), each row is a data point\n",
    "sample = np.vstack((_exp[\"logE\"], _exp[\"dec\"], _exp[\"sigma\"], _exp[\"ra\"])).T\n",
    "mc_sample = np.vstack((_mc[\"logE\"], _mc[\"dec\"], _mc[\"sigma\"], _mc[\"ra\"])).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Production Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test if the modules work correctly.\n",
    "They contain the same code as in the main test notebook, but can be used as classes.\n",
    "This should simplyfy production.\n",
    "\n",
    "Currently each submodul only does a very special task:\n",
    "\n",
    "- `bg_injector`: Samples (\"injects\") backgorund events for trials\n",
    "- `bg_rate_injector`: Samples (\"injects\") the number of BG events to be injected per trial.\n",
    "- `rate_function`: Describes the time depence of the background rate.\n",
    "- `llh`: Implements the likelihood function and signal and background PDFs.\n",
    "- `signal_injector`: Same as `bg_injector` but injecting signal evts from MC.\n",
    "- `analysis`: Main module pulling it all together, making trials, fitting llhs, provides methods for advanced tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BG Injector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Injects information for background-like events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Setup for tests in this chapter\n",
    "n_samples = int(1e5)\n",
    "rndgen = np.random.RandomState(7353)\n",
    "\n",
    "xlabel = [\"logE\", \"dec\", \"logE\", \"dec\"]\n",
    "ylabel = [\"dec\", \"sigma\", \"sigma\", \"ra\"]\n",
    "\n",
    "axes = [[0, 1], [1, 2], [0,2], [1, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data Resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_inj = BGInj.DataBGInjector(random_state=rndgen)\n",
    "data_inj.fit(_exp)\n",
    "data_sam = data_inj.sample(n_samples)\n",
    "X_names = data_inj._X_names + [\"ra\"]\n",
    "\n",
    "# shape (n_samples, n_features) for plotting\n",
    "_d_sam = np.vstack((data_sam[n] for n in X_names)).T\n",
    "for i, axis in enumerate(axes):\n",
    "    fig, (al, ar) = hlp.hist_comp(sample[:, axis], _d_sam[:, axis])\n",
    "    al.set_xlabel(xlabel[i])\n",
    "    ar.set_xlabel(xlabel[i])\n",
    "    al.set_ylabel(ylabel[i])\n",
    "    ar.set_ylabel(ylabel[i])\n",
    "    al.set_title(\"Data\")\n",
    "    ar.set_title(\"Data sample: {} evts from original Data\".format(\n",
    "        len(_d_sam)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Adaptive Width KDE sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assign model from CV, which has already evaluated adaptive kernels.\n",
    "# Otherwise we would have to reevaluate which takes a long time.\n",
    "# This should be an official option, to set KDE values for datasets.\n",
    "with open(\"data/awKDE_CV/CV10_glob_bw_alpha_EXP_IC86I_CUT_sig.ll.20_\" +\n",
    "          \"PARS_diag_True_pass2.pickle\", \"rb\") as f:\n",
    "    model_selector = pickle.load(f)\n",
    "    print(model_selector.best_params_)\n",
    "\n",
    "# Pickled KDE was created in a different version, so recomnstruct using the\n",
    "# params to avoid refitting (DON'T USE PICKLE!)\n",
    "alpha = model_selector.best_params_[\"alpha\"]\n",
    "glob_bw = model_selector.best_params_[\"glob_bw\"]\n",
    "diag_cov = model_selector.best_estimator_.diag_cov\n",
    "    \n",
    "kde_inj = BGInj.KDEBGInjector(alpha=alpha, glob_bw=glob_bw,\n",
    "                              diag_cov=diag_cov, random_state=rndgen)\n",
    "kde_inj._kde_model._kde_values = model_selector.best_estimator_._kde_values\n",
    "\n",
    "# Fit doesn't take long because all adaptive kernels are set.\n",
    "# Note: The original order cannot be changed now [logE, dec, sigma]\n",
    "bounds = np.array([[None, None], [-np.pi / 2. , np.pi / 2.], [0, None]])\n",
    "kde_inj.fit(_exp, bounds)\n",
    "\n",
    "# Sample (bounds are preventing spillover in undefined regions)\n",
    "kde_sam = kde_inj.sample(n_samples)\n",
    "X_names = kde_inj._X_names + [\"ra\"]\n",
    "_kde_sam = np.vstack((kde_sam[n] for n in X_names)).T\n",
    "\n",
    "for i, axis in enumerate(axes):\n",
    "    fig, (al, ar) = hlp.hist_comp(sample[:, axis], _kde_sam[:, axis])\n",
    "    al.set_xlabel(xlabel[i])\n",
    "    ar.set_xlabel(xlabel[i])\n",
    "    al.set_ylabel(ylabel[i])\n",
    "    ar.set_ylabel(ylabel[i])\n",
    "    al.set_title(\"Data\")\n",
    "    ar.set_title(\"KDE sample: {} evts\".format(len(_kde_sam)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### GRBLLH style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# If False, only sample where data was\n",
    "# If True sample in global min/max bounding box\n",
    "minmax = True\n",
    "\n",
    "mrinj = BGInj.MRichmanBGInjector(random_state=rndgen)\n",
    "ax0_bins, ax1_bins, ax2_bins = mrinj.fit(_exp, nbins=10, minmax=minmax)\n",
    "mr_sam = mrinj.sample(n_samples=n_samples)\n",
    "X_names = mrinj._X_names + [\"ra\"]\n",
    "_mr_sam = np.vstack((mr_sam[n] for n in X_names)).T\n",
    "\n",
    "for i, axis in enumerate(axes):\n",
    "    fig, (al, ar) = hlp.hist_comp(sample[:, axis], _mr_sam[:, axis])\n",
    "    al.set_xlabel(xlabel[i])\n",
    "    ar.set_xlabel(xlabel[i])\n",
    "    al.set_ylabel(ylabel[i])\n",
    "    ar.set_ylabel(ylabel[i])\n",
    "    al.set_title(\"Data\")\n",
    "    ar.set_title(\"Pseudo MR sample: {} evts\".format(len(_mr_sam)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Pseudo Data (uniform) sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uni_inj = BGInj.UniformBGInjector(random_state=rndgen)\n",
    "uni_sam = uni_inj.sample(n_samples)\n",
    "X_names = uni_inj._X_names + [\"ra\"]\n",
    "_uni_sam = np.vstack([uni_sam[n] for n in X_names]).T\n",
    "\n",
    "for i, axis in enumerate(axes):\n",
    "    fig, (al, ar) = hlp.hist_comp(sample[:, axis], _uni_sam[:, axis])\n",
    "    al.set_xlabel(xlabel[i])\n",
    "    ar.set_xlabel(xlabel[i])\n",
    "    al.set_ylabel(ylabel[i])\n",
    "    ar.set_ylabel(ylabel[i])\n",
    "    al.set_title(\"Data\")\n",
    "    ar.set_title(\"Pseudo (uniform) sample: {} evts\".format(len(_uni_sam)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BG Rate Injector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This module injects times of background like events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Injector created from runlist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First step is always to fit a RateFunction to rates from detector runs.\n",
    "Here we use a Sinus1yrRateFunction with fixed period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now parse the rundict and make the fitted injector from that\n",
    "def filter_runs(run):\n",
    "    \"\"\"\n",
    "    Filter runs as stated in jfeintzig's doc.\n",
    "    \"\"\"\n",
    "    exclude_runs = [120028, 120029, 120030, 120087, 120156, 120157]\n",
    "    if ((run[\"good_i3\"] == True) & (run[\"good_it\"] == True) &\n",
    "        (run[\"run\"] not in exclude_runs)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# Create a rate function. We fix the period to 1 year here\n",
    "rndgen = np.random.RandomState(7353)\n",
    "rate_func_obj = RateFunc.Sinus1yrRateFunction(random_state=rndgen)\n",
    "    \n",
    "# Let's create an injector using a goodrun list. This creates a run dict\n",
    "runlist = \"data/runlists/ic86-i-goodrunlist.json\"\n",
    "runlist_inj = BGRateInj.RunlistBGRateInjector(rate_func_obj, runlist,\n",
    "                                              filter_runs, rndgen)\n",
    "\n",
    "# Fit function to exp times to runlist bins\n",
    "times = exp[\"timeMJD\"]\n",
    "rate_func = runlist_inj.fit(T=times, x0=None, remove_zero_runs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rebin (donglians proposal)\n",
    "rates = runlist_inj._rate_rec\n",
    "start_mjd = rates[\"start_mjd\"]\n",
    "stop_mjd = rates[\"stop_mjd\"]\n",
    "\n",
    "tmin, tmax = np.amin(start_mjd), np.amax(stop_mjd)\n",
    "ntbins = 12\n",
    "tbins = np.linspace(tmin, tmax, ntbins + 1)\n",
    "\n",
    "# Get bin idx in which the runs fall\n",
    "# This is not a 100% correct, because runs may be right over bin edges\n",
    "idx = np.digitize(stop_mjd, tbins) - 1\n",
    "rates_per_bin = np.zeros(ntbins, dtype=np.float)\n",
    "\n",
    "evts_in_run = rates[\"nevts\"]\n",
    "dts = (stop_mjd - start_mjd) * secinday\n",
    "for i in range(ntbins):\n",
    "    rates_per_bin[i] = np.sum(evts_in_run[idx == i]) / np.sum(dts[idx == i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot runs (zorder, because errorbar seems to have high zorder for centers)\n",
    "xerr = 0.5 * (stop_mjd - start_mjd)\n",
    "yerr = rates[\"rate_std\"]\n",
    "binmids = 0.5 * (stop_mjd + start_mjd)\n",
    "\n",
    "plt.errorbar(binmids, rates[\"rate\"], xerr=xerr, yerr=yerr,\n",
    "             fmt=\",\", alpha=0.25, zorder=0)\n",
    "plt.ylim(0, None);\n",
    "\n",
    "# Plot fit\n",
    "t = np.linspace(start_mjd[0], stop_mjd[-1], 1000)\n",
    "y = rate_func(t)\n",
    "plt.plot(t, y, zorder=5, lw=2, color=\"C1\")\n",
    "\n",
    "# Plot y shift dashed to see baseline or years average\n",
    "avg = runlist_inj.best_pars[2]\n",
    "plt.axhline(avg, 0, 1, color=\"C1\", ls=\"--\", label=\"\", lw=1.5)\n",
    "\n",
    "plt.xlim(start_mjd[0], stop_mjd[-1])\n",
    "plt.xlabel(\"MJD\")\n",
    "plt.ylabel(\"Rate in Hz\")\n",
    "\n",
    "# Show rebinned (as expected you see nothing new)\n",
    "m = get_binmids([tbins])[0]\n",
    "plt.errorbar(m, rates_per_bin, xerr=np.diff(tbins),\n",
    "             fmt=\",\", lw=2, color=\"C2\", zorder=3)\n",
    "\n",
    "# plt.savefig(\"./data/figs/time_rate_sinus_rebinned.png\", dpi=200)\n",
    "plt.ylim(0, 0.009)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Best fit params:\")\n",
    "for par, name in zip(runlist_inj.best_pars, [\"amp\", \"toff\", \"base\"]):\n",
    "    print(\" {:5} : {:+.3g}\".format(name, par))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sample some trials for a single src and time with the poisson=True keyword to see if we sample correctly for each trial.\n",
    "\n",
    "Also compare with poisson=False to see if it's working correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rates = runlist_inj._rate_rec\n",
    "start_mjd = rates[\"start_mjd\"]\n",
    "\n",
    "# Pick some random time and time frame\n",
    "t = rndgen.choice(start_mjd, size=1)\n",
    "trange = np.array([-120, 220])\n",
    "\n",
    "# This is a list of times per trial\n",
    "ntrials = int(1e4)\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trial = runlist_inj.sample(t, trange, poisson=True)\n",
    "    # Make one array of times, because we have only one src here\n",
    "    trials.append(flatten_list_of_1darrays(trial))\n",
    "\n",
    "nevents = np.array(list(map(len, trials)))\n",
    "print(\"Sampled total of {:d} events in {:d} trials.\".format(\n",
    "        np.sum(nevents), ntrials))\n",
    "\n",
    "# Plot poisson distribution of nevents with expectation from integral\n",
    "expect = runlist_inj.best_estimator_integral(t, trange)\n",
    "_ = plt.hist(nevents, bins=np.arange(10), normed=True)\n",
    "plt.axvline(expect, 0, 1, color=\"C1\", ls=\"--\", lw=2, label=\"expect\")\n",
    "x = np.arange(0, 10)\n",
    "y = scs.poisson.pmf(x, mu=expect)\n",
    "_ = plt.plot(x, y, \"C1\", lw=2, drawstyle=\"steps-post\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Now the same for possion=False as a crosscheck\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trial = runlist_inj.sample(t, trange, poisson=False)\n",
    "    # Make one array of times, because we have only one src here\n",
    "    trials.append(flatten_list_of_1darrays(trial))\n",
    "\n",
    "nevents = np.array(list(map(len, trials)))\n",
    "print(\"Sampled total of {:d} events in {:d} trials.\".format(\n",
    "        np.sum(nevents), ntrials))\n",
    "\n",
    "# Plot poisson distribution of nevents with expectation from integral, here\n",
    "# for comparison to the previous case only\n",
    "expect = runlist_inj.best_estimator_integral(t, trange)\n",
    "_ = plt.hist(nevents, bins=np.arange(10), normed=True)\n",
    "plt.axvline(expect, 0, 1, color=\"C1\", ls=\"--\", lw=2, alpha=0.5,\n",
    "            label=\"expect\")\n",
    "plt.axvline(np.round(expect), 0, 1, color=\"C1\", ls=\"--\", lw=2,\n",
    "            label=\"round expect\")\n",
    "x = np.arange(0, 10)\n",
    "y = scs.poisson.pmf(x, mu=expect)\n",
    "_ = plt.plot(x, y, \"C1\", lw=2, drawstyle=\"steps-post\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we do the same, but with multiple sources.\n",
    "Each src gets a larger time window, so the expectation gets higher and we can compare different poisson distributions at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rates = runlist_inj._rate_rec\n",
    "start_mjd = rates[\"start_mjd\"]\n",
    "\n",
    "# Pick random times and make increasing time frames per source\n",
    "nsrcs = 3\n",
    "t = rndgen.choice(start_mjd, size=nsrcs)\n",
    "trange = np.vstack((np.repeat([-100], nsrcs),\n",
    "                    500 * np.arange(1, 3 * nsrcs + 1, 3))).T\n",
    "\n",
    "# This is a list of times per trial\n",
    "ntrials = int(1e4)\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trial = runlist_inj.sample(t, trange, poisson=True)\n",
    "    # Make one array of times, because we have only one src here\n",
    "    trials.append(trial)\n",
    "\n",
    "# The format of `trials` is list(array_src1, array_src2, ...) for each trial.\n",
    "# We want the number of events sampled per src per trial\n",
    "nevents = []\n",
    "for i in range(nsrcs):\n",
    "    nevents.append([len(trial[i]) for trial in trials])\n",
    "    print(\"Sampled {:d} events in {:d} trials for src {:d}.\".format(\n",
    "          np.sum(nevents[i]), ntrials, i))\n",
    "\n",
    "# Plot poisson distributions of nevents with expectations from integrals\n",
    "expect = runlist_inj.best_estimator_integral(t, trange)\n",
    "colors = [\"C0\", \"C1\", \"C3\"]\n",
    "for i in range(nsrcs):\n",
    "    _ = plt.hist(nevents[i], bins=np.arange(np.amax(nevents)), normed=True,\n",
    "                 color=colors[i], alpha=.25)\n",
    "    plt.axvline(expect[i], 0, 1, ls=\"--\", lw=2, label=\"mu src {}\".format(i),\n",
    "                color=colors[i])\n",
    "    x = np.arange(0, np.amax(nevents))\n",
    "    y = scs.poisson.pmf(x, mu=expect[i])\n",
    "    _ = plt.plot(x, y, lw=2, drawstyle=\"steps-post\", color=colors[i])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now we want to look at the actual sampled times in each trial.\n",
    "First we sample a single in a small timeframe.\n",
    "It should be approximately uniformly distributed, respectively not to distinguish by eye from a constant PDF, because the sine is way to broad to be resolved on such a small time scale.\n",
    "We also show the bg and signal pdf for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First the small time frame\n",
    "# Arbitrary start date from data\n",
    "nsrcs = 1\n",
    "t0 = np.random.choice(start_mjd, size=nsrcs)\n",
    "t0_sec = t0 * secinday\n",
    "\n",
    "# dt from t0 in seconds, clip at 4 sigma\n",
    "dt = 200\n",
    "nsig = 4.\n",
    "\n",
    "# Make t values for plotting in MJD around t0\n",
    "clip = np.clip(dt, 2, 30) * nsig\n",
    "trange = np.array([-clip, dt + clip]).reshape(nsrcs, 2)\n",
    "ntrials = int(1e4)\n",
    "\n",
    "# Sample times for each trial and flatten to single array with all trials\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trials += runlist_inj.sample(t0, trange, poisson=True)\n",
    "trials = flatten_list_of_1darrays(trials)\n",
    "\n",
    "# Plot them in together with the PDFs\n",
    "def time_bg_pdf(t, t0, a, b):\n",
    "    # Normalize relative to t0 in seconds (first multiply avoids rounding?)\n",
    "    _t = t * secinday - t0 * secinday\n",
    "  \n",
    "    pdf = np.zeros_like(_t, dtype=np.float)\n",
    "    uni = (_t >= a) & (_t <= b)\n",
    "    pdf[uni] = 1. / (b - a)\n",
    "    return pdf\n",
    "\n",
    "def time_sig_pdf(t, t0, dt, nsig=4):\n",
    "    if dt < 0:\n",
    "        raise ValueError(\"dt must not be negative.\")\n",
    "\n",
    "    # Normalize relative to t0 in seconds (first multiply avoids rounding?)\n",
    "    _t = t * secinday - t0 * secinday\n",
    "    \n",
    "    # Constrain sig_t to [2, 30]s regardless of uniform time window\n",
    "    sig_t = np.clip(dt, 2, 30)\n",
    "    sig_t_clip = nsig * sig_t\n",
    "    gaus_norm = (np.sqrt(2 * np.pi) * sig_t)\n",
    "    \n",
    "    # Split in def regions gaus rising, uniform, gaus falling and zero\n",
    "    gr = (_t < 0) & (_t >= -sig_t_clip)\n",
    "    gf = (_t > dt) & (_t <= dt + sig_t_clip)\n",
    "    uni = (_t >= 0) & (_t <= dt)\n",
    "    \n",
    "    pdf = np.zeros_like(t, dtype=np.float)\n",
    "    pdf[gr] = scs.norm.pdf(_t[gr], loc=0, scale=sig_t)\n",
    "    pdf[gf] = scs.norm.pdf(_t[gf], loc=dt, scale=sig_t)\n",
    "    # Connect smoothly with the gaussians\n",
    "    pdf[uni] = 1. / gaus_norm\n",
    "    \n",
    "    # Normalize whole distribtuion\n",
    "    dcdf = (scs.norm.cdf(dt + sig_t_clip, loc=dt, scale=sig_t) -\n",
    "            scs.norm.cdf(-sig_t_clip, loc=0., scale=sig_t))\n",
    "    norm = dcdf + dt / gaus_norm\n",
    "    \n",
    "    return pdf / norm\n",
    "\n",
    "\n",
    "# Plot the pdfs\n",
    "t = np.linspace(t0_sec + trange[:, 0], t0_sec + trange[:, 1], 200) / secinday\n",
    "bg_pdf = time_bg_pdf(t, t0, -clip, dt + clip)\n",
    "sig_pdf = time_sig_pdf(t, t0, dt, nsig)\n",
    "\n",
    "# Plot in normalized time\n",
    "_t = t * secinday - t0 * secinday\n",
    "plt.plot(_t, bg_pdf, \"C0-\")\n",
    "plt.plot(_t, sig_pdf, \"C1-\")\n",
    "plt.axvline(dt, 0, 1, color=\"C3\", ls=\"--\")\n",
    "plt.axvline(0, 0, 1, color=\"C2\", ls=\"--\")\n",
    "\n",
    "# Plot injected events from all trials, relative times\n",
    "times = (trials - t0) * secinday\n",
    "_ = plt.hist(times, bins=50, normed=True, color=dg, alpha=.25)\n",
    "\n",
    "plt.xlabel(\"Time relative to t0 in sec\")\n",
    "plt.ylim(0, None);\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"./data/figs/bg_events_time_sampled_narrow.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now the really large time frame, over the whole time range\n",
    "t0 = start_mjd[0]\n",
    "t0_sec = t0 * secinday\n",
    "\n",
    "# Maximum dt over all runs\n",
    "dt = (stop_mjd[-1] - start_mjd[0]) * secinday\n",
    "nsig = 4.\n",
    "\n",
    "# Make t values for plotting in MJD around t0\n",
    "clip = np.clip(dt, 2, 30) * nsig\n",
    "trange = [-clip, dt + clip]\n",
    "ntrials = 100  # More trials mean smaller errors, better see the sinus shape \n",
    "\n",
    "# Sample times\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trials += runlist_inj.sample(t0, trange, poisson=True)\n",
    "trials = flatten_list_of_1darrays(trials)\n",
    "\n",
    "# We choose the same style as in the intial rate plot further above\n",
    "h, b = np.histogram(trials, bins=1081)\n",
    "m = get_binmids([b])[0]\n",
    "scale = np.diff(b) * secinday * ntrials\n",
    "yerr = np.sqrt(h) / scale\n",
    "h = h / scale\n",
    "\n",
    "plt.errorbar(m, h, yerr=yerr, fmt=\",\")\n",
    "\n",
    "# Plot normalized rate function to compare\n",
    "t = np.linspace(start_mjd[0], stop_mjd[-1], 100)\n",
    "r = runlist_inj.best_estimator(t)\n",
    "plt.plot(t, r, lw=2, zorder=5)\n",
    "plt.axhline(runlist_inj.best_pars[2], 0, 1, color=\"C1\",\n",
    "            ls=\"--\", label=\"\", zorder=5)\n",
    "\n",
    "plt.xlim(start_mjd[0], stop_mjd[-1])\n",
    "plt.ylim(0.004, 0.006)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"./data/figs/bg_events_time_sampled_wide.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Injector from binned rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we use the sampled rate from above to create a new injector.\n",
    "Everything else is staying the same.\n",
    "So we just reproduce the plot last plot above.\n",
    "Also see the note about the livetime further below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make up ten bins with a total live time of 100 days, but the difference between first and last event time is 365 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dt = 365.\n",
    "start_mjd = np.amin(_exp[\"timeMJD\"])\n",
    "stop_mjd = start_mjd + dt\n",
    "\n",
    "nruns = 10\n",
    "tbins_start = np.linspace(start_mjd, stop_mjd, nruns)\n",
    "# Runs are 10 days long\n",
    "tbins_stop = tbins_start + 10.\n",
    "\n",
    "# Make approximately the same rates as in the real sample\n",
    "mids = 0.5 * (tbins_start + tbins_stop)\n",
    "rate = -0.0005 * np.sin(2 * np.pi / dt * (mids - start_mjd)) + 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create a rate function. We fix the period to 1 year here\n",
    "rndgen = np.random.RandomState(7353)\n",
    "rate_func_obj = RateFunc.Sinus1yrRateFunction(random_state=rndgen)\n",
    "    \n",
    "binned_inj = BGRateInj.BinnedBGRateInjector(rate_func_obj)\n",
    "\n",
    "# Fit function to the sampled times from the above runlist injector\n",
    "# tbins = [start_mjd_arr, stop_mjd_arr], shape = (2, nruns)\n",
    "tbins = np.vstack((tbins_start, tbins_stop)).T\n",
    "\n",
    "rate_func = binned_inj.fit(tbins, rate, x0=None)\n",
    "\n",
    "# Livetime should be 100 days by construction\n",
    "print(\"Livetime is: {:.2f} days\".format(binned_inj.livetime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "trange = [0, (stop_mjd - start_mjd) * secinday]\n",
    "ntrials = 10\n",
    "\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trials += binned_inj.sample(start_mjd, trange, poisson=True)\n",
    "trials = flatten_list_of_1darrays(trials)\n",
    "\n",
    "# We choose the same style as in the intial rate plot further above\n",
    "h, b = np.histogram(trials, bins=1081)\n",
    "m = get_binmids([b])[0]\n",
    "scale = np.diff(b) * secinday * ntrials\n",
    "yerr = np.sqrt(h) / scale\n",
    "h = h / scale\n",
    "\n",
    "plt.errorbar(m, h, yerr=yerr, fmt=\",\")\n",
    "\n",
    "# Plot normalized rate function to compare\n",
    "t = np.linspace(start_mjd, stop_mjd, 100)\n",
    "r = binned_inj.best_estimator(t)\n",
    "plt.plot(t, r, lw=2, zorder=5)\n",
    "plt.axhline(binned_inj.best_pars[2], 0, 1, color=\"C1\",\n",
    "            ls=\"--\", label=\"\", zorder=5)\n",
    "\n",
    "plt.errorbar(mids, rate, xerr=(tbins_stop - tbins_start), color=\"w\",\n",
    "             fmt=\",\", zorder=5, lw=3)\n",
    "\n",
    "plt.xlim(start_mjd, stop_mjd)\n",
    "plt.ylim(0.004, 0.006)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"./data/figs/bg_events_time_sampled_wide_100days.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# First the small time frame. Arbitrary start date from data\n",
    "nsrcs = 1\n",
    "t0 = start_mjd\n",
    "t0_sec = t0 * secinday\n",
    "\n",
    "# dt from t0 in seconds, clip at 4 sigma\n",
    "dt = 200\n",
    "nsig = 4.\n",
    "\n",
    "# Make t values for plotting in MJD around t0\n",
    "clip = np.clip(dt, 2, 30) * nsig\n",
    "trange = np.array([-clip, dt + clip]).reshape(nsrcs, 2)\n",
    "ntrials = int(1e4)\n",
    "\n",
    "# Sample times for each trial and flatten to single array with all trials\n",
    "trials = []\n",
    "for i in range(ntrials):\n",
    "    trials += binned_inj.sample(t0, trange, poisson=True)\n",
    "trials = flatten_list_of_1darrays(trials)\n",
    "\n",
    "# Plot them in together with the PDFs\n",
    "def time_bg_pdf(t, t0, a, b):\n",
    "    # Normalize relative to t0 in seconds (first multiply avoids rounding?)\n",
    "    _t = t * secinday - t0 * secinday\n",
    "  \n",
    "    pdf = np.zeros_like(_t, dtype=np.float)\n",
    "    uni = (_t >= a) & (_t <= b)\n",
    "    pdf[uni] = 1. / (b - a)\n",
    "    return pdf\n",
    "\n",
    "def time_sig_pdf(t, t0, dt, nsig=4):\n",
    "    if dt < 0:\n",
    "        raise ValueError(\"dt must not be negative.\")\n",
    "\n",
    "    # Normalize relative to t0 in seconds (first multiply avoids rounding?)\n",
    "    _t = t * secinday - t0 * secinday\n",
    "    \n",
    "    # Constrain sig_t to [2, 30]s regardless of uniform time window\n",
    "    sig_t = np.clip(dt, 2, 30)\n",
    "    sig_t_clip = nsig * sig_t\n",
    "    gaus_norm = (np.sqrt(2 * np.pi) * sig_t)\n",
    "    \n",
    "    # Split in def regions gaus rising, uniform, gaus falling and zero\n",
    "    gr = (_t < 0) & (_t >= -sig_t_clip)\n",
    "    gf = (_t > dt) & (_t <= dt + sig_t_clip)\n",
    "    uni = (_t >= 0) & (_t <= dt)\n",
    "    \n",
    "    pdf = np.zeros_like(t, dtype=np.float)\n",
    "    pdf[gr] = scs.norm.pdf(_t[gr], loc=0, scale=sig_t)\n",
    "    pdf[gf] = scs.norm.pdf(_t[gf], loc=dt, scale=sig_t)\n",
    "    # Connect smoothly with the gaussians\n",
    "    pdf[uni] = 1. / gaus_norm\n",
    "    \n",
    "    # Normalize whole distribtuion\n",
    "    dcdf = (scs.norm.cdf(dt + sig_t_clip, loc=dt, scale=sig_t) -\n",
    "            scs.norm.cdf(-sig_t_clip, loc=0., scale=sig_t))\n",
    "    norm = dcdf + dt / gaus_norm\n",
    "    \n",
    "    return pdf / norm\n",
    "\n",
    "\n",
    "# Plot the pdfs\n",
    "t = np.linspace(t0_sec + trange[:, 0], t0_sec + trange[:, 1], 200) / secinday\n",
    "bg_pdf = time_bg_pdf(t, t0, -clip, dt + clip)\n",
    "sig_pdf = time_sig_pdf(t, t0, dt, nsig)\n",
    "\n",
    "# Plot in normalized time\n",
    "_t = t * secinday - t0 * secinday\n",
    "plt.plot(_t, bg_pdf, \"C0-\")\n",
    "plt.plot(_t, sig_pdf, \"C1-\")\n",
    "plt.axvline(dt, 0, 1, color=\"C3\", ls=\"--\")\n",
    "plt.axvline(0, 0, 1, color=\"C2\", ls=\"--\")\n",
    "\n",
    "# Plot injected events from all trials, relative times\n",
    "times = (trials - t0) * secinday\n",
    "_ = plt.hist(times, bins=50, normed=True, color=dg, alpha=.25)\n",
    "\n",
    "plt.xlabel(\"Time relative to t0 in sec\")\n",
    "plt.ylim(0, None);\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"./data/figs/bg_events_time_sampled_narrow.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Utils -- rejection_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test the utils.py rejection sampler.\n",
    "We generate trials for multiple sources at once and check how fast this is.\n",
    "Currently the method just loops over sources, rejection sampling for each interval, but it seems fast enough.\n",
    "\n",
    "A short note on the test below:\n",
    "We make nsrcs, each with ordered center times and increasing time windows.\n",
    "Then we sample an increasing number of samples per source.\n",
    "This is the same as a single trial.\n",
    "\n",
    "In the histogram we expect 2 things:\n",
    "\n",
    "1. If the time windows are smaller than 1 day, which is the bin size, then we just get a nice lineraly increaing bin content (triangle shaped, with hard cut at the right edge).\n",
    "2. If the time windows increase, we get spillover resulting in a way more spread distribution. Also the time windows are only widened to to the right, so the spillover occurs only to the right edges. When the time windows are really large, we even begin to see the underlying oscillation of the sinusodial test function we generate samples from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sample_test_sin(t):\n",
    "    \"\"\"Simple sinus, similar to fitted rate function\"\"\"\n",
    "    return 0.001 * np.sin(2 * np.pi / 365. * (t - 50000)) + 0.005\n",
    "\n",
    "rndgen = np.random.RandomState(7353)\n",
    "\n",
    "# Make some srcs and incresing time windows\n",
    "nsrcs = 100\n",
    "t = np.arange(0, nsrcs) + 50000\n",
    "scaler = 2 * secinday  # Time window scaler: Increase to see spillover\n",
    "dts = np.vstack((np.zeros(nsrcs), scaler * np.arange(1, nsrcs + 1))).T\n",
    "dts = t.reshape(nsrcs, 1) + dts / secinday\n",
    "\n",
    "# Sample increasing number of events in time windows\n",
    "n_samples = 100 * np.arange(1, nsrcs + 1)\n",
    "sample = rejection_sampling(sample_test_sin, dts,\n",
    "                            n_samples=n_samples, rndgen=rndgen)\n",
    "\n",
    "flatsam = flatten_list_of_1darrays(sample)\n",
    "\n",
    "# If the time windows are larger than one day (the binning) we get spillover\n",
    "_ = plt.hist(flatsam, bins=nsrcs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's look at the distribution in the largest time window.\n",
    "# It should be sinusodial\n",
    "_ = plt.hist(sample[-1], bins=20, normed=True)\n",
    "# Plot sampled function as comparison\n",
    "t = np.linspace(dts[-1, 0],dts[-1, 1], 100)\n",
    "intgrl = scint.quad(sample_test_sin, dts[-1, 0],dts[-1, 1])[0]\n",
    "y = sample_test_sin(t) / intgrl\n",
    "plt.plot(t, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Quickly check how fast we are. Set nsrcs to 100 above for many srcs\n",
    "rejection_sampling(sample_test_sin, dts, n_samples=n_samples, rndgen=rndgen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Cache fmax values and measure the time agian. We should get significantly faster because we don't have to find the maximum in each step.\n",
    "\n",
    "**Attention:** Be sure that the values match with the used time windows. If they're off or not matching we either don't produce the correct distribution or are getting very inefficient because we start to reject almost everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def negpdf(t):\n",
    "    return -1. * sample_test_sin(t)\n",
    "\n",
    "rndgen = np.random.RandomState(7353)\n",
    "\n",
    "f0 = []\n",
    "fmax = []\n",
    "for bound in dts:\n",
    "    # Repeat some code from func_min_in_interval to get the seed\n",
    "    x_scan = np.linspace(bound[0], bound[1], 7)[1:-1]\n",
    "    max_idx = np.argmin(negpdf(x_scan))\n",
    "    x0 = x_scan[max_idx]\n",
    "    f0.append(-1 * negpdf(x0))\n",
    "\n",
    "    fmax.append(-1. * func_min_in_interval(negpdf, bound))\n",
    "\n",
    "fmax = flatten_list_of_1darrays(fmax)\n",
    "\n",
    "# Time windows get so large, that the maximium is always in the windows\n",
    "start_dts = dts[:, 0].flatten()\n",
    "plt.plot(start_dts, sample_test_sin(start_dts), label=\"fun\")\n",
    "plt.plot(start_dts, fmax, label=\"fit\")\n",
    "plt.plot(start_dts, f0, label=\"seed\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Should be faster than before\n",
    "rejection_sampling(sample_test_sin, dts, n_samples=n_samples,\n",
    "                   rndgen=rndgen, max_fvals=fmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Utils -- rotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test correct conservation of circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here do the following:\n",
    "\n",
    "1. Target point is (ra2, dec2)\n",
    "2. Points (r3, dec3) to be rotated are random and the same as the ones\n",
    "   (ra2, dec2) defining the rotation angles.\n",
    "3. After rotation they should be all exactly at (ra2, dec2)\n",
    "\"\"\"\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "npts = 10000\n",
    "# Coordinates to rotate to\n",
    "ra2 = np.repeat(np.deg2rad(250.), npts)\n",
    "dec2 = np.repeat(np.deg2rad(30.), npts)\n",
    "\n",
    "# Positions that shall be rotated to (ra2, dec2)\n",
    "ra3 = np.random.uniform(0, 2 * np.pi, npts)\n",
    "# Get more at the poles, else use: np.arcsin(rndgen.uniform(-1, 1, npts))\n",
    "dec3 = np.random.uniform(-np.pi / 2., np.pi / 2., npts)\n",
    "# Add some special cases for dec3, as it is not periodical\n",
    "dec3_spec = np.deg2rad([-90, -60, -30, 0, 30, 60, 90])\n",
    "ra3_spec = np.ones_like(dec3_spec) * 2 * np.pi\n",
    "nspec = len(dec3_spec)\n",
    "dec3[-nspec:] = dec3_spec\n",
    "ra3[-nspec:] = ra3_spec\n",
    "\n",
    "# Here the point defining the rotation angles dra, dtheta are the same as the\n",
    "# point that get rotated, so they end up all on (ra2, dec2)\n",
    "ra1 = ra3\n",
    "dec1 = dec3\n",
    "\n",
    "# Rotate\n",
    "ra3t, dec3t = rotator(ra1, dec1, ra2, dec2, ra3, dec3)\n",
    "\n",
    "# Plot original points, highlight special cases\n",
    "plt.plot(ra3, dec3, \"C0.\")\n",
    "plt.plot(ra3[-nspec:], dec3[-nspec:], \"kx\", ms=10)\n",
    "\n",
    "# Plot intdermediate steps\n",
    "plt.plot(ra3t, dec3, \"C2.\")\n",
    "plt.plot(ra3, dec3t, \"C3.\")\n",
    "\n",
    "# Plot fixed target point (ra2, dec2)\n",
    "plt.plot(ra2, dec2, \"wo\", ms=10, mec=\"k\")\n",
    "\n",
    "# Plot all transformed\n",
    "plt.plot(ra3t, dec3t, \"C4x\")\n",
    "plt.plot(ra3t[-nspec:], dec3t[-nspec:], \"k+\")\n",
    "\n",
    "# Check if we ended up in target point\n",
    "print(\"All points where they should be: \", np.allclose(ra3t, ra2))\n",
    "print(\"All points where they should be: \", np.allclose(dec3t, dec2))\n",
    "\n",
    "# ra guides\n",
    "plt.axvline(0, 0, 1, color=\"#353132\", ls=\"--\")\n",
    "plt.axvline(np.pi, 0, 1, color=\"#353132\", ls=\"-\")\n",
    "plt.axvline(2 * np.pi, 0, 1, color=\"#353132\", ls=\"--\")\n",
    "# dec guides\n",
    "plt.axhline(-np.pi / 2., 0, 1, color=\"#353132\", ls=\"--\")\n",
    "plt.axhline(0, 0, 1, color=\"#353132\", ls=\"-\")\n",
    "plt.axhline(np.pi / 2., 0, 1, color=\"#353132\", ls=\"--\")\n",
    "\n",
    "plt.xlabel(\"ra\")\n",
    "plt.ylabel(\"dec\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here do the following:\n",
    "\n",
    "1. Target points are ra2, dec2\n",
    "2. Initial point is a circle center at ra1, dec1\n",
    "3. Points to be rotated are (ra3, dec3) in a circle around (ra1, dec1)\n",
    "4. After rotation they should be in a circla around (ra2, dec2)\n",
    "\n",
    "Test with multiple targets (ra2, dec2)\n",
    "\"\"\"\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Fixed coordinates to rotate to. Try 5 different places\n",
    "npts = 20\n",
    "ntarget = 5\n",
    "\n",
    "ra2_all = np.deg2rad(np.linspace(5, 355, ntarget))\n",
    "dec2_all = np.deg2rad(np.linspace(-85, 85, ntarget))\n",
    "\n",
    "# Center of the fixed initial circle\n",
    "radius = np.deg2rad(10)\n",
    "ra1 = np.repeat(np.deg2rad(90), npts)\n",
    "dec1 = np.repeat(np.deg2rad(30), npts)\n",
    "theta1 = np.pi / 2. - dec1\n",
    "\n",
    "# Plot circle dots with squential cmap to see correct order\n",
    "cmap = plt.cm.get_cmap(\"viridis\", npts + 2)\n",
    "colors = cmap.colors[1:-1]\n",
    "\n",
    "# Fixed initial center point\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 8))\n",
    "ax.plot(ra1, dec1, \"C2o\", label=\"orig\")\n",
    "\n",
    "# Fixed positions around (ra1, dec1) that shall be rotated around (ra2, dec2)\n",
    "t = np.linspace(0, 2 * np.pi, npts)\n",
    "ra3 = radius * np.cos(t) + ra1\n",
    "dec3 = radius * np.sin(t) + dec1\n",
    "\n",
    "for i in range(npts):\n",
    "    ax.plot(ra3[i], dec3[i], marker=\".\", ls=\"\", color=colors[i])\n",
    "\n",
    "\n",
    "# Now rotate to various places\n",
    "for ra2, dec2 in zip(ra2_all, dec2_all):\n",
    "    # Rotate\n",
    "    ra3t, dec3t = rotator(ra1, dec1,\n",
    "                          np.repeat([ra2], npts), np.repeat([dec2], npts),\n",
    "                          ra3, dec3)\n",
    "\n",
    "    ax.plot(ra2, dec2, \"C1o\")\n",
    "    ax.arrow(ra1[0], dec1[0], (ra2 - ra1[0]), (dec2 - dec1[0]),\n",
    "             fc=\"C7\", ec=\"C7\", length_includes_head=True,\n",
    "             head_width=0.05, head_length=0.1)\n",
    "\n",
    "    for i in range(npts):\n",
    "        ax.plot(ra3t[i], dec3t[i], marker=\".\", ls=\"\", color=colors[i])\n",
    "\n",
    "# ra guides\n",
    "plt.axvline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.axvline(np.pi, 0, 1, color=\"C7\", ls=\"-\")\n",
    "plt.axvline(2 * np.pi, 0, 1, color=\"C7\", ls=\"--\")\n",
    "# dec guides\n",
    "plt.axhline(-np.pi / 2., 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.axhline(0, 0, 1, color=\"C7\", ls=\"-\")\n",
    "plt.axhline(np.pi / 2., 0, 1, color=\"C7\", ls=\"--\")\n",
    "\n",
    "plt.xlabel(\"ra\")\n",
    "plt.ylabel(\"dec\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Here do the following:\n",
    "\n",
    "1. Target point is ra0, dec0\n",
    "2. Initial point is ra1, dec1\n",
    "3. Points to be rotated are in a circle around (ra1, dec1)\n",
    "4. After rotation they should be in a circla around (ra0, dec0)\n",
    "\n",
    "Test with multiple targets (ra0, dec0)\n",
    "\"\"\"\n",
    "\n",
    "# Fixed coordinates to rotate to. Try 5 different places\n",
    "ntarget = 5\n",
    "npts = 20\n",
    "\n",
    "ra2_all = np.deg2rad(np.linspace(5, 355, ntarget))\n",
    "dec2_all = np.deg2rad(np.linspace(-85, 85, ntarget))\n",
    "\n",
    "# Center of the initial circle\n",
    "radius = np.deg2rad(15)\n",
    "ra1 = np.repeat(np.deg2rad(90), npts)\n",
    "dec1 = np.repeat(np.deg2rad(30), npts)\n",
    "\n",
    "# Plot circle dots with squential cmap to see correct order\n",
    "cmap = plt.cm.get_cmap(\"viridis\", npts)\n",
    "colors = cmap.colors\n",
    "sm = amp_plt.skymap()\n",
    "fig, ax = sm.figure(tex=False)\n",
    "\n",
    "# Fixed initial center point\n",
    "x1, y1 = amp_plt.EquCoordsToMapCoords(ra1, dec1)\n",
    "ax.plot(x1, y1, \"C2o\", label=\"orig\")\n",
    "\n",
    "# Fixed positions around (ra1, dec1) that shall be rotated to (ra0, dec0)\n",
    "t = np.linspace(0, 2 * np.pi, npts)\n",
    "ra3 = radius * np.cos(t) + ra1\n",
    "dec3 = radius * np.sin(t) + dec1\n",
    "x3, y3 = amp_plt.EquCoordsToMapCoords(ra3, dec3)\n",
    "\n",
    "for i in range(npts):\n",
    "    ax.plot(x3[i], y3[i], marker=\".\", ls=\"\", color=colors[i])\n",
    "\n",
    "# Now rotate to various places\n",
    "for ra2, dec2 in zip(ra2_all, dec2_all):\n",
    "    ra3t, dec3t = rotator(ra1, dec1,\n",
    "                          np.repeat([ra2], npts), np.repeat([dec2], npts),\n",
    "                          ra3, dec3)\n",
    "\n",
    "    x2, y2 = amp_plt.EquCoordsToMapCoords(ra2, dec2)\n",
    "    ax.plot(x2, y2, \"C1o\")\n",
    "\n",
    "    ax.arrow(x1[0], y1[0], (x2 - x1)[0], (y2 - y1)[0], fc=\"C7\", ec=\"C7\",\n",
    "             length_includes_head=True, head_width=0.05, head_length=0.1)\n",
    "\n",
    "    x3t, y3t = amp_plt.EquCoordsToMapCoords(ra3t, dec3t)\n",
    "\n",
    "    for i in range(npts):\n",
    "        ax.plot(x3t[i], y3t[i], marker=\".\", ls=\"\", color=colors[i])\n",
    "\n",
    "ax.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BG Rate Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test if fit, sample and integral works, with a simple example.\n",
    "First for only a single source."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### SinusRateFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define parameters for the test function\n",
    "period_days = 300.\n",
    "b = 2 * np.pi / period_days  # Period in 1/MJD\n",
    "c = 0  # t-Offset in MJD\n",
    "d = 1  # Rate offset in Hz = 1 evt/sec is average -> 86400 evts/day\n",
    "a = d / 2.  # Amplitude in Hz = +- 0.5 evts / per second\n",
    "pars = np.array([a, b, c, d])\n",
    "\n",
    "sinfun = RateFunc.SinusRateFunction()\n",
    "\n",
    "# Plot function\n",
    "t0, t1 = c, c + period_days\n",
    "t = np.linspace(0, t1, 200)  # In MJD days\n",
    "y = sinfun.fun(t, pars)\n",
    "\n",
    "_ = plt.plot(t, y, lw=2, label=\"fun\")\n",
    "\n",
    "# Plot integral\n",
    "intgrl = np.zeros_like(t)\n",
    "for i, ti in enumerate(t):\n",
    "    intgrl[i] = sinfun.integral(t=t0, trange=[t0, ti*secinday], pars=pars)\n",
    "    \n",
    "# Scale integral, we expect 24*3600=86400 evts/day * (period_days days)\n",
    "print(\"Expect   : \", secinday * t1)\n",
    "print(\"Integral : \", intgrl[-1])\n",
    "_ = plt.plot(t, intgrl / 1e7, lw=2, label=\"integral/1e7\")\n",
    "\n",
    "# Sample from whole range and scale normed hist with time scale to match rate\n",
    "nsam = [int(1e4),]\n",
    "trange = np.array([[t0, t1],]) * secinday\n",
    "sam = sinfun.sample(t=t0, trange=trange,\n",
    "                    pars=pars, n_samples=nsam)\n",
    "h, b = np.histogram(sam, range=[t0, t1], bins=50, density=True)\n",
    "m = get_binmids([b])[0]\n",
    "_ = plt.hist(m, bins=b, weights=h * (t1 - t0), color=\"C0\",\n",
    "             alpha=0.5, label=\"sampled\")\n",
    "\n",
    "# Finally fit the sampled points again\n",
    "runtime = (t1 - t0)\n",
    "p0 = None  # Test default args\n",
    "bf_pars = sinfun.fit(t=m, rate=h * (t1 - t0), rate_std=None, p0=p0)\n",
    "yfit = sinfun.fun(t, bf_pars)\n",
    "_ = plt.plot(t, yfit, lw=2, color=\"C3\", ls=\"--\", label=\"fitted\")\n",
    "p0 = sinfun._get_default_seed(t=m, rate=h * (t1 - t0),\n",
    "                              rate_std=np.ones_like(m))\n",
    "yseed = sinfun.fun(t, p0)\n",
    "_ = plt.plot(t, yseed, lw=2, color=\"C3\", ls=\"-\", alpha=0.3,\n",
    "             label=\"default seed\")\n",
    "\n",
    "plt.xlabel(\"time in MJD\")\n",
    "plt.ylabel(\"rate in Hz\")\n",
    "_ = plt.ylim(0, None)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"data/figs/rate_function_sinus.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sinus1yrRateFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The same as above, but now with fixed period of 1 year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define parameters for the test function\n",
    "period_days = 365.25\n",
    "c = 0  # t-Offset in MJD\n",
    "d = 1  # Rate offset in Hz = 1 evt/sec is average -> 86400 evts/day\n",
    "a = d / 2.  # Amplitude in Hz = +- 0.5 evts / per second\n",
    "pars = np.array([a, c, d])\n",
    "\n",
    "sinfun = RateFunc.Sinus1yrRateFunction()\n",
    "\n",
    "# Plot function\n",
    "t0, t1 = c, c + period_days\n",
    "t = np.linspace(0, t1, 200)  # In MJD days\n",
    "y = sinfun.fun(t, pars)\n",
    "\n",
    "_ = plt.plot(t, y, lw=2, label=\"fun\")\n",
    "\n",
    "# Plot integral\n",
    "intgrl = np.zeros_like(t)\n",
    "for i, ti in enumerate(t):\n",
    "    intgrl[i] = sinfun.integral(t=t0, trange=[t0, ti*secinday], pars=pars)\n",
    "    \n",
    "# Scale integral, we expect 24*3600=86400 evts/day * (period_days days)\n",
    "print(\"Expect   : \", secinday * t1)\n",
    "print(\"Integral : \", intgrl[-1])\n",
    "_ = plt.plot(t, intgrl / 1e7, lw=2, label=\"integral/1e7\")\n",
    "\n",
    "# Sample from whole range and scale normed hist with time scale to match rate\n",
    "nsam = int(1e4)\n",
    "sam = sinfun.sample(t=t0, trange=[t0, t1*secinday], pars=pars, n_samples=nsam)\n",
    "h, b = np.histogram(sam, range=[t0, t1], bins=50, density=True)\n",
    "m = get_binmids([b])[0]\n",
    "_ = plt.hist(m, bins=b, weights=h * (t1 - t0), color=\"C0\",\n",
    "             alpha=0.5, label=\"sampled\")\n",
    "\n",
    "# Finally fit the sampled points again\n",
    "runtime = (t1 - t0)\n",
    "p0 = None  # Test default args\n",
    "bf_pars = sinfun.fit(t=m, rate=h * (t1 - t0), rate_std=None, p0=p0)\n",
    "yfit = sinfun.fun(t, bf_pars)\n",
    "_ = plt.plot(t, yfit, lw=2, color=\"C3\", ls=\"--\", label=\"fitted\")\n",
    "p0 = sinfun._get_default_seed(t=m, rate=h * (t1 - t0),\n",
    "                              rate_std=np.ones_like(m))\n",
    "yseed = sinfun.fun(t, p0)\n",
    "_ = plt.plot(t, yseed, lw=2, color=\"C3\", ls=\"-\", alpha=0.3,\n",
    "             label=\"default seed\")\n",
    "\n",
    "plt.xlabel(\"time in MJD\")\n",
    "plt.ylabel(\"rate in Hz\")\n",
    "_ = plt.ylim(0, None)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"data/figs/rate_function_sinus1yr.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ConstantRateFunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Use constant rate function but leave the sinus to see how the fit behaves.\n",
    "Otherwise it would be boring to just see 3 flat lines over another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define sinus parameters\n",
    "period_days = 365.25\n",
    "c = 0  # t-Offset in MJD\n",
    "d = 1  # Rate offset in Hz = 1 evt/sec is average -> 86400 evts/day\n",
    "a = d / 2.  # Amplitude in Hz = +- 0.5 evts / per second\n",
    "sinpars = np.array([a, c, d])\n",
    "\n",
    "# Same for the constant function.\n",
    "constpars = (d,)\n",
    "\n",
    "sinfun = RateFunc.Sinus1yrRateFunction()\n",
    "constfun = RateFunc.ConstantRateFunction()\n",
    "\n",
    "# Plot sinus and constant function\n",
    "t0, t1 = c, c + period_days\n",
    "t = np.linspace(0, t1, 200)  # In MJD days\n",
    "y = sinfun.fun(t, sinpars)\n",
    "yc = constfun.fun(t, constpars)\n",
    "\n",
    "_ = plt.plot(t, y, color=\"C0\", lw=2, ls=\"--\")\n",
    "_ = plt.plot(t, yc, lw=2, label=\"fun\")\n",
    "\n",
    "# Plot integral\n",
    "intgrl = np.zeros_like(t)\n",
    "for i, ti in enumerate(t):\n",
    "    intgrl[i] = constfun.integral(t=t0, trange=[t0, ti*secinday],\n",
    "                                  pars=constpars)\n",
    "    \n",
    "# Scale integral, we expect 24*3600=86400 evts/day * (period_days days)\n",
    "print(\"Expect   : \", secinday * t1)\n",
    "print(\"Integral : \", intgrl[-1])\n",
    "_ = plt.plot(t, intgrl / 1e7, lw=2, label=\"integral/1e7\")\n",
    "\n",
    "# Sample from whole range and scale normed hist with time scale to match rate\n",
    "nsam = int(1e4)\n",
    "sam = sinfun.sample(t=t0, trange=[t0, t1*secinday], pars=sinpars,\n",
    "                      n_samples=nsam)\n",
    "h, b = np.histogram(sam, range=[t0, t1], bins=50, density=True)\n",
    "m = get_binmids([b])[0]\n",
    "_ = plt.hist(m, bins=b, weights=h * (t1 - t0), color=\"C0\",\n",
    "             alpha=0.5, label=\"sampled\")\n",
    "\n",
    "# Finally fit the sampled points again\n",
    "runtime = (t1 - t0)\n",
    "p0 = None  # Test default args\n",
    "bf_pars = constfun.fit(t=m, rate=h * (t1 - t0), rate_std=None, p0=p0)\n",
    "yfit = constfun.fun(t, bf_pars)\n",
    "_ = plt.plot(t, yfit, lw=2, color=\"C3\", ls=\"--\", label=\"fitted\")\n",
    "p0 = constfun._get_default_seed(t=m, rate=h * (t1 - t0),\n",
    "                                rate_std=np.ones_like(m))\n",
    "yseed = constfun.fun(t, p0)\n",
    "_ = plt.plot(t, yseed, lw=2, color=\"C3\", ls=\"-\", alpha=0.3,\n",
    "             label=\"default seed\")\n",
    "\n",
    "plt.xlabel(\"time in MJD\")\n",
    "plt.ylabel(\"rate in Hz\")\n",
    "_ = plt.ylim(0, None)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"data/figs/rate_function_const.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sinus fit with constant sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The fit is done with a sinus function to describe the bg rate properly.\n",
    "But the sampling is just uniform in each time window to skip rejection sampling and to mimic older analysis.\n",
    "\n",
    "So if we choose some windows small enought, then we basically can not differentiate between this methof and the true rejection sampling, because the sinus is pretty flat.\n",
    "\n",
    "If we increase the time windows we see, that we sample truly uniformly and do not follow the sinus shape anymore.\n",
    "\n",
    "We leave the integral and the fit out this time, because they are all derived from the Sinus1yrRateFunction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define sinus parameters\n",
    "period_days = 365.25\n",
    "c = 0  # t-Offset in MJD\n",
    "d = 1  # Rate offset in Hz = 1 evt/sec is average -> 86400 evts/day\n",
    "a = d / 2.  # Amplitude in Hz = +- 0.5 evts / per second\n",
    "sinpars = np.array([a, c, d])\n",
    "\n",
    "rndgen = np.random.RandomState(7353)\n",
    "sinfun = RateFunc.Sinus1yrConstRateFunction(random_state=rndgen)\n",
    "\n",
    "# Plot true sinus function defining the rate\n",
    "t0, t1 = c, c + period_days\n",
    "t = np.linspace(0, t1, 200)  # In MJD days\n",
    "y = sinfun.fun(t, sinpars)\n",
    "_ = plt.plot(t, y, lw=2, label=\"fun\")\n",
    "\n",
    "# 1. Sample from whole range: See the unifrom samples averaging the sine\n",
    "nsam = int(1e4)\n",
    "sam = sinfun.sample(t=t0, trange=[t0, t1*secinday], pars=sinpars,\n",
    "                      n_samples=[nsam])\n",
    "h, b = np.histogram(sam, range=[t0, t1], bins=50, density=True)\n",
    "m = get_binmids([b])[0]\n",
    "_ = plt.hist(m, bins=b, weights=h * (t1 - t0), color=\"C0\",\n",
    "             alpha=0.5, label=\"full range\")\n",
    "\n",
    "# 2. Make finer sampling windows: See how the rate matches the sines better\n",
    "t0s = np.linspace(t0, t1, 20)[:-1]\n",
    "dts = np.repeat([[0., np.diff(t0s)[0]]], len(t0s), axis=0) * secinday\n",
    "# Get the integral to see how many we must sample (as in bg_rate_injector)\n",
    "expect = sinfun.integral(t0s, dts, sinpars)\n",
    "expect = np.round(expect).astype(int)  # Keep it easy: No poisson sampling\n",
    "\n",
    "fine_sam = sinfun.sample(t=t0s, trange=dts, pars=sinpars, n_samples=expect)\n",
    "fine_sam = flatten_list_of_1darrays(fine_sam)\n",
    "h, b = np.histogram(fine_sam, range=[t0, t1], bins=50, density=True)\n",
    "m = get_binmids([b])[0]\n",
    "_ = plt.hist(m, bins=b, weights=h * (t1 - t0), color=\"C0\",\n",
    "             alpha=0.5, label=\"small windows\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"time in MJD\")\n",
    "plt.ylabel(\"rate in Hz\")\n",
    "_ = plt.ylim(0, None)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"data/figs/rate_function_sinus_uniform_sample.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "See how it gets faster with uniform sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def fun(t):\n",
    "    return sinfun.fun(t, sinpars)\n",
    "\n",
    "bound = [[0, 10]]\n",
    "fmax = fun(bound[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "rejection_sampling(fun, bounds=bound, n_samples=100, max_fvals=fmax, rndgen=rndgen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit\n",
    "sinfun.sample(0., bound, sinpars, n_samples=[100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LLH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test the LLH module.\n",
    "\n",
    "It contains all functions for a specific LLH we want to use in our analysis.\n",
    "Currently GRBLLH is implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "init_cell": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sin_dec_bins = np.linspace(-1, 1, 50)\n",
    "\n",
    "min_logE = 1  #  min(np.amin(_exp[\"logE\"]), np.amin(mc[\"logE\"]))\n",
    "max_logE = 10 #  max(np.amax(_exp[\"logE\"]), np.amax(mc[\"logE\"]))\n",
    "logE_bins = np.linspace(min_logE, max_logE, 40)\n",
    "\n",
    "spatial_pdf_args = {\"bins\": sin_dec_bins, \"k\": 3, \"kent\": True}\n",
    "\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins],\n",
    "                   \"gamma\": 2., \"fillval\": \"col\", \"interpol_log\": False}\n",
    "\n",
    "time_pdf_args = {\"nsig\": 4., \"sigma_t_min\": 2., \"sigma_t_max\": 30.}\n",
    "\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Time PDF Ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Reproduce the paper plot.\n",
    "\n",
    "Note that we get the PDFs for all srcs at once.\n",
    "Their times are just all the same here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make a plot with ratios for different time windows as in the paper\n",
    "# dt from t0 in seconds, clip at 4 sigma\n",
    "dts = np.array([[-1, 5], [-5, 50], [-20, 200]])\n",
    "nsrcs = len(dts)\n",
    "nsig = 4.\n",
    "\n",
    "# Arbitrary start date. Choose t0 all the same for plotting\n",
    "t0 = 50500.\n",
    "t0_sec = t0 * secinday\n",
    "\n",
    "# Make t values for plotting in MJD around t0, to fit all in one plot\n",
    "max_dt, min_dt = np.amax(dts), np.amin(dts)\n",
    "dt_tot = max_dt - min_dt\n",
    "clip = np.clip(dt_tot, 2, 30) * nsig\n",
    "plt_range = np.array([min_dt - clip, max_dt + clip])\n",
    "\n",
    "npts = 1000\n",
    "t = np.linspace(t0_sec + 1.2 * plt_range[0],\n",
    "                t0_sec + 1.2 * plt_range[1], npts) / secinday\n",
    "\n",
    "_t = t * secinday - t0 * secinday\n",
    "\n",
    "# Mark t0 = 0 = rel. src time\n",
    "plt.axvline(0, 0, 1, c=\"k\", ls=\"--\", lw=2, alpha=0.8)\n",
    "\n",
    "# # Get all at once\n",
    "SoB = grbllh._soverb_time(t=t, src_t=np.repeat([t0], nsrcs), dt=dts)\n",
    "assert len(SoB) == nsrcs\n",
    "\n",
    "colors = [\"C0\", \"C3\", \"C2\"]\n",
    "for i in range(nsrcs):\n",
    "    # Plot seperately to give colors and labels\n",
    "    plt.plot(_t, SoB[i], lw=2, c=colors[i],\n",
    "             label=r\"$T_\\mathrm{{uni}}$: {:>3d}s, {:>3d}s\".format(*dts[i]))\n",
    "\n",
    "# Make it look like the paper plot, but with slightly extended borders\n",
    "plt.xlim(1.2 * plt_range)\n",
    "plt.ylim(0, np.amax(SoB) * 1.05)\n",
    "plt.xlabel(\"t - t0 in sec\")\n",
    "plt.ylabel(\"S / B\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.grid(ls=\"--\", lw=1)\n",
    "\n",
    "# plt.savefig(\"./data/figs/time_pdf_ratio.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get the injection time window.\n",
    "This is needed for the injector, so only events in regions with non-zero PDF are injected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"dts:\\n\", dts)\n",
    "print(\"\\nclip range:\\n\", np.hstack((dts[:, [0]] - clip, dts[:, [1]] + clip)))\n",
    "print(\"\\nsigma clips:\\n\", grbllh.time_pdf_def_range(np.repeat([t0], nsrcs),\n",
    "                                                    dts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compare manually\n",
    "dts = np.array([[-1, 5], [-5, 50], [-20, 200]], dtype=np.float)\n",
    "nsig, sig_min, sig_max = time_pdf_args.values()  # Beware if order is wrong :P\n",
    "clip = np.clip(np.diff(dts, axis=1), sig_min, sig_max) * nsig\n",
    "dts[:, 0] -= clip.reshape(len(dts))  # Same as flatten()\n",
    "dts[:, 1] += clip.flatten()\n",
    "\n",
    "dts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Spatial background spline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the same technique as used in skylab, but with an extra step of adding the outermost bin edges to the spline gridpoints.\n",
    "This way, the spline behaves reasonable at the edges and doesn't overshoot.\n",
    "\n",
    "We could extend this by using the KDE integrated over every variable and then fitting a spline to that.\n",
    "Or we could sample from the KDE and bin finely and fit a splien again.\n",
    "\n",
    "For now we leave only the option to use data directly.\n",
    "The spline fit is depending on the binning anyway.\n",
    "Only the finely binned KDE version could resolve that issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sin_dec = np.linspace(-1.05, 1.05, 200)\n",
    "y = np.exp(grbllh._spatial_bg_spl(sin_dec))\n",
    "_ = plt.hist(np.sin(_exp[\"dec\"]), bins=50, normed=True)\n",
    "plt.plot(sin_dec, y, lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Spatial background pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Should be identical to calling the spline directly, except that the BG PDF is normalized to the whole sphere.\n",
    "So we multiply the values by 2pi to account for that.\n",
    "\n",
    "Here we see the difference to just calling the spline directly: The PDF is zero outside the definition range, the spline extrapolated.\n",
    "We raise an error if that happens, because we can expect that this is not wanted and caused by carelessness of the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_ = plt.hist(np.sin(_exp[\"dec\"]), bins=grbllh.spatial_pdf_args[\"bins\"],\n",
    "             normed=True)\n",
    "# sin_dec = np.linspace(-1.05, 1.05, 200)  # Will throw an error a wanted\n",
    "sin_dec = np.linspace(-1., 1., 200)\n",
    "y = 2 * np.pi * grbllh._pdf_spatial_background(ev_sin_dec=sin_dec)\n",
    "plt.plot(sin_dec, y, lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Spatial signal PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Compare signal and BG pdf.\n",
    "\n",
    "First we create multiple sources and a single event and scan the event PDF by moving the event along the declination axis.\n",
    "All PDFs have the height, because the same sigma is used.\n",
    "\n",
    "Note that BG is here usually very small compared to the signal, because we sample the ev positions within 1 sigma around the source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LOG = False\n",
    "\n",
    "nsrcs = 4\n",
    "# Choose the event sigma from data\n",
    "ev_sigma = np.random.choice(_exp[\"sigma\"], size=1)\n",
    "\n",
    "# Make nsrcs, same ra, but different dec. decs are distributed uniformly in\n",
    "# the range of the largest sigma from the events (for illustration only)\n",
    "src_dec = np.random.uniform(-ev_sigma, ev_sigma, size=nsrcs)\n",
    "src_ra = np.ones_like(src_dec) * np.pi\n",
    "plt_rnge = [np.amin(src_dec) - ev_sigma, np.amax(src_dec) + ev_sigma]\n",
    "\n",
    "# Scan signal PDF for event declination\n",
    "ev_dec = np.sin(np.linspace(plt_rnge[0], plt_rnge[1], 200))\n",
    "ev_sin_dec = np.sin(ev_dec)\n",
    "ev_ra = src_ra[0] * np.ones_like(ev_sin_dec)\n",
    "ev_sig = np.ones_like(ev_sin_dec) * ev_sigma\n",
    "\n",
    "# y has shape (nsrcs, nevts), where nevts are the ev_sin_dec values here (scan)\n",
    "y = grbllh._pdf_spatial_signal(src_ra, src_dec, ev_ra, ev_sin_dec, ev_sig)\n",
    "\n",
    "if LOG:\n",
    "    y = np.log10(y)\n",
    "\n",
    "plt.plot(ev_dec, y.T, lw=2)\n",
    "plt.vlines(src_dec, 0, np.amax(y), color=\"C7\", linestyles=\"--\", lw=2,\n",
    "           label=\"srcs pos\")\n",
    "\n",
    "# Plot BG PDF to compare\n",
    "bg = grbllh._pdf_spatial_background(ev_sin_dec=ev_sin_dec)\n",
    "plt.plot(ev_dec, bg, lw=2, label=\"BG\")\n",
    "\n",
    "plt.xlim(*plt_rnge)\n",
    "if LOG:\n",
    "    plt.ylim(1e-5, 1.1 * np.amax(y))\n",
    "else:\n",
    "    plt.ylim(0, 1.1 * np.amax(y))\n",
    "    \n",
    "    \n",
    "plt.xlabel(\"dec\")\n",
    "plt.ylabel(\"PDF per src\")\n",
    "plt.legend()\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we use multiple events with different sigmas and scan again in declination by moving a single possible src position.\n",
    "We get different heights, because of the different sigmas.\n",
    "\n",
    "The PDFs each peak where the event position is.\n",
    "If we had a single source, we would just read off the values at that position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LOG = True\n",
    "# Make nevts, same ra, but different dec. sigmas chosen from data\n",
    "nevts = 4\n",
    "ev_sigma = np.random.choice(_exp[\"sigma\"], size=nevts)\n",
    "# Sample some evt decs uniformly around the horizon with spread of the largest \n",
    "# sigma to get some variation\n",
    "max_sig = np.amax(ev_sigma)\n",
    "ev_dec = np.random.uniform(-max_sig, max_sig, size=nevts)\n",
    "ev_sin_dec = np.sin(ev_dec)\n",
    "ev_ra = np.ones_like(ev_dec) * np.pi\n",
    "\n",
    "# Plot margin PDF scanned for each src position for each event position\n",
    "src_dec = np.linspace(-2. * max_sig, 2 * max_sig, 200)\n",
    "src_ra = ev_ra[0] * np.ones_like(src_dec)\n",
    "\n",
    "# This has shape (nsrcs, nevts)\n",
    "y = grbllh._pdf_spatial_signal(src_ra, src_dec, ev_ra, ev_sin_dec, ev_sigma)\n",
    "\n",
    "if LOG:\n",
    "    y = np.log10(y)\n",
    "\n",
    "plt.plot(src_dec, y, lw=2)\n",
    "\n",
    "plt.vlines(ev_dec, 0, np.amax(y) * 1.1, color=\"C7\",\n",
    "           linestyles=\"--\", label=\"evts pos\")\n",
    "\n",
    "# Plot BG PDF to compare\n",
    "bg = grbllh._pdf_spatial_background(ev_sin_dec=np.sin(src_dec))\n",
    "plt.plot(src_dec, bg, lw=2, label=\"BG\")\n",
    "\n",
    "plt.xlim(src_dec[[0, -1]])\n",
    "if LOG:\n",
    "    plt.ylim(1e-5, 1.1 * np.amax(y))\n",
    "else:\n",
    "    plt.ylim(0, 1.1 * np.amax(y))\n",
    "    \n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Spatial PDF ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_dec_vs_signal(S, ev_dec, src_ra, src_dec, weights, ax=None):\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "    # Plot signal per source for each event\n",
    "    for i, (sra, sdec) in enumerate(zip(src_ra, src_dec)):\n",
    "        ax.plot(np.rad2deg(ev_dec), S[i], ls=\"-\")\n",
    "        ax.plot(np.rad2deg(sdec), -10, \"k|\")\n",
    "\n",
    "    # Simulate a simple stacking, one weight per source\n",
    "    ax.plot(np.rad2deg(ev_dec), np.sum(weights * S, axis=0) / np.sum(weights),\n",
    "             ls=\"--\", c=dg, label=\"stacked\")\n",
    "\n",
    "    ax.set_xlim([-1 + smin, smax + 1])\n",
    "    ax.set_xlabel(\"DEC in °\")\n",
    "    ax.set_ylabel(\"Signal pdf\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We make 4 plots to test everything:\n",
    "\n",
    "1. [Top left] We place densely packed srcs at the declination range and scan the PDFs by varying the event declinations.\n",
    "   Sigma is fixed to 1 for illustration.\n",
    "   We expect just a row of gaussians along the dec range.\n",
    "   The stacked signal is the weighted sum of all signal contributions at a single event dec position.\n",
    "   \n",
    "2. [Bottom left] We plot just the background PDF and its inverse for the dec range.\n",
    "   The inverse PDF is what modulates the signal PDF.\n",
    "   \n",
    "3. [Top right] This modulation can be seen in this plot.\n",
    "   It is basically the same as the first one, but now it's signal over background.\n",
    "   So the signal peaks are modulated with the inverse BG PDF.\n",
    "   \n",
    "4. [Bottom right] This is the same plot as the third one, but this time we use the real data declination values instead of nicely spaced ones.\n",
    "   The effect is the same but not reall visible, because each event has a different sigma, so the PDFs all have different heights and widths.\n",
    "   It becomes more similar when using an 1° sigma for all events (just comment that line in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make srcs across the dec range. The hull of SoB should be shaped like the\n",
    "# 1/(sinDec BG distribtuion). With a single source we couldn't see that,\n",
    "# because it drops to zero far from the src position\n",
    "smin, smax, step = -90, +90, 10\n",
    "src_ra = np.deg2rad(np.arange(smin, smax + step, step))\n",
    "src_dec = np.deg2rad(np.arange(smin, smax + step, step))\n",
    "\n",
    "# Scan in dec by varying the evts dec\n",
    "ev_ra = np.deg2rad(np.linspace(smin, smax, 1000))\n",
    "ev_dec = np.deg2rad(np.linspace(smin, smax, 1000))\n",
    "ev_sin_dec = np.sin(ev_dec)\n",
    "ev_sig = np.deg2rad(np.ones_like(ev_ra))\n",
    "\n",
    "# Some pseudo weights to simulate stacking\n",
    "weights = np.arange(1, len(src_dec) + 1)[:, np.newaxis]\n",
    "\n",
    "fig, ((axtl, axtr), (axbl, axbr)) = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Signal only (kent vs. gaus should look the same here)\n",
    "grbllh.spatial_pdf_args[\"kent\"] = True\n",
    "S = grbllh._pdf_spatial_signal(src_ra, src_dec, ev_ra, ev_sin_dec, ev_sig)\n",
    "_ = plot_dec_vs_signal(S, ev_dec, src_ra, src_dec, weights, ax=axtl)\n",
    "axtl.set_xlim(-90, 90)\n",
    "\n",
    "# Background only\n",
    "bins = grbllh.spatial_pdf_args[\"bins\"]\n",
    "h, b = np.histogram(np.sin(_exp[\"dec\"]), bins=bins, density=True)\n",
    "m = 0.5 * (b[:-1] + b[1:])\n",
    "_ = axbl.hist(m, bins=bins, weights=h / 2 / np.pi, alpha=0.5)\n",
    "_sin_dec = np.linspace(-1, 1, 1000)\n",
    "bg_pdf = grbllh._pdf_spatial_background(_sin_dec)\n",
    "axbl.plot(_sin_dec, bg_pdf, lw=2, label=\"pdf\")\n",
    "axbl.set_ylim(0, 0.2)\n",
    "# 1 / BG PDF on second axis\n",
    "axbl2 = axbl.twinx()\n",
    "axbl2.plot(_sin_dec, 1. / bg_pdf, c=\"C2\", lw=2, ls=\"--\", label=\"1/pdf\")\n",
    "axbl2.set_ylim(0, (1 / bg_pdf).max())\n",
    "axbl.set_xlabel(\"sinus DEC\")\n",
    "axbl.set_xlim(-1, 1)\n",
    "axbl.legend(loc=\"upper left\")\n",
    "axbl2.legend(loc=\"upper center\")\n",
    "\n",
    "# SoB on example + BG PDF\n",
    "SoB = grbllh._soverb_spatial(src_ra, src_dec, ev_ra, ev_sin_dec, ev_sig)\n",
    "weights = np.arange(1, len(src_dec) + 1)[:, np.newaxis]\n",
    "_ = plot_dec_vs_signal(SoB, ev_dec, src_ra, src_dec, weights, ax=axtr)\n",
    "axtr.plot(np.rad2deg(np.arcsin(_sin_dec)), bg_pdf, lw=3, label=\"BG pdf\", c=dg)\n",
    "axtr.set_xlim(-90, 90)\n",
    "axtr.set_yscale(\"log\")\n",
    "axtr.set_ylim(np.amin(bg_pdf), 1e5)\n",
    "axtr.legend(loc=\"upper left\")\n",
    "\n",
    "# Now with the real data. Sort first in dec to show with nice lines + BG PDF\n",
    "idx = np.argsort(exp[\"dec\"])\n",
    "ev_ra = exp[\"ra\"][idx]\n",
    "ev_dec = exp[\"dec\"][idx]\n",
    "ev_sin_dec = np.sin(ev_dec)\n",
    "ev_sig = exp[\"sigma\"][idx]\n",
    "# Comment in to match the simple example (all events have sigma 1°)\n",
    "# ev_sig = np.deg2rad(np.ones_like(ev_ra))\n",
    "SoB = grbllh._soverb_spatial(src_ra, src_dec, ev_ra, ev_sin_dec, ev_sig)\n",
    "\n",
    "_ = plot_dec_vs_signal(SoB, ev_dec, src_ra, src_dec, weights, ax=axbr)\n",
    "axbr.plot(np.rad2deg(np.arcsin(_sin_dec)), bg_pdf,\n",
    "          lw=3, label=\"BG pdf\", c=\"C0\")\n",
    "axbr.set_yscale(\"log\")\n",
    "axbr.set_ylim(np.amin(bg_pdf), 1e5)\n",
    "axbr.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Energy ratio spline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the creation of the signal over background ratio for the energy PDF.\n",
    "It is resolved in sinDec and logE to account for different positions on the sky and energies.\n",
    "\n",
    "Missing values, where no data or MC is present is filled with interpolation values, conttrolled by the \"fillval\" option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test col vs minmax. Also try different interpolations in linear or\n",
    "# logspace. Log interpolation falls off more quickly to the edge values.\n",
    "fig, (al, ar) = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins],\n",
    "                   \"gamma\": 2., \"fillval\": \"col\", \"interpol_log\": False}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args)\n",
    "\n",
    "# Ratio spline with 'col' filling\n",
    "x = np.linspace(-1.1, 1.1, num=1000 + 1)\n",
    "y = np.linspace(0.5, 10.5, num=1000 + 1)\n",
    "XX, YY = np.meshgrid(x, y)\n",
    "xx, yy = map(np.ravel, [XX, YY])\n",
    "gpts = np.vstack((xx, yy)).T\n",
    "zz = np.exp(grbllh._energy_spl(gpts))\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "# Plotting with hist creates strange effects... Use pcolormesh instead\n",
    "img = al.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "al.set_title(\"Spline interpolation: 'col'\")\n",
    "plt.colorbar(ax=al, mappable=img)\n",
    "\n",
    "# With 'minmax' filling. Note: The small values in the lower row are due to\n",
    "# plotting in log. We interpolate in linear space, so in log, the jump is\n",
    "# very steep for small values.\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins],\n",
    "                   \"gamma\": 2., \"fillval\": \"minmax\", \"interpol_log\": False}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args)\n",
    "\n",
    "zz = np.exp(grbllh._energy_spl(gpts))\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "img = ar.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "ar.set_title(\"Spline interpolation: 'minmax'\")\n",
    "plt.colorbar(ax=ar, mappable=img)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test min vs minmax. Only with interpol log we see the structure, because\n",
    "# Otherwise only in the last bin we get below 1, so the colors are mostly\n",
    "# red in the log norm color scale.\n",
    "fig, (al, ar) = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins],\n",
    "                   \"gamma\": 2., \"fillval\": \"min\", \"interpol_log\": True}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args)\n",
    "\n",
    "# Ratio spline with 'col' filling\n",
    "x = np.linspace(-1.1, 1.1, num=1000 + 1)\n",
    "y = np.linspace(0.5, 10.5, num=1000 + 1)\n",
    "XX, YY = np.meshgrid(x, y)\n",
    "xx, yy = map(np.ravel, [XX, YY])\n",
    "gpts = np.vstack((xx, yy)).T\n",
    "zz = np.exp(grbllh._energy_spl(gpts))\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "# Plotting with hist creates strange effects... Use pcolormesh instead\n",
    "img = al.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "al.set_title(\"Spline interpolation: 'min'\")\n",
    "plt.colorbar(ax=al, mappable=img)\n",
    "\n",
    "# With 'minmax' filling. Note: The small values in the lower row are due to\n",
    "# plotting in log. We interpolate in linear space, so in log, the jump is\n",
    "# very steep for small values.\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins],\n",
    "                   \"gamma\": 2., \"fillval\": \"minmax\", \"interpol_log\": True}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args)\n",
    "\n",
    "zz = np.exp(grbllh._energy_spl(gpts))\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "img = ar.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "ar.set_title(\"Spline interpolation: 'minmax'\")\n",
    "plt.colorbar(ax=ar, mappable=img)\n",
    "\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Energy PDF ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we see again the difference to the direct spline evaluation.\n",
    "The ratio function set's values outside to zero probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, (al, ar) = plt.subplots(1, 2, figsize=(14,5))\n",
    "\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins],\n",
    "                   \"gamma\": 2., \"fillval\": \"col\", \"interpol_log\": True}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args)\n",
    "\n",
    "# Ratio spline with 'col' filling\n",
    "x = np.linspace(-1.1, 1.1, num=1000 + 1)\n",
    "y = np.linspace(0.5, 10.5, num=1000 + 1)\n",
    "XX, YY = np.meshgrid(x, y)\n",
    "xx, yy = map(np.ravel, [XX, YY])\n",
    "gpts = np.vstack((xx, yy)).T\n",
    "zz = grbllh._soverb_energy(xx, yy)\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "# Plotting with hist creates strange effects... Use pcolormesh instead\n",
    "img = al.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "al.set_title(\"Spline interpolation: 'col'\")\n",
    "plt.colorbar(ax=al, mappable=img)\n",
    "\n",
    "# With 'minmax' filling. Note: The small values in the lower row are due to\n",
    "# plotting in log. We interpolate in linear space, so in log, the jump is\n",
    "# very steep for small values.\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins],\n",
    "                   \"gamma\": 2., \"fillval\": \"minmax\", \"interpol_log\": True}\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args)\n",
    "\n",
    "zz = grbllh._soverb_energy(xx, yy)\n",
    "ZZ = zz.reshape(XX.shape)\n",
    "img = ar.pcolormesh(XX, YY, ZZ, norm=LogNorm(), cmap=\"coolwarm\",\n",
    "                    vmin=1e-3, vmax=1e3)\n",
    "ar.set_title(\"Spline interpolation: 'minmax'\")\n",
    "plt.colorbar(ax=ar, mappable=img)\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Detector source weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We use the same spline method to create a spline describing the sinDec dependence of a signal MC weighted to a specific astrophysical flux modell (usually unbroken power law).\n",
    "\n",
    "Depending on the src position, we expect more or less signal from that src.\n",
    "This is equivalent to folding with the detector exposure function.\n",
    "\n",
    "Our stacking form is described by a multi position search where the signal term gets modified to:\n",
    "\n",
    "$$\n",
    "    S^\\text{tot} = \\sum_{j=1}^{N_\\text{srcs}} w_j S_{ij} \\quad\\text{with}\\quad\n",
    "    \\sum_j w_j = 1 \\quad\\text{with}\\quad w_j = w_j^\\text{theo}\\cdot w_j^\\text{det}\n",
    "$$\n",
    "\n",
    "The weights are a combination of the exposure weights and a-priori fixed intrinsic source weights, eg. from a known gamma flux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Small hack to change the gamma without recreating the grbllh object\n",
    "gamma_override = 2.13\n",
    "\n",
    "grbllh.energy_pdf_args[\"gamma\"] = gamma_override\n",
    "mc_sin_dec = np.sin(mc[\"dec\"])\n",
    "mc_bins = grbllh.energy_pdf_args[\"bins\"][0]\n",
    "mc_dict = {\"trueE\": mc[\"trueE\"], \"ow\": mc[\"ow\"]}\n",
    "\n",
    "grbllh._spatial_signal_spl = grbllh._create_sin_dec_spline(\n",
    "    sin_dec=mc_sin_dec, bins=mc_bins, mc=mc_dict)\n",
    "\n",
    "sin_dec = np.linspace(-1.05, 1.05, 200)\n",
    "y = np.exp(grbllh._spatial_signal_spl(sin_dec))\n",
    "\n",
    "# MC needs proper weighting\n",
    "gamma = grbllh.energy_pdf_args[\"gamma\"]\n",
    "mc_w = mc[\"ow\"] * mc[\"trueE\"]**(-gamma)\n",
    "mc_bins = energy_pdf_args[\"bins\"][0]\n",
    "h, b = np.histogram(np.sin(mc[\"dec\"]), bins=mc_bins, weights=mc_w, normed=True)\n",
    "\n",
    "# Smooth it, charge it, odd it, quick truncate it\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.savgol_filter.html\n",
    "m = get_binmids([b])[0]\n",
    "redux = 10  # Window len is nearest odd number to (number of bins / redux)\n",
    "window_len = int(2 * np.floor((len(b) / redux) / 2) + 1)  # Must be odd\n",
    "_h = scsignal.savgol_filter(h, window_len, 3, mode=\"mirror\")\n",
    "plt.hist(m, bins=b, weights=_h, histtype=\"step\", lw=2, color=\"C1\", ls=\"--\")\n",
    "plt.hist(m, bins=b, weights=h, histtype=\"step\", lw=2, color=\"C3\")\n",
    "\n",
    "# Plot spline (fitted to unsmoothed)\n",
    "plt.plot(sin_dec, y, lw=2, color=\"C2\")\n",
    "\n",
    "# Get weights for some srcs\n",
    "src_sin_dec = np.linspace(-1, 1, 11)\n",
    "src_dec = np.arcsin(src_sin_dec)\n",
    "src_w_theo = np.ones_like(src_dec)\n",
    "w = grbllh.src_weights(src_dec=src_dec, src_w_theo=src_w_theo)\n",
    "\n",
    "# Revoke norm for plotting to see if weights are on the curve\n",
    "src_dec_w = np.exp(grbllh._spatial_signal_spl(src_sin_dec))\n",
    "_w = w * np.sum(src_dec_w * src_w_theo)\n",
    "\n",
    "plt.plot(src_sin_dec, _w, \"wo\", ms=7, mew=1.5, mec=\"k\")\n",
    "plt.vlines(np.sin(src_dec), 0, 1.05 * np.amax(y), colors=\"C7\",\n",
    "           lw=1, linestyles=\"--\")\n",
    "\n",
    "plt.xlabel(\"sin(dec)\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.title(\"$\\gamma = {:.1f}$\".format(gamma))\n",
    "\n",
    "plt.xlim(-1, 1)\n",
    "plt.ylim(0, 1.05 * np.amax(y))\n",
    "plt.tight_layout()\n",
    "\n",
    "print(w)\n",
    "print(w.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we just use some ascending theoretical weights in both directions.\n",
    "\n",
    "- w1 should resemble the sindec curve from above\n",
    "- w2 should rise overall to the right (less steep or reversed from w1)\n",
    "- w3 should fall overall to the right (steeper than w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_src_dec = np.arcsin(np.linspace(-1, 1, 21))\n",
    "\n",
    "# Compare for different theoretical weights\n",
    "src_w_theo = np.ones_like(_src_dec)\n",
    "w1 = grbllh.src_weights(src_dec=_src_dec, src_w_theo=src_w_theo)\n",
    "\n",
    "src_w_theo = np.arange(len(_src_dec)) + 1\n",
    "w2 = grbllh.src_weights(src_dec=_src_dec, src_w_theo=src_w_theo)\n",
    "\n",
    "src_w_theo = (np.arange(len(_src_dec)) + 1)[::-1]\n",
    "w3 = grbllh.src_weights(src_dec=_src_dec, src_w_theo=src_w_theo)\n",
    "\n",
    "plt.plot(np.sin(_src_dec), w1, \"o\", label=\"theo = 1 (orig)\")\n",
    "plt.plot(np.sin(_src_dec), w2, \"o\", label=\"theo = arange\")\n",
    "plt.plot(np.sin(_src_dec), w3, \"o\", label=\"theo = arange[::-1]\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Check if weights are the same when using event density (skylab style) instead.\n",
    "It should make no difference because the weights are normalized anyway.\n",
    "\n",
    "**This will be included, if we get to fitting multiple years.\n",
    "We can then use the same weights for the stacking and for normalizing ns per year.**\n",
    "\n",
    "Note: The normalization and the pivot will not be included in the end, because they are constant for every source and for every dataset/year, so they get normalized out anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Weight with numu diffuse 6yr flux norm, but same index as above\n",
    "index = gamma_override\n",
    "norm = 0.9 * 1e-18  # (GeV s sr cm^2)^-1, valid at 100 TeV = 1e5 GeV\n",
    "pivot = 1e5\n",
    "flux = norm * (mc[\"trueE\"] / pivot)**(-index)\n",
    "mc_w = mc[\"ow\"] * flux * livetime * secinday\n",
    "mc_bins = energy_pdf_args[\"bins\"][0]\n",
    "\n",
    "density = True\n",
    "h, b = np.histogram(np.sin(mc[\"dec\"]), bins=mc_bins, weights=mc_w,\n",
    "                    density=density)\n",
    "\n",
    "# Normalize (same as density=True)\n",
    "if not density:\n",
    "    h /= np.diff(b) * np.sum(h)\n",
    "\n",
    "# PDF * Number of total events = Event densitiy\n",
    "_h = h * mc_w.sum()  \n",
    "\n",
    "mids = get_binmids([mc_bins])[0]\n",
    "_ = plt.hist(mids, bins=mc_bins, weights=_h)\n",
    "\n",
    "# Make spline, use also outermost edges\n",
    "x = np.concatenate((b[[0]], mids, b[[-1]]))\n",
    "y = np.log(_h)\n",
    "y = np.concatenate((y[[0]], y, y[[-1]]))\n",
    "spl = sci.InterpolatedUnivariateSpline(x, y, k=3, ext=\"extrapolate\")\n",
    "\n",
    "x = np.linspace(-1, 1, 100)\n",
    "y = np.exp(spl(x))\n",
    "plt.plot(x, y, \"C1-\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"sindec\")\n",
    "plt.ylabel(\"Event density Nevts / sindec\")\n",
    "\n",
    "# Total events by integrating _h: Ntot = sum_i (_h_i * diff(bins)_i)\n",
    "plt.title(\"Gamma = {:.2f}: Ntot = {:.2f}\".format(\n",
    "        index, np.sum(_h * np.diff(mc_bins))))\n",
    "\n",
    "# Check the weight, deviation from float error I guess\n",
    "src_w_dec = np.exp(spl(src_sin_dec[1:-1]))\n",
    "src_w_theo = np.ones_like(src_dec[1:-1])\n",
    "src_w = src_w_dec * src_w_theo / np.sum(src_w_dec * src_w_theo)\n",
    "\n",
    "plt.plot(src_sin_dec[1:-1], src_w_dec, \"wo\", ms=7, mew=1.5, mec=\"k\")\n",
    "plt.tight_layout()\n",
    "\n",
    "print(\"Spline from PDF only\")\n",
    "print(w[1:-1])\n",
    "\n",
    "print(\"\\nSpline from event density with livetime\")\n",
    "print(src_w.reshape(len(src_w), 1))\n",
    "\n",
    "print(\"\\nRatio\")\n",
    "for ratio in w[1:-1] / np.sum(w[1:-1]) / src_w.reshape(len(src_w), 1):\n",
    "    print(\"[ {:.6f} ]\".format(*ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### ln-LLH ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot llh and gradient.\n",
    "The gradient is calculated analytically.\n",
    "With this test, we simply want to check, if the gradient is OK and the likelihood behaves correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Snippet to plot lnLLH ratio and gradient next each other\n",
    "def plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax, lw=2):\n",
    "    fig, (al, ar) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    al.plot(ns, lnllh, lw=lw)\n",
    "    al.set_xlim(xmin, xmax)\n",
    "    if np.amax(lnllh) == 0.:\n",
    "        al.set_ylim(np.amin(lnllh), 1)\n",
    "    else:\n",
    "        al.set_ylim(0, 1.05 * np.amax(lnllh))\n",
    "    al.axvline(ns_max, 0, 1, ls=\"--\", lw=2, color=\"C7\")\n",
    "    al.set_title(\"LLH\")\n",
    "\n",
    "    ar.plot(ns, lnllh_grad, lw=lw)\n",
    "    ar.axhline(0, 0, 1, ls=\"--\", lw=2, color=\"C7\")\n",
    "    ar.axvline(ns_max, 0, 1, ls=\"--\", lw=2, color=\"C7\")\n",
    "    al.set_xlim(xmin, xmax)\n",
    "    ar.set_ylim(-5, 5)\n",
    "    ar.set_title(\"LLH gradient in ns\")\n",
    "    fig.tight_layout()\n",
    "    return fig, (al, ar)\n",
    "\n",
    "names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "rndgen = np.random.RandomState(7353)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### No Events given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Quickly check if the LLH handles an empty array of events correctly.\n",
    "\n",
    "If no events given, then the per event terms should all be zero.\n",
    "Then the test statistic, which is $\\Lambda = 2 \\cdot \\ln(\\mathcal{L}_1-\\mathcal{L}_0)$ reduces simply to $\\Lambda = -2n_s$.\n",
    "\n",
    "The gradient is then trivially $\\partial_{ns}\\Lambda = -2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make up some setup\n",
    "nsrcs = 1\n",
    "src_t = np.random.choice(_exp[\"timeMJD\"], size=nsrcs)\n",
    "dt = np.array([-20, 200])\n",
    "\n",
    "# Expected background with rate 5mHz, kind of realistic.\n",
    "# Increase nb scale to test different BG expectations.\n",
    "scale = 1e5\n",
    "nb = 0.005 * np.diff(dt) * scale\n",
    "src_ra = np.deg2rad([180])  # Arbitrarily placed single source\n",
    "src_dec = np.deg2rad([10])\n",
    "src_w_theo = np.ones_like(src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((src_t, [dt[0]], [dt[1]],\n",
    "                  [src_ra], [src_dec], src_w_theo))\n",
    "names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                       formats=len(names) * [\"float64\"])\n",
    "args = {\"nb\": nb, \"srcs\": srcs}\n",
    "\n",
    "# Setup zero events = empty array\n",
    "X = np.empty((0,), dtype=[(n, np.float) for n in _exp.dtype.names])\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "xmin, xmax = 0, 20\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "lnllh = np.empty(n_ns)\n",
    "lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    _lnllh, _lnllh_grad = grbllh.lnllh_ratio(X, ns[i], args)\n",
    "    lnllh[i], lnllh_grad[i] = _lnllh, _lnllh_grad[0]\n",
    "    \n",
    "# Manual \"fit\" by scanning the maximum\n",
    "ns_max = ns[np.argmax(lnllh)]\n",
    "\n",
    "_, (al, ar) = plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax, lw=4)\n",
    "\n",
    "# Cross check with expected result:\n",
    "lnllh_exp = -2 * ns\n",
    "lnllh_grad_exp = -2 * np.ones_like(ns)\n",
    "al.plot(ns, lnllh_exp, \"C1--\", lw=2, label=\"expect\")\n",
    "ar.plot(ns, lnllh_grad_exp, \"C1--\", lw=2, label=\"expect\")\n",
    "\n",
    "al.legend(loc=\"upper right\")\n",
    "ar.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Single Source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First with only one source.\n",
    "\n",
    "Note: We test here \"super-signal-like\" events. Every event is exactly at the src position and every time is exactly in the time window, where the ratio is max.\n",
    "Only the energy is distributed as background.\n",
    "So only for really large time windows (really large) which have insanely high background rates we drop lower than the injected ns in our prediction.\n",
    "This is because the background term can only counter background-like events, which have a low signal over background ratio.\n",
    "For the events injected here, this rate is super high, so we always \"fit\" the exact amount of injected events.\n",
    "\n",
    "For this setup each events SoB is equal and we can calculate the sum over the events directly by replacing it with N*SoB.\n",
    "In this cse, the gradient is zero at:\n",
    "\n",
    "\\begin{align}\n",
    "    0 &= -1 + \\sum_i \\frac{S}{n_b B}\\cdot \\frac{1}{n_s \\frac{S}{n_b B} + 1}\n",
    "       = -1 + N \\frac{S}{n_b B}\\cdot \\frac{1}{n_s \\frac{S}{n_b B} + 1} \\\\\n",
    "    \\Leftrightarrow \\frac{1}{N} &= \\frac{1}{n_s + \\frac{n_b B}{S}} \\\\\n",
    "    \\Leftrightarrow N &= n_s + \\frac{n_b B}{S}\n",
    "\\end{align}\n",
    "\n",
    "So now if the signal is super large (and that's what we ensured by using our super-signal-like events) the term $\\frac{n_b B}{S} \\rightarrow 0$ and we get $\\hat{n}_S = N$ which is exactly what we observe.\n",
    "\n",
    "Only if we set super high $n_B$, our $\\hat{n}_S$ shrinks as $\\frac{n_b B}{S}$ gets larger and larger and in the end $\\hat{n}_S$ even turns negative, when the 1 / SoB ratio is larger than N."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Make up some setup\n",
    "nsrcs = 1\n",
    "src_t = rndgen.choice(_exp[\"timeMJD\"], size=nsrcs)\n",
    "dt = np.array([-20, 200])\n",
    "\n",
    "# Expected background with rate 5mHz, kind of realistic.\n",
    "# Increase nb scale to see ns best fit shrink.\n",
    "scale = 1e4\n",
    "nb = 0.005 * np.diff(dt) * scale\n",
    "src_ra = np.deg2rad([180])  # Arbitrarily placed single source\n",
    "src_dec = np.deg2rad([10])\n",
    "src_w_theo = np.ones_like(src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((src_t, [dt[0]], [dt[1]],\n",
    "                  [src_ra], [src_dec], src_w_theo))\n",
    "srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                       formats=len(names) * [\"float64\"])\n",
    "args = {\"nb\": nb, \"srcs\": srcs}\n",
    "\n",
    "# Set the events artificially where the srcs are in space and nicely spaced\n",
    "# times inside the search window, where time sob is large. Otherwise the llh\n",
    "# is almost always peaked at 0\n",
    "N = 10\n",
    "mint, maxt = src_t + dt / secinday  # In MJD\n",
    "timeMJD = np.linspace(mint, maxt, N)\n",
    "X = rndgen.choice(_exp, size=N)  # Only to copy the recarray structure\n",
    "X[\"timeMJD\"] = timeMJD\n",
    "X[\"ra\"] = np.ones_like(timeMJD) * src_ra\n",
    "X[\"sinDec\"] = np.ones_like(timeMJD) * np.sin(src_dec)\n",
    "X[\"sigma\"] = np.deg2rad(np.ones_like(timeMJD))\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "xmin, xmax = 0, 2 * N\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "lnllh = np.empty(n_ns)\n",
    "lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    _lnllh, _lnllh_grad = grbllh.lnllh_ratio(X, ns[i], args)\n",
    "    lnllh[i], lnllh_grad[i] = _lnllh, _lnllh_grad[0]\n",
    "\n",
    "# Manual \"fit\" by scanning the maximum\n",
    "ns_max = ns[np.argmax(lnllh)]\n",
    "\n",
    "plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Multiple Sources -- All at same position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This time we use multiple sources, but all at the exact same location and with the exact same properties.\n",
    "We expect the very same result as in the single source case above, because the weighted sum of the signal terms reduces to\n",
    "\n",
    "\\begin{align}\n",
    "    S^\\text{tot} &= \\sum_{j=1}^{N_\\text{srcs}} w_j S_{ij}\n",
    "                 = S_{i} \\sum_{j=1}^{N_\\text{srcs}} \\frac{1}{N_\\text{srcs}}\n",
    "                 = S_i \\\\\n",
    "    \\Lambda &= -2\\ln\\left(\\frac{\\mathcal{L}_0}{\\mathcal{L}_1}\\right)\n",
    "             = -n_S + \\sum_{i=1}^N\\ln\\left(\\frac{n_S\\ S^\\text{tot}}{\\langle n_B\\rangle B_i} + 1\\right)\n",
    "             = -n_S + \\sum_{i=1}^N\\ln\\left(\\frac{n_S\\ S_i}{\\langle n_B\\rangle B_i} + 1\\right)\n",
    "\\end{align}\n",
    "\n",
    "as all signal terms are exaxtly the same and no further background locations are introduced.\n",
    "\n",
    "We only have to scale the BG manually because we do not treat overlapping windows correctly in the code.\n",
    "So we just scale the nb expecation down by 1/nsrcs manually before feeding it into the llh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Repeat sources exactly as the single one from above\n",
    "nsrcs = 100\n",
    "_src_t = np.repeat(src_t, repeats=nsrcs, axis=0)\n",
    "_dt = np.repeat(dt.reshape(1, 2), axis=0, repeats=nsrcs)\n",
    "# Attention here: 100% overlapping windows so total BG is unchanged. To work\n",
    "# in the stacking framework, we just split the expectation equally\n",
    "\n",
    "# Increase nb scale as in single src case above to see ns best fit shrink\n",
    "_nb = 0.005 * np.diff(_dt, axis=1).flatten() / nsrcs * scale\n",
    "\n",
    "_src_ra = np.repeat(src_ra, repeats=nsrcs, axis=0)\n",
    "_src_dec = np.repeat(src_dec, repeats=nsrcs, axis=0)\n",
    "_src_w_theo = np.ones_like(_src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((_src_t, _dt[:, 0], _dt[:, 1],\n",
    "                  _src_ra, _src_dec, _src_w_theo))\n",
    "_srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                       formats=len(names) * [\"float64\"])\n",
    "_args = {\"nb\": _nb, \"srcs\": _srcs}\n",
    "\n",
    "# Also use the very same events for all sources here\n",
    "_X = np.copy(X)\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "_lnllh = np.empty(n_ns)\n",
    "_lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    __lnllh, __lnllh_grad = grbllh.lnllh_ratio(_X, ns[i], _args)\n",
    "    _lnllh[i], _lnllh_grad[i] = __lnllh, __lnllh_grad[0]\n",
    "\n",
    "# Manual \"fit\" by scanning the maximum\n",
    "_ns_max = ns[np.argmax(_lnllh)]\n",
    "\n",
    "plot_llh(ns, _lnllh, _lnllh_grad, _ns_max, xmin, xmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Multiple Sources -- Different Right-Ascensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now the almost same thing, but with changed src right ascensions.\n",
    "We distribute them equally around a fixed declination.\n",
    "Everything else is left as before, except for giving an equally distributed number of events the same right ascension as the sources.\n",
    "\n",
    "This case is a bit more tricky, and we don't expect the same TS here, because:\n",
    "We inject the same number of events (N) but we get nsrcs times the BG (because the windows don't overlap anymore).\n",
    "Each event only contributes to the window where it spatially is placed, so per source only N / nsrcs events (we choosed them so the number distribute nicely) have a SoB > 0.\n",
    "\n",
    "This means, that the total signal term is reduced by a factor of nsrcs, as the zero signal terms can't compensate the unaffected backgound which is still the same for all events.\n",
    "\n",
    "So even though our stacked signal term is reduced by a factor of nsrcs  we still get the same fit result for super signal like events, because the signal term is still huge and we still satisfy the condition $\\frac{n_b B}{S}\\rightarrow 0$.\n",
    "But we need slightly less cranked up background rate to let the best fit ns shrink as in the previous cases because the signal term is reduced by 1/Nsrc.\n",
    "\n",
    "So with the same scale factor as above the TS should end up lower in every case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Repeat sources exactly as the single one from above\n",
    "nsrcs = 5\n",
    "_src_t = np.repeat(src_t, repeats=nsrcs, axis=0)\n",
    "_dt = np.repeat(dt.reshape(1, 2), axis=0, repeats=nsrcs)\n",
    "\n",
    "# Windows don't overlap anymore, so use full BG for each window\n",
    "# Increase nb scale to see ns best fit shrink\n",
    "_nb = 0.005 * np.diff(_dt) * scale\n",
    "\n",
    "# Handpick to let regions not overlap\n",
    "_src_ra = np.deg2rad([0, 30, 60, 90, 120])\n",
    "_src_dec = np.repeat(src_dec, repeats=nsrcs, axis=0)\n",
    "_src_w_theo = np.ones_like(_src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((_src_t, _dt[:, 0], _dt[:, 1],\n",
    "                  _src_ra, _src_dec, _src_w_theo))\n",
    "\n",
    "_srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                       formats=len(names) * [\"float64\"])\n",
    "_args = {\"nb\": _nb, \"srcs\": _srcs}\n",
    "\n",
    "# We used 5 srcs and 10 events, so we just repeat the ras once\n",
    "# This is not very obvious on how to scale to arbirary Ns and nsrcs\n",
    "# I'm not very sure here, how many events to inject to exactly match the cases\n",
    "# above.\n",
    "# Here we just have 2 evts per window and still have ns of 10, even though\n",
    "# signal should get downweighted to 1/5 of the two cases above per source.\n",
    "_X = np.copy(X)\n",
    "_X[\"ra\"] = np.repeat(_src_ra, repeats=2)\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "xmin, xmax = 0, 2 * N\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "_lnllh = np.empty(n_ns)\n",
    "_lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    __lnllh, __lnllh_grad = grbllh.lnllh_ratio(_X, ns[i], _args)\n",
    "    _lnllh[i], _lnllh_grad[i] = __lnllh, __lnllh_grad[0]\n",
    "\n",
    "# Manual \"fit\" by scanning the maximum\n",
    "_ns_max = ns[np.argmax(_lnllh)]\n",
    "\n",
    "plot_llh(ns, _lnllh, _lnllh_grad, _ns_max, xmin, xmax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### SoB Thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "See if the absolute and relative thresholds are working to reduce the amount of points we need to calculate in the LLH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Just see the absolute threshold = 0.001 in action. Everything below is cut\n",
    "# so with high enough nb the ratio drops below that value. When nb=2e9 all\n",
    "# Events are gone, try it.\n",
    "thresh = 1e-3\n",
    "grbllh.llh_args[\"sob_abs_eps\"] = thresh\n",
    "\n",
    "# Just vary this between [0, 1]. The closer to 1 the less evts survive.\n",
    "# At 1 only the highest sob evt survives the relativ cut. At 0 all survive\n",
    "grbllh.llh_args[\"sob_rel_eps\"] = 1e-2\n",
    "\n",
    "nsurvive = []\n",
    "sobs = []\n",
    "nbs = np.linspace(6, 10, 100)\n",
    "for _nb in nbs:\n",
    "    args[\"nb\"] = np.array([[int(10**_nb)]])\n",
    "    _sob = grbllh._soverb(X, args)\n",
    "    sobs.append(_sob)\n",
    "    nsurvive.append(len(_sob))\n",
    "    if len(_sob) == 1:\n",
    "        last_sob = _sob[0]\n",
    "    \n",
    "plt.plot(nbs, nsurvive)\n",
    "plt.hlines(np.arange(1, 11, 1), 6, 10, linestyles=\"--\", colors=\"C7\")\n",
    "plt.xlabel(\"log10(nb)\")\n",
    "plt.ylabel(\"nr. of surviving evts\")\n",
    "plt.title(\"Highest surviving sob: {:.5f} > {:.5f} (abs thresh)\".format(\n",
    "    last_sob, thresh))\n",
    "plt.xlim(6, 10)\n",
    "plt.ylim(0, 10.5)\n",
    "plt.show()\n",
    "\n",
    "# Now show the actual sob values dropping below abs thresh.\n",
    "# See the dashed dropping below the threshold being at the same nb as the\n",
    "# steps in the first plot.\n",
    "for i, _nb in enumerate(nbs):\n",
    "    x = np.ones(nsurvive[i]) * _nb\n",
    "    y = np.sort(np.log10(sobs[i]))\n",
    "    plt.plot(x, y, marker=\".\", ls=\"\", color=\"C7\")\n",
    "plt.axhline(np.log10(thresh), 0, 1)\n",
    "plt.xlim(6, 10)\n",
    "plt.title(\"sob values dropping below thresh when nb is increased\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Getting the Test Statistic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The LLH evaluates it's Test Statistic.\n",
    "Even if this is not quite the logic way to go here, it is imporving speed, because trivial cases (no, 1 or 2 evts given) can be solved analytically to skip the minimization.\n",
    "\n",
    "It would be nicer to have that in the analysis module, so we could choose which hypotheses to test, but we fit only one parameter anyway (ns) so here that doesn't really matter, if we put everything in the LLH.\n",
    "Things just don't have to be that flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Snippet to plot lnLLH ratio and gradient next each other\n",
    "def plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax, lw=2):\n",
    "    fig, (al, ar) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    al.plot(ns, lnllh, lw=lw)\n",
    "    al.set_xlim(xmin, xmax)\n",
    "    if np.amax(lnllh) == 0.:\n",
    "        al.set_ylim(np.amin(lnllh), 1)\n",
    "    else:\n",
    "        al.set_ylim(0, 1.05 * np.amax(lnllh))\n",
    "    al.axvline(ns_max, 0, 1, ls=\"--\", lw=2, color=\"C7\")\n",
    "    al.set_title(\"LLH\")\n",
    "\n",
    "    ar.plot(ns, lnllh_grad, lw=lw)\n",
    "    ar.axhline(0, 0, 1, ls=\"--\", lw=2, color=\"C7\")\n",
    "    ar.axvline(ns_max, 0, 1, ls=\"--\", lw=2, color=\"C7\")\n",
    "    al.set_xlim(xmin, xmax)\n",
    "    ar.set_ylim(-5, 5)\n",
    "    ar.set_title(\"LLH gradient in ns\")\n",
    "    fig.tight_layout()\n",
    "    return fig, (al, ar)\n",
    "\n",
    "names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "rndgen = np.random.RandomState(7353)\n",
    "\n",
    "bounds = [[0, None]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Analytic ns best fit and TS for nevts = [0, 1, 2]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Compare the analytic best fits with the ones from the fitter (here just scanned LLH) just to be sure.\n",
    "\n",
    "Just choose some upper number for nevts and see how the fitter and the scan are just the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _get_best_fit(sob):\n",
    "    \"\"\"\n",
    "    Copied from code, otherwise we'd have to setup sources again and wouldn't\n",
    "    have direct control on the SoB values.\n",
    "    \"\"\"\n",
    "    def _neglnllh(ns):\n",
    "        lnllh, lnllh_grad = grbllh._lnllh_ratio(ns, sob)\n",
    "        return -1. * lnllh, -1. * lnllh_grad\n",
    "\n",
    "    # Get the best fit parameter and TS. Analytic cases are handled:\n",
    "    # For nevts = [1 | 2] we get a [linear | quadratic] equation to solve.\n",
    "    nevts = len(sob)\n",
    "    # Test again, because we applied some threshold cuts\n",
    "    if nevts == 0:\n",
    "        return 0., 0.\n",
    "    if nevts == 1:\n",
    "        # Use scalar math functions, they're faster than numpy\n",
    "        sob = sob[0]\n",
    "        ns = 1. - (1. / sob)\n",
    "        if ns <= 0:\n",
    "            return 0., 0.\n",
    "        else:\n",
    "            TS = -ns + math.log(sob)\n",
    "        return ns, 2. * TS\n",
    "    elif nevts == 2:\n",
    "        a = 1. / (sob[0] * sob[1])\n",
    "        c = (sob[0] + sob[1]) * a\n",
    "        ns = 1. - 0.5 * c + math.sqrt(c * c / 4. - a + 1.)\n",
    "        if ns <= 0:\n",
    "            return 0., 0.\n",
    "        else:\n",
    "            TS, _ = grbllh._lnllh_ratio(ns, sob)\n",
    "        return ns, TS\n",
    "    else:\n",
    "        # Fit other cases\n",
    "        res = sco.minimize(fun=_neglnllh, x0=[10], jac=True, bounds=bounds)\n",
    "\n",
    "        return res.x[0], -1. * res.fun[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Just use a sob value directly (see how ns gets more accurate with high sob)\n",
    "_sob = 8.1\n",
    "\n",
    "nevts = np.arange(0, 6 + 1)\n",
    "nscan = 100\n",
    "\n",
    "for i, ni in enumerate(nevts): \n",
    "    sob = np.array(ni * [_sob])\n",
    "    ns = np.linspace(0, 1.5 * np.amax(nevts), nscan)\n",
    "    TS = np.empty(nscan, dtype=np.float)\n",
    "    grad = np.empty(nscan, dtype=np.float)\n",
    "    for j, nsj in enumerate(ns):\n",
    "        TS[j], grad_j = grbllh._lnllh_ratio(nsj, sob)\n",
    "        grad[j] = grad_j[0]\n",
    "\n",
    "    ns_bf = ns[np.argmax(TS)]\n",
    "    _, ax = plot_llh(ns, TS, grad, ns_bf, ns[0], ns[-1])\n",
    "    for axi in ax:\n",
    "        axi.set_xlabel(\"ns\")\n",
    "        axi.axvline(_get_best_fit(sob)[0], 0, 1, ls=\"--\", lw=3, color=\"C1\")\n",
    "    plt.suptitle(\"Number of events: {:d}. SoB = {:.1f}\".format(ni, _sob))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Single source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "First we test if the module simply wrapps the LLH module correctly.\n",
    "This should reproduce same results (not regarding random fluctuations of course) as in the section ln-llh ratio, as we test the same setup as above here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make up some setup\n",
    "nsrcs = 1\n",
    "src_t = np.random.choice(_exp[\"timeMJD\"], size=nsrcs)\n",
    "dt = np.array([-20, 200])\n",
    "\n",
    "# Expected background with rate 5mHz, kind of realistic.\n",
    "# Increase nb scale to see ns best fit shrink.\n",
    "scale = 1e5\n",
    "nb = 0.005 * np.diff(dt) * scale\n",
    "src_ra = np.deg2rad([180])  # Arbitrarily placed single source\n",
    "src_dec = np.deg2rad([10])\n",
    "src_w_theo = np.ones_like(src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((src_t, [dt[0]], [dt[1]],\n",
    "                  [src_ra], [src_dec], src_w_theo))\n",
    "names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                       formats=len(names) * [\"float64\"])\n",
    "args = {\"nb\": nb, \"srcs\": srcs}\n",
    "\n",
    "# Set the events artificially where the srcs are in space and nicely spaced\n",
    "# times inside the search window, where time sob is large. Otherwise the llh\n",
    "# is almost always peaked at 0\n",
    "N = 10\n",
    "mint, maxt = src_t + dt / secinday  # In MJD\n",
    "timeMJD = np.linspace(mint, maxt, N)\n",
    "X = np.random.choice(_exp, size=N)  # Only to copy the recarray structure\n",
    "X[\"timeMJD\"] = timeMJD\n",
    "X[\"ra\"] = np.ones_like(timeMJD) * src_ra\n",
    "X[\"sinDec\"] = np.ones_like(timeMJD) * np.sin(src_dec)\n",
    "X[\"sigma\"] = np.deg2rad(np.ones_like(timeMJD))\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "xmin, xmax = 0, 2 * N\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "lnllh = np.empty(n_ns)\n",
    "lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    lnllh[i], lnllh_grad[i] = grbllh.lnllh_ratio(X, ns[i], args)\n",
    "\n",
    "# Manual \"fit\" by scanning the maximum\n",
    "ns_max = ns[np.argmax(lnllh)]\n",
    "\n",
    "_, ax = plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax)\n",
    "ax[0].set_title(\"LLH. ns best fit {:.3f}\".format(ns_max))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Also let's quickly see, how the times are distributed within the time PDF\n",
    "inj_trange = grbllh.time_pdf_def_range(src_t=srcs[\"t\"], dt=dt)\n",
    "inj_trange = src_t + inj_trange.flatten() / secinday\n",
    "\n",
    "x = np.linspace(inj_trange[0], inj_trange[1], 100)\n",
    "y = grbllh._soverb_time(t=x, src_t=srcs[\"t\"], dt=dt)\n",
    "\n",
    "plt.plot(x, y.reshape(len(x)))\n",
    "plt.vlines(X[\"timeMJD\"], 0, np.amax(y), colors=\"C7\", linestyles=\"--\", lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test if we can do the same as above, but using the scipy fitter this time to get the maximum.\n",
    "The LLH curve and the maximum should be identical to the ones above (except for small errors in scanning vs fitting ns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seed for the fitter\n",
    "ns0 = 1\n",
    "\n",
    "ns_bf, TS = grbllh.fit_lnllh_ratio(X, ns0, args, bounds, {})\n",
    "\n",
    "_, ax = plot_llh(ns, lnllh, lnllh_grad, ns_bf, xmin, xmax)\n",
    "ax[0].set_title(\"LLH. ns best fit {:.3f}\".format(ns_bf))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Multiple Sources -- All at same position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Repeat sources exactly as the single one from above\n",
    "nsrcs = 5\n",
    "_src_t = np.repeat(src_t, repeats=nsrcs, axis=0)\n",
    "_dt = np.repeat(dt.reshape(1, 2), axis=0, repeats=nsrcs)\n",
    "# Attention here: 100% overlapping windows so total BG is unchanged. To work\n",
    "# in the stacking framework, we just split the expectation equally\n",
    "\n",
    "# Increase nb scale to see ns best fit shrink\n",
    "scale = 1e5\n",
    "nb = 0.005 * np.diff(_dt, axis=1).flatten() / nsrcs  * scale\n",
    "\n",
    "_src_ra = np.repeat(src_ra, repeats=nsrcs, axis=0)\n",
    "_src_dec = np.repeat(src_dec, repeats=nsrcs, axis=0)\n",
    "src_w_theo = np.ones_like(_src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((_src_t, _dt[:, 0], _dt[:, 1], _src_ra, _src_dec, src_w_theo))\n",
    "\n",
    "srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                  formats=len(names) * [\"float64\"])\n",
    "args = {\"nb\": nb, \"srcs\": srcs}\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "xmin, xmax = 0, 2 * N\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "lnllh = np.empty(n_ns)\n",
    "lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    lnllh[i], lnllh_grad[i] = grbllh.lnllh_ratio(X, ns[i], args)\n",
    "\n",
    "# Manual \"fit\" by scanning the maximum\n",
    "ns_max = ns[np.argmax(lnllh)]\n",
    "\n",
    "_, ax = plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax)\n",
    "ax[0].set_title(\"LLH. ns best fit {:.3f}\".format(ns_max))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Again check using the class function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seed for the fitter\n",
    "ns0 = 1\n",
    "\n",
    "ns_bf, TS = grbllh.fit_lnllh_ratio(X, ns0, args, bounds, {})\n",
    "\n",
    "_, ax = plot_llh(ns, lnllh, lnllh_grad, ns_bf, xmin, xmax)\n",
    "ax[0].set_title(\"LLH. ns best fit {:.3f}\".format(ns_bf))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Multiple Sources -- Different Right-Ascencions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Repeat sources exactly as the single one from above\n",
    "nsrcs = 5\n",
    "_src_t = np.repeat(src_t, repeats=nsrcs, axis=0)\n",
    "_dt = np.repeat(dt.reshape(1, 2), axis=0, repeats=nsrcs)\n",
    "\n",
    "# Windows don't overlap anymore, so use full BG for each window\n",
    "# Increase nb scale to see ns best fit shrink\n",
    "scale = 1e5\n",
    "nb = 0.005 * np.diff(_dt) * scale\n",
    "\n",
    "# Do not let windows overlap\n",
    "src_ra = np.deg2rad(np.linspace(0, 2 * np.pi, nsrcs + 1)[:-1])\n",
    "_src_dec = np.repeat(src_dec, repeats=nsrcs, axis=0)\n",
    "src_w_theo = np.ones_like(_src_dec)\n",
    "\n",
    "# Setup src record array\n",
    "srcs = np.vstack((_src_t, _dt[:, 0], _dt[:, 1], src_ra, _src_dec, src_w_theo))\n",
    "\n",
    "srcs = np.core.records.fromarrays(srcs, names=names,\n",
    "                                       formats=len(names) * [\"float64\"])\n",
    "args = {\"nb\": nb, \"srcs\": srcs}\n",
    "\n",
    "# We used 5 srcs and 10 events, so we just repeat the ras once\n",
    "# This is not very obvious on how to scale to arbirary Ns and nsrcs\n",
    "# I'm not very sure here, how many events to inject to exactly match the cases\n",
    "# above.\n",
    "# Here we just have 2 evts per window and still have ns of 10, even though\n",
    "# signal should get donwweighted to 1/5 of the two cases above per source.\n",
    "X[\"ra\"] = np.repeat(src_ra, repeats=2)\n",
    "\n",
    "# Scan a single LLH for the chosen data above\n",
    "n_ns = 500\n",
    "xmin, xmax = 0, 2 * N\n",
    "ns = np.linspace(xmin, xmax, n_ns)\n",
    "lnllh = np.empty(n_ns)\n",
    "lnllh_grad = np.empty(n_ns)\n",
    "for i in range(n_ns):\n",
    "    lnllh[i], lnllh_grad[i] = grbllh.lnllh_ratio(X, ns[i], args)\n",
    "\n",
    "# Manual \"fit\" by scanning the maximum\n",
    "ns_max = ns[np.argmax(lnllh)]\n",
    "\n",
    "_, ax = plot_llh(ns, lnllh, lnllh_grad, ns_max, xmin, xmax)\n",
    "ax[0].set_title(\"LLH. ns best fit {:.3f}\".format(ns_max))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Again check with the class function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Seed for the fitter\n",
    "ns0 = 1\n",
    "\n",
    "ns_bf, TS = grbllh.fit_lnllh_ratio(X, ns0, args, bounds, {})\n",
    "\n",
    "_, ax = plot_llh(ns, lnllh, lnllh_grad, ns_bf, xmin, xmax)\n",
    "ax[0].set_title(\"LLH. ns best fit {:.3f}\".format(ns_bf))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Signal Injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define a simple stripped version of injector for single method tests\n",
    "dec = np.deg2rad([-60., -30., 0, 30., 60.])\n",
    "sin_dec = np.sin(dec)\n",
    "srcs = np.core.records.fromarrays([dec], names=\"dec\")\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "sig_inj = SigInj.SignalInjector(gamma=2., mode=\"band\",\n",
    "                               inj_width=np.deg2rad(5.))\n",
    "sig_inj._srcs = srcs\n",
    "sig_inj._nsrcs = len(srcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Injection bands and omega calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Mode \"band\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sig_inj._inj_width = np.deg2rad(5.)\n",
    "sig_inj._mode = \"band\"\n",
    "sig_inj._set_solid_angle()\n",
    "\n",
    "_min_dec = sig_inj._min_dec\n",
    "_max_dec = sig_inj._max_dec\n",
    "_omega = sig_inj._omega\n",
    "\n",
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "# Dec\n",
    "axl.hlines(dec, 0, 2 * np.pi, linestyles=\"-\", colors=\"C1\")\n",
    "axl.hlines(_min_dec, 0, 2 * np.pi, linestyles=\"--\", colors=\"#353132\")\n",
    "axl.hlines(_max_dec, 0, 2 * np.pi, linestyles=\"--\", colors=\"#353132\")\n",
    "\n",
    "_x = np.array([0, 2 * np.pi])\n",
    "for mind, maxd in zip(_min_dec, _max_dec):\n",
    "    axl.fill_between(_x, [mind, mind], [maxd, maxd], color=\"C7\", alpha=.25)\n",
    "\n",
    "axl.set_xlim(0, 2 * np.pi)\n",
    "axl.set_ylim(-np.pi / 2., np.pi / 2.)\n",
    "axl.set_title(\"dec bands\")\n",
    "\n",
    "# Sindec\n",
    "axr.hlines(np.sin(dec), 0, 2 * np.pi, linestyles=\"-\", colors=\"C1\")\n",
    "axr.hlines(np.sin(_min_dec), 0, 2 * np.pi, linestyles=\"--\", colors=\"#353132\")\n",
    "axr.hlines(np.sin(_max_dec), 0, 2 * np.pi, linestyles=\"--\", colors=\"#353132\")\n",
    "\n",
    "_x = np.array([0, 2 * np.pi])\n",
    "for mind, maxd in zip(np.sin(_min_dec), np.sin(_max_dec)):\n",
    "    axr.fill_between(_x, [mind, mind], [maxd, maxd], color=\"C7\", alpha=.25)\n",
    "\n",
    "axr.set_xlim(0, 2 * np.pi)\n",
    "axr.set_ylim(-1., 1.)\n",
    "axr.set_title(\"sin dec bands\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Mode \"circle\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Only for printing the values below, plot is not able to test correctness\n",
    "r = np.deg2rad(15.)\n",
    "sig_inj._mode = \"circle\"\n",
    "sig_inj._inj_width = r\n",
    "sig_inj._set_solid_angle()\n",
    "_omega = sig_inj._omega\n",
    "\n",
    "# Now make the circles with wrapping\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ra = np.linspace(0, 2. * np.pi, len(dec))\n",
    "t = np.linspace(0, 2. * np.pi, 100)\n",
    "for deci, rai in zip(dec, ra):    \n",
    "    x = r * np.cos(t) + rai\n",
    "    y = r * np.sin(t) + deci\n",
    "    \n",
    "    ax.hlines(dec, 0, 2 * np.pi, linestyles=\"--\", colors=\"C1\")\n",
    "    ax.hlines(dec - r, 0, 2 * np.pi, linestyles=\"--\", colors=\"#353132\")\n",
    "    ax.hlines(dec + r, 0, 2 * np.pi, linestyles=\"--\", colors=\"#353132\")\n",
    "    \n",
    "    hlp.circle_on_skymap(rai, deci, r, ax, flat=True, color=\"C0\", lw=3)\n",
    "\n",
    "ax.set_xlim(0, 2 * np.pi)\n",
    "ax.set_ylim(-np.pi / 2., np.pi / 2.)\n",
    "ax.set_title(\"circles around sources\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Omegas are\\n\", _omega)\n",
    "print(\"  in percent of the sky\\n\", _omega / 4. / np.pi * 100, \"%\")\n",
    "test = 2 * np.pi * (1. - np.cos(r))\n",
    "print(\"Omegas should be\\n\", test)\n",
    "print(\"  in percent of the sky\\n\", test / 4. / np.pi * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Sun and Moon\n",
    "\n",
    "Test sun, moon and obvious cases of half and full sphere.\n",
    "Sun and moon from https://en.wikipedia.org/wiki/Solid_angle#Sun_and_Moon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sig_inj._mode = \"circle\"\n",
    "\n",
    "print(\"\")\n",
    "sun = 9.35e-3 / 2.\n",
    "sig_inj._inj_width = sun\n",
    "sig_inj._set_solid_angle()\n",
    "print(\"Sun has \", sig_inj._omega[0])\n",
    "print(\"Wiki says 6.87×10−5 sr\")\n",
    "moon = 9.22e-3 / 2.\n",
    "sig_inj._inj_width = moon\n",
    "sig_inj._set_solid_angle()\n",
    "print(\"Moon has \", sig_inj._omega[0])\n",
    "print(\"Wiki says 6.67×10−5 sr\")\n",
    "\n",
    "# Half and full sphere\n",
    "half = np.pi / 2.\n",
    "full = np.pi\n",
    "sig_inj._inj_width = half\n",
    "sig_inj._set_solid_angle()\n",
    "print(\"Half sphere 4pi\", sig_inj._omega[0] / 4. / np.pi)\n",
    "sig_inj._inj_width = full\n",
    "sig_inj._set_solid_angle()\n",
    "print(\"Full sphere in 4pi\", sig_inj._omega[0] / 4. / np.pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Time signal sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Time sampling - Check multiple window sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make some src times and tranges (repeated to get multiple times in there)\n",
    "dt = 100. * np.vstack((np.arange(0, 39, 4), np.arange(1, 40, 4))).T\n",
    "src_t = np.repeat(50000. + 100 * np.arange(0, len(dt)), 2)\n",
    "dt = np.repeat(dt, 2, axis=0)\n",
    "rndgen = check_random_state(3537)\n",
    "\n",
    "times = sig_inj._sample_times(src_t, dt)\n",
    "\n",
    "print(\"dt.T\\n\", dt.T)\n",
    "print(\"src_t\\n\", src_t)\n",
    "print(\"sampled times\\n\", times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Time sampling - Check against time signal pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Attention:** Signal is sampled in the uniform region only.\n",
    "Signal PDF is defined only in unifrom region of the signal PDF.\n",
    "So the normalized heights don't really match because the gaussian edges steal normalization.\n",
    "\n",
    "This is OK, as the time PDF has no real seperation power.\n",
    "It acts more like a theta function, cutting out the region around a source.\n",
    "Only if we would assume, that the signal PDF had a different shape from uniform (and thus from the BG PDF) we would have real seperation power in subregions of the on time intervall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make some src times and tranges (repeated to get multiple times in there)\n",
    "dt = 100. * np.vstack((np.arange(0, 39, 4), np.arange(1, 40, 4))).T\n",
    "src_t = np.repeat(50000. + 100 * np.arange(0, len(dt)), 2)\n",
    "dt = np.repeat(dt, 2, axis=0)\n",
    "rndgen = check_random_state(3537)\n",
    "\n",
    "# Arbitrary start date from data\n",
    "nsrcs = 1\n",
    "t0 = 50000.\n",
    "t0_sec = t0 * secinday\n",
    "\n",
    "# dt from t0 in seconds, clip at 4 sigma\n",
    "dt = 200\n",
    "nsig = 4.\n",
    "\n",
    "# Make t values for plotting in MJD around t0\n",
    "clip = np.clip(dt, 2, 30) * nsig\n",
    "trange = np.array([-clip, dt + clip]).reshape(nsrcs, 2)\n",
    "ntrials = int(1e4)\n",
    "\n",
    "_src_t = np.repeat(t0, ntrials)\n",
    "_dt = np.repeat([[0., dt]], ntrials, axis=0)\n",
    "trials = sig_inj._sample_times(_src_t, _dt)\n",
    "\n",
    "# Plot them in together with the PDFs\n",
    "def time_bg_pdf(t, t0, a, b):\n",
    "    # Normalize relative to t0 in seconds (first multiply avoids rounding?)\n",
    "    _t = t * secinday - t0 * secinday\n",
    "  \n",
    "    pdf = np.zeros_like(_t, dtype=np.float)\n",
    "    uni = (_t >= a) & (_t <= b)\n",
    "    pdf[uni] = 1. / (b - a)\n",
    "    return pdf\n",
    "\n",
    "def time_sig_pdf(t, t0, dt, nsig=4):\n",
    "    if dt < 0:\n",
    "        raise ValueError(\"dt must not be negative.\")\n",
    "\n",
    "    # Normalize relative to t0 in seconds (first multiply avoids rounding?)\n",
    "    _t = t * secinday - t0 * secinday\n",
    "    \n",
    "    # Constrain sig_t to [2, 30]s regardless of uniform time window\n",
    "    sig_t = np.clip(dt, 2, 30)\n",
    "    sig_t_clip = nsig * sig_t\n",
    "    gaus_norm = (np.sqrt(2 * np.pi) * sig_t)\n",
    "    \n",
    "    # Split in def regions gaus rising, uniform, gaus falling and zero\n",
    "    gr = (_t < 0) & (_t >= -sig_t_clip)\n",
    "    gf = (_t > dt) & (_t <= dt + sig_t_clip)\n",
    "    uni = (_t >= 0) & (_t <= dt)\n",
    "    \n",
    "    pdf = np.zeros_like(t, dtype=np.float)\n",
    "    pdf[gr] = scs.norm.pdf(_t[gr], loc=0, scale=sig_t)\n",
    "    pdf[gf] = scs.norm.pdf(_t[gf], loc=dt, scale=sig_t)\n",
    "    # Connect smoothly with the gaussians\n",
    "    pdf[uni] = 1. / gaus_norm\n",
    "    \n",
    "    # Normalize whole distribtuion\n",
    "    dcdf = (scs.norm.cdf(dt + sig_t_clip, loc=dt, scale=sig_t) -\n",
    "            scs.norm.cdf(-sig_t_clip, loc=0., scale=sig_t))\n",
    "    norm = dcdf + dt / gaus_norm\n",
    "    \n",
    "    return pdf / norm\n",
    "\n",
    "\n",
    "# Plot the pdfs\n",
    "t = np.linspace(t0_sec + trange[:, 0], t0_sec + trange[:, 1], 200) / secinday\n",
    "bg_pdf = time_bg_pdf(t, t0, -clip, dt + clip)\n",
    "sig_pdf = time_sig_pdf(t, t0, dt, nsig)\n",
    "\n",
    "# Plot in normalized time\n",
    "_t = t * secinday - t0 * secinday\n",
    "plt.plot(_t, bg_pdf, \"C0-\")\n",
    "plt.plot(_t, sig_pdf, \"C1-\")\n",
    "plt.axvline(dt, 0, 1, color=\"C3\", ls=\"--\")\n",
    "plt.axvline(0, 0, 1, color=\"C2\", ls=\"--\")\n",
    "\n",
    "# Plot injected events from all trials, relative times\n",
    "times = (trials - t0) * secinday\n",
    "_ = plt.hist(times, bins=50, normed=True, color=dg, alpha=.25)\n",
    "\n",
    "plt.xlabel(\"Time relative to t0 in sec\")\n",
    "plt.ylim(0, None);\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"./data/figs/signal_events_time_sampled.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Compare to mhuber raw_flux and event selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**We need to change the kernel to Python 2 here, to load skylab**\n",
    "\n",
    "No modifications have been done to skylab code.\n",
    "\n",
    "The conversion from flux to fluence is simply the lack of livetime in the weights.\n",
    "So we obtain skylab fluence by just repeating the steps from the code, but dropping the multiplication with the livetime.\n",
    "\n",
    "The event selection is not affected by the livetime, so we don't have to modify the code itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrc = 5\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrc)\n",
    "src_dec = np.deg2rad([-60., -30., 0, 30., 60.])\n",
    "src_t = np.linspace(50000, 50300, nsrc)\n",
    "dt0 = np.zeros(nsrc, dtype=np.float)\n",
    "dt1 = np.zeros(nsrc, dtype=np.float) + 200.\n",
    "w_theo = np.ones(nsrc)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "sig_inj = SigInj.SignalInjector(gamma=2., mode=\"band\",\n",
    "                               inj_width=np.arcsin(0.1))\n",
    "\n",
    "# Simulate skylab's band selection (debug flag only)\n",
    "sig_inj._skylab_band = True\n",
    "# Different sample sizes\n",
    "mc_dict = {0: mc, 1: mc[::10]}\n",
    "livetime = {0: 340., 1: 34.}\n",
    "sig_inj.fit(srcs, mc_dict, exp.dtype.names)\n",
    "\n",
    "print(\"\\nRaw Fluence: {}\".format(sig_inj._raw_fluence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(sig_inj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"/Users/tmenne/icecube/software/skylab-mhuber\")\n",
    "\n",
    "from skylab.ps_injector import StackingPointSourceInjector as psinj\n",
    "inj = psinj(gamma=2.)\n",
    "inj.fill(src_dec, mc_dict, livetime)\n",
    "\n",
    "ow = np.empty(0, dtype=np.float)\n",
    "omega = (inj._omega / inj.w_theo)[inj.mc_arr[\"src_idx\"]]\n",
    "print(\"\")\n",
    "for enum in mc_dict.keys():\n",
    "    idx = inj.mc_arr[inj.mc_arr[\"enum\"] == enum][\"idx\"]\n",
    "    _ow = (inj.mc[enum][\"ow\"] * inj.mc[enum][\"trueE\"]**(-inj.gamma))[idx]\n",
    "    _ow /= omega[inj.mc_arr[\"enum\"] == enum][idx]\n",
    "    ow = np.append(ow, _ow)\n",
    "    print(\"Raw Fluence at {} : {}\".format(enum, np.sum(_ow)))\n",
    "\n",
    "print(\"\\nRaw Fluence: {}\".format(np.sum(ow)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Are both raw_fluences and number of events equal?\n",
    "print(\"Selected events equal : {}\".format(len(sig_inj.mc_arr) ==\n",
    "                                          len(inj.mc_arr)))\n",
    "print(\"Raw fluences equal    : {}\".format(np.allclose(sig_inj._raw_fluence,\n",
    "                                                      np.sum(ow))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Fill Events - Plot positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### First: Band mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "src_dec = np.deg2rad([-60., -30., 0, 30., 60.])\n",
    "nsrc = len(src_dec)\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrc)\n",
    "src_t = np.linspace(50000, 50300, nsrc)\n",
    "dt0 = np.zeros(nsrc, dtype=np.float)\n",
    "dt1 = np.zeros(nsrc, dtype=np.float) + 200.\n",
    "w_theo = np.ones(nsrc)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "bandwidth = 0.1\n",
    "gamma = 2.\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=\"band\",\n",
    "                               inj_width=np.arcsin(bandwidth))\n",
    "skip = 50  # Just that it plots faster\n",
    "sig_inj.fit(srcs, {0: mc[::skip], 1:mc[::skip]}, exp.dtype.names)\n",
    "\n",
    "\n",
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot each src in a different color\n",
    "cmap = plt.cm.get_cmap(\"viridis\", nsrc + 2)\n",
    "colors = cmap.colors[1:-1]\n",
    "bins = np.linspace(-1., 1., 101)\n",
    "\n",
    "# Plot all MC: Selected parts must be equally filles\n",
    "weights = mc[\"ow\"] * mc[\"trueE\"]**(-sig_inj.gamma)\n",
    "h, b, _ = axl.hist(np.sin(mc[::skip][\"trueDec\"]), bins=bins,\n",
    "                   weights=weights[::skip], alpha=0.2, color=\"C7\")\n",
    "\n",
    "for i in range(nsrc):\n",
    "    # Get all events from all samples\n",
    "    for enum, mc_i in sig_inj._MC.items():\n",
    "        _enum = sig_inj.mc_arr[sig_inj.mc_arr[\"enum\"] == enum]\n",
    "        _src_m = _enum[\"src_idx\"] == i\n",
    "        _ev_idx = _enum[\"ev_idx\"]\n",
    "\n",
    "        _mc_i = mc_i[_ev_idx][_src_m]\n",
    "        weights = _mc_i[\"ow\"] * _mc_i[\"trueE\"]**(-sig_inj.gamma)\n",
    "        axl.hist(np.sin(_mc_i[\"trueDec\"]), bins=bins, weights=weights,\n",
    "                 color=colors[i])\n",
    "        axr.scatter(_mc_i[\"trueRa\"], _mc_i[\"trueDec\"], c=colors[i])\n",
    "\n",
    "    axl.axvline(np.sin(src_dec[i]), 0, 1, color=\"k\", ls=\"--\")\n",
    "    axl.axvline(np.sin(sig_inj._min_dec[i]), 0, 1, color=\"k\")\n",
    "    axl.axvline(np.sin(sig_inj._max_dec[i]), 0, 1, color=\"k\")\n",
    "    axr.axhline(src_dec[i], 0, 1, color=\"k\", ls=\"--\")\n",
    "    axr.axhline(sig_inj._min_dec[i], 0, 1, color=\"k\")\n",
    "    axr.axhline(sig_inj._max_dec[i], 0, 1, color=\"k\")\n",
    "\n",
    "# Plot outline to show that nothing is hidden\n",
    "m = 0.5 * (b[:-1] + b[1:])\n",
    "axl.hist(m, bins=bins, weights=h, color=\"k\", histtype=\"step\", linewidth=2)\n",
    "    \n",
    "axl.set_xlim(-1., 1.)\n",
    "axr.set_xlim(0., 2. * np.pi)\n",
    "axr.set_ylim(-np.pi/2., np.pi/2.)\n",
    "\n",
    "axl.set_xlabel(\"sin dec\")\n",
    "axr.set_xlabel(\"right-ascension\")\n",
    "axr.set_ylabel(\"dec\")\n",
    "\n",
    "axl.set_title(\"gamma = {:.2f}\".format(gamma))\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"data/figs/sig_inj_ev_selection_bands.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Second: Circle mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrc = 5\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrc)\n",
    "src_dec = np.deg2rad([-80., -30., 0, 30., 80.])\n",
    "src_t = np.linspace(50000, 50300, nsrc)\n",
    "dt0 = np.zeros(nsrc, dtype=np.float)\n",
    "dt1 = np.zeros(nsrc, dtype=np.float) + 200.\n",
    "w_theo = np.ones(nsrc)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "inj_width = np.deg2rad(10)\n",
    "gamma = 2.\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=\"circle\",\n",
    "                               inj_width=inj_width)\n",
    "skip = 50  # Just that it goes faster\n",
    "sig_inj.fit(srcs, {0: mc[::skip], 1:mc[::skip]}, exp.dtype.names)\n",
    "\n",
    "\n",
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"viridis\", nsrc + 2)\n",
    "colors = cmap.colors[1:-1]\n",
    "\n",
    "# Plot all MC: Selected parts must be equally filles\n",
    "weights = mc[\"ow\"] * mc[\"trueE\"]**(-sig_inj.gamma)\n",
    "h, b, _ = axl.hist(np.sin(mc[::skip][\"trueDec\"]), bins=bins, log=True,\n",
    "                   weights=weights[::skip], alpha=0.2, color=\"C7\")\n",
    "\n",
    "# Plot each src in a different color\n",
    "for i in range(nsrc):\n",
    "    # Get all events from all samples\n",
    "    for enum, mc_i in sig_inj._MC.items():\n",
    "        _enum = sig_inj.mc_arr[sig_inj.mc_arr[\"enum\"] == enum]\n",
    "        _src_m = _enum[\"src_idx\"] == i\n",
    "        _ev_idx = _enum[\"ev_idx\"]\n",
    "\n",
    "        _mc_i = mc_i[_ev_idx][_src_m]\n",
    "        axr.scatter(_mc_i[\"trueRa\"], _mc_i[\"trueDec\"], c=colors[i])\n",
    "        \n",
    "        _mc_i = mc_i[_ev_idx][_src_m]\n",
    "        weights = _mc_i[\"ow\"] * _mc_i[\"trueE\"]**(-sig_inj.gamma)\n",
    "        axl.hist(np.sin(_mc_i[\"trueDec\"]), bins=bins, weights=weights,\n",
    "                 log=True, color=colors[i])\n",
    "        axr.scatter(_mc_i[\"trueRa\"], _mc_i[\"trueDec\"], c=colors[i])\n",
    "\n",
    "    axl.axvline(np.sin(src_dec[i]), 0, 1, color=\"k\", ls=\"--\")\n",
    "    axl.axvline(np.sin(src_dec[i] - inj_width), 0, 1, color=\"k\")\n",
    "    axl.axvline(np.sin(src_dec[i] + inj_width), 0, 1, color=\"k\")\n",
    "        \n",
    "    axr.axhline(max(-np.pi / 2., srcs[\"dec\"][i] - sig_inj.inj_width),\n",
    "               0, 1, color=\"C7\", ls=\"--\")\n",
    "    axr.axhline(min(np.pi / 2., srcs[\"dec\"][i] + sig_inj.inj_width),\n",
    "               0, 1, color=\"C7\", ls=\"--\")\n",
    "    \n",
    "    hlp.circle_on_skymap(srcs[\"ra\"][i], srcs[\"dec\"][i], inj_width, axr,\n",
    "                         flat=True, color=\"k\", ls=\"-\", marker=\"\")  \n",
    "       \n",
    "axr.scatter(src_ra, src_dec, color=\"k\", marker=\"o\", edgecolor=\"k\",\n",
    "           facecolor=\"w\")\n",
    "\n",
    "m = 0.5 * (b[:-1] + b[1:])\n",
    "axl.hist(m, bins=bins, weights=h, color=\"k\", histtype=\"step\",\n",
    "         linewidth=2, log=True)\n",
    "\n",
    "axl.set_xlim(-1., 1.)\n",
    "axr.set_xlim(0., 2. * np.pi)\n",
    "axr.set_ylim(-np.pi/2., np.pi/2.)\n",
    "\n",
    "axl.set_xlabel(\"sin dec\")\n",
    "axr.set_xlabel(\"right-ascension\")\n",
    "axr.set_ylabel(\"dec\")\n",
    "axl.set_title(\"gamma = {:.2f}\".format(gamma))\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"data/figs/sig_inj_ev_selection_circle.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrc = 5\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrc)\n",
    "np.random.shuffle(src_ra)\n",
    "src_dec = np.deg2rad([-60., -30., 0, 30., 60.])\n",
    "src_t = np.linspace(50000, 50300, nsrc)\n",
    "dt0 = np.zeros(nsrc, dtype=np.float)\n",
    "dt1 = np.zeros(nsrc, dtype=np.float) + 200.\n",
    "w_theo = np.ones(nsrc)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "inj_width = np.deg2rad(11)\n",
    "gamma = 2.\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=\"circle\",\n",
    "                               inj_width=inj_width)\n",
    "skip = 50  # Just that it goes faster\n",
    "sig_inj.fit(srcs, {0: mc[::skip], 1:mc[::skip]}, exp.dtype.names)\n",
    "\n",
    "\n",
    "sm = amp_plt.skymap()\n",
    "fig, ax = sm.figure(tex=False)\n",
    "\n",
    "cmap = plt.cm.get_cmap(\"viridis\", nsrc + 2)\n",
    "colors = cmap.colors[1:-1]\n",
    "\n",
    "# Plot each src in a different color\n",
    "for i in range(nsrc):\n",
    "    # Get all events from all samples\n",
    "    for enum, mc_i in sig_inj._MC.items():\n",
    "        _enum = sig_inj.mc_arr[sig_inj.mc_arr[\"enum\"] == enum]\n",
    "        _src_m = _enum[\"src_idx\"] == i\n",
    "        _ev_idx = _enum[\"ev_idx\"]\n",
    "\n",
    "        _mc_i = mc_i[_ev_idx][_src_m]\n",
    "        x, y = amp_plt.EquCoordsToMapCoords(_mc_i[\"trueRa\"],\n",
    "                                            _mc_i[\"trueDec\"])\n",
    "        ax.scatter(x, y, c=colors[i])\n",
    "\n",
    "    hlp.circle_on_skymap(srcs[\"ra\"][i], srcs[\"dec\"][i], inj_width, ax,\n",
    "                         flat=False, color=\"k\", ls=\"-\", marker=\"\")  \n",
    "\n",
    "x, y = amp_plt.EquCoordsToMapCoords(src_ra, src_dec)\n",
    "ax.scatter(x, y, color=\"k\", marker=\"o\", edgecolor=\"k\",\n",
    "           facecolor=\"w\")\n",
    "\n",
    "ax.set_title(\"gamma = {:.2f}\".format(gamma))\n",
    "\n",
    "# fig.savefig(\"data/figs/sig_inj_ev_selection_circle_skymap.png\", dpi=200)\n",
    "    \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Inject events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "src_dec = np.deg2rad([-80., -30., 0, 30., 80.])\n",
    "nsrcs = len(src_dec)\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrcs)\n",
    "src_t = np.linspace(50000, 50300, nsrcs)\n",
    "# Use start = 0 only, plotter can't handle negative start times\n",
    "dt = np.vstack((np.repeat([0.], nsrcs), 100. * np.arange(1, nsrcs + 1))).T\n",
    "dt0 = dt[:, 0]\n",
    "dt1 = dt[:, 1]\n",
    "w_theo = np.ones(nsrcs)\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "\n",
    "# Only set the src params we need here manually\n",
    "gamma = 2.\n",
    "mode = \"band\"  # Change here to switch circle vs. band mode below\n",
    "if mode == \"band\":\n",
    "    inj_width = np.deg2rad(5.)\n",
    "elif mode == \"circle\":\n",
    "    inj_width = np.deg2rad(10.)\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=mode,\n",
    "                               inj_width=inj_width)\n",
    "sig_inj.fit(srcs, mc, exp.dtype.names)\n",
    "\n",
    "ngen = 10000\n",
    "gen = sig_inj.sample(ngen, poisson=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Spatial - Compare using band and circle with the same bandwidth\n",
    "\n",
    "In circle it lok like we selected way more events than in band mode, but we have way more MC than we select.\n",
    "So we just select the same amount of evts, but in a much denser region so the plot looks crowded in the circle case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extract injected events per source\n",
    "ninj, inj, idx = next(gen)\n",
    "\n",
    "evts_per_src = []\n",
    "trueRa_per_src = []\n",
    "trueDec_per_src = []\n",
    "for j in range(nsrcs):\n",
    "    per_src_ev_ids = idx[idx[\"src_idx\"] == j][\"ev_idx\"]\n",
    "    trueRa_per_src.append(sig_inj._MC[-1][per_src_ev_ids][\"trueRa\"])\n",
    "    trueDec_per_src.append(sig_inj._MC[-1][per_src_ev_ids][\"trueDec\"])\n",
    "    evts_per_src.append(inj[idx[\"src_idx\"] == j])\n",
    "    \n",
    "print(\"[true] Injected per src: \", list(map(len, trueRa_per_src)))\n",
    "print(\"[meas] Injected per src: \", list(map(len, evts_per_src)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cmap = plt.cm.get_cmap(\"viridis\", nsrcs + 2)\n",
    "colors = cmap.colors[1:-1]\n",
    "\n",
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "if mode == \"band\":\n",
    "    _min_dec = sig_inj._min_dec\n",
    "    _max_dec = sig_inj._max_dec\n",
    "elif mode == \"circle\":\n",
    "    _min_dec = src_dec - np.repeat(sig_inj.inj_width, nsrcs)\n",
    "    _max_dec = src_dec + np.repeat(sig_inj.inj_width, nsrcs)\n",
    "else:\n",
    "    raise ValueError(\"Choose 'band' or 'circle'.\")\n",
    "    \n",
    "\n",
    "for i in range(nsrcs):\n",
    "    trueRa = trueRa_per_src[i]\n",
    "    trueDec = trueDec_per_src[i]\n",
    "    _ev = evts_per_src[i]\n",
    "    n_sel = len(_ev)\n",
    "    \n",
    "    # Rotate again to if all all truths are at the src positions\n",
    "    ra3, dec3 = rotator(trueRa, trueDec,\n",
    "                        np.repeat(src_ra[i], n_sel),\n",
    "                        np.repeat(src_dec[i], n_sel),\n",
    "                        trueRa, trueDec)\n",
    "    \n",
    "    axl.scatter(_ev[\"ra\"], _ev[\"dec\"], marker=\".\", color=colors[i], alpha=0.1)\n",
    "    axr.scatter(trueRa, trueDec, marker=\".\", color=colors[i], alpha=0.1)\n",
    "\n",
    "    axl.scatter(ra3, dec3, marker=\".\", color=\"w\", edgecolor=\"k\", s=100)\n",
    "    axr.scatter(ra3, dec3, marker=\".\", color=\"w\", edgecolor=\"k\", s=100)\n",
    "    \n",
    "    \n",
    "    axl.axhline(src_dec[i], 0, 1, color=\"k\", ls=\"--\")\n",
    "    axl.axhline(_min_dec[i], 0, 1, color=\"k\")\n",
    "    axl.axhline(_max_dec[i], 0, 1, color=\"k\")\n",
    "    axr.axhline(src_dec[i], 0, 1, color=\"k\", ls=\"--\")\n",
    "    axr.axhline(_min_dec[i], 0, 1, color=\"k\")\n",
    "    axr.axhline(_max_dec[i], 0, 1, color=\"k\")\n",
    "    \n",
    "axl.set_xlabel(\"right-ascension\")\n",
    "axl.set_ylabel(\"dec\")\n",
    "axr.set_xlabel(\"right-ascension\")\n",
    "axr.set_ylabel(\"dec\")\n",
    "axl.set_title(\"Rotated measured and true positions\")\n",
    "axr.set_title(\"Rotated true and true positions\")\n",
    "\n",
    "fig.tight_layout()\n",
    "# fig.savefig(\"data/figs/signal_events_radec_sampled_\" +\n",
    "#             \"rotated_{}.png\".format(mode), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cos_dist(src_ra, src_dec, ev_ra, ev_dec):\n",
    "    cos_dist = (np.cos(src_ra - ev_ra) *\n",
    "                np.cos(src_dec) * np.cos(ev_dec) +\n",
    "                np.sin(src_dec) * np.sin(ev_dec))\n",
    "\n",
    "    return np.clip(cos_dist, -1., 1.)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "\n",
    "# Pool of MC event to select from\n",
    "ra = sig_inj._MC[-1][\"ra\"]\n",
    "dec = sig_inj._MC[-1][\"dec\"]\n",
    "trueRa = sig_inj._MC[-1][\"trueRa\"]\n",
    "trueDec = sig_inj._MC[-1][\"trueDec\"]\n",
    "w = sig_inj._sample_w\n",
    "dist = cos_dist(trueRa, trueDec, ra, dec)\n",
    "_ = plt.hist(np.rad2deg(np.arccos(dist)), bins=100, weights=w,\n",
    "             range=[0., 180.], log=True, label=\"All selected\")\n",
    "\n",
    "# All currently injected events\n",
    "ev_idx = idx[\"ev_idx\"]  # Select only injected from all\n",
    "ra = ra[ev_idx]\n",
    "dec = dec[ev_idx]\n",
    "trueRa = trueRa[ev_idx]\n",
    "trueDec = trueDec[ev_idx]\n",
    "w = w[ev_idx]\n",
    "dist = cos_dist(trueRa, trueDec, ra, dec)\n",
    "_ = plt.hist(np.rad2deg(np.arccos(dist)), bins=100, weights=w,\n",
    "             range=[0., 180.], log=True, label=\"Injected\")\n",
    "plt.title(\"Space angle distribution between true and measured direction.\" +\n",
    "          \" Currently injected: {} evts\". format(ngen))\n",
    "\n",
    "plt.xlabel(\"delta Psi in degree\")\n",
    "plt.ylabel(\"sum of sample weights per bin\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"data/figs/signal_events_delta_psi_comp_{}.png\".format(mode,\n",
    "                                                                   dpi=150))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Times\n",
    "\n",
    "**Note:** The number of times per window (= events drawn per source) are distributed like the signal declination distribution, because we made up sources which are distributed linearly ascending in time and in declination, so they simply correlate.\n",
    "It's a nice double check in plot.\n",
    "But also compare to the histograms in the \"Fill Event\" cells above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create the GRBLLH object but only for the time pdf\n",
    "sin_dec_bins = np.linspace(-1, 1, 50)\n",
    "logE_bins = np.linspace(1, 10, 40)\n",
    "\n",
    "spatial_pdf_args = {\"bins\": sin_dec_bins, \"k\": 3, \"kent\": True}\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins],\n",
    "                   \"gamma\": 2., \"fillval\": \"col\", \"interpol_log\": False}\n",
    "time_pdf_args = {\"nsig\": 4., \"sigma_t_min\": 2., \"sigma_t_max\": 30.}\n",
    "llh_args = {\"sob_rel_eps\": 0., \"sob_abs_eps\": 1e-4}\n",
    "\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Extract injected events per source\n",
    "ninj, inj, idx = next(gen)\n",
    "\n",
    "times_per_src = []\n",
    "for j in range(nsrcs):\n",
    "    times_per_src.append(inj[idx[\"src_idx\"] == j][\"timeMJD\"])\n",
    "    \n",
    "print(\"[true] Injected per src: \", list(map(len, times_per_src)))\n",
    "\n",
    "\n",
    "# Now each times in the centered time frame in seconds together with the\n",
    "# signal PDFs\n",
    "vline_scale = 20.\n",
    "\n",
    "nsig = 4.\n",
    "clip = np.clip(np.diff(dt, axis=1), 2, 30) * nsig\n",
    "trange = np.hstack((dt[:, [0]] - clip, dt[:, [1]] + clip))\n",
    "\n",
    "for i, ti in enumerate(times_per_src):\n",
    "    t_sec = ti * secinday - src_t[i] * secinday\n",
    "    _t = np.linspace(trange[i, 0], trange[i, 1], 100)\n",
    "    _t_mjd = _t / secinday + src_t[i]\n",
    "#     _pdf = time_sig_pdf(_t_mjd, src_t[i],\n",
    "#                         dt[i, 1] - dt[i, 0]).flatten()\n",
    "    _pdf = grbllh._soverb_time(_t_mjd, src_t[i], dt[i]).ravel()\n",
    "    if i == 0:\n",
    "        _max = 1.05 * np.amax(_pdf)\n",
    "    # Small ticks for event positions below the 0 line\n",
    "    plt.vlines(t_sec, -i * _max / vline_scale, -(i+1) * _max / vline_scale,\n",
    "               linestyles=\"-\", colors=\"C{:1d}\".format(i))\n",
    "    plt.vlines(dt[i], _max, -nsrcs * _max / vline_scale, linestyles=\":\",\n",
    "               colors=\"C{:1d}\".format(i))\n",
    "    plt.plot(_t, _pdf, \"C{:1d}-\".format(i),\n",
    "             label=\"{:d} evts\".format(len(ti)))\n",
    "\n",
    "plt.axhline(0, 0, 1, color=\"C7\")\n",
    "plt.xlim(1.1 * trange[1, 0], trange[-1, 1] - 0.1 * trange[-1, 0])\n",
    "plt.ylim(-nsrcs * _max / vline_scale, _max)\n",
    "plt.xlabel(\"time in sec, centered at src t0\")\n",
    "plt.title(\"Injected evts per window, total of {} signal evts.\".format(ninj))\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "# plt.savefig(\"data/figs/signal_events_time_sampled_multi.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Check expected vs injected evts per src\n",
    "\n",
    "We inject events and comnpare the fraction of events injected per source with the total src weight, which is detector acceptance (signal weighted) and intrinsic weight.\n",
    "If we sample in a narrow band around each src we expect the fraction of sampled events to match the total source weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Note:** Circle mode doesn't match when the radius is very small.\n",
    "That is because we inject from less events and are very dominated by initial mc fluctuations, inserting only a tiny fraction of events.\n",
    "If we increase the circle size (0.1 in sindec) we get similarly stable results as in band mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "src_dec = np.deg2rad([-80.,- 60., -45., -30., -15., 0,\n",
    "                      15., 30., 45., 60., 80.])\n",
    "nsrcs = len(src_dec)\n",
    "src_ra = np.linspace(0, 2. * np.pi, nsrcs)\n",
    "src_t = np.linspace(50000, 50300, nsrcs)\n",
    "# Use start = 0 only, plotter can't handle negative start times\n",
    "dt = np.vstack((np.repeat([0.], nsrcs), 100. * np.arange(1, nsrcs + 1))).T\n",
    "dt0 = dt[:, 0]\n",
    "dt1 = dt[:, 1]\n",
    "\n",
    "w_theo = np.ones(nsrcs)\n",
    "# Try to see the deviation from the MC, but not from injected evts\n",
    "# w_theo = np.arange(nsrcs, dtype=np.float) + 1.\n",
    "\n",
    "src_names = [\"ra\", \"dec\", \"t\", \"dt0\", \"dt1\", \"w_theo\"]\n",
    "srcs = np.core.records.fromarrays(np.vstack((src_ra, src_dec,src_t,\n",
    "                                             dt0, dt1, w_theo)),\n",
    "                                  names=src_names)\n",
    "gamma = 1.8\n",
    "mode = \"band\"\n",
    "# Make it narrow so only events in close proximity to the srcs are selected\n",
    "# so the fraction matches the  total src weight.\n",
    "inj_width = np.arcsin(0.02)\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=mode,\n",
    "                               inj_width=inj_width)\n",
    "sig_inj.fit(srcs, mc, exp.dtype.names)\n",
    "\n",
    "ngen = 10000\n",
    "gen = sig_inj.sample(ngen, poisson=False)\n",
    "\n",
    "# Extract injected events per source\n",
    "ninj, inj, idx = next(gen)\n",
    "\n",
    "trueDec_per_src = []\n",
    "for j in range(nsrcs):\n",
    "    per_src_ev_ids = idx[idx[\"src_idx\"] == j][\"ev_idx\"]\n",
    "    trueDec_per_src.append(sig_inj._MC[-1][per_src_ev_ids][\"dec\"])\n",
    "    \n",
    "evts_per_src = list(map(len, trueDec_per_src))\n",
    "print(\"[true] Injected per src: \", evts_per_src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get src detector * theo weights\n",
    "grbllh = LLH.GRBLLH(exp, mc,\n",
    "                    spatial_pdf_args={\"bins\": np.linspace(-1., 1., 50)},\n",
    "                    energy_pdf_args={\"bins\": np.vstack((\n",
    "                    np.linspace(-1., 1., 50), np.linspace(1., 10., 50))),\n",
    "                                    \"gamma\": sig_inj.gamma})\n",
    "\n",
    "norm_src_w = grbllh.src_weights(srcs[\"dec\"], src_w_theo=w_theo).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "sin_dec = np.linspace(-1., 1., 201)\n",
    "bins = np.linspace(-1., 1., 201)\n",
    "\n",
    "# Normed src weights, sum=1\n",
    "ax.plot(np.sin(srcs[\"dec\"]), norm_src_w, ls=\"\", marker=\"o\", color=\"#353132\",\n",
    "        label=\"norm. src_w = acc_w * theo_w\")\n",
    "\n",
    "# Spline must be pseudo weighted to match the single weights (PMF style)\n",
    "pseudo_norm = np.sum(np.exp(grbllh._spatial_signal_spl(np.sin(srcs[\"dec\"]))))\n",
    "y = np.exp(grbllh._spatial_signal_spl(sin_dec)) / pseudo_norm\n",
    "ax.plot(sin_dec, y, color=\"#353132\")\n",
    "\n",
    "# Make MC hist (origin of spline)\n",
    "weights = mc[\"ow\"] * mc[\"trueE\"]**(-sig_inj.gamma)\n",
    "h, b = np.histogram(np.sin(mc[\"trueDec\"]), bins=bins, weights=weights,\n",
    "                    normed=True)\n",
    "m = 0.5 * (b[:-1] + b[1:])\n",
    "_ = ax.hist(m, bins=b, weights=h / pseudo_norm, alpha=0.2, color=\"C7\")\n",
    "\n",
    "# Make fraction of sampled events per band\n",
    "frac = evts_per_src / np.sum(evts_per_src)\n",
    "ax.plot(np.sin(srcs[\"dec\"]), frac, ls=\"\", marker=\"_\",\n",
    "        color=\"C1\", mew=2, ms=10, label=\"Fraction of inj. events\")\n",
    "ax.vlines(np.sin(srcs[\"dec\"]), np.zeros_like(frac), frac, zorder=5,\n",
    "           color=\"C1\", linestyle=\"-\", lw=3)\n",
    "\n",
    "ax.set_xlabel(\"sin_dec\")\n",
    "ax.set_ylabel(\"fraction of inj events\")\n",
    "ax.set_xlim(-1., 1.)\n",
    "# ax.semilogy()\n",
    "ax.legend()\n",
    "ax.set_title(\"{} injected events, mode='{}'\".format(ngen, mode))\n",
    "\n",
    "# plt.savefig(\"./data/figs/sig_inj_src_w_vs_inj_fraction.png\", dpi=150)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis module grabs all the stuf from before and creates trial calculation from it.\n",
    "So we test here, if everything wrapped up correctly and if we get OK looking test statistics from our trials.\n",
    "\n",
    "A genreal note on how our experimental is handled:\n",
    "\n",
    "Before we start out analysis, we split our data in off-time and on-time data.\n",
    "On-time data is data around a a-priori fixed time frame around our sources we want to test.\n",
    "We exclude this data until the very end, because we don't want to bias ourselfes as there is the possibility that the signal we want to find is in that on-time data.\n",
    "\n",
    "The off-time data is everything else and is assumed to not contain the sought after signal.\n",
    "The on-time time frame should be choosen large enough to account for that.\n",
    "It should definitely be larger than the time frames we test for in our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BG only Trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using all the modules from above we can run trials with pure background now.\n",
    "\n",
    "A trial is a single pseudo experiment we perform and evaluate to get an idea of the underlying statistical distribtuion and to build our test statistic from which we can infer the significance of real data later.\n",
    "For that we need to generate sets of pseudo-data which has background-like properties.\n",
    "The `bg_injector`, `bg_rate_injector` and `rate_function` classes are used to generate these properties.\n",
    "\n",
    "So each trial consist of the following steps, in which the source positions are always fixed and a-priori known:\n",
    "\n",
    "1. Determine the expected number background events per source time window we test.\n",
    "   This is derived from the `bg_rate_injector` which returns a list of sampled times for each time window.\n",
    "   It knows the expected rate from the given `rate_function`\n",
    "2. In addition to our sampled times, we need all the other event features we have on real data (positions, energy, uncertainty) , because our sampled pseudo-data should have the same properties as real data.\n",
    "   These missing properties are generated by the `bg_injector` class.\n",
    "3. When we sampled our pseudo-events we need to fit the LLH to this set of events and see what best fit we get.\n",
    "4. We do that a lot of times and see how our best fits are distributed which gives us a so called test statistic which describes the distribution of LLH firs using BG only.\n",
    "\n",
    "On background-like events we expect to get a null fit result most of the times, because no signal is present.\n",
    "But out of chance, we sometimes get a combination of background-like events, that has very signal-like properties.\n",
    "\n",
    "The so build test statistic is then used to see how unlikely the single fit to our on-time data was and how lucky we'd have to get to observe that result out of chance from pure background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def _percentile_nzeros(vals, nzeros, q):\n",
    "    \"\"\"\n",
    "    Returns the percentile q for a dataset with `vals` > 0 and `nzeros`\n",
    "    entries that are zero.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    vals : array-like\n",
    "        Non-zero values.\n",
    "    nzeros : int\n",
    "        Number of zero trials.\n",
    "    q : float\n",
    "        Percentile in [0, 100].\n",
    "    \"\"\"\n",
    "    q /= 100.\n",
    "    nonzero = len(vals)\n",
    "    ntot = nonzero + nzeros\n",
    "    idx = int(q * ntot) - nzeros - 1\n",
    "    vals = np.sort(vals)\n",
    "        \n",
    "    if idx < 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        return vals[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_trials(vals, ntrials, bins, ax=None,\n",
    "                CHI2=True, GEN=False, SIGMA=True, **kwargs):\n",
    "    if len(vals) == 0:\n",
    "        raise ValueError(\"No values given. Maybe sample more trials.\")\n",
    "\n",
    "    def prop_in_1d_sigma(sigma):\n",
    "        # To draw the sigma lines\n",
    "        if sigma < 0:\n",
    "            raise ValueError(\"'sigma' must be >= 0\")\n",
    "        return scs.norm.cdf(sigma) - scs.norm.cdf(-sigma)\n",
    "\n",
    "    # Compare with generated chi2 with df=1 and same nzeros\n",
    "    if GEN:\n",
    "        vals = np.random.chisquare(df=1, size=len(res))\n",
    "        fname = \"gen_chi2_df=1\"\n",
    "    else:\n",
    "        fname = \"trials\"\n",
    "        \n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(1, 1)\n",
    "\n",
    "    # Add nzeros to first bin manually\n",
    "    nzeros = ntrials - len(vals)\n",
    "    h, b = np.histogram(vals, bins=bins)\n",
    "    h[0] += nzeros\n",
    "\n",
    "    m = 0.5 * (b[:-1] + b[1:])\n",
    "    _ = ax.hist(m, b, weights=h, normed=True, log=True, **kwargs)\n",
    "\n",
    "    if CHI2:\n",
    "        # Fit delta-chi2 PDF to TS\n",
    "        (df, loc, scale) = scs.chi2.fit(vals, floc=0)\n",
    "        chi2fit = scs.chi2(df, loc, scale)\n",
    "        eta = len(vals) / ntrials\n",
    "        x = np.linspace(0.1, bins[-1], 200)\n",
    "        y = chi2fit.pdf(x) * eta\n",
    "        ydf1 = scs.chi2.pdf(x, df=1, loc=0, scale=1) * eta\n",
    "\n",
    "        # Plot fitted and dof=1 chi2 for comparison\n",
    "        ax.plot(x, y, \"C1-\")\n",
    "        ax.plot(x, ydf1, \"C2--\")\n",
    "\n",
    "    # Plot sigmas with increasing shade\n",
    "    if SIGMA:\n",
    "        sigmas = np.arange(3, 6)\n",
    "        sig_vals = [prop_in_1d_sigma(i) for i in sigmas]\n",
    "        for sig, sigval in zip(sigmas, sig_vals):\n",
    "            ax.axhline(1 - sigval, 0, 1, color=dg, ls=\"--\",\n",
    "                       label=\"{} sigma\".format(sig),\n",
    "                       alpha=(1 - 0.5 * (np.amax(sigmas) - sig) /\n",
    "                              (np.amax(sigmas) - np.amin(sigmas))))\n",
    "        ax.legend(loc=\"best\")\n",
    "\n",
    "    ax.set_ylabel(\"PDF\")\n",
    "\n",
    "    if CHI2:\n",
    "        ax.set_title(\"Percent non-zero trials: \" +\n",
    "                     \"{:.1f} (=eta). df={:.2f}, scale={:.2f}\".format(\n",
    "                      100 * len(vals) / ntrials, df, scale))\n",
    "    else:\n",
    "        ax.set_title(\"Percent non-zero trials: {:.1f} (=eta).\".format(\n",
    "            100 * len(vals) / ntrials))\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We're going through the full steps here:\n",
    "\n",
    "1. Create bg_rate_injector with a specific rate_function.\n",
    "2. Create a bg_injector injecting random data events.\n",
    "3. Create LLH which is used to test our hypthesis.\n",
    "4. Create some src hyptheses to test against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "rndgen = np.random.RandomState(7353)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create some srcs we want to test, with some different properties.\n",
    "# We don't use randomness here to have full control\n",
    "nsrcs = 5\n",
    "dt = np.vstack((np.repeat([-20.], nsrcs), 100. * np.arange(1, nsrcs + 1))).T\n",
    "\n",
    "names = [\"t\", \"dt0\", \"dt1\", \"ra\", \"dec\", \"w_theo\"]\n",
    "types = len(names) * [np.float]\n",
    "dtype = [(_n, _t) for _n, _t in zip(names, types)]\n",
    "srcs = np.empty((nsrcs, ), dtype=dtype)\n",
    "\n",
    "# Choose times equally spaced, but away from borders\n",
    "mint, maxt = np.amin(_exp[\"timeMJD\"]), np.amax(_exp[\"timeMJD\"])\n",
    "srcs[\"t\"] = np.linspace(mint, maxt, nsrcs + 2)[1:-1]\n",
    "\n",
    "srcs[\"dt0\"] = dt[:, 0]\n",
    "srcs[\"dt1\"] = dt[:, 1]\n",
    "\n",
    "# Don't let them overlap by choosing 0 and 2pi\n",
    "srcs[\"ra\"] = np.linspace(0, 2 * np.pi, nsrcs + 1)[:-1]\n",
    "\n",
    "# Same as with time here, do not select directly at poles\n",
    "srcs[\"dec\"] = np.arcsin(np.linspace(-1, 1, nsrcs + 2)[1:-1])\n",
    "\n",
    "# These are just ones, they shouldn't cause problems\n",
    "srcs[\"w_theo\"] = np.ones(nsrcs, dtype=np.float)\n",
    "\n",
    "print(\"t   : \" + \", \".join(\"{:.2f}\".format(_t) for _t in srcs[\"t\"]))\n",
    "print(\"dt0 : \", srcs[\"dt0\"])\n",
    "print(\"dt1 : \", srcs[\"dt1\"])\n",
    "print(\"RA  : \" + \", \".join(\"{:.2f}\".format(_ra) for _ra\n",
    "                           in np.rad2deg(srcs[\"ra\"])))\n",
    "print(\"DEC : \" + \", \".join(\"{:.2f}\".format(_dec) for _dec\n",
    "                           in np.rad2deg(srcs[\"dec\"])))\n",
    "print(\"wt  : \", srcs[\"w_theo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the GRBLLH object with all the PDF settings\n",
    "sin_dec_bins = np.linspace(-1, 1, 50)\n",
    "\n",
    "min_logE = 1  #  min(np.amin(_exp[\"logE\"]), np.amin(mc[\"logE\"]))\n",
    "max_logE = 10 #  max(np.amax(_exp[\"logE\"]), np.amax(mc[\"logE\"]))\n",
    "logE_bins = np.linspace(min_logE, max_logE, 40)\n",
    "\n",
    "spatial_pdf_args = {\"bins\": sin_dec_bins, \"k\": 3, \"kent\": True}\n",
    "\n",
    "energy_pdf_args = {\"bins\": [sin_dec_bins, logE_bins],\n",
    "                   \"gamma\": 2., \"fillval\": \"col\", \"interpol_log\": False}\n",
    "\n",
    "time_pdf_args = {\"nsig\": 4., \"sigma_t_min\": 2., \"sigma_t_max\": 30.}\n",
    "\n",
    "llh_args = {\"sob_rel_eps\": 0., \"sob_abs_eps\": 1e-4}\n",
    "\n",
    "grbllh = LLH.GRBLLH(X=_exp, MC=_mc,\n",
    "                    spatial_pdf_args=spatial_pdf_args,\n",
    "                    energy_pdf_args=energy_pdf_args,\n",
    "                    time_pdf_args=time_pdf_args,\n",
    "                    llh_args=llh_args)\n",
    "\n",
    "print(grbllh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a bg rate injector model\n",
    "def filter_runs(run):\n",
    "    \"\"\"\n",
    "    Filter runs as stated in jfeintzig's doc.\n",
    "    \"\"\"\n",
    "    exclude_runs = [120028, 120029, 120030, 120087, 120156, 120157]\n",
    "    if ((run[\"good_i3\"] == True) & (run[\"good_it\"] == True) &\n",
    "        (run[\"run\"] not in exclude_runs)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# Create an injector using a goodrun list, use a sinus rate function with\n",
    "# fixed period of 1yr\n",
    "runlist = \"data/runlists/ic86-i-goodrunlist.json\"\n",
    "\n",
    "# Choose your rate function\n",
    "RFUNC = \"CONST\"  # \"SIN1YR\", \"CONST\"\n",
    "print(\"Choosing '{}' function\".format(RFUNC))\n",
    "\n",
    "if RFUNC == \"SIN\" or RFUNC == \"SIN1YR\":\n",
    "    # Give fixed srs, to use caching\n",
    "    t = srcs[\"t\"]\n",
    "    trange = grbllh.time_pdf_def_range(src_t=srcs[\"t\"], dt=dt)\n",
    "    if RFUNC == \"SIN\":\n",
    "        rate_func_obj = RateFunc.SinusRateFunction(t, trange, rndgen)\n",
    "    else:\n",
    "        rate_func_obj = RateFunc.Sinus1yrRateFunction(t, trange, rndgen)\n",
    "elif RFUNC == \"CONST\":\n",
    "    rate_func_obj = RateFunc.ConstantRateFunction(rndgen)\n",
    "\n",
    "bg_rate_inj = BGRateInj.RunlistBGRateInjector(rate_func_obj, runlist,\n",
    "                                              filter_runs, rndgen)\n",
    "\n",
    "# Fit the injector to make it usable\n",
    "times = _exp[\"timeMJD\"]\n",
    "rate_func = bg_rate_inj.fit(T=times, x0=None, remove_zero_runs=True)\n",
    "\n",
    "if RFUNC != \"CONST\":\n",
    "    print(\"RateFunction uses cached fmax vals:\\n  - \", rate_func_obj._fmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Choose your bg injector\n",
    "BGINJ = \"DATA\"  # \"KDE\", \"UNI\", \"MR\"\n",
    "print(\"Choosing '{}' injector\".format(BGINJ))\n",
    "\n",
    "if BGINJ == \"DATA\":\n",
    "    bg_inj = BGInj.DataBGInjector(rndgen)\n",
    "    bg_inj.fit(_exp)\n",
    "    \n",
    "elif BGINJ == \"KDE\":\n",
    "    # We use precahced KDE values, because the model is fixed\n",
    "    # Note: The original order cannot be changed now [logE, dec, sigma]\n",
    "    with open(\"data/awKDE_CV/CV10_glob_bw_alpha_EXP_IC86I_CUT_sig.ll.20_\" +\n",
    "              \"PARS_diag_True_pass2.pickle\", \"rb\") as f:\n",
    "        model_selector = pickle.load(f)\n",
    "        print(model_selector.best_params_)\n",
    "\n",
    "    bg_inj = BGInj.KDEBGInjector(rndgen)\n",
    "    bg_inj.kde_model = model_selector.best_estimator_\n",
    "\n",
    "    # We could still change the alpha, but the global bandwidth must stay fixed\n",
    "    # bg_inj.kde_model.alpha = 0.3\n",
    "\n",
    "    # Fit doesn't take long because all adaptive kernels are set.\n",
    "    bounds = np.array([[None, None], [-np.pi / 2. , np.pi / 2.], [0, None]])\n",
    "#     bg_inj.fit(_exp, bounds)\n",
    "\n",
    "elif BGINJ == \"UNI\":\n",
    "    bg_inj = BGInj.UniformBGInjector(rndgen)\n",
    "    \n",
    "elif BGINJ == \"MR\":\n",
    "    bg_inj = BGInj.MRichmanBGInjector(rndgen)\n",
    "    bg_inj.fit(_exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# And now the analysis object\n",
    "ana = Analysis.TransientsAnalysis(srcs=srcs, llh=grbllh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Manual steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make a single trial fit in the end while looking at all the intermediate steps.\n",
    "\n",
    "Need to run the setuo cells above.\n",
    "\n",
    "**Here are some time background plots that should get it's own category but we leave them here for now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rndgen = np.random.RandomState(7353)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Prepare fixed source parameters for injector arguments\n",
    "src_t = srcs[\"t\"]\n",
    "src_dt = np.vstack((srcs[\"dt0\"], srcs[\"dt1\"])).T\n",
    "\n",
    "# First step: Get the injection time windows per source in seconds centered\n",
    "# around each source position\n",
    "trange = ana.llh.time_pdf_def_range(src_t, src_dt)\n",
    "\n",
    "print(\"dt in sec\\n\", dt)\n",
    "print(\"\")\n",
    "print(\"trange in sec\\n\", trange)\n",
    "\n",
    "# Compare to our expectation by calculcating manually trange:\n",
    "#   trange = diff(dt) + 2 * nsig * clip_t, which were setup for the LLH\n",
    "print(\"\")\n",
    "clip = np.clip(np.diff(dt).flatten(), time_pdf_args[\"sigma_t_min\"],\n",
    "               time_pdf_args[\"sigma_t_max\"])\n",
    "nsig = time_pdf_args[\"nsig\"]\n",
    "_trange = np.copy(dt)\n",
    "_trange[:, 0] = dt[:, 0] - clip * nsig\n",
    "_trange[:, 1] = dt[:, 1] + clip * nsig\n",
    "print(\"manual\\n\", _trange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the number of expected background events in each given time frame from\n",
    "# the bg_rate_injector which gets it from the integral over the rate_function\n",
    "nb = bg_rate_inj.get_nb(src_t, trange)\n",
    "args = {\"nb\": nb}\n",
    "\n",
    "print(\"nb from integral\\n\", nb)\n",
    "print(\"\")\n",
    "print(\"args wrapper\\n\", args)\n",
    "\n",
    "# We compare that with a naive integration by just using trange * mean_rate\n",
    "# directly from the fit params of the rate_function. These are approximately\n",
    "# the same when our time windows are not too large and is not constant.\n",
    "if RFUNC == \"SIN\":\n",
    "    print(\"\\n# Used a SinusRateFunction\")\n",
    "    mean_rate = bg_rate_inj.best_pars[3]\n",
    "if RFUNC == \"SIN1YR\":\n",
    "    print(\"\\n# Used a Sinus1yrRateFunction\")\n",
    "    mean_rate = bg_rate_inj.best_pars[2]\n",
    "if RFUNC == \"CONST\":\n",
    "    print(\"\\n# Used a ConstantRateFunction, values must be excatly the same\")\n",
    "    mean_rate = bg_rate_inj.best_pars[0]\n",
    "    \n",
    "intgrls = mean_rate * np.diff(trange)\n",
    "print(\"\")\n",
    "print(\"Naive mean_rate * diff(trange)\\n\", intgrls.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now we sample times for a few trials, just to get some more events\n",
    "ntrials = 100\n",
    "times = []\n",
    "for i in range(ntrials):\n",
    "    times.append(bg_rate_inj.sample(src_t, trange, poisson=True))\n",
    "    \n",
    "# This is now a list of lists of arrays\n",
    "flat_times_per_src = []\n",
    "for i in range(nsrcs):\n",
    "    flat_times_per_src.append(flatten_list_of_1darrays(\n",
    "        [ti[i] for ti in times]))\n",
    "\n",
    "flat_times = flatten_list_of_1darrays(flat_times_per_src)\n",
    "\n",
    "# First all times in MJD in the global position. Won't see much, just to\n",
    "# check if no stray times are generated\n",
    "plt.vlines(flat_times, 0, 1, linestyles=\"--\", colors=\"C7\")\n",
    "plt.vlines(src_t - trange[:, 0] / secinday, 0, 0.25,  # only 1/4 to see all\n",
    "           linestyles=\"--\", colors=\"C3\")\n",
    "plt.vlines(src_t - trange[:, 1] / secinday, 0.25, 0.5,  # only 1/4 to see all\n",
    "           linestyles=\"--\", colors=\"C2\")\n",
    "plt.xlim(mint, maxt)\n",
    "plt.xlabel(\"Each time sample in MJD\")\n",
    "plt.ylabel(\"Just vlines, no real unit\")\n",
    "plt.title(\"Time windows too small to see evts, just to check for stray evts\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"data/figs/background_events_time_sampled_large.png\", dpi=200)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Now each times in the centered time frame in seconds together with the\n",
    "# signal PDFs\n",
    "vline_scale = 20.\n",
    "for i, ti in enumerate(flat_times_per_src):\n",
    "    t_sec = ti * secinday - src_t[i] * secinday\n",
    "    _t = np.linspace(trange[i, 0], trange[i, 1], 100)\n",
    "    _t_mjd = _t / secinday + src_t[i]\n",
    "    _pdf = ana.llh._soverb_time(_t_mjd, src_t[i], dt[i]).flatten()\n",
    "    if i == 0:\n",
    "        _max = 1.05 * np.amax(_pdf)\n",
    "    # Small ticks for event positions below the 0 line\n",
    "    plt.vlines(t_sec, -i * _max / vline_scale, -(i+1) * _max / vline_scale,\n",
    "               linestyles=\"-\", colors=\"C{:1d}\".format(i))\n",
    "    plt.vlines(trange[i], 0, -nsrcs * _max / vline_scale, linestyles=\":\",\n",
    "               colors=\"C{:1d}\".format(i))\n",
    "    plt.plot(_t, _pdf, \"C{:1d}-\".format(i),\n",
    "             label=\"{:d} evts\".format(len(ti)))\n",
    "\n",
    "plt.axhline(0, 0, 1, color=\"C7\")\n",
    "plt.xlim(1.1 * trange[-1, 0], trange[-1, 1] - 0.1 * trange[-1, 0])\n",
    "plt.ylim(-nsrcs * _max / vline_scale, _max)\n",
    "plt.xlabel(\"time in sec, centered at src t0\")\n",
    "plt.title(\"Individual samples in each window, \" +\n",
    "          \"combined of {} trials.\".format(ntrials))\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"data/figs/background_events_time_sampled_windows.png\", dpi=200)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Just sample a bit more to have enough events\n",
    "ntrials = 10000\n",
    "times = []\n",
    "for i in range(ntrials):\n",
    "    times.append(bg_rate_inj.sample(src_t, trange, poisson=True,\n",
    "                                    random_state=rndgen))\n",
    "flat_times_per_src = []\n",
    "for i in range(nsrcs):\n",
    "    flat_times_per_src.append(flatten_list_of_1darrays(\n",
    "        [ti[i] for ti in times]))\n",
    "flat_times = flatten_list_of_1darrays(flat_times_per_src)\n",
    "\n",
    "\n",
    "# Next up, sample alle other features than time:\n",
    "# ra, dec (sinDec), logE, sigma\n",
    "nevts_per_source = np.array(list(map(len, flat_times_per_src)))\n",
    "nevts = len(flat_times)\n",
    "\n",
    "X = []\n",
    "for i in range(nsrcs):\n",
    "    X_ = bg_inj.sample(nevts_per_source[i], random_state=rndgen)\n",
    "    X.append(numpy.lib.recfunctions.append_fields(\n",
    "        X_, \"timeMJD\", flat_times_per_src[i],\n",
    "        dtypes=np.float, usemask=False))\n",
    "\n",
    "# Show sampled events per src for all trials\n",
    "skymap = amp_plt.skymap()\n",
    "fig, ax = skymap.figure(tex=False, gal_plane=True)\n",
    "for i in range(nsrcs):\n",
    "    x, y = skymap.EquCoordsToMapCoords(X[i][\"ra\"], X[i][\"dec\"])\n",
    "    ax.plot(x, y, ls=\"\", marker=\".\", ms=2, color=\"C{:1d}\".format(i),\n",
    "            alpha=0.5)\n",
    "plt.show()\n",
    "\n",
    "# Plot RA\n",
    "for i in range(nsrcs):\n",
    "    plt.hist(X[i][\"ra\"], bins=10, range=[0, 2 * np.pi], histtype=\"step\",\n",
    "             color=\"C{:1d}\".format(i))\n",
    "plt.xlabel(\"ra\")\n",
    "plt.ylabel(\"number of events\")\n",
    "plt.show()\n",
    "    \n",
    "# Plot dec\n",
    "for i in range(nsrcs):\n",
    "    plt.hist(X[i][\"sinDec\"], bins=20, range=[-1, +1], histtype=\"step\",\n",
    "             color=\"C{:1d}\".format(i))\n",
    "plt.xlabel(\"sin(dec)\")\n",
    "plt.ylabel(\"number of events\")\n",
    "plt.show()    \n",
    "\n",
    "# Plot logE\n",
    "for i in range(nsrcs):\n",
    "    plt.hist(X[i][\"logE\"], bins=20, range=[2, 6], histtype=\"step\",\n",
    "             color=\"C{:1d}\".format(i))\n",
    "plt.xlabel(\"logE\")\n",
    "plt.ylabel(\"number of events\")\n",
    "plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now the fit itself. One every cell execution we do a single trial\n",
    "times = bg_rate_inj.sample(src_t, trange, poisson=True,\n",
    "                           random_state=rndgen)\n",
    "flat_times = flatten_list_of_1darrays(times)\n",
    "nevts_per_src = list(map(len, times))\n",
    "nevts = len(flat_times)\n",
    "\n",
    "print(\"nevts total\\n\", nevts)\n",
    "print(\"nevts per src\\n\", nevts_per_src)\n",
    "print(\"times\\n\", flat_times)\n",
    "\n",
    "X = bg_inj.sample(nevts, random_state=rndgen)\n",
    "X = numpy.lib.recfunctions.append_fields(X, \"timeMJD\", flat_times,\n",
    "                                         dtypes=np.float, usemask=False)\n",
    "\n",
    "print(\"X['ra'] degrees\\n\", np.rad2deg(X[\"ra\"]))\n",
    "print(\"X['dec'] degrees\\n\", np.rad2deg(X[\"dec\"]))\n",
    "print(\"X['sinDec']\\n\", X[\"sinDec\"])\n",
    "print(\"X['logE']\\n\", X[\"logE\"])\n",
    "print(\"X['sigma'] degress\\n\", np.rad2deg(X[\"sigma\"]))\n",
    "\n",
    "args = {\"nb\": nb, \"srcs\": srcs}\n",
    "ns0 = 1.\n",
    "bounds = [[0., 2. * nevts]]\n",
    "res = grbllh.fit_lnllh_ratio(X, ns0, args, bounds=bounds, minimizer_opts={})\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "heading_collapsed": true
   },
   "source": [
    "#### Local Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Everything we did above, wrapped in a single method.\n",
    "Trials up to 1e3 - 1e4 run fast enough to quick check.\n",
    "Everything else needs some more cluster time, see cell below.\n",
    "Trials are zero a lot of times, so you really need a lot of trials to get a good enough sampled TS.\n",
    "\n",
    "Note on the ns distribution:\n",
    "As we sample the number of events per trial from a poisson distribution, we see the fitted ns peaked at integer numbers.\n",
    "The main peak is of course at 0 because most of our events are not even close to the sources.\n",
    "The second peak is the next likely number of events, 1 and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%prun  # Profile the run. The are some unoptimized things due to\n",
    "          # generality of the code\n",
    "\n",
    "ns0 = 1  # The closer to small number of evts the faster\n",
    "minopts = {\"bounds\": [[0, None],]}\n",
    "ntrials = int(1e4)\n",
    "\n",
    "t0 = time()\n",
    "res, nzeros = ana.do_trials(ntrials, ns0,\n",
    "                            bg_inj=bg_inj, bg_rate_inj=bg_rate_inj,\n",
    "                            minimizer_opts=minopts)\n",
    "t1 = time()\n",
    "print(\"Elapsed time; {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "name = \"TS\"\n",
    "ax = plot_trials(res[name], ntrials=ntrials)\n",
    "ax.set_xlabel(name)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Signal trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Setup signal injector.\n",
    "Use the same srcs as in the analysis setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Only set the src params we need here manually\n",
    "gamma = 2.\n",
    "mode = \"band\"  # Change here to switch circle vs. band mode below\n",
    "if mode == \"band\":\n",
    "    inj_width = np.deg2rad(5.)\n",
    "elif mode == \"circle\":\n",
    "    inj_width = np.deg2rad(10.)\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=mode,\n",
    "                                inj_width=inj_width)\n",
    "sig_inj.fit(srcs, mc, exp.dtype.names)\n",
    "\n",
    "ngen = 2\n",
    "gen = sig_inj.sample(ngen, poisson=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# %%prun\n",
    "\n",
    "ns0 = ngen + 1  \n",
    "minopts = {\"bounds\": [[0, None],]}\n",
    "ntrials = int(1e5)\n",
    "\n",
    "t0 = time()\n",
    "res, nzeros = ana.do_trials(ntrials, ns0,\n",
    "                            bg_inj=bg_inj, bg_rate_inj=bg_rate_inj,\n",
    "                            signal_inj=gen,\n",
    "                            minimizer_opts=minopts)\n",
    "t1 = time()\n",
    "print(\"Elapsed time; {:.2f}s\".format(t1 - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test if numpy percentile with zeros filled is equal to custom function\n",
    "equal = (_percentile_nzeros(res[\"TS\"], nzeros, 50) ==\n",
    "         np.percentile(np.concatenate((np.zeros(nzeros), res[\"TS\"])), 50,\n",
    "                       interpolation=\"lower\"))\n",
    "print(\"Both percentiles are equal: {}\".format(equal))\n",
    "\n",
    "# Plot TS and ns distribution\n",
    "fig, (axl, axr) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "name = \"TS\"\n",
    "axl = plot_trials(res[name], ntrials=ntrials, xmax=max(res[name]), ax=axl,\n",
    "                  CHI2=False, SIGMA=False)\n",
    "axl.axvline(_percentile_nzeros(res[name], nzeros, 10), 0, 1, color=\"C1\",\n",
    "           label=\"10%\")\n",
    "axl.axvline(_percentile_nzeros(res[name], nzeros, 50), 0, 1, color=\"C1\",\n",
    "           ls=\"--\", label=\"50%\")\n",
    "axl.set_title(axl.get_title() + \" n_inj = {}\".format(ngen))\n",
    "axl.set_xlabel(name)\n",
    "axl.legend(loc=\"upper right\")\n",
    "\n",
    "name = \"ns\"\n",
    "axr = plot_trials(res[name], ntrials=ntrials, xmax=max(res[name]), ax=axr,\n",
    "                  CHI2=False, SIGMA=False)\n",
    "axr.axvline(_percentile_nzeros(res[name], nzeros, 50), 0, 1, color=\"C1\",\n",
    "           ls=\"--\")\n",
    "axr.set_title(\"ntrials = {}, n_inj = {}\".format(ntrials, ngen))\n",
    "axr.set_xlabel(name)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"data/figs/SIGT_ntrials={}_ninj={}.png\".format(ntrials, ngen),\n",
    "            dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do BG + Signal in same plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First some BG trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns0 = 1.\n",
    "minopts = {\"bounds\": [[0, None],]}\n",
    "n_bg_trials = int(1e5)\n",
    "\n",
    "bg_res, bg_nzeros = ana.do_trials(n_bg_trials, ns0,\n",
    "                                  bg_inj=bg_inj, bg_rate_inj=bg_rate_inj,\n",
    "                                  minimizer_opts=minopts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_trials(bg_res[\"TS\"], n_bg_trials, np.linspace(0, 20, 50),\n",
    "                CHI2=True, SIGMA=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now signal trials for multiple number of injected events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only set the src params we need here manually\n",
    "gamma = 2.\n",
    "mode = \"band\"\n",
    "inj_width = np.deg2rad(5.)\n",
    "sig_inj = SigInj.SignalInjector(gamma=gamma, mode=mode, inj_width=inj_width)\n",
    "sig_inj.fit(srcs, mc, exp.dtype.names)\n",
    "\n",
    "\n",
    "minopts = {\"bounds\": [[0, None],]}\n",
    "n_sig_trials = int(1e4)\n",
    "\n",
    "sig_res = []\n",
    "sig_nzeros = []\n",
    "\n",
    "n_inj = [0.01, 0.1, 1]\n",
    "for n_inj_i in n_inj:\n",
    "    print(\"{} Trials with {} injected events.\".format(n_sig_trials, n_inj_i))\n",
    "    gen = sig_inj.sample(n_inj_i, poisson=True)\n",
    "    res_i, nzeros_i = ana.do_trials(n_sig_trials, n_inj_i + 1.,\n",
    "                                    bg_inj=bg_inj, bg_rate_inj=bg_rate_inj,\n",
    "                                    signal_inj=gen,\n",
    "                                    minimizer_opts=minopts)\n",
    "    sig_res.append(res_i)\n",
    "    sig_nzeros.append(nzeros_i)\n",
    "    \n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BG only      -> eta = {:.3f}%\".format(bg_nzeros / n_bg_trials * 100))\n",
    "\n",
    "for n_inj_i, nzerosi in zip(n_inj, sig_nzeros):\n",
    "    print(\"n_inj = {:.2f} -> eta = {:.3f}%\".format(n_inj_i,\n",
    "                                           nzerosi / n_sig_trials * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "colors=[\"C0\", \"C1\", \"C2\"]\n",
    "bins = np.linspace(0, 70, 70)\n",
    "\n",
    "for resi, nzerosi, ci in zip(sig_res, sig_nzeros, colors):\n",
    "    _ = plot_trials(resi[\"TS\"], n_sig_trials, bins, ax=ax,\n",
    "                    CHI2=False, SIGMA=False, color=ci,\n",
    "                    histtype=\"step\")\n",
    "    ax.axvline(_percentile_nzeros(resi[\"TS\"], nzerosi, 50), 0, 1,\n",
    "               color=ci, ls=\"--\")\n",
    "    \n",
    "_ = plot_trials(bg_res[\"TS\"], n_bg_trials, bins, ax=ax,\n",
    "                CHI2=False, SIGMA=True, color=\"C7\",\n",
    "                histtype=\"step\")\n",
    "\n",
    "ax.set_title(\"\")\n",
    "ax.legend_.remove()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig(\"data/figs/SIGT_BGT_ninj=0.01_0.1_1.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### NOTE on performance\n",
    "\n",
    "1. soverb time is slow due to heyva broadcasting\n",
    "2. replace signal pdf cos_dist with C++ snippet\n",
    "\n",
    "Test again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%timeit grbllh.fit_lnllh_ratio(X, ns0, args, bounds=bounds, minimizer_opts={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%prun grbllh.fit_lnllh_ratio(X, ns0, args, bounds=bounds, minimizer_opts={})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit rndgen = np.random.RandomState(32423423)\n",
    "check_random_state(rndgen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Is if faster than function call with pass? -> Yes, use if**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit  a = \"Not None\"\n",
    "if a is not None:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit def test(): pass\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Is inline if faster than outline? -> No, use normal if**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit sobmax = 1.\n",
    "if sobmax > 0.:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit sobmax = 1.\n",
    "sobmax = 1 if sobmax == 0 else sobmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Is math faster than numpy for scalars? -> Yes, use math for scalars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = 15.\n",
    "math.exp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = 15.\n",
    "np.exp(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Single scalar to list or to ndarray (for gradient)? -> Use single element list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = 15.\n",
    "out = [a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = 15.\n",
    "out = np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = 15.\n",
    "out = np.atleast_1d(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** numpy reshape vs bracket notation? -> Yes use [:, None] instead of function call or np.newaxis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = np.random.uniform(size=10000)\n",
    "b = a[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = np.random.uniform(size=10000)\n",
    "b = a[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = np.random.uniform(size=10000)\n",
    "a = a.reshape(10000, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**shape vs len in ndarrays -> Use len**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = np.random.uniform(size=10000)[:, None]\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = np.random.uniform(size=10000)[:, None]\n",
    "a.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "** numpy clip vs two masks? -> Equal in both cases, use clip it's clearer to read**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%timeit a = np.random.uniform(size=10000)\n",
    "a = np.clip(a, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%timeit a = np.random.uniform(size=10000)\n",
    "a[a < 0.1] = 0.1\n",
    "a[a > 0.9] = 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**np.concatenate vs ndarry.tolist and then merge list -> Dont use with function that convert to array anyway, otherwise use list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = np.arange(100)\n",
    "out = np.concatenate((a[[0]], a, a[[-1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = np.arange(100)\n",
    "out = [a[0]] + a.tolist() + [a[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = np.arange(100)\n",
    "out = np.array([a[0]] + a.tolist() + [a[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = np.arange(100) + 1\n",
    "out = [a[0]] + a.tolist() + [a[-1]]\n",
    "sci.InterpolatedUnivariateSpline(out, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%timeit a = np.arange(100) + 1\n",
    "out = np.concatenate((a[[0]], a, a[[-1]]))\n",
    "sci.InterpolatedUnivariateSpline(out, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Cluster Trials - How To"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Same one as above but with many trials run on a remote machine.\n",
    "Here we generate the DAGMan scripts used to start the jobs.\n",
    "DAGMan system operates on a code which gets called with different arguments specified in a argument list file.\n",
    "For each job it just plugs in the arguments and runs the job.\n",
    "\n",
    "To get the jobs running do:\n",
    "\n",
    "1. Put all scripts in a folder on iccobalt\n",
    "2. Adapt path to script in `onejob.submit` file\n",
    "3. Generate DAGMan argument file with: `python job_options_generator.py`\n",
    "4. Submit using: `condor_submit_dag -config dagman.config job_options.dag `\n",
    "\n",
    "When jobs are finished you should receive a mail.\n",
    "\n",
    "Check job status on cluster using `<command>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### `DAGMan Configuration file`\n",
    "\n",
    "Steers how many jobs run in parallel.\n",
    "\n",
    "`dagman.config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FileLink(\"./data/bgtrials_ic86I/dagman.config\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### `Submit File for a single Job`\n",
    "\n",
    "Shell script that makes a single programm call with parameters plugged in and is the one called for each job.\n",
    "It plugs the arguments from `job_options.dag` into the real job script `onejob.py`.\n",
    "\n",
    "`onejob.submit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FileLink(\"./data/bgtrials_ic86I/onejob.submit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### `Script for a single Job`\n",
    "\n",
    "This code gets executed with different args per job and is our main program.\n",
    "\n",
    "`onejob.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FileLink(\"./data/bgtrials_ic86I/onejob.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### `Job Argument Generator`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We need to generate arguments for each job and write them in `joboptions.dag`.\n",
    "In this generator we specify how many trials and how many jobs we want run.\n",
    "`job_ptions.dag` has the following structure for each job:\n",
    "\n",
    "```bash\n",
    "JOB <jobname> <path/to/onejob.submit>\n",
    "VARS <jobname> -arg1=\"arg1\" -argn \"argn\"\n",
    "```\n",
    "\n",
    "Here the generation script:\n",
    "\n",
    "`job_options_generator.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FileLink(\"./data/bgtrials_ic86I/job_options_generator.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This is the generated argument list file:\n",
    "\n",
    "`job_options.dag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "FileLink(\"./data/bgtrials_ic86I/job_options.dag\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Prepare Data - On/Offtime Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here we train to split data in on- and off-time part, like it would be done later in the analysis.\n",
    "\n",
    "To be save we scramble times for exp, just to be sure we don't get blindness issues here.\n",
    "We do this after the PDFs from data have bee build, because otherwise, we'd get flat rate functions.\n",
    "The injectors draw random times anyway so and we use made up src positions so it's not critical anyway..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsrcs = 5\n",
    "\n",
    "# Make up some srcs\n",
    "dt = np.vstack((np.repeat([-20.], nsrcs), 100. * np.arange(1, nsrcs + 1))).T\n",
    "\n",
    "# Choose times equally spaced, but away from borders\n",
    "mint, maxt = np.amin(_exp[\"timeMJD\"]), np.amax(_exp[\"timeMJD\"])\n",
    "src_t = np.linspace(mint, maxt, nsrcs + 2)[1:-1].reshape(nsrcs, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Seed set to we get some evts in the windows\n",
    "rndgen = np.random.RandomState(seed=5)\n",
    "mint, maxt = np.amin(_exp[\"timeMJD\"]), np.amax(_exp[\"timeMJD\"])\n",
    "exp_rnd = np.copy(_exp)\n",
    "exp_rnd[\"timeMJD\"] = rndgen.uniform(mint, maxt, len(_exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get time windows in MJD and mask the data\n",
    "dt_MJD = src_t + dt / secinday\n",
    "evt_t = exp_rnd[\"timeMJD\"]\n",
    "\n",
    "# This assumes no time window overlap\n",
    "ontime_per_src = np.logical_and(evt_t >= dt_MJD[:, [0]],\n",
    "                                evt_t <= dt_MJD[:, [1]])\n",
    "ontime_tot = np.any(ontime_per_src, axis=0)\n",
    "\n",
    "nevts_per_src = np.sum(ontime_per_src, axis=1)\n",
    "nevts = np.sum(ontime_tot)\n",
    "\n",
    "print(\"Ontime events in each dt\\n\", nevts_per_src)\n",
    "print(\"Total Ontime events\\n\", nevts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# This always plots all event times but places dt as the plot lims.\n",
    "# So we can double check the number of on time events.\n",
    "fig, ax = plt.subplots(nsrcs, 1)\n",
    "y = np.zeros_like(evt_t)\n",
    "for i, axi in enumerate(ax):\n",
    "    axi.plot(evt_t, y, color=\"C{}\".format(i), ls=\"\", marker=\"|\",\n",
    "             mew=2, ms=10, label=\"{} evts\".format(nevts_per_src[i]))\n",
    "    axi.set_xlim(dt_MJD[i])\n",
    "    axi.set_ylim(-1, 1)\n",
    "    axi.set_yticklabels([])\n",
    "    axi.set_xticklabels([])\n",
    "\n",
    "    # Steal space for legend. Stackoverflow: 4700614 :+1:\n",
    "    box = axi.get_position()\n",
    "    axi.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    axi.legend(loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "               title=\"window {}\".format(i))\n",
    "\n",
    "ax[-1].set_xlabel(\"Time MJD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Cut events out and see they're gone from the ontime windows\n",
    "_exp_cut = exp_rnd[~ontime_tot]\n",
    "\n",
    "# Now all events should be gone\n",
    "fig, ax = plt.subplots(nsrcs, 1)\n",
    "y = np.zeros_like(_exp_cut[\"timeMJD\"])\n",
    "for i, axi in enumerate(ax):\n",
    "    axi.plot(_exp_cut[\"timeMJD\"], y, color=\"C{}\".format(i), ls=\"\", marker=\"|\",\n",
    "             mew=2, ms=10, label=\"had {} evts\".format(nevts_per_src[i]))\n",
    "    axi.set_xlim(dt_MJD[i])\n",
    "    axi.set_ylim(-1, 1)\n",
    "    axi.set_yticklabels([])\n",
    "    axi.set_xticklabels([])\n",
    "\n",
    "    # Steal space for legend. Stackoverflow: 4700614 :+1:\n",
    "    box = axi.get_position()\n",
    "    axi.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
    "    axi.legend(loc='center left', bbox_to_anchor=(1, 0.5),\n",
    "               title=\"window {}\".format(i))\n",
    "\n",
    "ax[-1].set_xlabel(\"Time MJD\")\n",
    "fig.suptitle(\"All gone\")"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2 (OSX)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load the plot setup for thesis quality plots\n",
    "from mpl_latex_settings import create_latex_setup\n",
    "config = \"/Users/tmenne/git/thesis/inc/mpl_latex_config.json\"\n",
    "latex_setup = create_latex_setup(config, interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "init_cell": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "import os\n",
    "import json\n",
    "import gzip\n",
    "from glob import glob\n",
    "from copy import deepcopy\n",
    "from sklearn.utils import check_random_state\n",
    "import dill  # Advanced pickle\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.interpolate as sci\n",
    "import scipy.stats as scs\n",
    "import scipy.optimize as sco\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.colors import LogNorm\n",
    "from astropy.time import Time as astrotime\n",
    "\n",
    "from tdepps.utils import (make_rate_records, rebin_rate_rec,\n",
    "                          get_pixel_in_sigma_region,interval_overlap,\n",
    "                          make_spl_edges, fit_spl_to_hist, arr2str,\n",
    "                          power_law_flux, dict_map, fill_dict_defaults,\n",
    "                          make_src_records, make_src_records)\n",
    "from tdepps.grb import GRBLLH, GRBModel, MultiGRBLLH\n",
    "from tdepps.grb import (SignalFluenceInjector, UniformTimeSampler,\n",
    "                        HealpySignalFluenceInjector,\n",
    "                        TimeDecDependentBGDataInjector)\n",
    "from tdepps.grb import MultiBGDataInjector, MultiSignalFluenceInjector\n",
    "import tdepps.grb.analysis as GRBAna\n",
    "from tdepps.grb import SinusFixedConstRateFunction\n",
    "import tdepps.utils.phys as phys\n",
    "import tdepps.utils.stats as stats\n",
    "\n",
    "from mypyscripts.stats import sigma2prob, prob2sigma\n",
    "\n",
    "from _loader import loader as LOADER\n",
    "from _paths import PATHS_ORIG as PATHS  # Use the original 22 HESE sources\n",
    "import _plots as plots\n",
    "\n",
    "# Make some globals\n",
    "SECINDAY = 24. * 60. * 60.\n",
    "RNDGEN = np.random.RandomState(42439462)\n",
    "loader = LOADER(PATHS, verb=False)\n",
    "\n",
    "print(\"Started: \", astrotime.now())\n",
    "print(\"Paths are:\\n\", PATHS)\n",
    "\n",
    "def save_plot(folder, fname, **savefig_args):\n",
    "    # deprecated\n",
    "    \"\"\" Checks existence of save folder and saves current figure.\"\"\"\n",
    "    dpi = savefig_args.pop(\"dpi\", 200)\n",
    "    bbox_inches = savefig_args.pop(\"bbox_inches\", \"tight\")\n",
    "    outp = os.path.join(PATHS.plots, folder)\n",
    "    if not os.path.isdir(outp):\n",
    "        os.makedirs(outp)\n",
    "    plt.tight_layout()\n",
    "    fname = os.path.join(outp, fname)\n",
    "    plt.savefig(fname, dpi=dpi, bbox_inches=bbox_inches, **savefig_args)\n",
    "    print(\"Saved plot to:\\n  {}\".format(fname))\n",
    "    \n",
    "def save_fig(fig, path, **save_args):\n",
    "    path = os.path.abspath(path)\n",
    "    dirname = os.path.dirname(path)\n",
    "    if not os.path.isdir(dirname):\n",
    "        os.makedirs(dirname)   \n",
    "    fig.savefig(path, **save_args)\n",
    "    \n",
    "def key2label(key, short=False):\n",
    "    \"\"\" Makes 'IC86, 2012--2014' from 'IC86_2012-2104' \"\"\"\n",
    "    if short:  # Abbreviate 20YY -> 'YY\n",
    "        return \", \".join(map(lambda s: s.replace(\"-\", \"--\").replace(\"20\", \"'\"),\n",
    "                             key.split(\"_\")))\n",
    "    return \", \".join(map(lambda s: s.replace(\"-\", \"--\"), key.split(\"_\")))\n",
    "\n",
    "def trunc_cmap(cmap, arr):\n",
    "    \"\"\"\n",
    "    Adapted from: https://stackoverflow.com/questions/18926031\n",
    "    Makes a new colormap with original values selected from arr in [0, 1].\n",
    "    \"\"\"\n",
    "    vmin, vmax = np.amin(arr), np.amax(arr)\n",
    "    new_cmap = LinearSegmentedColormap.from_list(\n",
    "        'trunc({}_{:.2f}_{:.2f})'.format(cmap.name, vmin, vmax), cmap(arr))\n",
    "    return new_cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Pre-loading stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make a local source list version with adapted paths, only when an updated version from cobalt is fetched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from _loader import _change_local_src_map_paths\n",
    "_change_local_src_map_paths(PATHS.local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Reload stuff mini example:\n",
    "\n",
    "```Python\n",
    "# GRBLLHAnalysis was loaded with: from tdepps.grb import GRBLLHAnalysis\n",
    "import tdepps.grb.analysis as ANA\n",
    "reload(ANA)\n",
    "GRBLLHAnalysis = ANA.GRBLLHAnalysis\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and setup models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This defines the tested sources time windows\n",
    "tw_id = -1\n",
    "dt0, dt1 = loader.time_window_loader(tw_id)\n",
    "print(\"Time window: [{:.0f}, {:.0f}]\".format(dt0, dt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "bg_injs = {}\n",
    "sig_injs = {}\n",
    "llhs = {}\n",
    "\n",
    "# :: Debug ::\n",
    "bg_inj_opts = {}\n",
    "sig_inj_opts = {}\n",
    "mod_spatial_opts = {}\n",
    "mod_energy_opts = {}\n",
    "llh_opts = {}\n",
    "srcs_dict = {}\n",
    "runlists_dict = {}\n",
    "exp_off_dict = {}\n",
    "mc_dict = {}\n",
    "srcs_recs_dict = {}\n",
    "rate_recs_dict = {}\n",
    "# :: Debug :: END\n",
    "\n",
    "time_sam = UniformTimeSampler(random_state=RNDGEN)\n",
    "# Make sure the sig inj type fits to the rest. This should be HEALPY in general!\n",
    "HEALPY_SIG = True\n",
    "\n",
    "# Load files and build the models one after another to save memory\n",
    "sample_names = loader.source_list_loader()\n",
    "for key in sample_names:\n",
    "    print(\"\\n\" + 80 * \"#\")\n",
    "    print(\"# :: Setup for sample {} ::\".format(key))\n",
    "    opts = loader.settings_loader(key)[key].copy()\n",
    "    exp_off = loader.off_data_loader(key)[key]\n",
    "    mc = loader.mc_loader(key)[key]\n",
    "    srcs_i = loader.source_list_loader(key)[key]\n",
    "    runlist_i = loader.runlist_loader(key)[key]\n",
    "    # Process to tdepps format\n",
    "    srcs_rec_i = make_src_records(srcs_i, dt0=dt0, dt1=dt1)\n",
    "    \n",
    "    # Setup BG injector\n",
    "    bg_inj_i = TimeDecDependentBGDataInjector(inj_opts=opts[\"bg_inj_opts\"],\n",
    "                                              random_state=RNDGEN)\n",
    "    bg_inj_i.fit(X=exp_off, srcs=srcs_rec_i, run_list=runlist_i)\n",
    "    bg_injs[key] = bg_inj_i\n",
    "    \n",
    "    # Setup Signal injector\n",
    "    fmod = opts[\"sig_inj_opts\"].pop(\"flux_model\")\n",
    "    flux_model = phys.flux_model_factory(fmod[\"model\"], **fmod[\"args\"])\n",
    "    if HEALPY_SIG:\n",
    "        opts[\"sig_inj_opts\"][\"inj_sigma\"] = 3.\n",
    "        src_maps = loader.source_map_loader(src_list=srcs_i)\n",
    "        sig_inj_i = HealpySignalFluenceInjector(\n",
    "            flux_model, time_sampler=time_sam, inj_opts=opts[\"sig_inj_opts\"],\n",
    "            random_state=RNDGEN)\n",
    "        sig_inj_i.fit(srcs_rec_i, src_maps=src_maps, MC=mc)\n",
    "    else:\n",
    "        sig_inj_i = SignalFluenceInjector(\n",
    "            flux_model, time_sampler=time_sam, inj_opts=opts[\"sig_inj_opts\"],\n",
    "            random_state=RNDGEN)\n",
    "        sig_inj_i.fit(srcs_rec_i, MC=mc)\n",
    "    sig_injs[key] = sig_inj_i\n",
    "    \n",
    "    # Setup LLH model and LLH\n",
    "    fmod = opts[\"model_energy_opts\"].pop(\"flux_model\")\n",
    "    flux_model = phys.flux_model_factory(fmod[\"model\"], **fmod[\"args\"])\n",
    "    opts[\"model_energy_opts\"][\"flux_model\"] = flux_model\n",
    "    llhmod = GRBModel(spatial_opts=opts[\"model_spatial_opts\"],\n",
    "                      energy_opts=opts[\"model_energy_opts\"])\n",
    "    llhmod.fit(X=exp_off, MC=mc, srcs=srcs_rec_i, run_list=runlist_i)\n",
    "    llhs[key] = GRBLLH(llh_model=llhmod, llh_opts=opts[\"llh_opts\"])\n",
    "    \n",
    "    # Add debug info for tests\n",
    "    bg_inj_opts[key] = bg_inj_i.inj_opts\n",
    "    sig_inj_opts[key] = sig_inj_i.inj_opts\n",
    "    mod_spatial_opts[key] = llhmod.spatial_opts\n",
    "    mod_energy_opts[key] = llhmod.energy_opts\n",
    "    llh_opts[key] = llhs[key].llh_opts\n",
    "    srcs_dict[key] = srcs_i\n",
    "    runlists_dict[key] = runlist_i\n",
    "    exp_off_dict[key] = exp_off\n",
    "    mc_dict[key] = mc\n",
    "    srcs_recs_dict[key] = srcs_rec_i\n",
    "    rate_recs_dict[key] = make_rate_records(ev_runids=exp_off[\"Run\"],\n",
    "                                            run_list=runlist_i)\n",
    "\n",
    "exp_on_dict = loader.on_data_loader(\"all\")\n",
    "print(\":: Done ::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_bg_inj = MultiBGDataInjector()\n",
    "multi_bg_inj.fit(bg_injs)\n",
    "\n",
    "multi_sig_inj = MultiSignalFluenceInjector(random_state=RNDGEN)\n",
    "multi_sig_inj.fit(sig_injs)\n",
    "\n",
    "multi_llh_opts = loader.settings_loader(\"multi_llh\")[\"multi_llh\"]\n",
    "multi_llh = MultiGRBLLH(llh_opts=multi_llh_opts)\n",
    "multi_llh.fit(llhs=llhs)\n",
    "\n",
    "ana = GRBAna.GRBLLHAnalysis(multi_llh, multi_bg_inj, sig_inj=multi_sig_inj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save for fast reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/tmenne/Downloads/multi_bg_inj.pickle\", \"w\") as fp:\n",
    "    dill.dump(multi_bg_inj, fp)\n",
    "    \n",
    "with open(\"/Users/tmenne/Downloads/multi_sig_inj.pickle\", \"w\") as fp:\n",
    "    dill.dump(multi_sig_inj, fp)\n",
    "    \n",
    "with open(\"/Users/tmenne/Downloads/multi_llh.pickle\", \"w\") as fp:\n",
    "    dill.dump(multi_llh, fp)\n",
    "    \n",
    "with open(\"/Users/tmenne/Downloads/ana.pickle\", \"w\") as fp:\n",
    "    dill.dump(ana, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load for fast reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/tmenne/Downloads/multi_bg_inj.pickle\", \"r\") as fp:\n",
    "    multi_bg_inj = dill.load(fp)\n",
    "    \n",
    "with open(\"/Users/tmenne/Downloads/multi_sig_inj.pickle\", \"r\") as fp:\n",
    "    multi_sig_inj = dill.load(fp)\n",
    "    \n",
    "with open(\"/Users/tmenne/Downloads/multi_llh.pickle\", \"r\") as fp:\n",
    "    multi_llh = dill.load(fp)\n",
    "    \n",
    "with open(\"/Users/tmenne/Downloads/ana.pickle\", \"r\") as fp:\n",
    "    ana = dill.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Method TESTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Local coord BG PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://icecube.wisc.edu/~tkintscher/internal/gfu_doc/likelihood.html#background-space-pdf\n",
    "# 'azimuth', 'zenith' only in GFU so far\n",
    "exp = np.load(\"/Users/tmenne/Downloads/hese_transient_stacking_data/\" +\n",
    "              \"skylab_data/SplineMPEmax.MuEx.IC86-2015.npy\")\n",
    "\n",
    "bx = np.linspace(0, 2. * np.pi, 72 + 1)\n",
    "by = np.linspace(-1, 1, 40 + 1)\n",
    "h, bx, by = np.histogram2d(exp[\"azimuth\"], np.cos(exp[\"zenith\"]), bins=[bx, by],\n",
    "                           normed=True)\n",
    "xx, yy = np.meshgrid(bx, by)\n",
    "mx, my = 0.5 * (bx[:-1] + bx[1:]), 0.5 * (by[:-1] + by[1:])\n",
    "coszen, _ =  np.histogram(np.cos(exp[\"zenith\"]), bins=by, normed=True)\n",
    "flat = np.repeat([coszen], repeats=len(bx)-1, axis=0) / (2. * np.pi)\n",
    "\n",
    "ratio = h / flat\n",
    "ratio_interpol = sci.RegularGridInterpolator(points=[mx, my], values=ratio,\n",
    "                                             bounds_error=False, fill_value=0.)\n",
    "\n",
    "plt.pcolormesh(xx, yy, h.T, cmap=\"Blues\", vmin=0, vmax=0.2)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "plt.pcolormesh(xx, yy, flat.T, cmap=\"Blues\", vmin=0, vmax=0.2)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "x = np.linspace(bx[0], bx[-1], 500)\n",
    "y = np.linspace(by[0], by[-1], 500)\n",
    "XX, YY = np.meshgrid(x, y)\n",
    "pts = np.vstack((map(np.ravel, [XX, YY]))).T\n",
    "plt.pcolormesh(XX, YY, ratio_interpol(pts).reshape(XX.shape),\n",
    "                                      cmap=\"coolwarm\", vmin=0., vmax=2.)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Interval overlap test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test interval overlap\n",
    "# Fixed interval\n",
    "a0, a1 = [1, 2]\n",
    "# Test intervals, all cases. Overlap: [0, 0, 0.6, 1, 0.2, 0.2]\n",
    "b0 = np.array([0.5  , 2.2, 1.2, 0.8, 0.8, 1.8])\n",
    "b1 = np.array([0.8, 2.5, 1.8, 2.2, 1.2, 2.2])\n",
    "idx = np.argsort(b0)\n",
    "b0, b1 = b0[idx], b1[idx]\n",
    "\n",
    "nintervals = len(b0)\n",
    "overlap = interval_overlap(a0, a1, b0, b1)\n",
    "\n",
    "c = plt.cm.viridis(np.linspace(0, 1, nintervals))\n",
    "for i in range(nintervals):\n",
    "    plt.fill_between([b0[i], b1[i]], 1 + i / 5., 2 + i / 5.,\n",
    "                     color=c[i], alpha=0.5)\n",
    "    plt.vlines(b0[i], 1 + i / 5., 2 + i / 5., color=\"k\")\n",
    "    plt.vlines(b1[i], 1 + i / 5., 2 + i / 5., color=\"k\")\n",
    "    plt.axhline(1, 0, 1, c=\"k\", ls=\"--\")\n",
    "    plt.text(s=\"{:.1f}\".format(overlap[i]),\n",
    "             horizontalalignment=\"center\",\n",
    "             verticalalignment=\"bottom\",\n",
    "             x=0.5 * (b0[i] + b1[i]), y=2 + i / 5.)\n",
    "\n",
    "plt.fill_between([a0, a1], 0, 1, color=\"C7\")\n",
    "plt.vlines(a0, 0, 1, colors=\"k\")\n",
    "plt.vlines(a1, 0, 1, colors=\"k\")\n",
    "plt.ylim(0, None)    \n",
    "    \n",
    "save_plot(\"misc\", \"interval_overlap.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sample only in ontime runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sample_uniform(runtimes, size=1, random_state=None):\n",
    "    \"\"\"\n",
    "    Draws ``size`` event times uniformly distributed over all ontime regions,\n",
    "    which borders are defined by ``runtimes[i] = [tstart_i, tstop_i]``.\n",
    "    \n",
    "    The method draws a random number from the effective livetime w/o offtime\n",
    "    runs and rescales them linearly to the correct absolute time in the ontime\n",
    "    runs.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    runtimes : array-like, shape (nruns, 2)\n",
    "        Start and end times of each run. Each pair\n",
    "        ``runtimes[i] = [tstart_i, tstop_i]`` defines the livetime of run ``i``.\n",
    "    size : int, optional\n",
    "        How many events to sample over all runs in ``runtimes``.\n",
    "    random_state : int, None or np.random.RandomState instance\n",
    "        Passes to ``sklearn.utils.check_random_state``. (default: ``None``)\n",
    "    \"\"\"\n",
    "    rndgen = check_random_state(random_state)\n",
    "    # Make empiric cum. dist. for the effective ontime runs\n",
    "    comb_ontime = np.hstack((0, np.cumsum(np.diff(runtimes, axis=0))))\n",
    "    cdf = comb_ontime / comb_ontime[-1]\n",
    "    # Draw uniformly and scale to total livetime\n",
    "    u = rndgen.uniform(0, 1, size=size)\n",
    "    total_mjd = u * comb_ontime[-1]\n",
    "    # Get the ontime run id, subtract the combined ontime from all runs before\n",
    "    # and add the run's start time to get the absolute event time information\n",
    "    run_idx = np.searchsorted(cdf, u, side=\"right\") - 1\n",
    "    print(run_idx)\n",
    "    sample = total_mjd - comb_ontime[run_idx] + runtimes[0][run_idx]\n",
    "    return sample\n",
    "    \n",
    "def sample_expectation(runtimes, expectations, random_state=None):\n",
    "    \"\"\"\n",
    "    Same as ``sample_uniform`` but the number of events per ontime bin is drawn\n",
    "    from a poisson distribution with given expectation per bin. The events times\n",
    "    per bin are still drawn uniformly.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    runtimes : array-like, shape (nruns, 2)\n",
    "        Start and end times of each run. Each pair\n",
    "        ``runtimes[i] = [tstart_i, tstop_i]`` defines the livetime of run ``i``.\n",
    "    expectations : array-like, shape (nruns, )\n",
    "        Poisson expectation values per run.\n",
    "    random_state : int, None or np.random.RandomState instance\n",
    "        Passes to ``sklearn.utils.check_random_state``. (default: ``None``)\n",
    "    \"\"\"\n",
    "    if len(expectations) != runtimes.shape[1]:\n",
    "        raise ValueError(\"`runtimes` and `expectations` must match.\")\n",
    "    rndgen = check_random_state(random_state)\n",
    "    # Poisson sampling the new total event number for all runs\n",
    "    total_expectation = np.sum(expectations)\n",
    "    weights = expectations / total_expectation\n",
    "    # Distribute events to single runs weighting with relative expectations\n",
    "    nevts_total = rndgen.poisson(total_expectation, size=None)\n",
    "    nevts_per_run = rndgen.multinomial(nevts_total, weights, size=None)\n",
    "    # Sample the number of events per bin uniformly in each bin by transforming\n",
    "    # the uniform numbers with the start time and length of the correct runs\n",
    "    u = np.random.uniform(0, 1, size=nevts_total)\n",
    "    nruns = len(expectations)\n",
    "    run_idx = np.repeat(np.arange(nruns), repeats=nevts_per_run)\n",
    "    livetimes = np.ravel(np.diff(runtimes, axis=0))\n",
    "    sample = u * livetimes[run_idx] + runtimes[0][run_idx]\n",
    "    return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _iso2mjd(iso):\n",
    "    return astrotime(iso, format=\"iso\").mjd\n",
    "\n",
    "rl = loader.runlist_loader(\"IC79\")[\"IC79\"]\n",
    "tstart = np.array([_iso2mjd(d[\"good_tstart\"]) for d in rl])\n",
    "tstop = np.array([_iso2mjd(d[\"good_tstop\"]) for d in rl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_rndgen = np.random.RandomState(123123)\n",
    "runtimes = np.array([[1, 2, 3, 4], [1.5, 2.5, 3.5, 5.5]])\n",
    "size=100\n",
    "\n",
    "sample = sample_uniform(runtimes, size, _rndgen)\n",
    "for ti in sample:\n",
    "    plt.axvline(ti, color=\"C7\", alpha=0.5)\n",
    "    \n",
    "plt.vlines(runtimes[0], 0, 1, colors=\"C2\")\n",
    "plt.vlines(runtimes[1], 0, 1, colors=\"C3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_rndgen = np.random.RandomState(123123)\n",
    "runtimes = np.array([[1, 2, 3, 4], [1.5, 2.5, 3.5, 5.5]])\n",
    "expectations = (np.arange(0, len(runtimes.T)) + 1) * 10\n",
    "\n",
    "sample = sample_expectation(runtimes, expectations, _rndgen)\n",
    "for ti in sample:\n",
    "    plt.axvline(ti, color=\"C7\", alpha=0.5)\n",
    "    \n",
    "plt.vlines(runtimes[0], 0, 1, colors=\"C2\")\n",
    "plt.vlines(runtimes[1], 0, 1, colors=\"C3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Sample empirically from spline PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sample_spline(spl, a, b, nbins, size=None, random_state=None):\n",
    "    rndgen = check_random_state(random_state)\n",
    "    # Scan the PDF to create the empirical CDF\n",
    "    x = np.linspace(a, b, nbins + 1)\n",
    "    cdf = np.array([spl.integral(a, xi) for xi in x])\n",
    "    cdf = cdf / cdf[-1]\n",
    "    # Draw from the empirical CDF\n",
    "    u = rndgen.uniform(0, 1, size=size)\n",
    "    idx = np.searchsorted(cdf, u, side=\"right\") - 1\n",
    "    return x[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a, b = -1, 10\n",
    "x = np.linspace(a, b, 20)\n",
    "y = np.sin(x) + 1\n",
    "\n",
    "spl = sci.InterpolatedUnivariateSpline(x, y, k=3)\n",
    "norm = spl.integral(a, b)\n",
    "\n",
    "t = np.linspace(a, b, 100)\n",
    "plt.plot(t, spl(t) / norm)\n",
    "\n",
    "nbins = 100\n",
    "sample = sample_spline(spl, a, b, nbins=nbins, size=10000)\n",
    "plt.hist(sample, bins=np.linspace(a, b, 50 + 1), density=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Fixate x,y ratio hist edges :: NEEDS MAINTANANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Similar to make_spl_edges, but just repeat the outermost values.\n",
    "We have the full bin range covered with the interpolator, without introducing artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Generate test data\n",
    "rndgen = np.random.RandomState(3242342)\n",
    "x = rndgen.uniform(0, 1, size=1000)\n",
    "y = rndgen.uniform(0, 1, size=1000)\n",
    "\n",
    "bx = np.linspace(0, 1, 6)\n",
    "by = np.linspace(0, 1, 11)\n",
    "bxm, bym = map(lambda b: 0.5 * (b[:-1] + b[1:]), [bx, by])\n",
    "\n",
    "print(h.shape)\n",
    "print(len(bx))\n",
    "print(len(by))\n",
    "\n",
    "h = plt.hist2d(x, y, bins=[bx, by], normed=True)[0]\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Repeat outermost values, first in all cols, then the rows\n",
    "h_ext = np.zeros((len(bxm) + 2, len(bym) + 2), dtype=h.dtype) - 1.\n",
    "for j, col in enumerate(h):\n",
    "    h_ext[j+1] = np.concatenate([col[[0]], col, col[[-1]]])\n",
    "h_ext[0] = h_ext[1]\n",
    "h_ext[-1] = h_ext[-2]\n",
    "pts_x = np.concatenate((bx[[0]], bxm, bx[[-1]]))\n",
    "pts_y = np.concatenate((by[[0]], bym, by[[-1]]))\n",
    "\n",
    "print(h_ext.shape)\n",
    "print(len(pts_x))\n",
    "print(len(pts_y))\n",
    "\n",
    "# Orignal bins\n",
    "xx, yy = np.meshgrid(bx, by)\n",
    "# Original bin mids\n",
    "xxm, yym = np.meshgrid(bxm, bym)\n",
    "# New grid points from bin mids\n",
    "xxg, yyg = np.meshgrid(pts_x, pts_y)\n",
    "\n",
    "# Plot original hist again\n",
    "plt.pcolormesh(xx, yy, h.T)\n",
    "plt.colorbar()\n",
    "# Plot original bin edges, bin mids and new pts for the interpolator\n",
    "plt.scatter(xx, yy, marker=\"o\", color=\"C3\", s=50)\n",
    "plt.scatter(xxm, yym, marker=\"o\", color=\"w\", s=50)\n",
    "plt.scatter(xxg, yyg, marker=\".\", color=\"k\")\n",
    "plt.show()\n",
    "\n",
    "# Plot rows and cols of the new hist\n",
    "# Note: The first/last row and col are repeated and are drawn on top of the next\n",
    "# row/col in the plot\n",
    "for i, col in enumerate(h_ext):\n",
    "    plt.plot(pts_y, col, label=\"{:d}\".format(i))\n",
    "for p in pts_y:\n",
    "    plt.axvline(p, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.title(\"Cols\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=\"upper center\", ncol=4)\n",
    "plt.savefig(\"/Users/tmenne/Downloads/col_rep\")\n",
    "plt.show()\n",
    "\n",
    "for i, row in enumerate(h_ext.T):\n",
    "    plt.plot(pts_x, row, label=\"{:d}\".format(i))\n",
    "for p in pts_x:\n",
    "    plt.axvline(p, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.title(\"Rows\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=\"upper center\", ncol=6)\n",
    "plt.savefig(\"/Users/tmenne/Downloads/row_rep\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Linearly extrapolate outermost values, first in all cols, then the rows\n",
    "h_ext = np.zeros((len(bxm) + 2, len(bym) + 2), dtype=h.dtype) - 1.\n",
    "for j, col in enumerate(h):\n",
    "    vals, pts_y, _ = make_spl_edges(vals=col, bins=by)\n",
    "    h_ext[j+1] = vals\n",
    "for i, row in enumerate(h_ext.T):\n",
    "    vals, pts_x, _ = make_spl_edges(vals=row[1:-1], bins=bx)\n",
    "    h_ext[:, i] = vals\n",
    "\n",
    "print(h_ext.shape)\n",
    "print(len(pts_x))\n",
    "print(len(pts_y))\n",
    "\n",
    "# Orignal bins\n",
    "xx, yy = np.meshgrid(bx, by)\n",
    "# Original bin mids\n",
    "xxm, yym = np.meshgrid(bxm, bym)\n",
    "# New grid points from bin mids\n",
    "xxg, yyg = np.meshgrid(pts_x, pts_y)\n",
    "\n",
    "# Plot original hist again\n",
    "plt.pcolormesh(xx, yy, h.T)\n",
    "plt.colorbar()\n",
    "# Plot original bin edges, bin mids and new pts for the interpolator\n",
    "plt.scatter(xx, yy, marker=\"o\", color=\"C3\", s=50)\n",
    "plt.scatter(xxm, yym, marker=\"o\", color=\"w\", s=50)\n",
    "plt.scatter(xxg, yyg, marker=\".\", color=\"k\")\n",
    "plt.show()\n",
    "\n",
    "# Plot rows and cols of the new hist\n",
    "for i, col in enumerate(h_ext):\n",
    "    plt.plot(pts_y, col, label=\"{:d}\".format(i))\n",
    "for p in pts_y:\n",
    "    plt.axvline(p, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.title(\"Cols\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=\"upper center\", ncol=4)\n",
    "plt.savefig(\"/Users/tmenne/Downloads/col_lin\")\n",
    "plt.show()\n",
    "\n",
    "for i, row in enumerate(h_ext.T):\n",
    "    plt.plot(pts_x, row, label=\"{:d}\".format(i))\n",
    "for p in pts_x:\n",
    "    plt.axvline(p, 0, 1, color=\"C7\", ls=\"--\")\n",
    "plt.title(\"Rows\")\n",
    "plt.ylim(0, 2)\n",
    "plt.legend(loc=\"upper center\", ncol=6)\n",
    "plt.savefig(\"/Users/tmenne/Downloads/row_lin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### LLH scan instead of hess_inv from fitres :: NEEDS MAINTANANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     35
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_llh_scan(bfs, stds, llh, grid):\n",
    "    \"\"\"\n",
    "    Plot the llh scan with errors and contours\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    bfs : array-like, shape (2)\n",
    "        Best fit result parameters, around which the LLH was scanned.\n",
    "    stds : array-like, shape (2)\n",
    "        Approximate standard deviations (symmetric) for each fit parameter,\n",
    "        obtained using Wilks' theorem on the scanned space.\n",
    "    llh : array-like, shape (nbins, nbins)\n",
    "        Scanned LLH values.\n",
    "    grid : list\n",
    "        X, Y grid, same shape as ``llh``.\n",
    "    \"\"\"\n",
    "    bf_x, bf_y = bfs\n",
    "    std_x, std_y = stds\n",
    "    x, y = grid\n",
    "    \n",
    "    # Plot scan\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    img = ax.pcolormesh(x, y, llh)\n",
    "    fig.colorbar(img, ax=ax)\n",
    "\n",
    "    # Plot 1, 2, 3 sigma contours\n",
    "    vals = np.amin(llh) - scs.chi2.logsf(df=2, x=[1**2, 2**2, 3**2])\n",
    "    ax.contour(x, y, llh, vals, linestyles=[\"--\", \"-.\", \"--\"], colors=\"w\")\n",
    "    \n",
    "    # Plot best fit with symmetric errors\n",
    "    ax.errorbar(bf_x, bf_y, xerr=std_x, yerr=std_y, fmt=\"o\", c=\"w\", capsize=5)   \n",
    "    \n",
    "    ax.xlabel = (\"amplitude\")\n",
    "    ax.ylabel = (\"baseline\")\n",
    "\n",
    "def get_stddev_from_scan(func, args, bfs, rngs, nbins=50):\n",
    "    \"\"\"\n",
    "    Scan the rate_func chi2 fit LLH to get stddevs for the best fit params a, d.\n",
    "    Using matplotlib contours and averaging to approximately get the variances.\n",
    "    Note: This is not a true LLH profile scan in both variables.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func : callable\n",
    "        Loss function to be scanned, used to obtain the best fit. Function\n",
    "        is called as done with a scipy fitter, ``func(x, *args)``.\n",
    "    args : tuple\n",
    "        Args passed to the loss function ``func``. For a rate function, this is\n",
    "        ``(mids, rates, weights)``.\n",
    "    bfs : array-like, shape (2)\n",
    "        Best fit result parameters.\n",
    "    rngs : list\n",
    "        Parameter ranges to scan: ``[bf[i] - rng[i], bf[i] + rng[i]]``.\n",
    "    nbins : int, optional\n",
    "        Number of bins in each dimension to scan. (Default: 100)\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    stds : array-like, shape (2)\n",
    "        Approximate standard deviations (symmetric) for each fit parameter,\n",
    "        obtained using Wilks' theorem on the scanned space.\n",
    "    llh : array-like, shape (nbins, nbins)\n",
    "        Scanned LLH values.\n",
    "    grid : list\n",
    "        X, Y grid, same shape as ``llh``.\n",
    "    \"\"\"\n",
    "    def _scan_llh(bf_x, rng_x, bf_y, rng_y):\n",
    "        \"\"\" Scan LLH and return contour vertices \"\"\"\n",
    "        x_bins = np.linspace(bf_x - rng_x, bf_x + rng_x, nbins)\n",
    "        y_bins = np.linspace(bf_y - rng_y, bf_y + rng_y, nbins)   \n",
    "        x, y = np.meshgrid(x_bins, y_bins)\n",
    "        AA, DD = map(np.ravel, [x, y])\n",
    "        llh = np.empty_like(AA)\n",
    "        for i, (ai, di) in enumerate(zip(AA, DD)):\n",
    "            llh[i] = func((ai, di), *args)\n",
    "        llh = llh.reshape(x.shape)\n",
    "        # Get the contour points and average over min, max per parameter\n",
    "        one_sigma_level = np.amin(llh) - scs.chi2.logsf(df=2, x=[1**2])\n",
    "\n",
    "        # https://stackoverflow.com/questions/5666056\n",
    "        cntr = plt.contour(x, y, llh, one_sigma_level)\n",
    "        plt.close(\"all\")\n",
    "        paths = [lcol.vertices for lcol in cntr.collections[0].get_paths()]\n",
    "        # Call undocumented base of plt.contour, to avoid creating a figure.\n",
    "        # Not working for mpl 2.2.2 any more, because _cntr was deleted.\n",
    "        # cntr = contour.Cntr(x, y, llh)\n",
    "        # paths = cntr.trace(level0=one_sigma_level)\n",
    "        # paths = paths[:len(paths) // 2]  # First half of list has the vertices\n",
    "        return paths, llh, [x, y]\n",
    "\n",
    "    def _is_path_closed(paths, rng_x, rng_y):\n",
    "        \"\"\"\n",
    "        We want the contour to be fully contained. Means there is only one path\n",
    "        and the first and last point are close together.\n",
    "        Returns ``True`` if contour is closed.\n",
    "        \"\"\"\n",
    "        closed = False\n",
    "        if len(paths) == 1:\n",
    "            vertices = paths[0]\n",
    "            # If no contour is made, only 1 vertex is returned -> invalid\n",
    "            if len(vertices) > 1:\n",
    "                max_bin_dist = np.amax([rng_x / float(nbins),\n",
    "                                        rng_y / float(nbins)])\n",
    "                closed = np.allclose(vertices[0], vertices[-1],\n",
    "                                     atol=max_bin_dist, rtol=0.)\n",
    "        return closed\n",
    "    \n",
    "    def _get_stds_from_path(path):\n",
    "        \"\"\" Create symmetric stddevs from the path vertices \"\"\"\n",
    "        x, y = path[:, 0], path[:, 1]\n",
    "        # Average asymmetricities in both direction\n",
    "        x_min, x_max = np.amin(x), np.amax(x)\n",
    "        y_min, y_max = np.amin(y), np.amax(y)\n",
    "        return 0.5 * (x_max - x_min), 0.5 * (y_max - y_min)\n",
    "           \n",
    "    # Scan the LLH, adapt scan range if contour is not closed\n",
    "    bf_x, bf_y = bfs\n",
    "    rng_x, rng_y = rngs\n",
    "    closed = False\n",
    "    while not closed:\n",
    "        # Default is scaling up, when range is too small\n",
    "        scalex, scaley = 10., 10.\n",
    "        # Get contour from scanned LLH space\n",
    "        paths, llh, grid = _scan_llh(bf_x, rng_x, bf_y, rng_y)\n",
    "        closed = _is_path_closed(paths, rng_x, rng_y)       \n",
    "        if closed:\n",
    "            vertices = paths[0]\n",
    "            # Estimate scale factors to get contour in optimum resolution\n",
    "            diffx = np.abs(np.amax(vertices[:, 0]) - np.amin(vertices[:, 0]))\n",
    "            diffy = np.abs(np.amax(vertices[:, 1]) - np.amin(vertices[:, 1]))\n",
    "            scalex = diffx / rng_x\n",
    "            scaley = diffy / rng_y\n",
    "            # Contour can be closed, but extremely zoomed out in only one param\n",
    "            if not np.allclose([scalex, scaley], 1., atol=0.5, rtol=0.):\n",
    "                print(\"Contour is very distorted in one direction\")\n",
    "                closed = False\n",
    "            else:\n",
    "                # Rescan valid contour to use optimal scan resolution\n",
    "                for i in range(2):\n",
    "                    std_x, std_y = _get_stds_from_path(vertices)\n",
    "                    rng_x = std_x * 1.05  # Allow a little padding\n",
    "                    rng_y = std_y * 1.05\n",
    "                    paths, llh, grid = _scan_llh(bf_x, rng_x, bf_y, rng_y)\n",
    "                    # Recheck if path is still valid\n",
    "                    closed = _is_path_closed(paths, rng_x, rng_y)\n",
    "        # Must be seperated if, because path can get invalid in rescaling step\n",
    "        if not closed:\n",
    "            print(\"Open or no contour, rescale\")\n",
    "            rng_x *= scalex\n",
    "            rng_y *= scaley\n",
    "\n",
    "    vertices = paths[0]\n",
    "    stds = np.array(_get_stds_from_path(vertices))\n",
    "    return stds, llh, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sindec = exp_[\"sinDec\"]\n",
    "t_ = np.linspace(exp_[\"timeMJD\"].min(), exp_[\"timeMJD\"].max(), 200)\n",
    "\n",
    "allres = []\n",
    "errs = []\n",
    "for j, (lo, hi) in enumerate(zip(sindec_bins[:-1], sindec_bins[1:])[:]):\n",
    "    mask = (sindec >= lo) & (sindec <= hi)\n",
    "\n",
    "    recs = make_rate_records(T=exp_[\"timeMJD\"][mask], run_dict=run_dict_)\n",
    "    rates, new_bins, stddev, _ = rebin_rate_rec(rate_rec=recs, bins=rate_rebins,\n",
    "                                                ignore_zero_runs=True)\n",
    "    new_mids = 0.5 * (new_bins[:-1] + new_bins[1:])\n",
    "    weights = 1. / stddev\n",
    "    res = rate_func.fit(rate=rates, srcs=srcs_, t=new_mids, w=weights)\n",
    "    bfs = np.array([res.x[0], res.x[1]])\n",
    "    allres.append(res)\n",
    "    \n",
    "    plt.errorbar(recs[\"start_mjd\"], recs[\"rate\"], yerr=recs[\"rate_std\"],\n",
    "                 fmt=\",\", alpha=0.2, color=\"C0\")\n",
    "    plt.plot(recs[\"start_mjd\"], recs[\"rate\"], marker=\".\", ls=\"\", color=\"C0\")\n",
    "    plt.plot(new_bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "    plt.plot(t_, rate_func.fun(t=t_, pars=bfs), color=\"C3\")\n",
    "    plt.ylim(0, 3. * bfs[1])\n",
    "    plt.show()\n",
    "    \n",
    "    # Empirical seed estimates for amplitude and baseline scan range\n",
    "    args = (new_mids, rates, weights)\n",
    "    rngs = np.array([bfs[0], bfs[1] / 10.])\n",
    "    stds, llh, grid = get_stddev_from_scan(\n",
    "        func=rate_func._lstsq, args=args, bfs=bfs, rngs=rngs, nbins=20)\n",
    "    \n",
    "    plot_llh_scan(bfs, stds, llh, grid)\n",
    "    plt.show()\n",
    "    \n",
    "    errs.append(stds)\n",
    "\n",
    "errs = np.array(errs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# 0 = amp, 1 = base\n",
    "# Note: The spline is not renormalized here, so there might be differences in\n",
    "#       scale to the one from the module\n",
    "for idx in [0, 1]:\n",
    "    x = np.linspace(-1, 1, 100)\n",
    "    mids = 0.5 * (sindec_bins[:-1] + sindec_bins[1:])\n",
    "    norm = np.diff(sindec_bins)\n",
    "\n",
    "    vals = np.array([res.x[idx] for res in allres]) / norm\n",
    "    err_ = errs.T[idx] / norm\n",
    "\n",
    "    # Prepare for spl fit\n",
    "    w = 1. / err_\n",
    "    spl, vals, pts, w = fit_spl_to_hist(h=vals, bins=sindec_bins, w=w, s=10)\n",
    "    \n",
    "    plt.plot(pts, vals, color=\"C7\", ls=\"--\")\n",
    "    plt.errorbar(pts, vals, yerr=1. / w, fmt=\"o\", color=\"C1\")\n",
    "    plt.plot(x, spl(x), color=\"k\")\n",
    "    plt.title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "\n",
    "    if idx == 0:\n",
    "        plt.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "        plt.ylabel(\"amp\")\n",
    "    else:\n",
    "        plt.ylim(0, None)\n",
    "        plt.ylabel(\"base\")\n",
    "    plt.xlabel(\"sindec\")\n",
    " \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Event preselection :: NEEDS MAINTANANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    exp_.keys()\n",
    "    name = \"86II_III\"\n",
    "except:\n",
    "    name = sample_name\n",
    "\n",
    "ev_dec = exp[name][\"dec\"]\n",
    "ev_ra = exp[name][\"ra\"]\n",
    "ev_sigma = exp[name][\"sigma\"]\n",
    "\n",
    "src_dec = srcs[name][\"dec\"][:, None]\n",
    "src_ra = srcs[name][\"ra\"][:, None]\n",
    "\n",
    "nsigma = 1.\n",
    "\n",
    "# Only mask events in a square with length nsigma * sigma to one of the sources\n",
    "dec_mask = ((ev_dec > src_dec - ev_sigma * nsigma) &\n",
    "            (ev_dec < src_dec + ev_sigma * nsigma))\n",
    "mask = dec_mask\n",
    "# RA mask needs more thought due to soild angle differences\n",
    "# ra_mask = ((ev_ra > (src_ra - ev_sigma * nsigma / np.cos(src_dec))) &\n",
    "#            (ev_ra < (src_ra + ev_sigma * nsigma / np.cos(src_dec))))\n",
    "# mask = ra_mask & dec_mask\n",
    "\n",
    "print(np.sum(mask, axis=1))\n",
    "\n",
    "# Plot events per source\n",
    "m = (ev_sigma < np.deg2rad(1.))  # Only show well reconstructed events\n",
    "plt.plot(ev_ra[m], ev_dec[m], color=\"C7\", alpha=.1, marker=\".\", ls=\"\", ms=1)\n",
    "for j, m in enumerate(mask[:]):\n",
    "    m = m & (ev_sigma < np.deg2rad(1.))  # Only show well reconstructed events\n",
    "    plt.scatter(ev_ra[m], ev_dec[m], s=100 * ev_sigma[m], alpha=.5)\n",
    "    plt.plot(src_ra[j], src_dec[j], marker=\"*\", ms=5)\n",
    "    \n",
    "# Show events contributing to all sources (if any)\n",
    "m = np.where(np.all(mask, axis=0))\n",
    "plt.scatter(ev_ra[m], ev_dec[m], s=10 * ev_sigma[m], alpha=1, color=\"k\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Renormalize spline :: NEEDS MAINTANANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Apparently we can renormalize a spline by evluating it at the original data grid, renormalizing the points and refit an interpolating spline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 15)  # Try for less and more points, always works...\n",
    "y = np.random.uniform(1, 2, size=len(x))\n",
    "\n",
    "spl = sci.UnivariateSpline(x, y, s=1)\n",
    "\n",
    "# Make a new spline by interpolating the original grid\n",
    "new_spl = sci.UnivariateSpline(x, spl(x), s=0)\n",
    "\n",
    "# Now rescale before fitting a new one\n",
    "old_norm = spl.integral(x[0], x[-1])\n",
    "new_norm = 2.\n",
    "new_spl_res = sci.UnivariateSpline(x, spl(x) / old_norm * new_norm, s=0)\n",
    "\n",
    "# Plot it\n",
    "x_ = np.linspace(x[0], x[-1], 200)\n",
    "\n",
    "# Unscaled\n",
    "plt.plot(x_, spl(x_), c=\"C7\", label=\"orig\")\n",
    "plt.plot(x_, new_spl(x_), ls=\"--\", c=\"C3\")\n",
    "\n",
    "# Rescaled\n",
    "plt.plot(x_, spl(x_) / old_norm * new_norm, c=\"k\", label=\"rescaled\")\n",
    "plt.plot(x_, new_spl_res(x_), ls=\"--\", c=\"r\")\n",
    "\n",
    "plt.plot(x, y, ls=\"\", marker=\"o\")\n",
    "knots = spl.get_knots()\n",
    "plt.plot(knots, spl(knots), ls=\"\", marker=\"d\")\n",
    "\n",
    "plt.title(\"Old norm: {:.2f}, new norm: {:.2f}\".format(\n",
    "    spl.integral(x[0], x[-1]), new_spl_res.integral(x[0], x[-1])))\n",
    "plt.ylim(0, None)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Energy PDF dependent of gamma :: NEEDS MAINTANANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Try to create the histogram slices as done by tkintscher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mc_dict = loader.mc_loader(\"all\")\n",
    "off_dict = loader.off_data_loader(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "key = \"IC86_2012-2014\"\n",
    "exp = off_dict[key]\n",
    "mc = mc_dict[key]\n",
    "\n",
    "\n",
    "log_proxy_E = exp[\"logE\"]\n",
    "lo, hi = np.percentile(log_proxy_E, [5, 95])\n",
    "\n",
    "h, b, _ = plt.hist(log_proxy_E, bins=50, color=\"C7\")\n",
    "\n",
    "plt.hist(log_proxy_E[exp[\"dec\"] > 0], bins=b, histtype=\"step\",\n",
    "         color=\"k\", lw=2, ls=\"--\", label=\"north\")\n",
    "plt.hist(log_proxy_E[exp[\"dec\"] <= 0], bins=b, histtype=\"step\",\n",
    "         color=\"k\", lw=2, ls=\":\", label=\"south\")\n",
    "\n",
    "plt.axvline(lo, ls=\"-\", c=\"C3\")\n",
    "plt.axvline(hi, ls=\"-\", c=\"C1\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(r\"$\\log_{10}(E_\\mathrm{proxy} / \\mathrm{GeV})$\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "log_true_E = np.log10(mc[\"trueE\"])\n",
    "log_proxy_E = mc[\"logE\"]\n",
    "w = mc[\"ow\"] * power_law_flux(trueE=mc[\"trueE\"], E0=1e5, phi0=0.9e-18,\n",
    "                               gamma=2.13)\n",
    "\n",
    "plt.hist2d(log_true_E, log_proxy_E, weights=w, bins=50, norm=LogNorm())\n",
    "plt.axhline(lo, ls=\"-\", c=\"k\")\n",
    "plt.axhline(hi, ls=\"-\", c=\"k\")\n",
    "\n",
    "plt.xlabel(r\"$\\log_{10}(E_\\nu) / \\mathrm{GeV})$\")\n",
    "plt.ylabel(r\"$\\log_{10}(E_\\mathrm{proxy} / \\mathrm{GeV})$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "key = \"IC86_2012-2014\"\n",
    "exp = off_dict[key]\n",
    "mc = mc_dict[key]\n",
    "\n",
    "data_proxy_E = exp[\"logE\"]\n",
    "data_sin_dec = np.sin(exp[\"dec\"])\n",
    "\n",
    "mc_log_proxy_E = mc[\"logE\"]\n",
    "mc_sin_dec = np.sin(mc[\"dec\"])\n",
    "\n",
    "sindec_bins = np.arange(-1, 1 +  0.05, 0.05)\n",
    "log_E_bins = np.linspace(np.amin(mc_log_proxy_E),\n",
    "                         np.amax(mc_log_proxy_E), 30 + 1)\n",
    "bins = [sindec_bins, log_E_bins]\n",
    "\n",
    "dgamma = 0.1\n",
    "gammas = np.arange(1, 4 + dgamma, dgamma)\n",
    "\n",
    "ratio_hists = []\n",
    "for gamma in gammas:\n",
    "    w = mc[\"ow\"] * power_law_flux(trueE=mc[\"trueE\"], E0=1, phi0=1, gamma=gamma)\n",
    "    d_h = np.histogram2d(data_sin_dec, data_proxy_E, bins=bins, normed=True)[0]\n",
    "    mc_h = np.histogram2d(mc_sin_dec, mc_proxy_E, bins=bins, weights=w,\n",
    "                          normed=True)[0]\n",
    "\n",
    "    m = (d_h > 0)\n",
    "    d_h[~m] = np.amin(d_h[m])\n",
    "    m = (mc_h > 0)\n",
    "    mc_h[~m] = np.amin(mc_h[m])\n",
    "    \n",
    "    ratio_hists.append(mc_h / d_h)\n",
    "    \n",
    "ratio_hists = np.array(ratio_hists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_log_E = 0.5 * (log_E_bins[:-1] + log_E_bins[1:])\n",
    "\n",
    "XX, YY = np.meshgrid(gammas, m_log_E)\n",
    "\n",
    "for i in range(len(sindec_bins) - 1):\n",
    "    plt.pcolormesh(XX, YY, ratio_hists[:, i, :].T, cmap=\"coolwarm\",\n",
    "                   norm=LogNorm(), vmin=1e-3, vmax=1e3)\n",
    "    plt.colorbar()\n",
    "    plt.title(sindec_bins[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m_sin_dec = 0.5 * (sindec_bins[:-1] + sindec_bins[1:])\n",
    "\n",
    "XX, YY = np.meshgrid(gammas, m_sin_dec)\n",
    "\n",
    "for i in range(len(log_E_bins) - 1):\n",
    "    plt.pcolormesh(XX, YY, ratio_hists[:, :, i].T, cmap=\"coolwarm\",\n",
    "                   norm=LogNorm(), vmin=1e-3, vmax=1e3)\n",
    "    plt.colorbar()\n",
    "    plt.title(log_E_bins[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, rh in enumerate(ratio_hists):\n",
    "    plt.pcolormesh(rh.T, norm=LogNorm(), cmap=\"coolwarm\", vmin=1e-3, vmax=1e3)\n",
    "    plt.title(\"{:.1f}\".format(gammas[i]))\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"sindec\")\n",
    "    plt.ylabel(\"logE\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Split on/off data and effective runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from mypyscripts.general.misc import idx2rowcol\n",
    "\n",
    "exp_on_dict = loader.on_data_loader(\"all\")\n",
    "exp_off_dict = loader.off_data_loader(\"all\")\n",
    "src_dict = loader.source_list_loader(\"all\")\n",
    "run_dict = loader.runlist_loader(\"all\")\n",
    "dt0_max, dt1_max = loader.time_window_loader(-1)\n",
    "\n",
    "livetimes = {}\n",
    "for key in sorted(exp_on_dict.keys()):\n",
    "    exp_on = exp_on_dict[key]\n",
    "    exp_off = exp_off_dict[key]\n",
    "    srcs = src_dict[key]\n",
    "    all_ids = np.concatenate([exp_on[\"Run\"], exp_off[\"Run\"]])\n",
    "    run_rec = phys.make_rate_records(ev_runids=all_ids, run_list=run_dict[key])\n",
    "    \n",
    "    ncols = int(np.ceil(np.sqrt(len(srcs))))\n",
    "    nrows = ncols\n",
    "    \n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, sharey=True, sharex=True,\n",
    "                           figsize=(ncols * 4, nrows * 3))\n",
    "    \n",
    "    livetimes[key] = []\n",
    "    for i, src in enumerate(srcs):\n",
    "        src_t = src[\"mjd\"]\n",
    "        \n",
    "        def mjd2sec(mjd):\n",
    "            return  (mjd - src_t) * SECINDAY\n",
    "        \n",
    "        src_tstart = src_t + dt0_max / SECINDAY\n",
    "        src_tstop = src_t + dt1_max / SECINDAY\n",
    "      \n",
    "        r, c = idx2rowcol(idx=i, ncols=ncols)\n",
    "        dt_plot = 0.2\n",
    "        \n",
    "        m_on = ((exp_on[\"time\"] > src_tstart - dt_plot) &\n",
    "                (exp_on[\"time\"] < src_tstop + dt_plot))\n",
    "        ax[r, c].vlines(mjd2sec(exp_on[\"time\"][m_on]),\n",
    "                        0.1, 0.9, colors=\"C7\", label=\"On data\")\n",
    "        m_off = ((exp_off[\"time\"] > src_tstart - dt_plot) &\n",
    "                 (exp_off[\"time\"] < src_tstop + dt_plot))\n",
    "        ax[r, c].vlines(mjd2sec(exp_off[\"time\"][m_off]),\n",
    "                        0, 1, colors=\"#BBBBBB\", label=\"Off data\")\n",
    "\n",
    "        ax[r, c].axvline(mjd2sec(src_tstart), 0, 1, ls=\"-\", c=\"k\")\n",
    "        ax[r, c].axvline(mjd2sec(src_tstop), 0, 1, ls=\"-\", c=\"k\")\n",
    "\n",
    "        for rt0, rt1 in zip(run_rec[\"start_mjd\"], run_rec[\"stop_mjd\"]):\n",
    "            if rt1 > src_tstart and rt0 < src_tstop:\n",
    "                ax[r, c].axvline(mjd2sec(rt0), 0, 1, ls=\":\", c=\"k\")\n",
    "                ax[r, c].axvline(mjd2sec(rt1), 0, 1, ls=\":\", c=\"k\")\n",
    "                \n",
    "        lt = np.sum(interval_overlap(\n",
    "            src_tstart, src_tstop, run_rec[\"start_mjd\"], run_rec[\"stop_mjd\"]))\n",
    "        livetimes[key].append(lt)\n",
    "        \n",
    "        ax[r, c].set_xlabel(\"Time in sec rel. to src\")\n",
    "        ax[r, c].set_title(\"Src {}. Livetime {:.2f} / {} d ({:.1%})\".format(\n",
    "            i, lt, src_tstop - src_tstart, lt / (src_tstop - src_tstart)))\n",
    "        ax[r, c].set_xlim(mjd2sec(src_tstart - dt_plot),\n",
    "                          mjd2sec(src_tstop + dt_plot))\n",
    "        if i == len(srcs) - 1:\n",
    "            ax[r, c].legend(loc=\"upper center\")\n",
    "        \n",
    "    for j in range(i + 1, ax.size):\n",
    "        fig.delaxes(ax[idx2rowcol(idx=j, ncols=ncols)])\n",
    "\n",
    "    suptitle = fig.suptitle(\"On-/offdata for sources in sample \" +\n",
    "                            \"'{}'\".format(key))  # Gets displaced by bbox...\n",
    "    fig.suptitle(key)\n",
    "    fig.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    save_plot(\"on_off_data_split\", \"{}.png\".format(key),\n",
    "              rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def print_dict(d):\n",
    "    shift = max(map(len, d.keys())) + 1\n",
    "    for key, val in d.items():\n",
    "        print(\"{1:{0:d}s}: {2:.1%}\".format(shift, key, val))\n",
    "        \n",
    "mean_lt = dict_map(lambda k, v: np.mean(v) / 5., livetimes)\n",
    "mean_lt_tot = np.mean(mean_lt.values())\n",
    "\n",
    "print_dict(mean_lt)\n",
    "print(\"Total mean livetime in all time windows: {:.1%}\".format(mean_lt_tot))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Filtered HESE events in MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Manually load all data and recreate LLH model with new MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def remove_hese_from_mc(mc, heseids):\n",
    "    \"\"\"\n",
    "    Mask all values in ``mc`` that have the same run and event ID combination\n",
    "    as in ``heseids``.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    mc : record-array\n",
    "        MC data, needs names ``'Run', 'Event'``.\n",
    "    heseids : dict or record-array\n",
    "        Needs names / keys ``'run_id', 'event_id``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    is_hese_like : array-like, shape (len(mc),)\n",
    "        Mask: ``True`` for each event in ``mc`` that is HESE like.\n",
    "    \"\"\"\n",
    "    # Make combined IDs to easily match against HESE IDs with `np.isin`\n",
    "    factor_mc = 10**np.ceil(np.log10(np.amax(mc[\"Event\"])))\n",
    "    _evids = np.atleast_1d(heseids[\"event_id\"])\n",
    "    factor_hese = 10**np.ceil(np.log10(np.amax(_evids)))\n",
    "    factor = max(factor_mc, factor_hese)\n",
    "\n",
    "    combined_mcids = (factor * mc[\"Run\"] + mc[\"Event\"]).astype(int)\n",
    "    assert np.all(combined_mcids > factor)  # Is int overflow a thing here?\n",
    "\n",
    "    _runids = np.atleast_1d(heseids[\"run_id\"])\n",
    "    combined_heseids = (factor * _runids + _evids).astype(int)\n",
    "    assert np.all(combined_heseids > factor)\n",
    "\n",
    "    # Check which MC event is tagged as HESE like\n",
    "    is_hese_like = np.isin(combined_mcids, combined_heseids)\n",
    "    print(\"  Found {} / {} HESE like events in MC\".format(np.sum(is_hese_like),\n",
    "                                                          len(mc)))\n",
    "    return is_hese_like\n",
    "\n",
    "def _get_weights(ow, trueE):\n",
    "    \"\"\" Common model to weight to event rate \"\"\"\n",
    "    lt = 365. * SECINDAY\n",
    "    return ow * power_law_flux(trueE, E0=1e5, phi0=0.9e-18, gamma=2.13) * lt\n",
    "\n",
    "name2skylab = {\n",
    "    \"IC79\" : \"IC79b_corrected_MC.npy\",\n",
    "    \"IC86_2011\" : \"IC86_corrected_MC.npy\",\n",
    "    \"IC86_2012-2014\" : \"IC86-2012_corrected_MC_v2.npy\",\n",
    "    \"IC86_2015\" : \"SplineMPEmax.MuEx.MC.npy\",\n",
    "}\n",
    "name2idx = {\n",
    "    \"IC79\" : \"IC79.json.gz\",\n",
    "    \"IC86_2011\" : \"IC86_2011.json.gz\",\n",
    "    \"IC86_2012-2014\" : \"IC86_2012-2015.json.gz\",\n",
    "    \"IC86_2015\" : \"IC86_2012-2015.json.gz\",    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "proxy = True  # Switch False | True to see plots in trueE, trueDec, vs. proxies\n",
    "if proxy:\n",
    "    _sindec = lambda mc: np.sin(mc[\"dec\"])\n",
    "    _logE = lambda mc: mc[\"logE\"]\n",
    "    _logE_label = r\"$\\log_{10}(E_\\mathrm{proxy} / \\mathrm{GeV})$\"\n",
    "    _sindec_label = r\"$\\sin(\\delta_\\mathrm{proxy})$\"\n",
    "    _info = \"_proxy\"\n",
    "else:\n",
    "    _sindec = lambda mc: np.sin(mc[\"trueDec\"])\n",
    "    _logE = lambda mc: np.log10(mc[\"trueE\"])\n",
    "    _logE_label = r\"$\\log_{10}(E_\\nu / \\mathrm{GeV})$\"\n",
    "    _sindec_label = r\"$\\sin(\\delta_\\nu)$\"\n",
    "    _info = \"\"\n",
    "\n",
    "for sample_name in name2skylab.keys()[:]:\n",
    "    print(\"# {}\".format(sample_name))\n",
    "    # Load full skylab data\n",
    "    _mc = np.load(os.path.join(PATHS.skylab_data, name2skylab[sample_name]))\n",
    "\n",
    "    # Filter HESE events\n",
    "    _path = os.path.join(PATHS.local, \"check_hese_mc_ids\", name2idx[sample_name])\n",
    "    heseids = json.load(gzip.open(_path))\n",
    "    is_hese_mask = remove_hese_from_mc(_mc, heseids)\n",
    "\n",
    "    _mc_hese = _mc[is_hese_mask]\n",
    "    _mc_no_hese = _mc[~is_hese_mask]\n",
    "\n",
    "    w_all = _get_weights(_mc[\"ow\"], _mc[\"trueE\"])\n",
    "    w_hese = _get_weights(_mc_hese[\"ow\"], _mc_hese[\"trueE\"])\n",
    "    w_no_hese = _get_weights(_mc_no_hese[\"ow\"], _mc_no_hese[\"trueE\"])\n",
    "\n",
    "    # Plot filtered out HESE events\n",
    "    fig, (axl, axc, axr) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    bins = [np.linspace(-1, 1, 40),\n",
    "            np.linspace(np.amin(_logE(_mc)), np.amax(_logE(_mc)), 40)]\n",
    "    h, _, _ = np.histogram2d(_sindec(_mc), _logE(_mc),\n",
    "                             bins=bins, weights=w_all)\n",
    "    vmin = 10**np.floor(np.amin(np.log10(h[h>0])))\n",
    "    vmax = 10**np.ceil(np.amax(np.log10(h[h>0])))\n",
    "\n",
    "    _, _, _, img = axl.hist2d(_sindec(_mc), _logE(_mc),\n",
    "                              bins=bins, norm=LogNorm(), cmap=\"inferno\",\n",
    "                              weights=w_all, vmin=vmin, vmax=vmax)\n",
    "    fig.colorbar(img, ax=axl)\n",
    "    \n",
    "    # Ratio no_mc / all\n",
    "    h_nh, _, _ = np.histogram2d(_sindec(_mc_no_hese), _logE(_mc_no_hese),\n",
    "                                bins=bins, weights=w_no_hese)\n",
    "    mask = (h > 0)\n",
    "    ratio = np.ones_like(h) + np.amin(h[mask])\n",
    "    ratio[mask] = h_nh[mask] / h[mask]\n",
    "    mids = [0.5 * (bi[:-1] + bi[1:]) for bi in bins]\n",
    "    xx, yy = map(np.ravel, np.meshgrid(*mids))\n",
    "    _, _, _, img = axc.hist2d(xx, yy, weights=np.ravel(ratio.T),\n",
    "                              bins=bins, cmap=\"inferno\",\n",
    "                              vmin=0.5, vmax=1.)\n",
    "    fig.colorbar(img, ax=axc)\n",
    "\n",
    "#     _, _, _, img = axc.hist2d(_sindec(_mc_no_hese), _logE(_mc_no_hese),\n",
    "#                               bins=bins, norm=LogNorm(), cmap=\"inferno\",\n",
    "#                               weights=w_no_hese, vmin=vmin, vmax=vmax)\n",
    "#     fig.colorbar(img, ax=axc)\n",
    "    _, _, _, img = axr.hist2d(_sindec(_mc_hese), _logE(_mc_hese),\n",
    "                              bins=bins, norm=LogNorm(), cmap=\"inferno\",\n",
    "                              weights=w_hese, vmin=vmin, vmax=vmax)\n",
    "    fig.colorbar(img, ax=axr)\n",
    "\n",
    "    axl.set_title(\"All MC: {:.2f} evts\".format(np.sum(w_all)))\n",
    "    axc.set_title(\"HESE-like removed: {:.2f} evts\".format(np.sum(w_no_hese)))\n",
    "    axr.set_title(\"Only HESE-like: {:.2f} evts\".format(np.sum(w_hese)))\n",
    "    for ax in (axl, axc, axr):\n",
    "        ax.set_xlabel(_sindec_label)\n",
    "        ax.set_ylabel(_logE_label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # save_plot(\"hese_mc_truncation\",\n",
    "    #           \"{}_comparison_sindec_logE{}.png\".format(sample_name, _info))\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot logE only\n",
    "    plt.hist(_logE(_mc), bins=bins[-1], alpha=0.5, density=False,\n",
    "             label=\"All MC\", weights=_get_weights(_mc[\"ow\"], _mc[\"trueE\"]))\n",
    "    plt.hist(_logE(_mc_hese), bins=bins[-1], alpha=0.5,\n",
    "             density=False, label=\"Only HESE-like\",\n",
    "             weights=_get_weights(_mc_hese[\"ow\"], _mc_hese[\"trueE\"]))\n",
    "    plt.yscale(\"log\", nonposy=\"clip\")\n",
    "    plt.xlabel(_logE_label)\n",
    "    plt.ylabel(\"# events\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # save_plot(\"hese_mc_truncation\",\n",
    "    #           \"{}_comparison_logE{}.png\".format(sample_name, _info))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Sources and rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot rates and sources for each sample\n",
    "_Hz2mHz = 1e3\n",
    "max_y = _Hz2mHz * 0.015\n",
    "for i, key in enumerate(sorted(exp_off_dict.keys())):\n",
    "    mids = 0.5 * (rate_recs_dict[key][\"start_mjd\"] +\n",
    "                  rate_recs_dict[key][\"stop_mjd\"])\n",
    "\n",
    "    min_x = np.amin(rate_recs_dict[key][\"start_mjd\"])\n",
    "    max_x = np.amax(rate_recs_dict[key][\"stop_mjd\"])\n",
    "#     plt.fill_between([min_x, max_x], [0, 0], [2, 2],\n",
    "#                      color=\"C{}\".format(i), alpha=0.05)\n",
    "    \n",
    "    plt.text(0.5 * (min_x + max_x), max_y - 1,\n",
    "             r\"{}\".format(key.replace(\"_\", \"\\n\")),\n",
    "             ha=\"center\", va=\"center\", color=\"C{}\".format(i))\n",
    "    \n",
    "    plt.errorbar(mids, _Hz2mHz * rate_recs_dict[key][\"rate\"],\n",
    "                 yerr=_Hz2mHz * rate_recs_dict[key][\"rate_std\"],\n",
    "                 fmt=\",\", color=\"C7\", alpha=0.1)\n",
    "        \n",
    "    plt.vlines(srcs_recs_dict[key][\"time\"], 0, 2, colors=\"C{}\".format(i),\n",
    "               linestyles=\"-\", label=key)\n",
    "    plt.axvline(np.amin(rate_recs_dict[key][\"start_mjd\"]), c=\"k\", ls=\"-.\")\n",
    "    \n",
    "plt.xlim(np.amin(rate_recs_dict[\"IC79\"][\"start_mjd\"]),\n",
    "         np.amax(rate_recs_dict[\"IC86_2015\"][\"stop_mjd\"]))\n",
    "plt.ylim(0, max_y)\n",
    "plt.xlabel(\"time in MJD days\")\n",
    "plt.ylabel(\"Rate in mHz\")\n",
    "plt.title(\"Rates and sources\")\n",
    "\n",
    "# save_plot(\"sources_and_rates\", \"rate_all_samples.png\", dpi=200,\n",
    "#           bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Source maps and source coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot a mollview with all prior maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import mypyscripts.plots as myplt\n",
    "\n",
    "all_srcs = loader.source_list_loader(\"all\")\n",
    "all_maps = []\n",
    "for src_list in all_srcs.values():\n",
    "    all_maps.append(loader.source_map_loader(src_list))\n",
    "    \n",
    "summed_maps = np.sum(np.concatenate(all_maps), axis=0)\n",
    "myplt.mollview(summed_maps, coords=\"equatorial\")\n",
    "\n",
    "save_plot(\"source_maps\", \"summed_maps.png\", dpi=200, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Load source s and source maps and check if the source coordinates match the maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "for key in [\"IC79\", \"IC86_2011\", \"IC86_2012-2014\", \"IC86_2015\"]:\n",
    "    # Load maps and sources\n",
    "    _srcs = loader.source_list_loader(key)[key]\n",
    "    _maps = loader.source_map_loader(_srcs)\n",
    "\n",
    "    # Get direct trafo ra, dec\n",
    "    _ras = np.array([s[\"ra\"] for s in _srcs])\n",
    "    _decs = np.array([s[\"dec\"] for s in _srcs])\n",
    "    _th = np.pi / 2. - _decs\n",
    "\n",
    "    # Compare to ra, dec to map\n",
    "    for i, m in enumerate(_maps):\n",
    "        m[m <= 0] = np.amin(m[m > 0])\n",
    "        hp.cartview(np.log10(m), cmap=\"gray_r\")\n",
    "        hp.projscatter(_th[i], _ras[i], marker=\"+\", color=\"r\")\n",
    "        hp.graticule(verbose=False)\n",
    "        plt.title(\"Sample: {}\".format(key))\n",
    "        save_plot(os.path.join(\"source_maps\", \"maps_and_src_points\"),\n",
    "                  \"sample_{}_src_{:02d}.png\".format(key, i), dpi=100)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show difference in truncated and maps with smoothing artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import healpy as hp\n",
    "# A map truncated to zero after 6 sigma contour\n",
    "_f = (\"/Users/tmenne/Downloads/hese_transient_stacking_data/\" +\n",
    "      \"123326.i3.bz2_event0000.json\")\n",
    "with open(_f) as f:\n",
    "    _src = json.load(f)\n",
    "    \n",
    "_m = np.array(_src[\"map\"])\n",
    "print(\"Chi2 6 sigma : \", scs.chi2.sf(6**2, df=2))\n",
    "print(\"Map min / max: \",np.amin(_m[_m > 0]) / np.amax(_m[_m > 0]))\n",
    "\n",
    "hp.cartview(np.log10(_m), cmap=\"gray_r\")\n",
    "hp.graticule(verbose=False)\n",
    "save_plot(os.path.join(\"source_maps\", \"artifacts\"), \"HESE_123326.png\")\n",
    "plt.show()\n",
    "\n",
    "# Now a map with smoothing artifacts\n",
    "_f = (\"/Users/tmenne/Downloads/hese_transient_stacking_data/\" +\n",
    "      \"123326.i3.bz2_event0000_art.json\")\n",
    "with open(_f) as f:\n",
    "    _src = json.load(f)\n",
    "    \n",
    "_m = np.array(_src[\"map\"])\n",
    "hp.cartview(np.log10(_m), cmap=\"gray_r\")\n",
    "hp.graticule(verbose=False)\n",
    "save_plot(os.path.join(\"source_maps\", \"artifacts\"), \"HESE_123326_artifacts.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Healpy source injection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Draw samples and show how the drawn sources scatter around the best fit position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, inj_i in multi_sig_inj.injs.items():\n",
    "    ra, dec = [], []\n",
    "    for i in range(1000):\n",
    "        sam = inj_i.sample(n_samples=1)\n",
    "        ra.append(inj_i._src_ra)\n",
    "        dec.append(inj_i._src_dec)\n",
    "\n",
    "    ra = np.array(ra)\n",
    "    dec = np.array(dec)\n",
    "\n",
    "    for i, (rai, deci) in enumerate(zip(ra.T, dec.T)):\n",
    "        plt.scatter(rai, deci, color=\"C{}\".format(i % 10), marker=\".\")\n",
    "        plt.plot(inj_i._srcs[\"ra\"][i], inj_i._srcs[\"dec\"][i],\n",
    "                 marker=\"o\", c=\"k\")\n",
    "\n",
    "    plt.xlim(0., 2. * np.pi)\n",
    "    plt.ylim(-np.pi / 2., np.pi / 2.)\n",
    "    plt.title(key)\n",
    "    save_plot(os.path.join(\"healpy_injection\", \"allsky\"),\n",
    "              \"sample_{}.png\".format(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Zoom in a cartview with the llh map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from mypyscripts.plots.astro import cartzoom_radius\n",
    "\n",
    "for key, inj in multi_sig_inj.injs.items():\n",
    "   # Sample some new source positions\n",
    "    ras, decs = [], []\n",
    "    for _ in range(1000):\n",
    "        _ = inj.sample(n_samples=1)\n",
    "        ras.append(inj._src_ra)\n",
    "        decs.append(inj._src_dec)\n",
    "    ras, decs = map(np.array, (ras, decs))\n",
    "    # Plot sampled positions and fixed source for each map\n",
    "    for i, cdf in enumerate(inj._src_map_CDFs):\n",
    "        # Rebuild map from CDF\n",
    "        map_i = np.diff(np.r_[cdf[0], cdf])\n",
    "        \n",
    "        max_idx = np.argmax(map_i)\n",
    "        ra_src, dec_src = inj._pix2ra[max_idx], inj._pix2dec[max_idx]\n",
    "\n",
    "        # Get declination band\n",
    "        _decs, _, _ = get_pixel_in_sigma_region(pdf_map=map_i, sigma=3)\n",
    "        min_dec, max_dec = np.amin(_decs), np.amax(_decs)\n",
    "        radius = 0.55 * (max_dec - min_dec)\n",
    "\n",
    "        map_i[map_i <= 0] = np.amin(map_i[map_i > 0])\n",
    "        cartzoom_radius(np.log10(map_i), center=[ra_src, dec_src],\n",
    "                        r=radius, cmap=\"viridis_r\")\n",
    "        # Plot declination band\n",
    "        _x0, _x1 = plt.gca().get_xlim()\n",
    "        plt.fill_between(x=[_x0, _x1], y1=[min_dec, min_dec],\n",
    "                         y2=[max_dec, max_dec], alpha=0.1, color=\"k\",\n",
    "                         label=\"MC selection region\")\n",
    "\n",
    "        plt.scatter(ras[:, i], decs[:, i], facecolors=\"w\", marker=\".\",\n",
    "                    edgecolors=\"k\", alpha=0.25, label=\"Injected sources\")\n",
    "        plt.scatter(ra_src, dec_src, marker=\"*\", color=\"C3\", s=30,\n",
    "                    label=\"Best fit HESE\")\n",
    "        plt.legend()\n",
    "        plt.title(\"{}. Source {}\".format(key, i))\n",
    "        save_plot(os.path.join(\"healpy_injection\", \"zoomed_with_map\"),\n",
    "                  \"{}_src_{:02d}\".format(key, i), dpi=200)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nbins = 100\n",
    "nsam = len(exp_off_dict)\n",
    "name2xlabel = {\"ra\": \"RA in rad\",\n",
    "               \"dec\": \"DEC in rad\",\n",
    "               \"logE\": \"log(E / GeV) proxy\",\n",
    "               \"sigma\": \"Circular sigma in deg\"}\n",
    "for name in [\"ra\", \"dec\", \"logE\", \"sigma\"]:\n",
    "    fig, ax = plt.subplots(1, nsam, figsize=(5 * nsam, 4))\n",
    "    for i, key in enumerate(sorted(exp_off_dict.keys())):\n",
    "        if name == \"sigma\":\n",
    "            ax[i].hist(np.rad2deg(exp_off_dict[key][name]), bins=nbins)\n",
    "        else:\n",
    "            ax[i].hist(exp_off_dict[key][name], bins=nbins)\n",
    "        ax[i].set_title(key)\n",
    "        if name in [\"sigma\", \"logE\"]:\n",
    "            ax[i].set_yscale(\"log\")\n",
    "        ax[i].set_xlabel(name2xlabel[name])\n",
    "    fig.tight_layout()\n",
    "    save_plot(\"data_distribution\", name, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BG splines and sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test if multi sampler samples correctly from each single injector.\n",
    "In the BG case this just collects all single samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n_samples = 1000\n",
    "multi_bg_sam_ = [multi_bg_inj.sample() for i in range(n_samples)]\n",
    "multi_bg_sam = {}\n",
    "for key in multi_bg_inj.names:\n",
    "    multi_bg_sam[key] = np.concatenate([sam_i[key] for sam_i in multi_bg_sam_])\n",
    "nsam = map(len, multi_bg_sam.values())\n",
    "for i, key in enumerate(multi_bg_inj.names):\n",
    "    print(\"{:8s} : {}\".format(key, nsam[i]))\n",
    "    \n",
    "name2xlabel = {\"ra\": \"RA in rad\",\n",
    "               \"dec\": \"DEC in rad\",\n",
    "               \"logE\": \"log(E / GeV) proxy\",\n",
    "               \"sigma\": \"Circular sigma in deg\"}\n",
    "nbins = 100\n",
    "for name in [\"ra\", \"dec\", \"logE\", \"sigma\"]:\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(18, 4))\n",
    "    for i, key in enumerate(sorted(multi_bg_inj.names)):\n",
    "        if name == \"sigma\":\n",
    "            ax[i].hist(np.rad2deg(multi_bg_sam[key][name]), bins=nbins)\n",
    "        else:\n",
    "            ax[i].hist(multi_bg_sam[key][name], bins=nbins)\n",
    "        ax[i].set_title(\"{}. {} times sampled BG\".format(key, n_samples))\n",
    "        if name in [\"sigma\", \"logE\"]:\n",
    "            ax[i].set_yscale(\"log\")\n",
    "        ax[i].set_xlabel(name2xlabel[name])\n",
    "#     save_plot(os.path.join(\"bg_injector\", \"sample_dist\"),\n",
    "#               \"bg_sample_{}.png\".format(name), dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show build spline models for time dependent injector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1, 100)\n",
    "for key, bg_inj in sorted(multi_bg_inj._injs.items()):\n",
    "    print(\"Plotting for sample '{}'\".format(key))\n",
    "\n",
    "    bins = bg_inj_opts[key][\"sindec_bins\"]\n",
    "    mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "    print(\"Allsky best params: \" + arr2str(\n",
    "        bg_inj._spl_info[\"allsky_best_params\"]))\n",
    "\n",
    "    for n in [\"amp\", \"base\"]:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "        spl = bg_inj._spl_info[\"param_splines\"][n]\n",
    "        vals = np.copy(bg_inj._spl_info[\"best_pars_norm\"][n])\n",
    "        err = np.copy(bg_inj._spl_info[\"best_stddevs_norm\"][n])\n",
    "\n",
    "        ax.plot(x, spl(x), color=\"k\")\n",
    "        ax.plot(mids, vals, color=\"C7\", ls=\"--\")\n",
    "        ax.errorbar(mids, vals, yerr=err, fmt=\"o\", color=\"C1\")\n",
    "\n",
    "        if n == \"amp\":\n",
    "            ax.axhline(0, 0, 1, color=\"C7\", ls=\"--\")\n",
    "        else:\n",
    "            ax.set_ylim(0, None)\n",
    "\n",
    "        ax.set_xlabel(\"sindec\")\n",
    "        ax.set_ylabel(n)\n",
    "        ax.set_title(\"Integral: {:.3f} mHz\".format(spl.integral(-1, 1) * 1e3))\n",
    "        # Show sindec bin borders\n",
    "        ylim = ax.get_ylim()\n",
    "        ax.vlines(bins, ylim[0], ylim[1], linestyles=\":\", colors=\"C7\")\n",
    "        ylim = ax.set_ylim(ylim)\n",
    "#         save_plot(os.path.join(\"bg_injector\", \"param_splines\"),\n",
    "#                   \"{}_{}.png\".format(key, n))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot rates vs rate model for each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, bg_inj in sorted(multi_bg_inj._injs.items())[:]:\n",
    "    # Show also rebinned\n",
    "    rebin = rebin_rate_rec(rate_rec=rate_recs_dict[key],\n",
    "                           bins=bg_inj_opts[key][\"rate_rebins\"],\n",
    "                           ignore_zero_runs=True)\n",
    "    rates, bins, rate_std, _ = rebin\n",
    "\n",
    "    mids = 0.5 * (rate_recs_dict[key][\"start_mjd\"] +\n",
    "                  rate_recs_dict[key][\"stop_mjd\"])\n",
    "    diff = rate_recs_dict[key][\"stop_mjd\"] - rate_recs_dict[key][\"start_mjd\"]\n",
    "    t = np.linspace(bins[0], bins[-1], 200)\n",
    "    \n",
    "    # Plot it\n",
    "    plt.errorbar(mids, rate_recs_dict[key][\"rate\"],\n",
    "                 xerr=diff, yerr=rate_recs_dict[key][\"rate_std\"],\n",
    "                 fmt=\",\", color=\"C0\", alpha=0.5, zorder=-5)\n",
    "    plt.plot(bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "    plt.plot(t, bg_inj._spl_info[\"allsky_rate_func\"].bf_fun(t),\n",
    "             color=\"C3\", lw=2)\n",
    "        \n",
    "    plt.ylim(0, 0.015)\n",
    "    plt.xlabel(\"time in MJD days\")\n",
    "    plt.ylabel(\"Rate in Hz\")\n",
    "    plt.title(\"Allsky rate model for sample {}\".format(key))\n",
    "    save_plot(os.path.join(\"bg_injector\", \"rate_models_and_rates\"),\n",
    "              key + \".png\", dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot rate model for each sindec bin per sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, bg_inj in sorted(multi_bg_inj._injs.items())[:]:\n",
    "    print(\"Making plots for sample: '{}'\".format(key))\n",
    "    runids = exp_off_dict[key][\"Run\"]\n",
    "    sindec = np.sin(exp_off_dict[key][\"dec\"])\n",
    "    sd_bins = bg_inj_opts[key][\"sindec_bins\"]\n",
    "    rate_fun = bg_inj._spl_info[\"allsky_rate_func\"]\n",
    "\n",
    "    # Make a plot grid\n",
    "    nplots, nrows, ncols = 20, 4, 5\n",
    "    assert ncols * nrows == nplots\n",
    "    assert nplots == len(sd_bins) - 1\n",
    "    fig, ax = plt.subplots(nrows=nrows, ncols=ncols, figsize=(24, 13.5),\n",
    "                           sharex=True, sharey=True)\n",
    "    \n",
    "    for i, (lo, hi) in enumerate(zip(sd_bins[:-1], sd_bins[1:])):\n",
    "        mask = (sindec >= lo) & (sindec < hi)\n",
    "        recs = make_rate_records(run_list=runlists_dict[key],\n",
    "                                 ev_runids=runids[mask])\n",
    "        rebin = rebin_rate_rec(\n",
    "            rate_rec=recs, bins=bg_inj_opts[key][\"rate_rebins\"],\n",
    "            ignore_zero_runs=True)\n",
    "        rates, bins, rate_std, _ = rebin\n",
    "        \n",
    "        mids = 0.5 * (recs[\"start_mjd\"] + recs[\"stop_mjd\"])\n",
    "        diff = recs[\"stop_mjd\"] - recs[\"start_mjd\"]\n",
    "        t = np.linspace(bins[0], bins[-1], 200)\n",
    "        \n",
    "        amp, base = bg_inj._spl_info[\"best_pars\"][i]\n",
    "        pars = (amp, bg_inj._spl_info[\"allsky_best_params\"][1], base)\n",
    "        lab = \"{:.2f} <= sindec < {:.2f}\".format(lo, hi)\n",
    "        \n",
    "        # Plot it\n",
    "        row, col = plots.idx2rowcol(i, ncols=ncols)\n",
    "        ax_ = ax[row, col]\n",
    "        ax_.errorbar(mids, recs[\"rate\"], xerr=diff, yerr=recs[\"rate_std\"],\n",
    "                     fmt=\",\", color=\"C0\", alpha=0.5, label=lab, zorder=-5)\n",
    "        ax_.plot(bins, np.r_[rates[0], rates], drawstyle=\"steps-pre\", color=\"k\")\n",
    "        ax_.plot(t, rate_fun.fun(t, pars), color=\"C3\", lw=2.5)\n",
    "\n",
    "        ax_.set_ylim(0, 0.001)\n",
    "        ax_.legend(loc=\"upper right\")\n",
    "    ax[0, 0].text(s=\"Sample: '{}'\".format(key), x=bins[0], y=0.0009,\n",
    "                  bbox={\"facecolor\": \"w\", \"alpha\": 0.5}, fontsize=12)\n",
    "    save_plot(os.path.join(\"bg_injector\", \"rate_models_per_dec_bin\"),\n",
    "              key + \".png\", dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Compare hist to allsky model\n",
    "x = np.linspace(-1, 1, 200)\n",
    "for key, bg_inj in sorted(multi_bg_inj._injs.items())[:]:\n",
    "    bins = bg_inj_opts[key][\"sindec_bins\"]\n",
    "    plt.vlines(bins, 0, 1, linestyles=\"--\",\n",
    "               colors=\"C7\", zorder=-1)\n",
    "    bins = np.linspace(-1, 1, 100)\n",
    "    h, b = np.histogram(np.sin(exp_off_dict[key][\"dec\"]),\n",
    "                        bins=bins, density=False)\n",
    "    m = 0.5 * (b[:-1] + b[1:])\n",
    "    norm = np.diff(b) * np.sum(h)\n",
    "    err = np.sqrt(h)\n",
    "    h_n = h / norm\n",
    "    err_n = err / norm\n",
    "    \n",
    "    plt.plot(b, np.r_[h_n[0], h_n], drawstyle=\"steps-pre\", c=\"C0\")\n",
    "    plt.errorbar(m, h_n, yerr=err_n, fmt=\",\", color=\"C0\")\n",
    "    \n",
    "    plt.plot(x, bg_inj._spl_info[\"data_sin_dec_pdf_spline\"](x), c=\"C1\")\n",
    "    plt.title(key)\n",
    "#     save_plot(os.path.join(\"bg_injector\", \"allsky_model\"),\n",
    "#               key + \".png\", dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show that sampled distribtuion follows PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, bg_inj in multi_bg_inj.injs.items():\n",
    "    print(\"Sample \", key)\n",
    "    nsrcs = len(bg_inj.srcs)\n",
    "    sam = [list() for _ in range(nsrcs)]\n",
    "    # Sample a few times to have better stats for smaller timw windows\n",
    "    nsamples = 5000\n",
    "    for _ in range(nsamples):\n",
    "        sami = bg_inj.sample(debug=True)\n",
    "        src_idx = bg_inj._sample_idx[\"src_idx\"]\n",
    "        for j in range(nsrcs):\n",
    "            sam[j].append(sami[src_idx == j])\n",
    "\n",
    "    sam = [np.concatenate(sami) for sami in sam]\n",
    "    # These should match closely\n",
    "    print(map(lambda spl: spl.integral(-1, 1),\n",
    "              bg_inj._spl_info[\"sin_dec_splines\"]))\n",
    "    print(bg_inj._nb)\n",
    "    \n",
    "    # Plot average all data distribution and the spline for each source\n",
    "    x = np.linspace(-1, 1, 200)\n",
    "    sindec_bins = bg_inj.inj_opts[\"sindec_bins\"]\n",
    "    _bins = np.linspace(-1, 1, 50)\n",
    "\n",
    "    for j, sami in enumerate(sam):\n",
    "        plt.vlines(sindec_bins, 0, 1, linestyles=\"--\", colors=\"C7\", zorder=-1)\n",
    "        # Plot allyear sample for comparison\n",
    "        h, b, _ = plt.hist(np.sin(exp_off_dict[key][\"dec\"]), bins=sindec_bins,\n",
    "                           density=True, color=\"C7\", alpha=0.5)\n",
    "        _spl = fit_spl_to_hist(h=h, bins=b)[0]\n",
    "        plt.plot(x, _spl(x), color=\"C0\", ls=\":\", lw=3)\n",
    "        # Drawn sample per source. Red hist should approx. follow black spline\n",
    "        h, b = np.histogram(np.sin(sami[\"dec\"]), bins=_bins, density=False)\n",
    "        norm = np.sum(h) * np.diff(b)\n",
    "        err = np.sqrt(h) / norm\n",
    "        h = h / norm\n",
    "        m = 0.5 * (b[:-1] + b[1:])\n",
    "        plt.plot(b, np.r_[h[0], h], drawstyle=\"steps-pre\", lw=2.5, color=\"C3\")\n",
    "        plt.errorbar(m, h, yerr=err, fmt=\",\", color=\"C3\")\n",
    "        plt.plot(x, bg_inj._spl_info[\"sin_dec_pdf_splines\"][j](x), color=\"k\")\n",
    "        plt.xlabel(\"sin dec\")\n",
    "        plt.ylabel(\"PDF\")\n",
    "        plt.title(\"{}. Source {:02d}\".format(key, j))\n",
    "\n",
    "        save_plot(os.path.join(\"bg_injector\", \"sindec_splines\"),\n",
    "                  \"{}_src_{:02d}.png\".format(key, j))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show sampling weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, bg_inj in multi_bg_inj.injs.items():\n",
    "    pts = np.sin(exp_off_dict[key][\"dec\"])\n",
    "    idx = np.argsort(pts)\n",
    "    pts = pts[idx]\n",
    "\n",
    "    nsrcs = len(bg_inj.srcs)\n",
    "    c = plt.cm.inferno(np.linspace(0, 0.8, nsrcs))\n",
    "    for j, w in enumerate(bg_inj._spl_info[\"sample_weights\"]):\n",
    "        plt.plot(pts, w[idx], label=\"source {}\".format(j), color=c[j])\n",
    "\n",
    "    plt.axhline(1, 0, 1, c=\"k\")\n",
    "    plt.xlabel(\"sin dec\")\n",
    "    plt.ylabel(\"Sample weights\")\n",
    "    plt.title(\"{}\".format(key))\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(0.75, 1.5)   \n",
    "    plt.legend(ncol=nsrcs // 5 + 1, loc=\"best\")\n",
    "\n",
    "    save_plot(os.path.join(\"bg_injector\", \"sample_weights\"),\n",
    "              \"{}_sample_weights.png\".format(key))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## MC injector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test splitting of signal samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsamples = 10000\n",
    "multi_sig_sam = multi_sig_inj.sample(n_samples=nsamples)\n",
    "# Total sample weight should be normed to 1\n",
    "print(sum(map(len, (multi_sig_sam.values()))))\n",
    "print(nsamples * sum(multi_sig_inj._distribute_weights.values()))\n",
    "# Show sampled events from each injector and split weights normed to tot samples\n",
    "print(dict_map(lambda key, sam: len(sam), multi_sig_sam))\n",
    "print(dict_map(lambda key, wts: \"{:.1f}\".format(wts * nsamples),\n",
    "               multi_sig_inj._distribute_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show sample distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key, sami in multi_sig_sam.items():\n",
    "    # Sampled MC hist\n",
    "    _inj = multi_sig_inj.injs[key]\n",
    "    _idx = multi_sig_inj.injs[key]._sample_idx\n",
    "    for name in [\"ra\", \"dec\", \"logE\", \"time\", \"sigma\"]:\n",
    "        # Show sampled data-like attributes\n",
    "        if name != \"time\":\n",
    "            # Compare to full MC pool distribution\n",
    "            w = _inj._MC[\"ow\"] * _inj.flux_model(_inj._MC[\"trueE\"])\n",
    "            if name == \"sigma\" and key == \"IC86_2015\":\n",
    "                bins = np.linspace(0, np.amax(sami[name]), 100)\n",
    "            else:\n",
    "                bins = 100\n",
    "\n",
    "            _ = plt.hist(_inj._MC[name], weights=w, density=True, bins=bins,\n",
    "                         alpha=.5)\n",
    "            _ = plt.hist(sami[name], density=True, bins=bins,\n",
    "                         histtype=\"step\", lw=3)\n",
    "        if name in [\"ra\", \"dec\"]:\n",
    "            plt.vlines(_inj.srcs[name], 0, 1)\n",
    "            plt.yscale(\"log\", nonposy=\"clip\")\n",
    "        if name == \"time\":\n",
    "            ts = _inj.srcs[\"time\"]\n",
    "            dt0s, dt1s = _inj.srcs[\"dt0\"], _inj.srcs[\"dt1\"]\n",
    "            for j in range(len(ts)):\n",
    "                plt.title(\"{}. {:.2f}, {:.2f}, {:.2f}\".format(\n",
    "                    name, ts[j], dt0s[j], dt1s[j]))\n",
    "                mask = (_idx[\"src_idx\"] == j)\n",
    "                trel = (ts[j] - sami[name][mask]) * SECINDAY\n",
    "                _ = plt.hist(trel, density=False, bins=bins,\n",
    "                             histtype=\"step\", lw=3)\n",
    "                plt.axvline(0, 0, 1)\n",
    "                plt.axvline(dt0s[j], 0, 1, ls=\"--\")\n",
    "                plt.axvline(dt1s[j], 0, 1, ls=\"--\")\n",
    "                save_plot(os.path.join(\"sig_inj\", \"sample\"),\n",
    "                          \"{}_time_src_{}.png\".format(key, j), dpi=150)\n",
    "                plt.show()\n",
    "        else:\n",
    "            plt.title(\"{}: {}\".format(key, name))\n",
    "            save_plot(os.path.join(\"sig_inj\", \"sample\"),\n",
    "                      \"{}_{}.png\".format(key, name), dpi=150)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sample from each injector on its own and show that the expected number of events match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nsamples = 10000\n",
    "\n",
    "# Plot for each sample\n",
    "for key in sorted(multi_sig_inj.injs.keys()):\n",
    "    _inj = multi_sig_inj.injs[key]\n",
    "    _grb_mod = multi_llh.model[key]\n",
    "    _Xsig = _inj.sample(n_samples=nsamples)\n",
    "    _src_idx = _inj._sample_idx[\"src_idx\"]\n",
    "\n",
    "    bins = _grb_mod._spatial_opts[\"sindec_bins\"]\n",
    "    mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "    lo, hi = bins[0], bins[-1]\n",
    "\n",
    "    # Make signal distribution from which is sampled\n",
    "    w_sig = mc_dict[key][\"ow\"] * _inj._flux_model(mc_dict[key][\"trueE\"])\n",
    "    sindec = np.sin(mc_dict[key][\"trueDec\"])\n",
    "    hist, _ = np.histogram(sindec, bins=bins, weights=w_sig)\n",
    "    var, _ = np.histogram(sindec, bins=bins, weights=w_sig**2)\n",
    "    dA = np.diff(bins)\n",
    "    hist = hist / dA\n",
    "    stddev = np.sqrt(var) / dA\n",
    "\n",
    "    # Normalize hist as injection weights: sum w = 1. Weights from src weights\n",
    "    src_w = _grb_mod.get_args()[\"src_w_dec\"]\n",
    "    norm = np.sum(src_w)\n",
    "    hist = hist / norm\n",
    "    stddev = stddev / norm\n",
    "    spl = _grb_mod._spl_info[\"mc_sin_dec_pdf_spline\"]\n",
    "\n",
    "    # Plot the spline and the histogram\n",
    "    x = np.linspace(lo, hi, 250)\n",
    "    plt.plot(bins, np.r_[hist[0], hist], drawstyle=\"steps-pre\", color=\"C7\")\n",
    "    plt.errorbar(mids, hist, yerr=stddev, fmt=\",\", color=\"C7\")\n",
    "    plt.plot(x, spl(x) / norm)\n",
    "\n",
    "    for j, srci in enumerate(_inj.srcs):\n",
    "        # Plot source positions in dec\n",
    "        plt.axvline(np.sin(srci[\"dec\"]), 0, 1, ls=\"--\", c=\"C7\")\n",
    "        # Plot relativ number of sampled events per src\n",
    "        m = (_src_idx == j)\n",
    "        nsam = np.sum(m) / len(m)\n",
    "        nsam_err = np.sqrt(np.sum(m)) / len(m)\n",
    "        plt.errorbar(np.sin(srci[\"dec\"]), nsam, yerr=nsam_err,\n",
    "                     fmt=\"o\", c=\"C{}\".format(j % 9), zorder=5, alpha=1.)\n",
    "        # Plot 1D scatter of sampled events per source\n",
    "        plt.vlines(np.sin(_Xsig[m][\"dec\"]), -0.15 * np.amax(hist), 0.,\n",
    "                   linestyles=\"-\", colors=\"C{}\".format(j % 9), alpha=0.1)\n",
    "        # Plot expected relativ event numbers (spline values)\n",
    "        plt.plot(np.sin(srci[\"dec\"]), src_w[j] / norm, c=\"C{}\".format(j % 9),\n",
    "                 marker=\"d\", ls=\"\", mec=\"k\", zorder=6)\n",
    "\n",
    "        plt.axhline(0, 0, 1, c=\"k\", ls=\"-\")\n",
    "\n",
    "    plt.ylim(-0.15 * np.amax(hist), None)\n",
    "    plt.title(key)\n",
    "\n",
    "    # plt.savefig(\"/Users/tmenne/Downloads/mc_inject_expect_\" +\n",
    "    #             \"{}_nsam={}.png\".format(sample_name, nsamples), dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now sample the multiinjector and get the events per injector and per source to see that the expectation still matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Sample with the multi injector and entangle to check single sample plots\n",
    "nsamples = 10000\n",
    "sam = multi_sig_inj.sample(nsamples)\n",
    "# Get samples event and source indices\n",
    "sig_idx = dict_map(lambda k, inj: inj._sample_idx, multi_sig_inj.injs)\n",
    "\n",
    "# Print stats\n",
    "print(\"Total samples: \", sum([len(sami) for sami in sam.values()]))\n",
    "for key, sami in sam.items():\n",
    "    _dw = multi_sig_inj._distribute_weights[key]\n",
    "    _space = int(np.ceil(np.log10(nsamples)))\n",
    "    print(\"  - {0:15s}: {1:{3:}d} (Expected: {2:{4:}.1f})\".format(\n",
    "        key, len(sami), nsamples * _dw, _space, _space + 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot for each sample\n",
    "for key in sorted(multi_sig_inj.injs.keys()):\n",
    "    _inj = multi_sig_inj.injs[key]\n",
    "    _grb_mod = multi_llh.model[key]\n",
    "    _Xsig = sam[key]\n",
    "    _src_idx = sig_idx[key][\"src_idx\"]\n",
    "\n",
    "    bins = _grb_mod._spatial_opts[\"sindec_bins\"]\n",
    "    lo, hi = bins[0], bins[-1]\n",
    "    bins = np.linspace(lo, hi, 100)  # Overwrite for finer binning\n",
    "    mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "    # Make signal distribution from which is sampled\n",
    "    w_sig = mc_dict[key][\"ow\"] * _inj._flux_model(mc_dict[key][\"trueE\"])\n",
    "    sindec = np.sin(mc_dict[key][\"trueDec\"])\n",
    "    hist, _ = np.histogram(sindec, bins=bins, weights=w_sig)\n",
    "    var, _ = np.histogram(sindec, bins=bins, weights=w_sig**2)\n",
    "    dA = np.diff(bins)\n",
    "    hist = hist / dA\n",
    "    stddev = np.sqrt(var) / dA\n",
    "\n",
    "    # Normalize hist as injection weights: sum w = 1. Weights from src weights\n",
    "    src_w = _grb_mod.get_args()[\"src_w_dec\"]\n",
    "    norm = np.sum(src_w)\n",
    "    hist = hist / norm\n",
    "    stddev = stddev / norm\n",
    "    spl = _grb_mod._spl_info[\"mc_sin_dec_pdf_spline\"]\n",
    "\n",
    "    # Plot the spline and the histogram\n",
    "    x = np.linspace(lo, hi, 250)\n",
    "    plt.plot(bins, np.r_[hist[0], hist], drawstyle=\"steps-pre\", color=\"C7\")\n",
    "    plt.errorbar(mids, hist, yerr=stddev, fmt=\",\", color=\"C7\")\n",
    "    plt.plot(x, spl(x) / norm)\n",
    "\n",
    "    for j, srci in enumerate(_inj.srcs):\n",
    "        # Plot source positions in dec\n",
    "        plt.axvline(np.sin(srci[\"dec\"]), 0, 1, ls=\"--\", c=\"C7\")\n",
    "        # Plot relativ number of sampled events per src\n",
    "        m = (_src_idx == j)\n",
    "        nsam = np.sum(m) / len(m)\n",
    "        nsam_err = np.sqrt(np.sum(m)) / len(m)\n",
    "        plt.errorbar(np.sin(srci[\"dec\"]), nsam, yerr=nsam_err,\n",
    "                     fmt=\"o\", c=\"C{}\".format(j % 9), zorder=5, alpha=1.)\n",
    "        # Plot 1D scatter of sampled events per source\n",
    "        plt.vlines(np.sin(_Xsig[m][\"dec\"]), -0.15 * np.amax(hist), 0.,\n",
    "                   linestyles=\"-\", colors=\"C{}\".format(j % 9), alpha=0.1)\n",
    "        # Plot expected relativ event numbers (spline values)\n",
    "        plt.plot(np.sin(srci[\"dec\"]), src_w[j] / norm, c=\"C{}\".format(j % 9),\n",
    "                 marker=\"d\", ls=\"\", mec=\"k\", zorder=6)\n",
    "\n",
    "        plt.axhline(0, 0, 1, c=\"k\", ls=\"-\")\n",
    "\n",
    "    plt.ylim(-0.15 * np.amax(hist), None)\n",
    "    plt.title(key)\n",
    "\n",
    "    save_plot(os.path.join(\"sig_inj\", \"mc_inject_expect\"),\n",
    "              \"{}_nsam={}.png\".format(key, len(_src_idx)), dpi=250)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LLH Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Energy PDF ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, grb_mod_i in multi_llh.model.items():\n",
    "    xbins = grb_mod_i.energy_opts[\"bins\"][0]\n",
    "    ybins = grb_mod_i.energy_opts[\"bins\"][1]\n",
    "\n",
    "    xlo, xhi = np.amin(xbins), np.amax(xbins)\n",
    "    ylo, yhi = np.amin(ybins), np.amax(ybins)\n",
    "\n",
    "    x = np.linspace(xlo, xhi, 250)\n",
    "    y = np.linspace(ylo, yhi, 250)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "    xmids, ymids = map(lambda b: 0.5 * (b[:-1] + b[1:]), [x, y])\n",
    "    XX, YY = map(np.ravel, np.meshgrid(xmids, ymids))\n",
    "    pts = np.vstack((XX, YY)).T\n",
    "\n",
    "    # zz = grb_mod_i._energy_interpol(pts)\n",
    "    zz = grb_mod_i._soverb_energy(XX, YY)\n",
    "    zz = zz.reshape(len(xmids), len(ymids))\n",
    "\n",
    "    plt.pcolormesh(xx, yy, np.log10(zz), cmap=\"coolwarm\", vmin=-3, vmax=3)\n",
    "    cbar = plt.colorbar()\n",
    "\n",
    "    cbar.set_label(\"log10(S/B)\")\n",
    "    plt.xlabel(\"sin(dec)\")\n",
    "    plt.ylabel(\"log10(E proxy / GeV)\")\n",
    "    plt.title(key)\n",
    "\n",
    "    save_plot(os.path.join(\"llh_model\", \"energy_pdfs\"), key, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Expected signal stacking weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot for each sample\n",
    "for key in sorted(multi_sig_inj.injs.keys()):\n",
    "    _inj = multi_sig_inj.injs[key]\n",
    "    _grb_mod = multi_llh.model[key]\n",
    "\n",
    "    bins = np.linspace(-1, 1, 100)\n",
    "    mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "    lo, hi = bins[0], bins[-1]\n",
    "\n",
    "    # Make signal distribution from which is sampled\n",
    "    w_sig = mc_dict[key][\"ow\"] * _inj._flux_model(mc_dict[key][\"trueE\"])\n",
    "    sindec = np.sin(mc_dict[key][\"trueDec\"])\n",
    "    hist, _ = np.histogram(sindec, bins=bins, weights=w_sig)\n",
    "    var, _ = np.histogram(sindec, bins=bins, weights=w_sig**2)\n",
    "    dA = np.diff(bins)\n",
    "    hist = hist / dA\n",
    "    stddev = np.sqrt(var) / dA\n",
    "\n",
    "    # Normalize hist as injection weights: sum w = 1. Weights from src weights\n",
    "    src_w = _grb_mod.get_args()[\"src_w_dec\"]\n",
    "    norm = np.sum(src_w)\n",
    "    hist = hist / norm\n",
    "    stddev = stddev / norm\n",
    "    spl = _grb_mod._spl_info[\"mc_sin_dec_pdf_spline\"]\n",
    "\n",
    "    # Plot the spline and the histogram\n",
    "    x = np.linspace(lo, hi, 250)\n",
    "    plt.plot(bins, np.r_[hist[0], hist], drawstyle=\"steps-pre\", color=\"C7\")\n",
    "    plt.errorbar(mids, hist, yerr=stddev, fmt=\",\", color=\"C7\")\n",
    "    plt.plot(x, spl(x) / norm)\n",
    "\n",
    "    c = plt.cm.inferno(np.linspace(0., 0.8, len(_inj.srcs)))\n",
    "    for j, srci in enumerate(_inj.srcs):\n",
    "        # Plot source positions in dec\n",
    "        plt.axvline(np.sin(srci[\"dec\"]), 0, 1, ls=\"--\", c=\"C7\")\n",
    "        # Plot expected relativ event numbers (spline values)\n",
    "        plt.plot(np.sin(srci[\"dec\"]), src_w[j] / norm, c=c[j], marker=\"d\",\n",
    "                 ls=\"\", mec=\"k\", zorder=6, label=\"src {}\".format(j))\n",
    "        plt.axhline(0, 0, 1, c=\"k\", ls=\"-\")\n",
    "\n",
    "    plt.ylim(-0.15 * np.amax(hist), None)\n",
    "    plt.xlabel(\"sin(dec)\")\n",
    "    plt.title(key)\n",
    "    plt.legend(ncol=len(_inj.srcs) // 5 + 1)\n",
    "\n",
    "    save_plot(os.path.join(\"llh_model\", \"stacking_src_weights\"), key, dpi=100)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#####  :: NEEDS MAINTANANCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sample some data and get soverb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Xbg = bg_inj.sample()\n",
    "Xsig = sig_inj.sample(n_samples=20)\n",
    "X = np.concatenate((Xbg, Xsig))\n",
    "\n",
    "bg_idx = bg_inj._sample_idx[\"src_idx\"]\n",
    "sig_idx = sig_inj._sample_idx[\"src_idx\"]\n",
    "src_idx = np.concatenate((bg_idx, sig_idx))\n",
    "\n",
    "dec_mask = grb_mod._select_X(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show the band selection effect (only dec band selection for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nsig = grb_mod._spatial_opts[\"select_ev_sigma\"]\n",
    "\n",
    "# Scatter all, highlight selected events per src\n",
    "plt.scatter(X[\"ra\"], X[\"dec\"], s=100*np.rad2deg(X[\"sigma\"]), color=\"C7\",\n",
    "            alpha=.5)\n",
    "for j, m in enumerate(dec_mask):\n",
    "    plt.scatter(X[m][\"ra\"], X[m][\"dec\"], s=10*np.rad2deg(X[m][\"sigma\"]),\n",
    "                color=\"C{}\".format(j))\n",
    "    plt.scatter(srcs_rec[j][\"ra\"], srcs_rec[j][\"dec\"], color=\"C{}\".format(j),\n",
    "                marker=\"*\", edgecolor=\"k\", linewidth=1, s=100)\n",
    "plt.xlim(0, 2 * np.pi)\n",
    "plt.ylim(-np.pi / 2, np.pi / 2)\n",
    "plt.xlabel(\"ra\")\n",
    "plt.ylabel(\"dec\")\n",
    "plt.show()\n",
    "\n",
    "# Plot all that made the selection\n",
    "if tw_id < 16:\n",
    "    for j, srci in enumerate(grb_mod.srcs):\n",
    "        # Combining the masks show not all selected, because an injected event\n",
    "        # can of course show up for a different src, especially in BG\n",
    "        # m = (src_idx == j) & dec_mask[j]\n",
    "        # This simply show, if the global dec band selection is working\n",
    "        m = dec_mask[j]\n",
    "        los = X[\"dec\"][m] - nsig * X[m][\"sigma\"]\n",
    "        his = X[\"dec\"][m] + nsig * X[m][\"sigma\"]\n",
    "        for i, (lo, hi) in enumerate(zip(los, his)):\n",
    "            plt.fill_between([lo, hi], [i, i], [i+1, i+1], alpha=.25,\n",
    "                             color=\"C{}\".format(j))\n",
    "            plt.vlines(X[\"dec\"][m][i], i, i+1, color=\"C{}\".format(j),\n",
    "                       linestyles=\"-\")\n",
    "        plt.axvline(srci[\"dec\"], 0, 1, color=\"C{}\".format(j), ls=\"--\",\n",
    "                    label=\"src {}\".format(j))\n",
    "    plt.xlabel(\"dec\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Events that made the selection\")\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping midlle plot with too many events...\")\n",
    "    \n",
    "# And all that didn't (only if there aren't so many events, takes too long)\n",
    "if tw_id < 16:\n",
    "    mask = np.any(dec_mask, axis=0)\n",
    "    los = X[\"dec\"][~mask] - nsig * X[~mask][\"sigma\"]\n",
    "    his = X[\"dec\"][~mask] + nsig * X[~mask][\"sigma\"]\n",
    "    for j, (lo, hi) in enumerate(zip(los, his)):\n",
    "        plt.fill_between([lo, hi], [j, j], [j+1, j+1], alpha=.25, color=\"C3\")\n",
    "        plt.vlines(X[\"dec\"][~mask][j], j, j+1, color=\"C3\")\n",
    "    for j, srci in enumerate(grb_mod.srcs):\n",
    "        plt.axvline(srci[\"dec\"], 0, 1, color=\"C{}\".format(j),\n",
    "                    ls=\"--\", label=\"src {}\".format(j))\n",
    "    plt.xlabel(\"dec\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Events that didn't make the selection\")\n",
    "\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping last plot with too many events...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Here we combine both masks to show selected events, that also belong to a\n",
    "# specific source by the time selection. That's why there might be no events\n",
    "# here, even if they were shown in the plot above.\n",
    "for j in range(len(grb_mod.srcs)):\n",
    "    _bg = Xbg[\"time\"][bg_idx == j]\n",
    "    _sig = Xsig[\"time\"][sig_idx == j] \n",
    "    _src = grb_mod.srcs[j][\"time\"]\n",
    "\n",
    "    trel_bg = (_bg - _src) * SECINDAY\n",
    "    trel_sig = (_sig - _src) * SECINDAY\n",
    "\n",
    "    plt.vlines(trel_bg, 0, 1, color=\"C{}\".format(j), linestyles=\":\")\n",
    "    plt.vlines(trel_sig, 0, 1, color=\"k\", linestyles=\"-\")\n",
    "\n",
    "    plt.axvline(0, 0, 1, ls=\"-\", c=\"C7\")\n",
    "    plt.axvline(srci[\"dt0\"], 0, 1, ls=\"-\", c=\"C7\")\n",
    "    plt.axvline(srci[\"dt1\"], 0, 1, ls=\"-\", c=\"C7\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get sob and scatter non zero sobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sob = grb_mod.get_soverb(X)\n",
    "\n",
    "# Prepare X same as done in get_soverb\n",
    "X_ = X[np.any(dec_mask, axis=0)]\n",
    "\n",
    "for j, sobi in enumerate(sob):\n",
    "    m = (src_idx == j) & dec_mask[j]\n",
    "    plt.scatter(X[m][\"ra\"], X[m][\"dec\"], color=\"C{}\".format(j), alpha=.25)\n",
    "    \n",
    "    m = (sobi > .1)\n",
    "    plt.scatter(X_[m][\"ra\"], X_[m][\"dec\"], color=\"C{}\".format(j), marker=\"d\",\n",
    "                edgecolor=\"k\")\n",
    "    plt.scatter(srcs_rec[j][\"ra\"], srcs_rec[j][\"dec\"], marker=\"*\", color=\"k\")\n",
    "    \n",
    "plt.xlabel(\"ra\")\n",
    "plt.ylabel(\"dec\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For all events, show energy and spatial contribution separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sob = grb_mod.get_soverb(X)\n",
    "\n",
    "# Prepare X same as done in get_soverb\n",
    "X_ = X[np.any(dec_mask, axis=0)]\n",
    "\n",
    "for j, sobi in enumerate(sob):\n",
    "    m = (src_idx == j) & dec_mask[j]\n",
    "    plt.hist(X[m][\"logE\"], bins=20, density=True, color=\"C{}\".format(j))\n",
    "    \n",
    "    m = (sobi > .1)\n",
    "    for logEi in X_[m][\"logE\"]:\n",
    "        plt.axvline(logEi, 0, 1, ls=\"--\", color=\"k\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "sob = grb_mod.get_soverb(X)\n",
    "\n",
    "# Prepare X same as done in get_soverb\n",
    "X_ = X[np.any(dec_mask, axis=0)]\n",
    "\n",
    "soverb_spatial = grb_mod._soverb_spatial(X_[\"ra\"], np.sin(X_[\"dec\"]),\n",
    "                                         X_[\"sigma\"]).sum(axis=0)\n",
    "soverb_energy = grb_mod._soverb_energy(np.sin(X_[\"dec\"]), X_[\"logE\"])\n",
    "   \n",
    "for srci in srcs_rec:\n",
    "    plt.axvline(srci[\"dec\"], 0, 1, ls=\"--\", c=\"k\")\n",
    "\n",
    "    sort_idx = np.argsort(X_[\"dec\"])\n",
    "plt.plot(np.sin(X_[\"dec\"])[sort_idx], soverb_spatial[sort_idx])\n",
    "plt.plot(np.sin(X_[\"dec\"])[sort_idx], soverb_energy[sort_idx])\n",
    "\n",
    "plt.yscale(\"log\", nonposy=\"clip\")\n",
    "plt.ylim(1e-3, None)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show spatial BG splines and allyear data histogram for each source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins = grb_mod._spatial_opts[\"sindec_bins\"]\n",
    "lo, hi = np.amin(bins), np.amax(bins)\n",
    "x = np.linspace(lo, hi, 250)\n",
    "\n",
    "# Normalize allyear data to PDF on a sphere\n",
    "h, b = np.histogram(np.sin(exp_off[\"dec\"]), bins=100, range=[lo, hi],\n",
    "                    density=False)\n",
    "mids = 0.5 * (b[:-1] + b[1:])\n",
    "norm = np.sum(h) * np.diff(b) * 2. * np.pi\n",
    "hn = h / norm\n",
    "errn = np.sqrt(h) / norm\n",
    "\n",
    "# Show data hist\n",
    "plt.plot(b, np.r_[hn[0], hn], color=\"C0\", drawstyle=\"steps-pre\")\n",
    "plt.errorbar(mids, hn, fmt=\",\", color=\"C0\")\n",
    "\n",
    "# Show allyear data spline (normalized to ra, sindec PDF)\n",
    "# Need to steal from the inj, with the same settings, illustration only\n",
    "plt.plot(x, bg_inj._spl_info[\"data_sin_dec_pdf_spline\"](x) / 2. / np.pi,\n",
    "         color=\"k\", ls=\"--\")\n",
    "\n",
    "for j, srci in enumerate(grb_mod.srcs):\n",
    "    spl = grb_mod._spatial_bg_spls[j]\n",
    "    plt.plot(x, spl(x), c=\"C{}\".format((j + 1) % 9),\n",
    "             label=\"src {}\".format(j + 1))\n",
    "    int_ = spl.integral(-1, 1) * 2. * np.pi\n",
    "    plt.title(\"Integral over ra, sindec: {:.2f}\".format(int_))\n",
    "    \n",
    "plt.axvline(lo, 0, 1, ls=\"-\", color=\"C7\")\n",
    "plt.axvline(hi, 0, 1, ls=\"-\", color=\"C7\")\n",
    "plt.ylim(0, None)\n",
    "plt.legend(loc=\"best\", ncol=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Set new time window.\n",
    "Redo the spline plot and check the LLH args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_bg_spline_plot(grb_mod, exp_off, title):\n",
    "    bins = grb_mod._spatial_opts[\"sindec_bins\"]\n",
    "    lo, hi = np.amin(bins), np.amax(bins)\n",
    "    x = np.linspace(lo, hi, 250)\n",
    "\n",
    "    # Normalize allyear data to PDF on a sphere\n",
    "    h, b = np.histogram(np.sin(exp_off[\"dec\"]), bins=100, range=[lo, hi],\n",
    "                        density=False)\n",
    "    mids = 0.5 * (b[:-1] + b[1:])\n",
    "    norm = np.sum(h) * np.diff(b) * 2. * np.pi\n",
    "    hn = h / norm\n",
    "    errn = np.sqrt(h) / norm\n",
    "\n",
    "    # Show data hist\n",
    "    plt.plot(b, np.r_[hn[0], hn], color=\"C7\", drawstyle=\"steps-pre\", alpha=.5)\n",
    "    plt.errorbar(mids, hn, fmt=\",\", color=\"C7\", alpha=.5)\n",
    "\n",
    "    for j, srci in enumerate(grb_mod.srcs):\n",
    "        spl = grb_mod._spatial_bg_spls[j]\n",
    "        plt.plot(x, spl(x), c=\"C{}\".format(j + 1), label=\"src {}\".format(j + 1))\n",
    "        int_ = spl.integral(-1, 1) * 2. * np.pi\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.axvline(lo, 0, 1, ls=\"-\", color=\"C7\")\n",
    "    plt.axvline(hi, 0, 1, ls=\"-\", color=\"C7\")\n",
    "    plt.ylim(0, None)\n",
    "    plt.legend(loc=\"best\", ncol=2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Show old settings\n",
    "print(\"Original settings:\")\n",
    "print(dt0, dt1)\n",
    "print(arr2str(grb_mod.get_args()[\"nb\"], fmt=\"{:.2f}\"))\n",
    "make_bg_spline_plot(grb_mod, exp_off, \"Original: tw = {}\".format(tw_id))\n",
    "\n",
    "# Make new\n",
    "new_tw = 5  # tw5 is approx. tw20 / 1e4 -> Rate should be equally lower\n",
    "new_dt0, new_dt1 = loader.time_window_loader(new_tw)\n",
    "scale = ((new_dt1 - new_dt0) / (dt1 - dt0))[0]\n",
    "grb_mod.set_new_srcs_dt(new_dt0[0], new_dt1[0])\n",
    "print(\"New settings:\")\n",
    "print(\"Rate scale factor: {:.2g}\".format(scale))\n",
    "print(grb_mod.srcs[\"dt0\"])\n",
    "print(grb_mod.srcs[\"dt1\"])\n",
    "print(grb_mod.get_args()[\"nb\"])\n",
    "print(\"Scaled up rates: {}\".format(\n",
    "    arr2str(grb_mod.get_args()[\"nb\"] / scale, fmt=\"{:.2f}\")))\n",
    "make_bg_spline_plot(grb_mod, exp_off, \"New: tw = {}\".format(new_tw))\n",
    "\n",
    "# Make really large windows to see the effect on the splines\n",
    "new_dt0, new_dt1 = 100 * dt0, 100 * dt1\n",
    "scale = ((new_dt1 - new_dt0) / (dt1 - dt0))[0]\n",
    "grb_mod.set_new_srcs_dt(new_dt0[0], new_dt1[0])\n",
    "print(\"New settings:\")\n",
    "print(\"Rate scale factor: {:.2g}\".format(scale))\n",
    "print(grb_mod.srcs[\"dt0\"])\n",
    "print(grb_mod.srcs[\"dt1\"])\n",
    "print(grb_mod.get_args()[\"nb\"])\n",
    "make_bg_spline_plot(grb_mod, exp_off, \"New: dt = {}s\".format(2 * new_dt1[0]))\n",
    "\n",
    "# Reset\n",
    "_dt0, _dt1 = loader.time_window_loader(tw_id)\n",
    "grb_mod.set_new_srcs_dt(_dt0[0], dt1[0])\n",
    "make_bg_spline_plot(grb_mod, exp_off, \"Reset: tw = {}\".format(tw_id))\n",
    "print(\"Reset settings:\")\n",
    "print(grb_mod.srcs[\"dt0\"])\n",
    "print(grb_mod.srcs[\"dt1\"])\n",
    "print(arr2str(grb_mod.get_args()[\"nb\"], fmt=\"{:.2f}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## LLH evaluation, test wrong injection mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make trial data and scan the LLH.\n",
    "Then overestimate n_B and rescan to see the effect.\n",
    "Becuase of the rate function the detector downtime is interpolated over.\n",
    "Thhis leads to overestimated livetime and overestimated background expectation.\n",
    "The injectors suffer the sam eproblem, becuase they inject without regarding the downtimes (uniformly in comlete time window).\n",
    "The trials themsleves are therefore self-consitent but a fit on data would be worse than needed.\n",
    "\n",
    "This tries to estimate the scale of which this affects this analysis.\n",
    "The effective livetime loss is approx. 10% for data compared to trials.\n",
    "So 10% of the data is randomly thrown away after trial generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make a BG trial data set and inject some signal\n",
    "def _concat(X, Xsig):\n",
    "    return dict_map(lambda k, Xi: np.concatenate((Xi, Xsig[k])), X)\n",
    "\n",
    "def _choice(X, eff):\n",
    "    return dict_map(lambda k, Xi: np.random.choice(Xi, replace=False,\n",
    "                                                   size=int(eff * len(Xi))), X)\n",
    "\n",
    "def _drop(X, eff):\n",
    "    return dict_map(lambda k, Xi: Xi[:int(eff * len(Xi))], X)\n",
    "\n",
    "n_sig = 0\n",
    "efficiencies = [0.8, 0.9, 0.95, 1.0]\n",
    "ns_scan = np.linspace(0, 10, 50)\n",
    "\n",
    "X = multi_bg_inj.sample()\n",
    "if n_sig > 0:\n",
    "    Xsig = multi_sig_inj.sample(n_sig)\n",
    "    X = _concat(X, Xsig)\n",
    "map(np.random.shuffle, X.values())\n",
    "\n",
    "ts = np.empty((len(efficiencies), len(ns_scan)), dtype=float)\n",
    "for j, eff in enumerate(efficiencies):\n",
    "    X_use = _drop(X, eff)\n",
    "    for i, nsi in enumerate(ns_scan):\n",
    "        ts[j, i], _ = multi_llh.lnllh_ratio(ns=nsi, X=X_use)\n",
    "        \n",
    "\n",
    "# Plot it\n",
    "for j, eff in enumerate(efficiencies):\n",
    "    plt.plot(ns_scan, ts[j], c=\"C{}\".format(j),\n",
    "             label=r\"$\\epsilon={:.2f}$\".format(eff))\n",
    "    plt.axvline(n_sig, 0, 1, ls=\"--\", c=\"k\")\n",
    "    plt.axvline(ns_scan[np.argmax(ts[j])], 0, 1, ls=\"-\", c=\"k\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now fit a few trials and see the TS changes.\n",
    "It should shift to smaller TS values for less efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _do_comp_trials(ntrials=int(1e5))\n",
    "    def _drop(X, eff):\n",
    "        # Not completely realistic but easiest to simulate data loss\n",
    "        return dict_map(lambda k, Xi: Xi[:int(eff * len(Xi))], X)\n",
    "    \n",
    "    efficiencies = [0.8, 0.9, 0.95, 1.0]\n",
    "    ts = np.empty((len(efficiencies), ntrials), dtype=float)\n",
    "\n",
    "    for i in range(ntrials):\n",
    "        X = multi_bg_inj.sample()\n",
    "        map(np.random.shuffle, X.values())\n",
    "        for j, eff in enumerate(efficiencies):\n",
    "            X_use = _drop(X, eff)\n",
    "            _, ts[j, i] = multi_llh.fit_lnllh_ratio(ns0=0.1, X=X_use)\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(\"Trial {}\".format(i))\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_path = os.path.join(PATHS.plots, \"misc\", \"ts_test_nb_var.npy\")\n",
    "try:\n",
    "    ts = np.load(_path)\n",
    "except:\n",
    "    try:\n",
    "        np.save(arr=ts, file=_path)\n",
    "    except:\n",
    "        print(\"No trials found to save or to load, generating new ones.\")\n",
    "        ts = _do_comp_trials()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bins = np.arange(0, np.amax(ts), 0.5)\n",
    "perc_ls = [\":\", \"--\", \"-\"]\n",
    "perc_a = [0.7, 0.8, 0.9]\n",
    "sigmas = [2, 3, 4]\n",
    "test_percs = 100 * sigma2prob(sigmas)\n",
    "percentiles = []\n",
    "\n",
    "for j, eff in enumerate(efficiencies):\n",
    "    c = \"C{}\".format(j)\n",
    "    plt.hist(ts[j], color=c, lw=1.5, bins=bins, density=True,\n",
    "             label=r\"$\\epsilon={:.2f}$\".format(eff), histtype=\"step\")\n",
    "    percentiles.append(np.percentile(ts[j], test_percs))\n",
    "    for i, perc in enumerate(percentiles[-1]):\n",
    "        if j == len(efficiencies) - 1:\n",
    "            label = r\"${:1d}\\sigma$\".format(sigmas[i])\n",
    "        else:\n",
    "            label = None\n",
    "        plt.axvline(perc,0, 1, ls=perc_ls[i], alpha=perc_a[i], c=c, label=label)\n",
    "\n",
    "plt.xlabel(\"test statistic\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.title(\"TS for largest time window for various data dropout efficiencies\")\n",
    "plt.xlim(bins[0], None)\n",
    "plt.yscale(\"log\")\n",
    "plt.legend(ncol=2)\n",
    "plt.tight_layout()\n",
    "save_plot(\"misc\", \"data_dropout_tw_{:02d}.png\".format(tw_id))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Ratios of the 3sigma lines behave exactly as the efficiency ratios. Why?\n",
    "percentiles = np.array(percentiles)\n",
    "percentiles_normalized = percentiles / percentiles[-1]\n",
    "percentiles_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### :: NEEDS MAINTANANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "Xbg = bg_inj.sample()\n",
    "nsig = 1\n",
    "Xsig = sig_inj.sample(n_samples=nsig)\n",
    "X = np.concatenate((Xbg, Xsig))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Sample some data and get the LLH values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "llh_args = llh.model.get_args()\n",
    "for key, val in llh_args.items():\n",
    "    print(\"{:11s}: {}\".format(key, arr2str(val, fmt=\"{:5.2f}\")))\n",
    "    \n",
    "print(\"Weights are normed: \", np.isclose(\n",
    "    np.sum(llh._src_w_over_nb * llh_args[\"nb\"][:, None]), 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make a quick LLH scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ts, grad = [], []\n",
    "ns = np.linspace(0, max(5, 5 * nsig), 500)\n",
    "for nsi in ns:\n",
    "    tsi, gradi = llh.lnllh_ratio(ns=nsi, X=X)\n",
    "    ts.append(tsi)\n",
    "    grad.append(gradi)\n",
    "    \n",
    "plt.plot(ns, ts, label=\"TS\", color=\"C0\")\n",
    "plt.plot(ns, grad, label=\"grad\", color=\"C3\")\n",
    "plt.plot(0.5 * (ns[:-1] + ns[1:]), np.diff(ts) / np.diff(ns), ls=\":\",\n",
    "         color=\"k\", label=\"numgrad\")\n",
    "\n",
    "plt.axhline(0, 0, 1, ls=\"-\", c=\"C7\")\n",
    "plt.axvline(0, 0, 1, ls=\"-\", c=\"C7\")\n",
    "plt.axvline(nsig, 0, 1, ls=\"-.\", c=\"C2\", label=\"n signal\")\n",
    "\n",
    "plt.xlabel(\"ns\")\n",
    "plt.ylabel(\"ts\")\n",
    "plt.legend()\n",
    "\n",
    "plt.ylim(min(-4, -2. * np.amax(ts)), max(1., 2. * np.amax(ts)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Test if band selection in model effectively doesn't change the LLH values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_nsig = 5\n",
    "ntrials = 100\n",
    "\n",
    "# Set additional sob cuts in the LLH\n",
    "_rel, _abs = 0., 0.\n",
    "llh._llh_opts[\"sob_abs_eps\"] = _abs\n",
    "llh._llh_opts[\"sob_rel_eps\"] = _rel\n",
    "\n",
    "ts_all = np.empty(ntrials, dtype=float)\n",
    "ts_sel = np.empty(ntrials, dtype=float)\n",
    "ts_all_fit = np.empty(ntrials, dtype=float)\n",
    "ts_sel_fit = np.empty(ntrials, dtype=float)\n",
    "ns_all_fit = np.empty(ntrials, dtype=float)\n",
    "ns_sel_fit = np.empty(ntrials, dtype=float)\n",
    "\n",
    "for i in range(ntrials):\n",
    "    # Make a new set of data\n",
    "    _Xbg = bg_inj.sample()\n",
    "    _Xsig = sig_inj.sample(n_samples=_nsig)\n",
    "    _X = np.concatenate((_Xbg, _Xsig))\n",
    "    \n",
    "    # First using all events\n",
    "    ts_all[i], _ = llh.lnllh_ratio(ns=_nsig, X=_X, band_select=False)\n",
    "    ns_all_fit[i], ts_all_fit[i] = llh.fit_lnllh_ratio(ns0=_nsig, X=_X,\n",
    "                                                       band_select=False)\n",
    "    \n",
    "    # Now same data with band selection\n",
    "    ts_sel[i], _ = llh.lnllh_ratio(ns=_nsig, X=_X, band_select=True)\n",
    "    ns_sel_fit[i], ts_sel_fit[i] = llh.fit_lnllh_ratio(ns0=_nsig, X=_X,\n",
    "                                                       band_select=False)\n",
    "    \n",
    "\n",
    "_, (axl, axr) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "# Show difference in fixed ns evaluation\n",
    "diff_fixed = ts_all - ts_sel\n",
    "axl.plot(diff_fixed)\n",
    "axl.set_title(\"sob cuts: abs = {:.3g}, rel = {:.3g}.\".format(_abs, _rel))\n",
    "axl.set_yscale(\"log\", nonposy=\"clip\")\n",
    "axl.set_ylabel(\"diff\")\n",
    "\n",
    "# Show difference but with fitted ns each time\n",
    "diff_fitted = ts_all_fit - ts_sel_fit\n",
    "axr.plot(diff_fitted)\n",
    "axr.set_title(\"All fitted diffs zero: {}\".format(np.allclose(\n",
    "    diff_fitted, 0.)))\n",
    "axr.set_ylabel(\"diff\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Show fitted values, where fixed eval had differences\n",
    "m = (diff_fitted > 0.)\n",
    "print(arr2str(ns_all_fit[m], fmt=\"{:6.5f}\"))\n",
    "print(arr2str(ts_all_fit[m], fmt=\"{:6.5f}\"))\n",
    "print(arr2str(ns_sel_fit[m], fmt=\"{:6.5f}\"))\n",
    "print(arr2str(ts_sel_fit[m], fmt=\"{:6.5f}\"))\n",
    "\n",
    "# Reset model\n",
    "for name in [\"sob_abs_eps\", \"sob_rel_eps\"]:\n",
    "    llh._llh_opts[name] = llh_opts[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Do the same, but when a diff occurs, scan the LLH\n",
    "def scan_llh(llh, X, nsig):\n",
    "    ns = np.linspace(0, max(5, 5 * nsig), 500)\n",
    "    ts_all, ts_sel = np.empty(500), np.empty(500)\n",
    "    for i, nsi in enumerate(ns):\n",
    "        ts_all[i], _ = llh.lnllh_ratio(ns=nsi, X=X, band_select=False)\n",
    "        ts_sel[i], _ = llh.lnllh_ratio(ns=nsi, X=X, band_select=True)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    gs = gridspec.GridSpec(2, 1, height_ratios=[4, 1])\n",
    "    axb = fig.add_subplot(gs[1])\n",
    "    axt = fig.add_subplot(gs[0])\n",
    "    _ = axt.set_xticklabels(axt.get_xticklabels(), visible=False)\n",
    "        \n",
    "    axt.plot(ns, ts_all, label=\"All\", color=\"C3\")\n",
    "    axt.plot(ns, ts_sel, label=\"Sel\", color=\"k\", ls=\":\")\n",
    "    axb.plot(ns, ts_all - ts_sel, label=\"Diff\", color=\"C7\", ls=\"-\")\n",
    "\n",
    "    axt.axhline(0, 0, 1, ls=\"-\", c=\"C7\")\n",
    "    axt.axvline(0, 0, 1, ls=\"-\", c=\"C7\")\n",
    "    axt.axvline(nsig, 0, 1, ls=\"-.\", c=\"C2\", label=\"n signal\")\n",
    "\n",
    "    axb.set_xlabel(\"ns\")\n",
    "    axb.set_ylabel(\"diff\")\n",
    "    axt.set_ylabel(\"ts\")\n",
    "    axt.legend(loc=\"best\")\n",
    "    axt.set_title(\"sob cuts: abs = {:.3g}, rel = {:.3g}.\".format(_abs, _rel))\n",
    "    axt.set_ylim(min(-4, -2. * np.amax(ts_all)),\n",
    "                 max(1., 2. * np.amax(ts_all)))\n",
    "    plt.show()\n",
    "\n",
    "_nsig = 5\n",
    "ntrials_max = 1000\n",
    "\n",
    "# Set additional sob cuts in the LLH\n",
    "_rel, _abs = 0., 0.\n",
    "llh._llh_opts[\"sob_abs_eps\"] = _abs\n",
    "llh._llh_opts[\"sob_rel_eps\"] = _rel\n",
    "\n",
    "# Change selection sigma, for small values the difference is large, as expected\n",
    "llh.model._spatial_opts[\"select_ev_sigma\"] = 5\n",
    "\n",
    "# Do trials but show at most 3 scan plots\n",
    "i = 0\n",
    "nscans, nscans_max = 0, 5\n",
    "while nscans < nscans_max and i < ntrials_max:\n",
    "    # Make a new set of data\n",
    "    _Xbg = bg_inj.sample()\n",
    "    _Xsig = sig_inj.sample(n_samples=_nsig)\n",
    "    _X = np.concatenate((_Xbg, _Xsig))\n",
    "    \n",
    "    # First using all events\n",
    "    ts_all, grad_all = llh.lnllh_ratio(ns=_nsig, X=_X, band_select=False)\n",
    "    \n",
    "    # Now same data with band selection\n",
    "    ts_sel, grad_sel = llh.lnllh_ratio(ns=_nsig, X=_X, band_select=True)\n",
    "\n",
    "    if ts_all - ts_sel != 0.:\n",
    "        print(\"Scanning LLH for trial {:d}\".format(i))\n",
    "        # Plot scan for current X once with band select, once without\n",
    "        scan_llh(llh, _X, _nsig)\n",
    "        nscans += 1\n",
    "\n",
    "    i += 1\n",
    "    \n",
    "print(\"Done after {} trials\".format(i))\n",
    "\n",
    "# Reset model and LLH\n",
    "for name in [\"sob_abs_eps\", \"sob_rel_eps\"]:\n",
    "    llh._llh_opts[name] = llh_opts[name]\n",
    "    \n",
    "llh.model._spatial_opts[\"select_ev_sigma\"] = mod_spatial_opts[\"select_ev_sigma\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## BG trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Timing tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Timing tests: For 6 year pass2 HESE, 5 years PS tracks data, 1 year GFU\n",
    "\n",
    "- tw00: 1e8 trials in 11h 19min 6s -> ~2455 trials / sec\n",
    "- tw10: 1e5 trials in ~193s -> ~ 518 trials / sec\n",
    "- tw20: 1e4 trials in ~430s -> ~  23 trials / sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(\"Time window ID is: {}\".format(tw_id))\n",
    "n_trials = int(1e8)\n",
    "n_signal = 0\n",
    "trials, nzeros, nsig = ana.do_trials(n_trials=n_trials, ns0=0.1, full_out=False)\n",
    "\n",
    "ns, ts = trials[\"ns\"], trials[\"ts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "out = {\n",
    "    \"ns\": trials[\"ns\"].tolist(),\n",
    "    \"ts\": trials[\"ts\"].tolist(),\n",
    "    \"time_window\": [dt0, dt1],\n",
    "    \"time_window_id\": tw_id,\n",
    "    \"nzeros\": nzeros,\n",
    "    \"rnd_seed\": [42439462],\n",
    "    \"ntrials\": n_trials,\n",
    "    \"ntrials_per_batch\": [n_trials],\n",
    "    }\n",
    "outpath = \"/Users/tmenne/Downloads/\"\n",
    "fpath = os.path.join(outpath, \"tw_{:02d}.json.gz\".format(tw_id))\n",
    "with gzip.open(fpath, \"w\") as outf:\n",
    "    json.dump(out, fp=outf, indent=2)\n",
    "    print(\"- Saved to:\\n    {}\".format(fpath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Try stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Create empirical PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "_tw = 20\n",
    "fpath = os.path.join(PATHS.data, \"bg_trials_combined\",\n",
    "                     \"tw_{:02d}.json.gz\".format(_tw))\n",
    "with gzip.open(fpath) as inf:\n",
    "    trials = json.load(inf)\n",
    "    print(\"- Loaded:\\n    {}\".format(fpath))\n",
    "    \n",
    "nzeros = trials[\"nzeros\"]\n",
    "ntrials = trials[\"ntrials\"]\n",
    "trials[\"ts\"] = np.array(trials[\"ts\"])\n",
    "trials[\"ns\"] = np.array(trials[\"ns\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Scan thresholds to select a good one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Scan it\n",
    "emp_dist = stats.ExpTailEmpiricalDist(trials[\"ts\"], trials[\"nzeros\"],\n",
    "                                      thresh=np.amax(trials[\"ts\"]))\n",
    "pval_thresh = 0.5\n",
    "lo, hi = emp_dist.ppf(q=100. * stats.sigma2prob([3., 5.5]))\n",
    "thresh_vals = np.arange(lo, hi, 0.1)\n",
    "best_thresh, best_idx, pvals, scales = stats.scan_best_thresh(\n",
    "    emp_dist, thresh_vals, pval_thresh=pval_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save it in float16\n",
    "fname = \"/Users/tmenne/Downloads/bg_pdf_tw_{:02d}.json.gz\".format(_tw)\n",
    "with gzip.open(fname, \"w\") as f:\n",
    "    emp_dist.to_json(fp=f, dtype=np.float16, indent=1, separators=(\",\",\":\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot ts and ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_bg_pdf_scan_plots(fname, emp_dist, thresh_vals, pvals, scales,\n",
    "                           pval_thresh):\n",
    "    def _plot_sigma_lines(ax, sigmas):\n",
    "        sigmas = np.sort(sigmas)\n",
    "        q = 100. * np.atleast_1d(stats.sigma2prob(sigmas))\n",
    "        _p = stats.percentile_nzeros(emp_dist.data, emp_dist.nzeros,\n",
    "                                     q=q, sorted=True)\n",
    "        for i, pi in enumerate(_p):\n",
    "            ax.axvline(pi, 0, 1, ls=\"--\", c=\"C7\",\n",
    "                       alpha=sigmas[i] / np.amax(sigmas),\n",
    "                       label=r\"{:.1f}$\\sigma$\".format(sigmas[i]))\n",
    "\n",
    "    fig, (axl, axc, axr) = plt.subplots(1, 3, figsize=(17.5, 5))\n",
    "\n",
    "    # ## Left: Plot the selected combined PDF ##\n",
    "    # Plot empirical PDF part\n",
    "    h, b, err, _ = emp_dist.data_hist(dx=.25, density=True, which=\"emp\")\n",
    "    axl.plot(b, np.r_[h[0], h], drawstyle=\"steps-pre\", color=\"k\")\n",
    "    mids = 0.5 * (b[:-1] + b[1:])\n",
    "    axl.errorbar(mids, h, yerr=err, fmt=\",\", color=\"k\")\n",
    "    # Plot exponential data part\n",
    "    h, b, err, _ = emp_dist.data_hist(dx=.25, density=True, which=\"exp\")\n",
    "    axl.plot(b, np.r_[h[0], h], drawstyle=\"steps-pre\", color=\"C7\")\n",
    "    mids = 0.5 * (b[:-1] + b[1:])\n",
    "    axl.errorbar(mids, h, yerr=err, fmt=\",\", color=\"C7\")\n",
    "    # Plot the exponetial PDF part\n",
    "    x = np.linspace(emp_dist.thresh, np.amax(emp_dist.data), 100)\n",
    "    axl.plot(x, emp_dist.pdf(x), color=\"C3\",\n",
    "             label=(\"exp tail\\n\" +\n",
    "                    r\"$\\lambda$={:.2f}\".format(1. / emp_dist.scale)))\n",
    "    axl.axvline(emp_dist.thresh, 0, 1, ls=\":\", color=\"C3\")\n",
    "    _plot_sigma_lines(axl, [3., 4., 5., 5.5])\n",
    "    axl.set_yscale(\"log\", nonposy=\"clip\")\n",
    "    axl.set_xlabel(\"ts\")\n",
    "    axl.set_title(\"Test Statitics\")\n",
    "    axl.legend()\n",
    "\n",
    "    # ## Center: Plot the selected combined p-values ##\n",
    "    x = np.linspace(0, np.amax(emp_dist.data), 500)\n",
    "    cdf_emp = 1. - stats.cdf_nzeros(emp_dist.data, emp_dist.nzeros, vals=x,\n",
    "                                    sorted=True)\n",
    "    cdf_dist = emp_dist.sf(x)\n",
    "    axc.plot(x, cdf_emp, color=\"k\")\n",
    "    axc.plot(x, cdf_dist, color=\"C3\")\n",
    "    axc.axvline(emp_dist.thresh, 0, 1, ls=\":\", color=\"C3\", label=\"threshold\")\n",
    "    _plot_sigma_lines(axc, [3., 4., 5., 5.5])\n",
    "    axc.set_yscale(\"log\", nonposy=\"clip\")\n",
    "    axc.set_xlabel(\"ts\")\n",
    "    axc.set_title(\"p-values\")\n",
    "    axc.legend()\n",
    "\n",
    "    # ## Right: Threshold scan\n",
    "    _plot_sigma_lines(axr, [3., 4., 5., 5.5])\n",
    "    axr.axhline(1, 0, 1, ls=\"--\", c=\"C7\")\n",
    "    axr.axhline(pval_thresh, 0, 1, ls=\"-\", c=\"C7\")      # Rejection line\n",
    "    axr.axvline(emp_dist.thresh, 0, 1, ls=\"-\", c=\"k\")   # Best thresh\n",
    "    axr.plot(thresh_vals, pvals, c=\"C1\", label=\"KS pval\")\n",
    "    axr.plot(thresh_vals, 1. / scales, c=\"C2\", label=\"lambdas\")\n",
    "    axr.set_xlabel(\"ts\")\n",
    "    axr.set_title(\"Best thresh: {:.2f}\".format(emp_dist.thresh))\n",
    "    axr.legend()\n",
    "    \n",
    "    for axi in [axl, axc, axr]:\n",
    "        axi.set_xlim(0, 40)\n",
    "\n",
    "    fig.tight_layout()\n",
    "#     plt.savefig(fname, dpi=200, bbox_inches=\"tight\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "make_bg_pdf_scan_plots(\"/Users/tmenne/Downloads/tw_{}.png\".format(_tw),\n",
    "                       emp_dist, thresh_vals, pvals, scales, pval_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot the ns distribution\n",
    "ns = trials[\"ns\"]\n",
    "dx = 0.5\n",
    "bins = np.arange(0, max(1, np.amax(ns)) + dx, dx)\n",
    "mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "h, _ = np.histogram(ns, bins=bins, density=False)\n",
    "h[0] += trials[\"nzeros\"]\n",
    "norm = np.diff(bins) * np.sum(h)\n",
    "err = np.sqrt(h) / norm\n",
    "h = h / norm\n",
    "\n",
    "plt.plot(bins, np.r_[h[0], h], drawstyle=\"steps-pre\", color=\"k\")\n",
    "plt.errorbar(mids, h, yerr=err, fmt=\",\", color=\"k\")\n",
    "    \n",
    "plt.yscale(\"log\", nonposy=\"clip\")\n",
    "plt.xlabel(\"ns\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Make some CDF, SF and PPF verification plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "emp_dist = stats.emp_with_exp_tail_dist(trials[\"ts\"], trials[\"nzeros\"],\n",
    "                                        thresh=best_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 30, 500)\n",
    "y = emp_dist.pdf(x, dx=0.25)\n",
    "\n",
    "h, b, _, _ = emp_dist.data_hist(dx=0.25, density=True, which=\"exp\")\n",
    "plt.plot(b, np.r_[h[0], h], drawstyle=\"steps-pre\", c=\"C7\", alpha=.75)\n",
    "\n",
    "plt.plot(x, y, c=\"k\")\n",
    "\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 30, 500)\n",
    "y = emp_dist.cdf(x)\n",
    "plt.plot(x, y, c=\"k\", label=\"fitted CDF\")\n",
    "\n",
    "plt.xlabel(\"test statistic\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.ylim(1. - len(emp_dist.data) / emp_dist.nzeros, 1)\n",
    "plt.ylim(0.9998, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 30, 500)\n",
    "y = emp_dist.sf(x)\n",
    "plt.plot(x, y, c=\"k\", label=\"fitted SF\")\n",
    "\n",
    "y2 = 1. - stats.cdf_nzeros(emp_dist.data, emp_dist.nzeros, vals=x, sorted=True)\n",
    "plt.plot(x, y2, c=\"C3\", ls=\"--\", label=\"empiric SF\")\n",
    "\n",
    "plt.xlabel(\"test statistic\")\n",
    "plt.ylabel(\"p-value\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "q = np.linspace(sigma2prob(4), sigma2prob(6), 500)\n",
    "y = emp_dist.ppf(q * 100.)\n",
    "plt.plot(q, y, c=\"k\", label=\"fitted CDF\")\n",
    "\n",
    "plt.xlabel(\"percentile\")\n",
    "plt.ylabel(\"PPF\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Integrate PDF and compare in tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def exp_pdf_integral(exp_pars, bins):\n",
    "    loc, scale = exp_pars\n",
    "    lam = 1. / scale\n",
    "    lo, hi = np.vstack([bins[:-1], bins[1:]])\n",
    "    return np.exp(lam * loc) * (np.exp(-lam * lo) - np.exp(-lam * hi))\n",
    "\n",
    "# Plot data hist\n",
    "dx = 0.25\n",
    "h, b, err, exp_norm = emp_dist.data_hist(dx, density=True, which=\"exp\")\n",
    "plt.plot(bins, np.r_[h_n[0], h_n], drawstyle=\"steps-pre\", color=\"C7\")\n",
    "mids = 0.5 * (b[:-1] + b[1:])\n",
    "plt.errorbar(mids, h, yerr=err, fmt=\",\", color=\"C7\")\n",
    "\n",
    "# Plot binned exponential tail\n",
    "pdf_binned = exp_norm * exp_pdf_integral(\n",
    "    (emp_dist.thresh, emp_dist.scale), b) / np.diff(b)\n",
    "plt.plot(b, np.r_[pdf_binned[0], pdf_binned],\n",
    "         drawstyle=\"steps-pre\", color=\"C3\")\n",
    "\n",
    "plt.xlabel(\"ts\")\n",
    "plt.xlim(emp_dist.thresh, None)\n",
    "plt.ylim(10**np.floor(np.log10(np.amin(pdf_binned))),\n",
    "         10**np.ceil(np.log10(np.amax(pdf_binned))))\n",
    "plt.yscale(\"log\", nonposy=\"clip\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Compare PDFs to independent trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We made a second set of independent trials for all time windows.\n",
    "We can compare the built PDFs with the new trials and see if the model was chosen OK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _load_lido_bg_pdfs(tw_id):\n",
    "    path = os.path.join(PATHS.local, \"bg_pdfs_lido\",\n",
    "                        \"bg_pdf_tw_{:02d}.json.gz\".format(tw_id))\n",
    "    with gzip.open(path) as json_file:\n",
    "        emp_dist = stats.ExpTailEmpiricalDist.from_json(json_file)\n",
    "        \n",
    "    return emp_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "all_ids = loader.time_window_loader()\n",
    "pvals = []\n",
    "\n",
    "dists = []\n",
    "dists_lido = []\n",
    "\n",
    "# From thesis plot notebook, yields way different results...\n",
    "locs = np.array([\n",
    "    14.5       , 16.6       , 15.1       , 15.        , 13.3       ,\n",
    "    12.5       , 12.89228516, 11.13515625, 10.7671875 , 14.203125  ,\n",
    "    13.978125  , 13.0890625 , 13.68203125, 11.38203125, 12.39375   ,\n",
    "    14.3203125 , 13.334375  , 16.6546875 , 11.1078125 , 15.99375   ,\n",
    "    15.934375  ])\n",
    "scales = np.array([\n",
    "    2.10419922, 1.51894531, 1.66953125, 1.75709416, 1.77044558,\n",
    "    1.71113281, 1.69013672, 1.74374709, 1.81924085, 2.0333777 ,\n",
    "    2.17947035, 2.25782082, 2.30058594, 2.23476563, 2.159459  ,\n",
    "    2.06757813, 2.03869447, 1.95997323, 2.01669922, 2.07603079,\n",
    "    2.11612734])\n",
    "\n",
    "for _tw in all_ids:\n",
    "    print(\"Testing tw {}\".format(_tw))\n",
    "    emp_dist = loader.bg_pdf_loader(_tw)[_tw]\n",
    "    emp_dist_lido = _load_lido_bg_pdfs(_tw)\n",
    "    \n",
    "    # Get best fit loc, scale from original trials\n",
    "#     loc, scale = emp_dist.thresh, emp_dist.scale\n",
    "    loc, scale = locs[_tw], scales[_tw]\n",
    "    emp_dist.fit_thresh(loc)\n",
    "    # Get the lido trial data for the KS test in the exp tail region\n",
    "    emp_dist_lido.fit_thresh(loc)\n",
    "    lido_over_thresh_data, _ = emp_dist_lido.get_split_data(emp=False)\n",
    "    \n",
    "    pvals.append(scs.kstest(lido_over_thresh_data, \"expon\",\n",
    "                            args=(loc, scale)).pvalue)\n",
    "    dists.append(emp_dist)\n",
    "    dists_lido.append(emp_dist_lido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Plot KS pvalue vs. time window. No outliers seen, fit is stable.\n",
    "# Only a bit fewer than 2/3 within 1sig and 19/20 within 2sig\n",
    "ls = [\"-\", \"-.\", \"--\"]\n",
    "for i, sigi in enumerate(sigma2prob([1, 2, 3])):\n",
    "    plt.axhline(1. - sigi, 0, 1, ls=ls[i], c=\"C7\",\n",
    "                label=r\"${:.0f}\\sigma$\".format(i + 1))\n",
    "\n",
    "plt.plot(all_ids + 1, pvals, color=\"#353132\", ls=\"\", marker=\"o\")\n",
    "\n",
    "plt.xticks(all_ids[::2] + 1)\n",
    "plt.yscale(\"log\")\n",
    "\n",
    "plt.xlabel(\"Time window ID\")\n",
    "plt.ylabel(\"KS test p-value\")\n",
    "plt.xlim(all_ids[0] + 0.5, all_ids[-1] + 1.5)\n",
    "plt.ylim(1e-4, 1)\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "save_fig(plt.gcf(),\n",
    "         os.path.join(PATHS.plots, \"bg_trials\", \"ks_test_lido_trials\",\n",
    "                      \"pvalues.pdf\"), bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i, ed in enumerate(dists):\n",
    "    x = np.linspace(0, ed.data.max(), 500)\n",
    "    y = ed.pdf(x, dx=0.25)\n",
    "    h, b, err, norm = dists_lido[i].data_hist(\n",
    "        dx=0.25, which=\"exp\", density=True)\n",
    "    mids = 0.5 * (b[:-1] + b[1:])\n",
    "\n",
    "    # Truncated for PDF/PGF\n",
    "    mask = (h > 0)\n",
    "    ymin = 10**(np.floor(np.log10(np.amin(h[mask]))))\n",
    "    h[~mask] = ymin / 10.\n",
    "    \n",
    "    plt.axvline(ed.thresh, 0, 1, ls=\"--\", c=\"#353132\")\n",
    "    plt.plot(b, np.r_[h[0], h], c=\"0.6\", drawstyle=\"steps-pre\",\n",
    "             label=\"2nd batch of trials\")\n",
    "    plt.errorbar(mids, h, yerr=err, c=\"0.6\", fmt=\",\", zorder=-10)\n",
    "    plt.plot(x, y, c=\"#353132\", label=\"Orig. emp. PDF\")\n",
    "\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlim(0, b[-1] + np.diff(b)[-1] / 2.)\n",
    "    plt.ylim(ymin, 10)\n",
    "    \n",
    "    plt.xlabel(r\"Test statistic $-2\\ln\\Lambda$\")\n",
    "    plt.ylabel(\"PDF\")\n",
    "    plt.title(\"Time window {}\".format(i + 1))\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    save_fig(\n",
    "        plt.gcf(),\n",
    "        os.path.join(PATHS.plots, \"bg_trials\", \"ks_test_lido_trials\",\n",
    "                     \"dist_compare\", \"tw_{:02d}.pdf\".format(i)),\n",
    "        bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Post Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "fname = os.path.join(PATHS.local, \"post_trials_combined\", \"post_trials.json.gz\")\n",
    "with gzip.open(fname) as infile:\n",
    "    post_trials = json.load(infile)\n",
    "    post_trials[\"ts\"] = np.array(post_trials[\"ts\"])\n",
    "    post_trials[\"ns\"] = np.array(post_trials[\"ns\"])\n",
    "    print(\"Loaded post trials from:\\n  {}\".format(fname))\n",
    "        \n",
    "ts = post_trials[\"ts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show TS values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# TS values per time window\n",
    "for i, tsi in enumerate(ts.T):\n",
    "    plt.plot(tsi + 2 * i, zorder=-i)\n",
    "plt.show()\n",
    "\n",
    "# Show histogram of each time window, should be similar to other BG trials\n",
    "bins = np.arange(0, np.amax(ts), 0.25)\n",
    "for i in range(len(ts.T)):\n",
    "    plt.hist(ts.T[i], bins=bins, density=True, alpha=0.1)\n",
    "    plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now load the BG only test statistic PDFs and pick the highest p-value per trial to build the post trial distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "bg_pdfs = loader.bg_pdf_loader(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Calculate all p-values from the BG only test statistics\n",
    "pvals = np.ones_like(ts)\n",
    "for i, bg_pdf in bg_pdfs.items():\n",
    "    pvals[:, i] = bg_pdf.sf(ts[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create an empirical PDF object for the post trial PDF\n",
    "post_pvals = np.amin(pvals, axis=1)\n",
    "neglogpvals = -np.log10(post_pvals)\n",
    "post_neglog10_pdf = stats.PureEmpiricalDist(neglogpvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(\"./data/post_neglog10_pdf.json\", \"w\") as fp:\n",
    "    out = post_neglog10_pdf.to_json(indent=1)\n",
    "    fp.write(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot the -log10(p-val) test statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_LOG = True\n",
    "# Distribution of best p-val per trial (p=1. excluded)\n",
    "bins = np.arange(0, int(np.amax(neglogpvals)) + 1, 0.1)\n",
    "mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "sigmas = [1, 2, 3, 4]\n",
    "ls = [\":\", \"--\", \"-.\", \"-\"]\n",
    "\n",
    "# Make hist and sqrt(N) errs\n",
    "h, _ = np.histogram(neglogpvals, bins=bins, density=False)\n",
    "err = np.sqrt(h)\n",
    "norm = np.sum(h) * np.diff(bins)\n",
    "h_n = h / norm\n",
    "err_n = err / norm\n",
    "\n",
    "# \"Broken\" axis for the zero entries\n",
    "height_ratios = [1, 3]\n",
    "gs = gridspec.GridSpec(2, 1, height_ratios=height_ratios)\n",
    "axt = plt.subplot(gs[0])\n",
    "ax = plt.subplot(gs[1])\n",
    "\n",
    "axt.hist(neglogpvals, bins=bins, density=True, color=\"C7\", alpha=0.5)\n",
    "axt.hist(neglogpvals, bins=bins, density=True, color=\"k\", histtype=\"step\")\n",
    "\n",
    "ax.plot(bins, np.r_[h_n[0], h_n], c=\"k\", drawstyle=\"steps-pre\", lw=1)\n",
    "ax.errorbar(mids, h_n, yerr=err_n, c=\"k\", fmt=\",\", elinewidth=1, ms=0)\n",
    "ax.hist(neglogpvals, bins=bins, density=True, color=\"C7\", alpha=0.5)\n",
    "\n",
    "# Adapt y-lims so the markers show the same distances (only for lin-lin axes)\n",
    "ax_ymax = np.sort(h_n)[-2] + 0.05\n",
    "axt_ymax = np.amax(h_n) + 0.05\n",
    "axt_ymin = axt_ymax - ax_ymax * height_ratios[0] / height_ratios[1]\n",
    "axt.set_ylim(axt_ymin, axt_ymax)\n",
    "\n",
    "if _LOG:\n",
    "    ax.set_yscale(\"log\")\n",
    "    ax.set_ylim(10**np.floor(np.log10(np.amin(h_n[h_n>0]))), ax_ymax)\n",
    "else:\n",
    "    ax.set_ylim(0, ax_ymax)\n",
    "\n",
    "ax.set_xlim(0, np.amax(neglogpvals) + 0.2)\n",
    "axt.set_xlim(ax.get_xlim())\n",
    "\n",
    "# Broken axis: matplotlib.org/2.0.2/examples/pylab_examples/broken_axis.html\n",
    "def breakmarks(ax, hr, d=0.01, where=\"top\"):\n",
    "    # hr: height ratios to make both diag lines have same slope\n",
    "    kwargs = dict(transform=ax.transAxes, clip_on=False, c=\"k\", lw=1)\n",
    "    if where == \"top\":\n",
    "        ax.plot((-d, +d), (-d * hr[1], +d * hr[1]), **kwargs)\n",
    "        ax.plot((1 - d, 1 + d), (-d * hr[1], +d * hr[1]), **kwargs)\n",
    "    elif where == \"bottom\":\n",
    "        ax.plot((-d, +d), (1 - d * hr[0], 1 + d * hr[0]), **kwargs)\n",
    "        ax.plot((1 - d, 1 + d), (1 - d * hr[0], 1 + d * hr[0]), **kwargs)\n",
    "    else:\n",
    "        raise ValueError(\"'where' can be 'top' or 'bottom'.\")\n",
    "\n",
    "# Plot sigma lines\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    perc = 100 * sigma2prob(sigma)\n",
    "    ax.axvline(post_neglog10_pdf.ppf(perc), 0, 1.47, c=\"k\", ls=ls[i],\n",
    "                label=r\"${}\\sigma$\".format(sigma), clip_on=False)\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.xaxis.tick_bottom()\n",
    "axt.spines['bottom'].set_visible(False)\n",
    "axt.xaxis.tick_top()\n",
    "axt.tick_params(labeltop='off')  # don't put tick labels at the top\n",
    "breakmarks(axt, hr=height_ratios, where=\"top\")\n",
    "breakmarks(ax, hr=height_ratios, where=\"bottom\")\n",
    "\n",
    "ax.set_xlabel( )\n",
    "axt.set_title(\"Pre trial p-value distribution\")\n",
    "ax.legend()\n",
    "\n",
    "save_plot(\"post_trials\", \"post_trials{}.png\".format(\"_log\" if _LOG else \"\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show post-trial(pre-trial) dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "thresh = np.amin(neglogpvals[neglogpvals > 0])\n",
    "\n",
    "neglog10_pre_trial = np.linspace(thresh, -np.log10(1. - sigma2prob(4)))\n",
    "_post_trial_vals = post_neglog10_pdf.sf(neglog10_pre_trial)\n",
    "neglog10_post_trial = -np.log10(_post_trial_vals)\n",
    "\n",
    "# Ratio between log10 post and pre trial, must be < 1\n",
    "plt.plot(neglog10_pre_trial, neglog10_post_trial / neglog10_pre_trial,\n",
    "         color=\"k\", lw=2.5)\n",
    "plt.axhline(1, 0, 1, c=\"C7\", ls=\"--\")\n",
    "plt.xlabel(r\"Pre-trial $-\\log_{10}(p)$\")\n",
    "plt.ylabel(\"post / pre trial p-value\")\n",
    "plt.xlim(0, None)\n",
    "plt.ylim(0, 2)\n",
    "save_plot(\"post_trials\", \"pre_vs_post_ratio.png\")\n",
    "plt.show()\n",
    "\n",
    "# Same but in sigma significance\n",
    "plt.plot(prob2sigma(1. - 10**-neglog10_pre_trial),\n",
    "         prob2sigma(1. - 10**-neglog10_post_trial), color=\"k\", lw=2.5)\n",
    "plt.plot([0, 5], [0, 5], c=\"C7\", ls=\"--\")\n",
    "plt.xlabel(r\"Pre-trial significance in $\\sigma$\")\n",
    "plt.ylabel(r\"Post-trial significance in $\\sigma$\")\n",
    "plt.xlim(0, 5)\n",
    "plt.ylim(0, 5)\n",
    "plt.grid()\n",
    "save_plot(\"post_trials\", \"pre_vs_post_sigmas.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show all p-values per time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for i, pvali in enumerate(pvals.T):\n",
    "    plt.plot(pvali + 0 * i, zorder=-i)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show histogram of all pre-trial p-values per time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# p-vals should be approx. uniform in all windows, because we inject uniformly\n",
    "# and the background expectation is also almost uniformly. Although we see that\n",
    "# it doesn't quite hold for small time windows.\n",
    "dx = 0.01\n",
    "bins = np.arange(0., np.amax(pvals[pvals<1]) + dx, dx)  # (p=1. excluded)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(pvals.T)))\n",
    "for i, pvali in enumerate(pvals.T):\n",
    "    plt.hist(pvali, bins=bins, density=False, zorder=-i, color=colors[i],\n",
    "             alpha=.2)\n",
    "    plt.hist(pvali, bins=bins, density=False, zorder=-i,\n",
    "             color=\"k\", histtype=\"step\", alpha=i / len(pvals.T))\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"p value\")\n",
    "plt.show()\n",
    "\n",
    "# Same in -log10(p-val)\n",
    "dx = 0.1\n",
    "bins = np.arange(0.1, 6. + dx, dx)  # (p=1. excluded)\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(pvals.T)))\n",
    "for i, pvali in enumerate(pvals.T):\n",
    "    _neglogp = -np.log10(pvali)\n",
    "    plt.hist(_neglogp, bins=bins, density=False, zorder=-i, color=colors[i],\n",
    "             alpha=0.2)\n",
    "    plt.hist(_neglogp, bins=bins, density=False, zorder=-i,\n",
    "             color=\"k\", histtype=\"step\", alpha=i / len(pvals.T))\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"-log10(p)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The percentage of zero trials should approx. be the same as for the single BG trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for j in range(len(ts.T)):\n",
    "    print(\"TW ID: \", j)\n",
    "    print(\" Post Trials, % zeros: \", np.sum(ts[:, j] == 0) / len(ts[:, j]) * 100)\n",
    "    print(\" BG trials, % nzeros : \", bg_pdfs[j].nzeros / 1e8 * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Do trials in notebook, only for testing. Skip if we can load trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "beta = 0.9\n",
    "ts_val = 0.\n",
    "ns0 = 1.\n",
    "mu_sig = np.r_[0.1, 0.5, np.arange(1, 20, 1)]\n",
    "n_batch_trials = 2500\n",
    "\n",
    "perf = ana.performance(ts_val=ts_val, beta=beta, mus=mu_sig, ns0=ns0,\n",
    "                       n_batch_trials=n_batch_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Make Neyman plane for TS vs true mean injected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path = os.path.join(PATHS.local, \"unblinding\", \"result.json\")\n",
    "with open(path) as fp:\n",
    "    result = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_tw = 20\n",
    "perf = loader.perf_trials_loader(typ=\"healpy\", idx=_tw, skylab=False)[_tw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "mus = perf[\"mus\"]\n",
    "ts = np.array(perf[\"ts\"])\n",
    "\n",
    "ts_bins = np.arange(0, np.ceil(np.amax(ts)), 0.25)\n",
    "\n",
    "# Rows have mus, cols have ts, as if matrix is viewed as an image\n",
    "hist = np.empty((len(mus), len(ts_bins) - 1), dtype=float)\n",
    "for i in range(len(mus)):\n",
    "    hist[i], _ = np.histogram(ts[i], bins=ts_bins, density=True)\n",
    "    \n",
    "# Create empirical Neyman bands\n",
    "band_lo_emp = np.percentile(a=ts, axis=1, q=84)\n",
    "band_hi_emp = np.percentile(a=ts, axis=1, q=16)\n",
    "uls_emp = np.percentile(a=ts, axis=1, q=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create mu borders for pcolormesh\n",
    "dmu = np.diff(mus)\n",
    "mu_mids = 0.5 * (mus[:-1] + mus[1:])\n",
    "mu_borders = np.r_[mus[0] - dmu[0], mu_mids, mus[-1] + dmu[-1]]\n",
    "\n",
    "XX, YY = np.meshgrid(ts_bins, mu_borders)\n",
    "ZZ = np.array(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# mesh = plt.pcolormesh(XX, YY, ZZ, cmap=\"Greys\", norm=LogNorm())\n",
    "# mesh.set_rasterized(True)\n",
    "step = 0.25\n",
    "levels = np.arange(-3, 0 + step, step)\n",
    "vals = np.log10(np.pad(ZZ, pad_width=[(0, 1), (0, 1)], mode=\"edge\"))\n",
    "\n",
    "# Smooth along x, except for the first two bins, in which the zero trials are!\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "vals[:, 2:] = gaussian_filter(vals[:, 2:], sigma=(0., 1.5))\n",
    "\n",
    "plt.contourf(XX, YY, vals, levels, cmap=\"Greys\", extend=\"both\")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(r\"$\\log_{10}(\\mathrm{PDF})$\")\n",
    "\n",
    "plt.plot(uls_emp, mus, c=\"k\", ls=\"--\", label=r\"\\SI{90}{\\percent} UL\")\n",
    "plt.plot(band_lo_emp, mus, c=\"k\", ls=\":\",\n",
    "         label=r\"\\SI{68}{\\percent} CL Band\")\n",
    "plt.plot(band_hi_emp, mus, c=\"k\", ls=\":\")\n",
    "\n",
    "exp_ts = result[\"ts\"][_tw]\n",
    "plt.axvline(exp_ts, 0, 1, ls=\"-\", c=\"k\", label=\"Exp. result\")\n",
    "\n",
    "plt.xlabel(r\"Test statistic $-2\\ln\\Lambda$\")\n",
    "plt.ylabel(r\"Mean injected number of signal events $\\mu$\")\n",
    "\n",
    "plt.xlim(0, 20)\n",
    "plt.ylim(0, 30)\n",
    "leg = plt.legend(loc=\"best\")\n",
    "# leg.get_frame().set_facecolor(\"0.65\")\n",
    "# plt.title(r\"Empiric Neyman plane\")\n",
    "\n",
    "# save_fig(plt.gcf(), \"plots/tw{}_neyman_plane_rasterized.png\".format(_tw),\n",
    "#          dpi=200, bbox_inches=\"tight\")\n",
    "save_fig(plt.gcf(), \"plots/tw{}_neyman_plane.pdf\".format(_tw),\n",
    "         bbox_inches=\"tight\")\n",
    "save_fig(plt.gcf(), \"plots/tw{}_neyman_plane.pgf\".format(_tw),\n",
    "         bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Not enough sampled for Feldman Cousins here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_fc_interval(arr, rmax, alpha=0.9):\n",
    "    arr = np.atleast_2d(arr)\n",
    "    # Divide by one rmax per row\n",
    "    r = arr / np.array(rmax)\n",
    "    idx = np.argsort(r, axis=1)\n",
    "    cl_idx = int(np.ceil(arr.shape[1] * alpha))\n",
    "    lo_idx = np.amax(idx[:, :cl_idx], axis=1)\n",
    "    up_idx = np.amin(idx[:, :cl_idx], axis=1)\n",
    "    return idx, lo_idx, up_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Here we see, where we didn't sample enough for FC\n",
    "plt.plot(ts_bins[:-1], mus[rmax_idx])\n",
    "\n",
    "plt.axvline(80, c=\"k\")\n",
    "idx = np.where(ts_bins < 80)[0][-1]\n",
    "\n",
    "plt.xlabel(\"ts\")\n",
    "plt.ylabel(\"mu\")\n",
    "plt.show()\n",
    "\n",
    "# The highest density per column distribution for a fixed ts\n",
    "plt.plot(ts_bins[:-1], rmax)\n",
    "plt.yscale(\"log\")\n",
    "plt.xlim(x[0], x[-1])\n",
    "plt.xlabel(\"ts\")\n",
    "plt.ylabel(\"rmax\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(hist / rmax / np.sum(hist / rmax, axis=1)[:,None],\n",
    "               norm=LogNorm(), cmap=\"Greys\")\n",
    "plt.xlim(0, 20)\n",
    "plt.ylim(0, 30)\n",
    "plt.xlabel(r\"Test statistic $-2\\ln\\Lambda$\")\n",
    "plt.ylabel(r\"Mean injected number of signal events $\\mu$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Get n sigma ts values from BG PDF and show performance for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change typ 'healpy' | 'ps' and make all plots in cells below\n",
    "typ = \"healpy\"\n",
    "# Select True for test plots requested by Sandro\n",
    "skylab = False\n",
    "\n",
    "sigmas = [1, 2, 3, 4, 5]\n",
    "betas = [0.9, 0.9, 0.9, 0.9, 0.9]\n",
    "tw_ids = loader.time_window_loader()\n",
    "\n",
    "# Store mus per sigma, beta and tw combination\n",
    "mu_bfs = []\n",
    "ts_vals = []\n",
    "\n",
    "c_perf = \"#353132\"\n",
    "\n",
    "for _tw in tw_ids[-1:]:\n",
    "    emp_dist = loader.bg_pdf_loader(_tw)[_tw]\n",
    "    perf = loader.perf_trials_loader(typ=typ, idx=_tw, skylab=skylab)[_tw]\n",
    "\n",
    "    ts_vals_tw = emp_dist.ppf(q=100. * sigma2prob(sigmas))\n",
    "    ts_vals.append(ts_vals_tw)\n",
    "\n",
    "    x = np.linspace(0, perf[\"mus\"][-1], 100)\n",
    "    ls = [\"-\", \"-.\", \"--\", \":\", \":\"][::-1]\n",
    "    assert len(ls) == len(ts_vals_tw)\n",
    "\n",
    "    # Plot performances\n",
    "    mu_bfs.append([])\n",
    "    for beta in np.unique(betas):\n",
    "        plt.axhline(beta, 0, 1, ls=\"-\", color=\"C7\")\n",
    "    for i, ts_vali in enumerate(ts_vals_tw):\n",
    "        p0 = [1., 1., 1.]\n",
    "        mu_bf, cdfs, pars = stats.fit_chi2_cdf(ts_val=ts_vali, beta=betas[i],\n",
    "                                               ts=perf[\"ts\"], mus=perf[\"mus\"],\n",
    "                                               p0=p0)\n",
    "        print(pars)\n",
    "        mu_bfs[-1].append(mu_bf)\n",
    "        \n",
    "        plt.axvline(mu_bf, 0, 1, ls=ls[i], color=\"C7\")\n",
    "        plt.errorbar(perf[\"mus\"], 1. - cdfs, fmt=\".\", color=c_perf)\n",
    "        if ts_vali == 0:\n",
    "            _label = r\"$\\SI{{{:.0f}}}{{\\percent}} > 0$\".format(100. * betas[i])\n",
    "        else:\n",
    "            _label = (r\"$\\SI{{{:.0f}}}{{\\percent}}\".format(100. * betas[i]) +\n",
    "                      r\" > {:.0f}\\sigma$\".format(sigmas[i]))\n",
    "        if ts_vali == 0. and i > 0:\n",
    "            pass\n",
    "        else:\n",
    "            plt.plot(x, scs.chi2.cdf(x, *pars), color=c_perf, ls=ls[i],\n",
    "                     label=_label)\n",
    "\n",
    "    plt.xlim(0, None)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.xlabel(r\"Mean injected number of signal events $\\mu$\")\n",
    "    plt.ylabel(\"CDF\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"Time window {:02d}\".format(_tw))\n",
    "    plt.tight_layout()\n",
    "#     save_plot(os.path.join(\"performance\",\n",
    "#                            typ + \"_skylab_MC\" if skylab else \"\", \"chi2_fits\"),\n",
    "#               \"tw_{:02d}.png\".format(_tw), dpi=250)\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Done!\")\n",
    "\n",
    "mu_bfs = np.array(mu_bfs)\n",
    "ts_vals = np.array(ts_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot BG PDF n sigma per time windows overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_dt0, _dt1 = loader.time_window_loader(\"all\")\n",
    "_dt = _dt1 - _dt0\n",
    "\n",
    "ls = [\"-\", \"--\", \"-.\", \":\", \"-\"][::-1]\n",
    "alpha = [1, 1, 1, 1, 0.5][::-1]\n",
    "\n",
    "for i, ts_vals_i in enumerate(ts_vals.T[:5]):\n",
    "    plt.plot(_dt, ts_vals_i, ls=ls[i], color=\"#353132\",\n",
    "             alpha=alpha[i], label=r\"{}$\\sigma$\".format(sigmas[i]))\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Time window length in seconds\")\n",
    "plt.ylabel(\"TS value\")\n",
    "plt.legend(ncol=2, framealpha=0)\n",
    "# save_plot(\"performance\", \"bg_ts_vals.png\", dpi=200)\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot performance in n inj and flux per for each trial type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_perf_vs_dt(mu_bfs, sigmas, betas, ls, alphas, typ, skylab,\n",
    "                    mu2flux=None):\n",
    "    from scipy.optimize import brentq\n",
    "    def get_poisson_ul(a, b, k=0, beta=0.9):\n",
    "        return brentq(lambda mu: scs.poisson.sf(k=k, mu=mu) - beta, a, b)\n",
    "\n",
    "    _dt0, _dt1 = loader.time_window_loader(\"all\")\n",
    "    _dt = _dt1 - _dt0\n",
    "\n",
    "    try:\n",
    "        poisson_k0_90ul = mu2flux(get_poisson_ul(2, 3, k=0, beta=0.9))\n",
    "    except:\n",
    "        poisson_k0_90ul = get_poisson_ul(2, 3, k=0, beta=0.9)\n",
    "    plt.axhline(poisson_k0_90ul, 0, 1, ls=\":\", alpha=1, color=\"C7\",\n",
    "                label=\"Poisson zero BG 90% UL\")\n",
    "\n",
    "    for i, mu_bfs_i in enumerate(mu_bfs.T):\n",
    "        if mu2flux is None:\n",
    "            vals = mu_bfs_i\n",
    "            ylabel = \"Mean injected no. of events\"\n",
    "            info = \"ninj\"\n",
    "        else:\n",
    "            vals = mu2flux(mu_bfs_i)\n",
    "            ylabel = (r\"Mean injected flux \" +\n",
    "                      r\"$\\left(\\frac{E}{\\mathrm{GeV}}\\right)^2\\phi$ \" +\n",
    "                      r\"in GeV$^{-1}$ cm$^{-2}$\")\n",
    "            info = \"flux\"\n",
    "        plt.plot(_dt, vals, ls=ls[i], alpha=alphas[i], color=\"#353132\",\n",
    "                 label=r\"{:.0%} > {:.0f}$\\sigma$\".format(betas[i], sigmas[i]))\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Time window length in seconds\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(framealpha=0)\n",
    "    plt.xlim(_dt[0], _dt[-1])\n",
    "    plt.ylim(0, None)\n",
    "    plt.title(r\"Performance for $E^{-2}$ signal flux\")\n",
    "    save_plot(os.path.join(\"performance\", typ + \"_skylab_MC\" if skylab else \"\"),\n",
    "              \"perf_{}.png\".format(info), dpi=200)\n",
    "    plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ls = [\"-\", \"--\", \"-.\", \":\", \"-\"][::-1]\n",
    "alphas = [1, 1, 1, 1, 0.5][::-1]\n",
    "plot_perf_vs_dt(mu_bfs, sigmas, betas, ls, alphas, typ=typ, skylab=skylab,\n",
    "                mu2flux=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_mu2flux(typ=\"ps\"):\n",
    "    \"\"\"\n",
    "    Make mu2flux method from saved mu2fux(1) from healpy or ps injector.\n",
    "    \"\"\"\n",
    "    if typ == \"ps\":\n",
    "        fname = os.path.join(\"/Users\", \"tmenne\", \"Downloads\",\n",
    "                             \"hese_transient_stacking_data\", \"mu2flux_ps.json\")\n",
    "    elif typ == \"healpy\":\n",
    "        fname = os.path.join(\"/Users\", \"tmenne\", \"Downloads\",\n",
    "                             \"hese_transient_stacking_data\",\n",
    "                             \"mu2flux_healpy.json\")\n",
    "    else:\n",
    "        raise ValueError(\"`typ` can be 'ps' or 'healpy'.\")\n",
    "    with open(fname) as f:\n",
    "        mu2fluxinfo = json.load(f)\n",
    "\n",
    "    def mu2flux(mu):\n",
    "        return mu * mu2fluxinfo[\"all\"]\n",
    "\n",
    "    return mu2flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ls = [\"-\", \"--\", \"-.\", \":\", \"-\"][::-1]\n",
    "alphas = [1, 1, 1, 1, 0.5][::-1]\n",
    "plot_perf_vs_dt(mu_bfs, sigmas, betas, ls, alphas, typ=typ,\n",
    "                mu2flux=make_mu2flux(typ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def flux_model_factory(model, **model_args):\n",
    "    def flux_model(trueE):\n",
    "        flux_mod = getattr(phys, model)\n",
    "        return flux_mod(trueE, **model_args)\n",
    "\n",
    "    return flux_model\n",
    "\n",
    "mc_dict = loader.mc_loader(\"all\")\n",
    "log_E_nu_lo = 2.0\n",
    "log_E_nu_hi = 2.5\n",
    "tw_id = 10\n",
    "dt0, dt1 = loader.time_window_loader(tw_id)\n",
    "\n",
    "time_sam = UniformTimeSampler(random_state=RNDGEN)\n",
    "\n",
    "sig_injs = {}\n",
    "for key, mc in mc_dict.items():\n",
    "    print(\"\\n\" + 80 * \"#\")\n",
    "    print(\"# :: Setup for sample {} ::\".format(key))\n",
    "    opts = loader.settings_loader(key)[key].copy()\n",
    "    srcs = loader.source_list_loader(key)[key]\n",
    "    # Process to tdepps format\n",
    "    srcs_rec = make_src_records(srcs, dt0=dt0, dt1=dt1)\n",
    "\n",
    "    # Setup Signal injector\n",
    "    fmod = opts[\"sig_inj_opts\"].pop(\"flux_model\")\n",
    "    flux_model = flux_model_factory(fmod[\"model\"], **fmod[\"args\"])\n",
    "\n",
    "    # Cut energy range for differential limit\n",
    "    _log_E_nu = np.log10(mc[\"trueE\"])\n",
    "    mask = (_log_E_nu >= log_E_nu_lo) & (_log_E_nu < log_E_nu_hi)\n",
    "    print(\"- Selected {} / {} MC events in energy range [{}, {}).\".format(\n",
    "        np.sum(mask), len(mc), log_E_nu_lo, log_E_nu_hi))\n",
    "\n",
    "    sig_inj_i = SignalFluenceInjector(\n",
    "        flux_model, time_sampler=time_sam, inj_opts=opts[\"sig_inj_opts\"],\n",
    "        random_state=RNDGEN)\n",
    "    sig_inj_i.fit(srcs_rec, MC=mc[mask])\n",
    "    sig_injs[key] = sig_inj_i\n",
    "\n",
    "# Build the multi models\n",
    "multi_sig_inj = MultiSignalFluenceInjector(random_state=RNDGEN)\n",
    "multi_sig_inj.fit(sig_injs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for key, sig_inj in sig_injs.items():\n",
    "    print(key)\n",
    "    print(\"  \", sig_inj._raw_flux)\n",
    "    print(\"  \", sig_inj._raw_flux_per_src)\n",
    "    print(\"  \", sig_inj.mu2flux(1., per_source=True))\n",
    "    print(\"  \", sig_inj.flux2mu(1., per_source=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Performance with full and HESE removed MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show how the performance changes if we use the HESE removed MC or the full skylab MC.\n",
    "Performance should get a bit better with full MC because we use more high energy events.\n",
    "Do the full plot suite for skylab M;C above, here, only load both, get the best fit mus and show the perfromance curve ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Change typ 'healpy' | 'ps' and make all plots in cells below\n",
    "typ = \"healpy\"\n",
    "\n",
    "sigmas = [1, 2, 3, 4, 5]\n",
    "betas = [0.9, 0.9, 0.9, 0.9, 0.9]\n",
    "tw_ids = loader.time_window_loader()\n",
    "\n",
    "# Store mus per sigma, beta and tw combination\n",
    "mu_bfs = {\"truncated\": [], \"skylab\": []}\n",
    "ts_vals = {\"truncated\": [], \"skylab\": []}\n",
    "\n",
    "for skylab in [True, False]:\n",
    "    name = \"skylab\" if skylab else \"truncated\"\n",
    "    print(\"Loading performance trials for '{}' MC.\".format(name))\n",
    "    for _tw in tw_ids:\n",
    "        print(\"  tw id: {}\".format(_tw))\n",
    "        emp_dist = loader.bg_pdf_loader(_tw)[_tw]\n",
    "        perf = loader.perf_trials_loader(typ=typ, idx=_tw, skylab=skylab)[_tw]\n",
    "\n",
    "        ts_vals_tw = emp_dist.ppf(q=100. * sigma2prob(sigmas))\n",
    "        ts_vals[name].append(ts_vals_tw)\n",
    "\n",
    "        x = np.linspace(0, perf[\"mus\"][-1], 100)\n",
    "        ls = [\"-\", \"-.\", \"--\", \":\", \":\"][::-1]\n",
    "        assert len(ls) == len(ts_vals_tw)\n",
    "\n",
    "        # Plot performances\n",
    "        mu_bfs[name].append([])\n",
    "        for i, ts_vali in enumerate(ts_vals_tw):\n",
    "            p0 = [1., 1., 1.]\n",
    "            mu_bf, cdfs, pars = stats.fit_chi2_cdf(\n",
    "                ts_val=ts_vali, beta=betas[i], ts=perf[\"ts\"], mus=perf[\"mus\"],\n",
    "                p0=p0)\n",
    "            mu_bfs[name][-1].append(mu_bf)\n",
    "            \n",
    "    mu_bfs[name] = np.array(mu_bfs[name])\n",
    "    ts_vals[name] = np.array(ts_vals[name])\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_perf_vs_dt(mu_bfs, sigmas, betas, ls, alphas, typ, appendix=\"\",\n",
    "                    mu2flux=None):\n",
    "    from scipy.optimize import brentq\n",
    "    def get_poisson_ul(a, b, k=0, beta=0.9):\n",
    "        return brentq(lambda mu: scs.poisson.sf(k=k, mu=mu) - beta, a, b)\n",
    "\n",
    "    _dt0, _dt1 = loader.time_window_loader(\"all\")\n",
    "    _dt = _dt1 - _dt0\n",
    "\n",
    "    try:\n",
    "        poisson_k0_90ul = mu2flux(get_poisson_ul(2, 3, k=0, beta=0.9))\n",
    "    except:\n",
    "        poisson_k0_90ul = get_poisson_ul(2, 3, k=0, beta=0.9)\n",
    "    plt.axhline(poisson_k0_90ul, 0, 1, ls=\":\", alpha=1, color=\"C7\",\n",
    "                label=\"Poisson zero BG 90% UL\")\n",
    "\n",
    "    for i, mu_bfs_i in enumerate(mu_bfs.T):\n",
    "        if mu2flux is None:\n",
    "            vals = mu_bfs_i\n",
    "            ylabel = \"Mean injected no. of events\"\n",
    "            info = \"ninj\"\n",
    "        else:\n",
    "            vals = mu2flux(mu_bfs_i)\n",
    "            ylabel = (r\"Mean injected flux \" +\n",
    "                      r\"$\\left(\\frac{E}{\\mathrm{GeV}}\\right)^2\\phi$ \" +\n",
    "                      r\"in GeV$^{-1}$ cm$^{-2}$\")\n",
    "            info = \"flux\"\n",
    "        plt.plot(_dt, vals, ls=ls[i], alpha=alphas[i], color=\"#353132\",\n",
    "                 label=r\"{:.0%} > {:.0f}$\\sigma$\".format(betas[i], sigmas[i]))\n",
    "    plt.xscale(\"log\")\n",
    "    plt.xlabel(\"Time window length in seconds\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend(framealpha=0)\n",
    "    plt.xlim(_dt[0], _dt[-1])\n",
    "    plt.ylim(0, 50)\n",
    "    plt.title(r\"Performance for $E^{-2}$ signal flux\")\n",
    "    save_plot(os.path.join(\"performance\", typ + \"_comp\"),\n",
    "              \"perf_{}_{}.png\".format(info, appendix), dpi=200)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ls = [\"-\", \"--\", \"-.\", \":\", \"-\"][::-1]\n",
    "alphas = [1, 1, 1, 1, 0.5][::-1]\n",
    "plot_perf_vs_dt(mu_bfs[\"skylab\"], sigmas, betas, ls, alphas, typ=typ,\n",
    "                mu2flux=None, appendix=\"skylab\")\n",
    "plot_perf_vs_dt(mu_bfs[\"truncated\"], sigmas, betas, ls, alphas, typ=typ,\n",
    "                mu2flux=None, appendix=\"truncated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot the ratio all MC / truncated MC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_dt0, _dt1 = loader.time_window_loader(\"all\")\n",
    "_dt = _dt1 - _dt0\n",
    "\n",
    "ls = [\"-\", \"--\", \"-.\", \":\", \"-\"][::-1]\n",
    "alphas = [1, 1, 1, 1, 0.5][::-1]\n",
    "\n",
    "for i in range(len(mu_bfs[\"skylab\"].T)):\n",
    "    ratios = mu_bfs[\"skylab\"].T[i] / mu_bfs[\"truncated\"].T[i]\n",
    "    plt.plot(_dt, ratios, ls=ls[i], alpha=alphas[i], color=\"#353132\",\n",
    "             label=r\"{:.0%} > {:.0f}$\\sigma$\".format(betas[i], sigmas[i]))\n",
    "\n",
    "plt.axhline(1, 0, 1, ls=\"-\", c=\"k\", alpha=0.2)\n",
    "    \n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Time window length in seconds\")\n",
    "plt.ylabel(r\"ninj all MC / ninj truncated MC\")\n",
    "plt.legend(framealpha=0)\n",
    "plt.xlim(_dt[0], _dt[-1])\n",
    "plt.ylim(0.98, 1.02)\n",
    "plt.title(\"Performance ratios\")\n",
    "\n",
    "save_plot(os.path.join(\"performance\", typ + \"_comp\"),\"ratio.png\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Differential Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "sig_inj_type = \"healpy\"\n",
    "perf_trials = loader.perf_trials_loader(sig_inj_type, diff=True, idx=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "bg_pdfs = loader.bg_pdf_loader(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Prepare signal injector to convert mu to flux skip when loaded from dill pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "perf_sig_injs = {}\n",
    "_time_sam = UniformTimeSampler(random_state=RNDGEN)\n",
    "\n",
    "# Load files and build the models one after another to save memory\n",
    "sample_names = loader.source_list_loader()\n",
    "for key in sample_names:\n",
    "    _opts = loader.settings_loader(key)[key].copy()\n",
    "    _mc = loader.mc_loader(key)[key]\n",
    "    _srcs_i = loader.source_list_loader(key)[key]\n",
    "    # Process to tdepps format\n",
    "    _srcs_rec_i = make_src_records(_srcs_i, dt0=np.nan, dt1=np.nan)\n",
    "    \n",
    "    # Setup Signal injector\n",
    "    _fmod = _opts[\"sig_inj_opts\"].pop(\"flux_model\")\n",
    "    _flux_model = phys.flux_model_factory(_fmod[\"model\"], **_fmod[\"args\"])\n",
    "    if sig_inj_type == \"healpy\":\n",
    "        _opts[\"sig_inj_opts\"][\"inj_sigma\"] = 3.\n",
    "        src_maps = loader.source_map_loader(src_list=_srcs_i)\n",
    "        sig_inj_i = HealpySignalFluenceInjector(\n",
    "            _flux_model, time_sampler=_time_sam, inj_opts=_opts[\"sig_inj_opts\"],\n",
    "            random_state=RNDGEN)\n",
    "        sig_inj_i.fit(_srcs_rec_i, src_maps=src_maps, MC=_mc)\n",
    "    elif sig_inj_type == \"ps\":\n",
    "        sig_inj_i = SignalFluenceInjector(\n",
    "            _flux_model, time_sampler=_time_sam, inj_opts=_opts[\"sig_inj_opts\"],\n",
    "            random_state=RNDGEN)\n",
    "        sig_inj_i.fit(_srcs_rec_i, MC=_mc)\n",
    "    else: \n",
    "        raise ValueError(\"`sig_inj_type` can be 'healpy' or 'ps'.\")\n",
    "    perf_sig_injs[key] = sig_inj_i\n",
    "    \n",
    "perf_multi_sig_inj = MultiSignalFluenceInjector(random_state=RNDGEN)\n",
    "perf_multi_sig_inj.fit(perf_sig_injs)\n",
    "\n",
    "print(\":: Done, setup {} signal injector ::\".format(sig_inj_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot sensitivity vs energy for a single time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def _cdf_func(x, df, loc, scale):\n",
    "    return scs.chi2.cdf(x, df, loc, scale)\n",
    "\n",
    "FLUX = True  # If True, use mu2flux as y units\n",
    "sigmas = [3., 5., 5.]\n",
    "betas = [0.9, 0.5, 0.9]\n",
    "ls = [\"-.\", \":\", \"-\"]\n",
    "label = [\"Sensitivity\", \"Disc. Pot. 50%\", \"Disc. Pot. 90%\"]\n",
    "sigmas = [3., 5.]\n",
    "betas = [0.9, 0.9]\n",
    "label = [\"Sensitivity\", \"Disc. Pot. 90%\"]\n",
    "ls = [\"-.\", \"-\"]\n",
    "tw_ids = loader.time_window_loader()\n",
    "\n",
    "_x = np.linspace(0, 100)\n",
    "hotfix_id = [100 * 18 + 0]  # Combined ID where to apply a hotfix chi2 solution\n",
    "\n",
    "for tw_id in tw_ids:\n",
    "    perf_bf_pars = []\n",
    "    logE_bins = perf_trials[tw_id][\"log_E_bins\"]\n",
    "    # For each logE bin get the mean injected events\n",
    "    for i in range(len(logE_bins) - 1):\n",
    "        bg_pdf = bg_pdfs[tw_id]\n",
    "        perf = perf_trials[tw_id]\n",
    "        # Get the BG TS values for the desired betas\n",
    "        bg_ts_vals = bg_pdf.ppf(q=100. * sigma2prob(sigmas))\n",
    "\n",
    "        # Get the best mus from the chi2 fits\n",
    "        bf_pars_i = []\n",
    "        ts_i = np.array(perf[\"ts\"][i])\n",
    "        \n",
    "        for j, bg_ts_val in enumerate(bg_ts_vals):\n",
    "            p0 = [1., 1., 1.]\n",
    "            mu_bf, cdfs, chi2_fit_pars = stats.fit_chi2_cdf(\n",
    "                ts_val=bg_ts_val, beta=betas[j],\n",
    "                ts=perf[\"ts\"][i], mus=perf[\"mus\"], p0=p0)\n",
    "            \n",
    "            if tw_id * 100 + i in hotfix_id:\n",
    "                # Hotfix for missing stats in high ninj regions: Add a CDF = 1\n",
    "                # point for very high signal to make the fit converge\n",
    "                chi2_fit_pars, _ = sco.curve_fit(\n",
    "                    _cdf_func, xdata=np.r_[perf[\"mus\"], 200],\n",
    "                    ydata=1. - np.r_[cdfs, 0], p0=p0)\n",
    "                mu_bf = scs.chi2.ppf(betas[j], *chi2_fit_pars)\n",
    "                # plt.plot(_x, scs.chi2.cdf(x, *chi2_fit_pars), c=\"C7\")\n",
    "                # plt.plot(np.r_[perf[\"mus\"], 200], 1. - np.r_[cdfs, 0],\n",
    "                #          ls=\"\", marker=\"o\", c=\"k\")\n",
    "                # plt.xlim(0, np.amax(perf[\"mus\"]) + 2)\n",
    "                # plt.show()\n",
    "    \n",
    "            bf_pars_i.append(mu_bf)\n",
    "        perf_bf_pars.append(bf_pars_i)\n",
    "    \n",
    "    # Plot performance curves per time window\n",
    "    perf_bf_pars = np.array(perf_bf_pars)\n",
    "    if FLUX:\n",
    "        perf_bf_pars = perf_multi_sig_inj.mu2flux(perf_bf_pars)\n",
    "        ylabel = (r\"Mean injected flux \" +\n",
    "                  r\"$\\left(\\frac{E}{\\mathrm{GeV}}\\right)^2\\phi$ \" +\n",
    "                  r\"in GeV$^{-1}$ cm$^{-2}$\")\n",
    "        info = \"flux\"\n",
    "    else:\n",
    "        ylabel = \"Mean injected no. of events\"\n",
    "        info = \"ninj\"\n",
    "    for j, _pars in enumerate(perf_bf_pars.T):\n",
    "        plt.plot(logE_bins, np.r_[_pars[0], _pars], ls=ls[j], c=\"C7\",\n",
    "                 label=label[j], drawstyle=\"steps-pre\")\n",
    "\n",
    "    plt.ylim(0, None)\n",
    "    plt.xlabel(r\"$\\log_{10}(E_\\nu / \\mathrm{GeV})$\")\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.title(\"Time window {}\".format(tw_id))\n",
    "    plt.legend()\n",
    "\n",
    "#     save_plot(os.path.join(\"differential_perf\", sig_inj_type),\n",
    "#               \"tw_{:02d}_{}.png\".format(tw_id, info))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Fake unblind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Load PDFs needed for p-value calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "post_trial_pdf = loader.post_trial_pdf_loader()\n",
    "bg_pdfs = loader.bg_pdf_loader(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dt0s, dt1s = loader.time_window_loader(\"all\")\n",
    "test_llhs = {}\n",
    "for i, (dt0i, dt1i) in enumerate(zip(dt0s, dt1s)):\n",
    "    print(\"# Build test LLH for time window pair {}: [{:.0f}, {:.0f}]\".format(\n",
    "        i, dt0i, dt1i))\n",
    "    test_multi_llh = deepcopy(ana.llh)\n",
    "    for key, model in test_multi_llh.model.items():\n",
    "        print(\"- {}\".format(key))\n",
    "        # Switch time windows and register new model\n",
    "        new_model = model.set_new_srcs_dt(dt0=dt0i, dt1=dt1i)\n",
    "        test_multi_llh.llhs[key].model = new_model\n",
    "\n",
    "    test_llhs[i] = test_multi_llh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With signal injected from the largest time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ntrials = 1000\n",
    "post_vals_sig = np.empty(ntrials, dtype=float)\n",
    "tw_ids_sig = np.empty(ntrials, dtype=int)\n",
    "for i in range(ntrials):\n",
    "    res_i = ana.unblind(X=None, test_llhs=test_llhs, bg_pdfs=bg_pdfs, ns0=1.,\n",
    "                        post_trial_pdf=post_trial_pdf, really_unblind=False,\n",
    "                        n_signal=2)\n",
    "    post_vals_sig[i] = res_i[\"post_pval\"]\n",
    "    tw_ids_sig[i] = res_i[\"best_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(tw_ids_sig, bins=np.arange(0, 21, 1), density=True)\n",
    "plt.title(\"Best time window\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(post_vals_sig[post_vals_sig<post_vals_sig.max()],\n",
    "         bins=np.arange(0, 1, 0.05), density=True)\n",
    "plt.title(\"Post-trial p-values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "BG only from largest time window, expect quite flat post p-value distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "ntrials = 1000\n",
    "post_vals_bg = np.empty(ntrials, dtype=float)\n",
    "tw_ids_bg = np.empty(ntrials, dtype=int)\n",
    "for i in range(ntrials):\n",
    "    res_i = ana.unblind(X=None, test_llhs=test_llhs, bg_pdfs=bg_pdfs, ns0=1.,\n",
    "                        post_trial_pdf=post_trial_pdf, really_unblind=False)\n",
    "    post_vals_bg[i] = res_i[\"post_pval\"]\n",
    "    tw_ids_bg[i] = res_i[\"best_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.hist(tw_ids_bg, bins=np.arange(0, 21, 1), density=True)\n",
    "plt.title(\"Best time window\")\n",
    "plt.show()\n",
    "\n",
    "plt.hist(post_vals_bg[post_vals_bg<post_vals_bg.max()],\n",
    "         bins=np.arange(0, 1, 0.05), density=True)\n",
    "plt.title(\"Post-trial p-values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNBLIND!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Result fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "if dt0 != -216000 or dt1 != 216000:\n",
    "    raise ValueError(\"Models must be constructed with largest time window!\")\n",
    "    \n",
    "print(\"Loading post trial PDF\")\n",
    "post_trial_pdf = loader.post_trial_pdf_loader()\n",
    "print(\"Loading BG PDFs\")\n",
    "bg_pdfs = loader.bg_pdf_loader(\"all\")\n",
    "print(\"Loading ontime data\")\n",
    "exp_on_dict = loader.on_data_loader(\"all\")\n",
    "print(\":: Done ::\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dt0s, dt1s = loader.time_window_loader(\"all\")\n",
    "test_llhs = {}\n",
    "for i, (dt0i, dt1i) in enumerate(zip(dt0s, dt1s)):\n",
    "    print(\"# Build test LLH for time window pair {}: [{:.0f}, {:.0f}]\".format(\n",
    "        i, dt0i, dt1i))\n",
    "    test_multi_llh = deepcopy(ana.llh)\n",
    "    for key, model in test_multi_llh.model.items():\n",
    "        print(\"- {}\".format(key))\n",
    "        # Switch time windows and register new model\n",
    "        new_model = model.set_new_srcs_dt(dt0=dt0i, dt1=dt1i)\n",
    "        test_multi_llh.llhs[key].model = new_model\n",
    "\n",
    "    test_llhs[i] = test_multi_llh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unblinded_res = ana.unblind(X=exp_on_dict, test_llhs=test_llhs, bg_pdfs=bg_pdfs,\n",
    "                            ns0=0.1, post_trial_pdf=post_trial_pdf,\n",
    "                            really_unblind=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def _dict_print(d):\n",
    "    shift = max(map(len, d.keys())) + 1\n",
    "    for key, val in d.items():\n",
    "        print(\"{0:{1:d}s}: \".format(key, shift), val)\n",
    "        \n",
    "_dict_print(unblinded_res)\n",
    "print(\"Post trial p-value is      : \" +\n",
    "      \"{:.3f}\".format(unblinded_res[\"post_pval\"]))\n",
    "print(\"Post trial significance is : \" +\n",
    "      \"{:.3f} sigma\".format(prob2sigma(1. - unblinded_res[\"post_pval\"])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show the best fit pre-trial and post trial position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "_dt0s, _dt1s = loader.time_window_loader(\"all\")\n",
    "dts = _dt1s - _dt0s\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "ax.plot(dts, unblinded_res[\"ts\"], c=\"#353132\", label=\"ts\")\n",
    "ax.plot(dts, unblinded_res[\"ns\"], c=\"#353132\", ls=\"--\", label=\"ns\")\n",
    "ax.plot(dts, unblinded_res[\"pvals\"], c=\"#353132\", ls=\":\",\n",
    "         label=r\"pre-trial $p$\")\n",
    "ax.axhline(1, 0, 1, ls=\"-\", c=\"k\", alpha=0.5)\n",
    "\n",
    "ax.set_xscale(\"log\")\n",
    "ax.set_xlim(dts[0], dts[-1])\n",
    "ax.set_ylim(0, None)\n",
    "ax.set_xlabel(\"time window in seconds\")\n",
    "ax.legend(loc=\"upper left\")\n",
    "save_plot(\"unblind\", \"best_fit_vals.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bf_idx = unblinded_res[\"best_idx\"]\n",
    "c = \"#353132\"\n",
    "sigmas = [2., 3.]\n",
    "alphas = [0.5, 0.75]\n",
    "bg_pdf = bg_pdfs[unblinded_res[\"best_idx\"]]\n",
    "dx = 0.5\n",
    "\n",
    "h, bins, err, norm = bg_pdf.data_hist(dx=dx, which=\"all\", density=True)\n",
    "mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "plt.plot(bins, np.r_[h[0], h], drawstyle=\"steps-pre\", c=c, lw=1.5)\n",
    "plt.errorbar(mids, h, yerr=err, fmt=\",\", c=c)\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    plt.axvline(bg_pdf.ppf(100 * sigma2prob(sigma)), 0, 1, ls=\"-\", c=\"k\",\n",
    "                alpha=alphas[i], label=r\"${:.0f}\\sigma$\".format(sigma))\n",
    "\n",
    "# Show bestfit result\n",
    "plt.vlines(unblinded_res[\"ts\"][bf_idx],\n",
    "           0, bg_pdf.pdf(unblinded_res[\"ts\"][bf_idx], dx=dx),\n",
    "           colors=\"C3\", label=\"Best fit ts\")\n",
    "    \n",
    "plt.yscale(\"log\")\n",
    "plt.xlim(0, bins[-1])\n",
    "plt.xlabel(\"test statistic\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.title(\"Best fit time window TS distribution\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "save_plot(\"unblind\", \"best_fit_ts_pre_trial.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bf_idx = unblinded_res[\"best_idx\"]\n",
    "c = \"#353132\"\n",
    "sigmas = [1., 2.]\n",
    "alphas = [0.5, 0.75]\n",
    "dx = 0.1\n",
    "\n",
    "bins = np.arange(0, np.ceil(np.amax(post_trial_pdf.data)), dx)\n",
    "h, bins = np.histogram(post_trial_pdf.data, bins=bins, density=False)\n",
    "norm = np.sum(h) * np.diff(bins)\n",
    "err = np.sqrt(h) / norm\n",
    "h = h / norm\n",
    "mids = 0.5 * (bins[:-1] + bins[1:])\n",
    "\n",
    "plt.plot(bins, np.r_[h[0], h], drawstyle=\"steps-pre\", c=c, lw=1.5)\n",
    "plt.errorbar(mids, h, yerr=err, fmt=\",\", c=c)\n",
    "for i, sigma in enumerate(sigmas):\n",
    "    plt.axvline(post_trial_pdf.ppf(100 * sigma2prob(sigma)), 0, 1, ls=\"-\",\n",
    "                c=\"k\", alpha=alphas[i], label=r\"${:.0f}\\sigma$\".format(sigma))\n",
    "\n",
    "# Show bestfit result\n",
    "neglog10pval = -np.log10(unblinded_res[\"pvals\"][bf_idx])\n",
    "plt.vlines(neglog10pval, 0, post_trial_pdf.pdf(neglog10pval, dx=dx),\n",
    "           colors=\"C3\", label=r\"pre-trial $p$\")\n",
    "    \n",
    "plt.yscale(\"log\")\n",
    "plt.xlim(0, bins[-1])\n",
    "plt.xlabel(r\"Pre trial $-\\log_{10}(p)$\")\n",
    "plt.ylabel(\"PDF\")\n",
    "plt.title(\"Pre trial p-value distribution\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "save_plot(\"unblind\", \"best_fit_post_trial.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Pre-trial Limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Trials were injected for multiple time windows and always tested against the same model as injected.\n",
    "We can thus draw the limits and the sensitivity in one plot.\n",
    "Sensitivity upper limits (90% over 0) are the same as the data upper limits when a null detection was made and higher were a small significance was detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load unblided result\n",
    "path = os.path.join(PATHS.local, \"unblinding\", \"result.json\")\n",
    "with open(path) as fp:\n",
    "    result = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load BG PDFs\n",
    "bg_pdfs = loader.bg_pdf_loader(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Load performance trials, has 90% upper limits prefitted\n",
    "typ = \"healpy\"\n",
    "perf = loader.perf_trials_loader(typ=\"healpy\", idx=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Load a signal injector\n",
    "perf_sig_injs = {}\n",
    "dt0, dt1 = loader.time_window_loader(-1)\n",
    "\n",
    "# Load files and build the models one after another to save memory\n",
    "time_sam = UniformTimeSampler(random_state=RNDGEN)\n",
    "sample_names = loader.source_list_loader()\n",
    "for key in sample_names:\n",
    "    print(\"\\n\" + 80 * \"#\")\n",
    "    print(\"# :: Setup for sample {} ::\".format(key))\n",
    "    opts = loader.settings_loader(key)[key].copy()\n",
    "    exp_off = loader.off_data_loader(key)[key]\n",
    "    mc = loader.mc_loader(key)[key]\n",
    "    srcs_i = loader.source_list_loader(key)[key]\n",
    "    runlist_i = loader.runlist_loader(key)[key]\n",
    "    # Process to tdepps format\n",
    "    srcs_rec_i = make_src_records(srcs_i, dt0=dt0, dt1=dt1)\n",
    "    \n",
    "    # Setup Signal injector\n",
    "    fmod = opts[\"sig_inj_opts\"].pop(\"flux_model\")\n",
    "    flux_model = phys.flux_model_factory(fmod[\"model\"], **fmod[\"args\"])\n",
    "    if typ == \"healpy\":\n",
    "        opts[\"sig_inj_opts\"][\"inj_sigma\"] = 3.\n",
    "        src_maps = loader.source_map_loader(src_list=srcs_i)\n",
    "        sig_inj_i = HealpySignalFluenceInjector(\n",
    "            flux_model, time_sampler=time_sam, inj_opts=opts[\"sig_inj_opts\"],\n",
    "            random_state=RNDGEN)\n",
    "        sig_inj_i.fit(srcs_rec_i, src_maps=src_maps, MC=mc)\n",
    "    else:\n",
    "        sig_inj_i = SignalFluenceInjector(\n",
    "            flux_model, time_sampler=time_sam, inj_opts=opts[\"sig_inj_opts\"],\n",
    "            random_state=RNDGEN)\n",
    "        sig_inj_i.fit(srcs_rec_i, MC=mc)\n",
    "    perf_sig_injs[key] = sig_inj_i\n",
    "\n",
    "perf_multi_sig_inj = MultiSignalFluenceInjector(random_state=RNDGEN)\n",
    "perf_multi_sig_inj.fit(perf_sig_injs)    \n",
    "print(\":: Done ::\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Get sensitivities (90% over 0) and upper-limits (90% over data) for pre-trial best fit results.\n",
    "In case of TS=0 data UL are equal to sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p0 = [1., 1., 1.]\n",
    "limits_mu_inj = []\n",
    "sens_mu_inj = []\n",
    "discpot_mu_inj = []\n",
    "\n",
    "for idx, ts in zip(result[\"time_window_ids\"], result[\"ts\"]):\n",
    "    sens_mu_inj.append(stats.fit_chi2_cdf(\n",
    "        ts_val=0., beta=0.9, p0=p0, ts=perf[idx][\"ts\"],\n",
    "        mus=perf[idx][\"mus\"])[0])\n",
    "    limits_mu_inj.append(stats.fit_chi2_cdf(\n",
    "        ts_val=ts, beta=0.9, p0=p0, ts=perf[idx][\"ts\"],\n",
    "        mus=perf[idx][\"mus\"])[0])\n",
    "    discpot_mu_inj.append(stats.fit_chi2_cdf(\n",
    "        ts_val=bg_pdfs[idx].ppf(100. * sigma2prob(5)), beta=0.9, p0=p0,\n",
    "        ts=perf[idx][\"ts\"], mus=perf[idx][\"mus\"])[0])\n",
    "\n",
    "sens_mu_inj = np.array(sens_mu_inj)\n",
    "limits_mu_inj = np.array(limits_mu_inj)\n",
    "discpot_mu_inj = np.array(discpot_mu_inj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def renorm_phi0(phi0, E0old, E0new, gamma):\n",
    "    \"\"\"\n",
    "    Renormalizes power law flux normalization phi0 to a different base energy:\n",
    "        phi0' = phi(E0') = phi0 * (E0' / E0)^-gamma\n",
    "    \"\"\"\n",
    "    phi0 = np.atleast_1d(phi0)\n",
    "    E0old = np.atleast_1d(E0old)\n",
    "    E0new = np.atleast_1d(E0new)\n",
    "    gamma = np.atleast_1d(gamma)\n",
    "    return power_law_flux(trueE=E0new, E0=E0old, gamma=gamma, phi0=phi0)\n",
    "\n",
    "def get_poisson_ul(a, b, k=0, beta=0.9):\n",
    "    return sco.brentq(lambda mu: scs.poisson.sf(k=k, mu=mu) - beta, a, b)\n",
    "\n",
    "_dt0, _dt1 = loader.time_window_loader(\"all\")\n",
    "_dt = _dt1 - _dt0\n",
    "\n",
    "FLUX = True\n",
    "E0old = 1.\n",
    "E0new = 1e5\n",
    "\n",
    "poisson_k0_90ul = get_poisson_ul(2, 3, k=0, beta=0.9)\n",
    "if FLUX:\n",
    "    poisson_k0_90ul = renorm_phi0(perf_multi_sig_inj.mu2flux(poisson_k0_90ul),\n",
    "                                  E0old, E0new, gamma=2.) * 1e10\n",
    "\n",
    "plt.axhline(poisson_k0_90ul, 0, 1, ls=\":\", alpha=1, color=\"C7\",\n",
    "            label=\"Poisson zero BG 90% UL\")\n",
    "\n",
    "if FLUX:\n",
    "    sens_vals = renorm_phi0(perf_multi_sig_inj.mu2flux(sens_mu_inj),\n",
    "                            E0old, E0new, gamma=2.) * 1e10\n",
    "    limits_vals = renorm_phi0(perf_multi_sig_inj.mu2flux(limits_mu_inj),\n",
    "                              E0old, E0new, gamma=2.) * 1e10\n",
    "    discpot_vals = renorm_phi0(perf_multi_sig_inj.mu2flux(discpot_mu_inj),\n",
    "                              E0old, E0new, gamma=2.) * 1e10\n",
    "#     ylabel = (r\"Mean injected flux \" +\n",
    "#               r\"$\\left(\\frac{E}{\\mathrm{GeV}}\\right)^2\\phi$ \" +\n",
    "#               r\"in GeV$^{-1}$ cm$^{-2}$\")\n",
    "    ylabel = r\"$\\phi_0$  at 100$\\,$TeV in $10^{-10}$ GeV$^{-1}$ cm$^{-2}$\"\n",
    "    info = \"flux\"\n",
    "else:\n",
    "    sens_vals = sens_mu_inj\n",
    "    limits_vals = limits_mu_inj\n",
    "    discpot_vals = discpot_mu_inj\n",
    "    ylabel = \"Mean injected no. of events\"\n",
    "    info = \"ninj\"\n",
    "\n",
    "plt.plot(_dt, sens_vals, ls=\"-\", alpha=0.5, color=\"#353132\",\n",
    "         label=\"Sensitivity\")\n",
    "plt.plot(_dt, limits_vals, ls=\"\", marker=\"v\", color=\"#353132\",\n",
    "         label=\"Pre-trial 90% UL\")\n",
    "plt.plot(_dt, discpot_vals, ls=\"--\", color=\"#353132\",\n",
    "         label=\"90% Disc. Potential\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"Time window length in seconds\")\n",
    "plt.ylabel(ylabel)\n",
    "plt.legend(framealpha=0)\n",
    "plt.xlim(_dt[0], _dt[-1] * 1.1)\n",
    "plt.ylim(0, None)\n",
    "plt.title(r\"Sensitivity and 90% UL for $E^{-2}$ signal flux\")\n",
    "\n",
    "save_plot(os.path.join(\"limits\", \"pre_trial_limits_\" + typ),\n",
    "          \"perf_{}.png\".format(info), dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Best Fit Limits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Trials were injected for multiple gammas and time windows but always tested against the best fit model.\n",
    "\n",
    "Because the largest time window was the best fit one, the curves doesn't vary with time window length, because when injecting in a smaller window but testing with a larger one, doesn't worsen the performance, because no additional separation power comes from the uniform time windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# gammas = np.arange(1.5, 3.5 + 0.1, 0.1)\n",
    "gammas = [1.5, 2.0, 2.5, 3.0, 3.5]\n",
    "tw_ids = loader.time_window_loader()\n",
    "_dt0s, _dt1s = loader.time_window_loader(\"all\")\n",
    "dt = _dt1s - _dt0s\n",
    "\n",
    "path = os.path.join(PATHS.data, \"limits_healpy\")\n",
    "\n",
    "mu_bfs = []\n",
    "flux_bfs = []\n",
    "\n",
    "for gamma in gammas:\n",
    "    files = glob(os.path.join(path, \"tw_*_gamma_{:.1f}.json.gz\".format(gamma)))\n",
    "    print(\"Loading limit trials for gamma = {:.1f}\".format(gamma))\n",
    "    print(\"  Loading trials from {} time windows.\".format(len(files)))\n",
    "    mu_bfs.append([])\n",
    "    flux_bfs.append([])\n",
    "    for f in sorted(files):\n",
    "        with gzip.open(f) as fp:\n",
    "            perf = json.load(fp)\n",
    "        mu_bfs[-1].append(perf[\"mu_bf\"])\n",
    "        flux_bfs[-1].append(perf[\"flux_bf\"])\n",
    "\n",
    "print(\":: Done ::\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot injected events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ls = [\"-\", \"-\", \"-.\", \"--\", \":\"]\n",
    "alphas = [1, 0.5, 1, 1, 1]\n",
    "# Needs all loaded gammas from above\n",
    "# colors = plt.cm.viridis(np.linspace(0, 1, len(mu_bfs)))\n",
    "\n",
    "for i, gamma in enumerate(gammas[::-1]):\n",
    "    plt.plot(dt, mu_bfs[::-1][i], ls=ls[i], alpha=alphas[i],\n",
    "             color=\"#353132\", label=r\"$\\gamma = {:.1f}$\".format(gamma))\n",
    "#     plt.plot(dt, mu_bfs[::-1][i], c=colors[i],\n",
    "#              label=r\"$\\gamma = {:.1f}$\".format(gamma))\n",
    "    \n",
    "plt.xscale(\"log\")\n",
    "plt.xlim(dt[0], dt[-1])\n",
    "plt.ylim(0, 50)\n",
    "plt.xlabel(\"time window length in seconds\")\n",
    "plt.ylabel(\"Mean injected no. of events\")\n",
    "plt.title(\"90% upper limits over data best fit\")\n",
    "plt.legend(loc=\"upper left\", ncol=1, bbox_to_anchor=(1, 1))\n",
    "save_plot(\"limits\", \"ninj.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Plot converted to power law flux normalization at 100TeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def renorm_phi0(phi0, E0old, E0new, gamma):\n",
    "    \"\"\"\n",
    "    Renormalizes power law flux normalization phi0 to a different base energy:\n",
    "        phi0' = phi(E0') = phi0 * (E0' / E0)^-gamma\n",
    "    \"\"\"\n",
    "    phi0 = np.atleast_1d(phi0)\n",
    "    E0old = np.atleast_1d(E0old)\n",
    "    E0new = np.atleast_1d(E0new)\n",
    "    gamma = np.atleast_1d(gamma)\n",
    "    return power_law_flux(trueE=E0new, E0=E0old, gamma=gamma, phi0=phi0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Renorm flux phi0 from 1GeV to 100TeV\n",
    "E0old = 1\n",
    "E0new = 1e5\n",
    "\n",
    "ls = [\"-\", \"-\", \"-.\", \"--\", \":\"]\n",
    "alphas = [0.5, 1, 1, 1, 1]\n",
    "\n",
    "for i, gamma in enumerate(gammas):\n",
    "    plt.plot(dt, renorm_phi0(flux_bfs[i], E0new=E0new,\n",
    "                             E0old=E0old, gamma=gamma),\n",
    "             ls=ls[i], alpha=alphas[i], color=\"#353132\",\n",
    "             label=r\"$\\gamma = {:.1f}$\".format(gamma))\n",
    "    \n",
    "# plt.plot(dt, hese_6yr_as_PS_fluence(E0new, dt), lw=1, c=\"C7\")\n",
    "    \n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xlim(dt[0], dt[-1])\n",
    "plt.ylim(2e-13, 5e-10)\n",
    "\n",
    "plt.xlabel(\"time window length in seconds\")\n",
    "# plt.ylabel(r\"Mean injected flux \" +\n",
    "#            r\"$\\left(\\frac{E}{\\mathrm{GeV}}\\right)^2\\phi$ \" +\n",
    "#            r\"in GeV$^{-1}$ cm$^{-2}$\")\n",
    "plt.ylabel(r\"$\\phi_0$ in GeV$^{-1}$ cm$^{-2}$ at 100 TeV\")\n",
    "\n",
    "plt.title(\"90% upper limits over data best fit. \" +\n",
    "          r\"$\\phi=\\phi_0 \\left(\\frac{E}{100\\ \\mathrm{TeV}}\\right)^{-\\gamma}$\")\n",
    "plt.legend(loc=\"upper left\", ncol=1, bbox_to_anchor=(1, 1))\n",
    "\n",
    "save_plot(\"limits\", \"flux.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Show power laws for each flux normalization at 1GeV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def hese_6yr_as_PS_fluence(trueE, dt):\n",
    "    \"\"\"\n",
    "    True energ in GeV. Multiplied with best fit tw. Fluence in 1/GeV/cm2.\n",
    "    Gives fluence per source, if the diffuse HESE flux originated from the\n",
    "    22 tracks alone from the largest time windows.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    trueE : array-like\n",
    "        True nu energies to evlaute the flux at.\n",
    "    dt : float\n",
    "        Tim window in seconds the flux gets integrated over.\n",
    "    \"\"\"\n",
    "    _omega = 4. * np.pi\n",
    "    _gamma = 2.92\n",
    "    _phi0 = 2.46 * 1e-18  # At 100TeV, in 1. / (s GeV cm2 sr)\n",
    "    E0 = 1e5\n",
    "    return _phi0 * (trueE / E0)**-_gamma * _omega * dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "enu = np.logspace(0, 9, 100)\n",
    "for i, gamma in enumerate(gammas):\n",
    "    plt.axhline(flux_bfs[i][0], 0, 1, ls=\":\", c=\"C{}\".format(i))\n",
    "    plt.plot(enu,\n",
    "             power_law_flux(enu, gamma=gamma, E0=E0old, phi0=flux_bfs[i][0]),\n",
    "             label=r\"$\\gamma={:.1f}$\".format(gamma), c=\"C{}\".format(i))\n",
    "# plt.plot(enu, hese_6yr_as_PS_fluence(enu), c=\"k\",\n",
    "#          label=r\"HESE 6yr. $\\phi_0=2.46,\\, \\gamma=2.92$\".format(gamma))\n",
    "plt.axhline(1e6, 0, 1, ls=\":\", c=\"k\")\n",
    "plt.axhline(1e-4, 0, 1, ls=\":\", c=\"k\")\n",
    "plt.axvline(E0new, 0, 1, ls=\"--\", c=\"k\")\n",
    "\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(1e-14, None)\n",
    "\n",
    "plt.xlabel(r\"$E_\\nu$ in GeV\")\n",
    "plt.ylabel(r\"$\\phi_0$ in GeV$^{-1}$ cm$^{-2}$ at 100 TeV\")\n",
    "\n",
    "plt.legend()\n",
    "save_plot(\"limits\", \"flux_power_laws.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Initialisation Cell",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2 (OSX)",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
